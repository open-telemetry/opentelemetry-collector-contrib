file:
file/2:
  # This will write the pipeline data to a JSON file.
  # The data is written in Protobuf JSON encoding
  # (https://developers.google.com/protocol-buffers/docs/proto3#json).
  # Note that there are no compatibility guarantees for this format, since it
  # just a dump of internal structures which can be changed over time.
  # This intended for primarily for debugging Collector without setting up backends.
  path: ./filename.json
  rotation:
    max_megabytes: 10
    max_days: 3
    max_backups: 3
    localtime: true
file/3:
  path: ./filename
  rotation:
    max_megabytes: 10
    max_days: 3
    max_backups: 3
    localtime: true
  format: proto
  compression: zstd

file/no_rotation:
  path: ./foo
file/rotation_with_default_settings:
  path: ./foo
  rotation:
file/rotation_with_custom_settings:
  path: ./foo
  rotation:
    max_megabytes: 1234

file/format_error:
  path: ./filename.log
  format: text

file/compression_error:
  path: ./filename.log
  compression: gzip

file/flush_interval_5:
  path: ./flushed
  flush_interval: 5

file/flush_interval_5s:
  path: ./flushed
  flush_interval: 5s

file/flush_interval_500ms:
  path: ./flushed
  flush_interval: 500ms

file/flush_interval_negative_value:
  path: ./flushed
  flush_interval: "-1s"

file/group_by:
  path: ./group_by/*.json
  group_by:
    enabled: true
    resource_attribute: dummy
    max_open_files: 10

file/group_by_defaults:
  path: ./group_by/*.json
  group_by:
    enabled: true

file/group_by_invalid_path:
  path: ./group_by_no_star
  group_by:
    enabled: true

file/group_by_invalid_path2:
  path: '*/./group_by'
  group_by:
    enabled: true

file/group_by_empty_resource_attribute:
  path: ./group_by/*.json
  group_by:
    enabled: true
    resource_attribute: ""
