// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/filter"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

var MetricsInfo = metricsInfo{
	NewrelicoracledbDbID: metricInfo{
		Name: "newrelicoracledb.db_id",
	},
	NewrelicoracledbDiskBlocksRead: metricInfo{
		Name: "newrelicoracledb.disk.blocks_read",
	},
	NewrelicoracledbDiskBlocksWritten: metricInfo{
		Name: "newrelicoracledb.disk.blocks_written",
	},
	NewrelicoracledbDiskReadTimeMilliseconds: metricInfo{
		Name: "newrelicoracledb.disk.read_time_milliseconds",
	},
	NewrelicoracledbDiskReads: metricInfo{
		Name: "newrelicoracledb.disk.reads",
	},
	NewrelicoracledbDiskWriteTimeMilliseconds: metricInfo{
		Name: "newrelicoracledb.disk.write_time_milliseconds",
	},
	NewrelicoracledbDiskWrites: metricInfo{
		Name: "newrelicoracledb.disk.writes",
	},
	NewrelicoracledbGlobalName: metricInfo{
		Name: "newrelicoracledb.global_name",
	},
	NewrelicoracledbLockedAccounts: metricInfo{
		Name: "newrelicoracledb.locked_accounts",
	},
	NewrelicoracledbLongRunningQueries: metricInfo{
		Name: "newrelicoracledb.long_running_queries",
	},
	NewrelicoracledbMemoryPgaAllocatedBytes: metricInfo{
		Name: "newrelicoracledb.memory.pga_allocated_bytes",
	},
	NewrelicoracledbMemoryPgaFreeableBytes: metricInfo{
		Name: "newrelicoracledb.memory.pga_freeable_bytes",
	},
	NewrelicoracledbMemoryPgaInUseBytes: metricInfo{
		Name: "newrelicoracledb.memory.pga_in_use_bytes",
	},
	NewrelicoracledbMemoryPgaMaxSizeBytes: metricInfo{
		Name: "newrelicoracledb.memory.pga_max_size_bytes",
	},
	NewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes: metricInfo{
		Name: "newrelicoracledb.memory.sga_shared_pool_library_cache_sharable_bytes",
	},
	NewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes: metricInfo{
		Name: "newrelicoracledb.memory.sga_shared_pool_library_cache_user_bytes",
	},
	NewrelicoracledbMemorySgaUgaTotalBytes: metricInfo{
		Name: "newrelicoracledb.memory.sga_uga_total_bytes",
	},
	NewrelicoracledbPdbActiveParallelSessions: metricInfo{
		Name: "newrelicoracledb.pdb.active_parallel_sessions",
	},
	NewrelicoracledbPdbActiveSerialSessions: metricInfo{
		Name: "newrelicoracledb.pdb.active_serial_sessions",
	},
	NewrelicoracledbPdbAverageActiveSessions: metricInfo{
		Name: "newrelicoracledb.pdb.average_active_sessions",
	},
	NewrelicoracledbPdbBackgroundCPUUsagePerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.background_cpu_usage_per_second",
	},
	NewrelicoracledbPdbBackgroundTimePerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.background_time_per_second",
	},
	NewrelicoracledbPdbBlockChangesPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.block_changes_per_second",
	},
	NewrelicoracledbPdbBlockChangesPerTransaction: metricInfo{
		Name: "newrelicoracledb.pdb.block_changes_per_transaction",
	},
	NewrelicoracledbPdbCPUTimeRatio: metricInfo{
		Name: "newrelicoracledb.pdb.cpu_time_ratio",
	},
	NewrelicoracledbPdbCPUUsagePerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.cpu_usage_per_second",
	},
	NewrelicoracledbPdbCPUUsagePerTransaction: metricInfo{
		Name: "newrelicoracledb.pdb.cpu_usage_per_transaction",
	},
	NewrelicoracledbPdbCurrentLogons: metricInfo{
		Name: "newrelicoracledb.pdb.current_logons",
	},
	NewrelicoracledbPdbCurrentOpenCursors: metricInfo{
		Name: "newrelicoracledb.pdb.current_open_cursors",
	},
	NewrelicoracledbPdbDbPhysicalReadBytesPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.db_physical_read_bytes_per_second",
	},
	NewrelicoracledbPdbDbPhysicalReadsPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.db_physical_reads_per_second",
	},
	NewrelicoracledbPdbDbPhysicalWriteBytesPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.db_physical_write_bytes_per_second",
	},
	NewrelicoracledbPdbDbPhysicalWritesPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.db_physical_writes_per_second",
	},
	NewrelicoracledbPdbExecuteWithoutParseRatio: metricInfo{
		Name: "newrelicoracledb.pdb.execute_without_parse_ratio",
	},
	NewrelicoracledbPdbExecutionsPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.executions_per_second",
	},
	NewrelicoracledbPdbExecutionsPerTransaction: metricInfo{
		Name: "newrelicoracledb.pdb.executions_per_transaction",
	},
	NewrelicoracledbPdbHardParseCountPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.hard_parse_count_per_second",
	},
	NewrelicoracledbPdbHardParseCountPerTransaction: metricInfo{
		Name: "newrelicoracledb.pdb.hard_parse_count_per_transaction",
	},
	NewrelicoracledbPdbLogicalReadsPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.logical_reads_per_second",
	},
	NewrelicoracledbPdbLogicalReadsPerTransaction: metricInfo{
		Name: "newrelicoracledb.pdb.logical_reads_per_transaction",
	},
	NewrelicoracledbPdbLogonsPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.logons_per_second",
	},
	NewrelicoracledbPdbLogonsPerTransaction: metricInfo{
		Name: "newrelicoracledb.pdb.logons_per_transaction",
	},
	NewrelicoracledbPdbNetworkTrafficBytePerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.network_traffic_byte_per_second",
	},
	NewrelicoracledbPdbOpenCursorsPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.open_cursors_per_second",
	},
	NewrelicoracledbPdbOpenCursorsPerTransaction: metricInfo{
		Name: "newrelicoracledb.pdb.open_cursors_per_transaction",
	},
	NewrelicoracledbPdbParseFailureCountPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.parse_failure_count_per_second",
	},
	NewrelicoracledbPdbPhysicalReadBytesPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.physical_read_bytes_per_second",
	},
	NewrelicoracledbPdbPhysicalReadsPerTransaction: metricInfo{
		Name: "newrelicoracledb.pdb.physical_reads_per_transaction",
	},
	NewrelicoracledbPdbPhysicalWriteBytesPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.physical_write_bytes_per_second",
	},
	NewrelicoracledbPdbPhysicalWritesPerTransaction: metricInfo{
		Name: "newrelicoracledb.pdb.physical_writes_per_transaction",
	},
	NewrelicoracledbPdbRedoGeneratedBytesPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.redo_generated_bytes_per_second",
	},
	NewrelicoracledbPdbRedoGeneratedBytesPerTransaction: metricInfo{
		Name: "newrelicoracledb.pdb.redo_generated_bytes_per_transaction",
	},
	NewrelicoracledbPdbResponseTimePerTransaction: metricInfo{
		Name: "newrelicoracledb.pdb.response_time_per_transaction",
	},
	NewrelicoracledbPdbSessionCount: metricInfo{
		Name: "newrelicoracledb.pdb.session_count",
	},
	NewrelicoracledbPdbSoftParseRatio: metricInfo{
		Name: "newrelicoracledb.pdb.soft_parse_ratio",
	},
	NewrelicoracledbPdbSQLServiceResponseTime: metricInfo{
		Name: "newrelicoracledb.pdb.sql_service_response_time",
	},
	NewrelicoracledbPdbTotalParseCountPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.total_parse_count_per_second",
	},
	NewrelicoracledbPdbTotalParseCountPerTransaction: metricInfo{
		Name: "newrelicoracledb.pdb.total_parse_count_per_transaction",
	},
	NewrelicoracledbPdbTransactionsPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.transactions_per_second",
	},
	NewrelicoracledbPdbUserCallsPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.user_calls_per_second",
	},
	NewrelicoracledbPdbUserCallsPerTransaction: metricInfo{
		Name: "newrelicoracledb.pdb.user_calls_per_transaction",
	},
	NewrelicoracledbPdbUserCommitsPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.user_commits_per_second",
	},
	NewrelicoracledbPdbUserCommitsPercentage: metricInfo{
		Name: "newrelicoracledb.pdb.user_commits_percentage",
	},
	NewrelicoracledbPdbUserRollbacksPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.user_rollbacks_per_second",
	},
	NewrelicoracledbPdbUserRollbacksPercentage: metricInfo{
		Name: "newrelicoracledb.pdb.user_rollbacks_percentage",
	},
	NewrelicoracledbPdbWaitTimeRatio: metricInfo{
		Name: "newrelicoracledb.pdb.wait_time_ratio",
	},
	NewrelicoracledbRedoLogParallelWriteWaits: metricInfo{
		Name: "newrelicoracledb.redo_log_parallel_write_waits",
	},
	NewrelicoracledbRedoLogSwitchArchivingNeededWaits: metricInfo{
		Name: "newrelicoracledb.redo_log_switch_archiving_needed_waits",
	},
	NewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits: metricInfo{
		Name: "newrelicoracledb.redo_log_switch_checkpoint_incomplete_waits",
	},
	NewrelicoracledbRedoLogSwitchCompletionWaits: metricInfo{
		Name: "newrelicoracledb.redo_log_switch_completion_waits",
	},
	NewrelicoracledbRollbackSegmentsGets: metricInfo{
		Name: "newrelicoracledb.rollback_segments_gets",
	},
	NewrelicoracledbRollbackSegmentsWaitRatio: metricInfo{
		Name: "newrelicoracledb.rollback_segments_wait_ratio",
	},
	NewrelicoracledbRollbackSegmentsWaits: metricInfo{
		Name: "newrelicoracledb.rollback_segments_waits",
	},
	NewrelicoracledbSessionsCount: metricInfo{
		Name: "newrelicoracledb.sessions.count",
	},
	NewrelicoracledbSgaBufferBusyWaits: metricInfo{
		Name: "newrelicoracledb.sga_buffer_busy_waits",
	},
	NewrelicoracledbSgaFixedSizeBytes: metricInfo{
		Name: "newrelicoracledb.sga_fixed_size_bytes",
	},
	NewrelicoracledbSgaFreeBufferInspectedWaits: metricInfo{
		Name: "newrelicoracledb.sga_free_buffer_inspected_waits",
	},
	NewrelicoracledbSgaFreeBufferWaits: metricInfo{
		Name: "newrelicoracledb.sga_free_buffer_waits",
	},
	NewrelicoracledbSgaHitRatio: metricInfo{
		Name: "newrelicoracledb.sga_hit_ratio",
	},
	NewrelicoracledbSgaLogAllocationRetriesRatio: metricInfo{
		Name: "newrelicoracledb.sga_log_allocation_retries_ratio",
	},
	NewrelicoracledbSgaLogBufferRedoAllocationRetries: metricInfo{
		Name: "newrelicoracledb.sga_log_buffer_redo_allocation_retries",
	},
	NewrelicoracledbSgaLogBufferRedoEntries: metricInfo{
		Name: "newrelicoracledb.sga_log_buffer_redo_entries",
	},
	NewrelicoracledbSgaLogBufferSpaceWaits: metricInfo{
		Name: "newrelicoracledb.sga_log_buffer_space_waits",
	},
	NewrelicoracledbSgaRedoBuffersBytes: metricInfo{
		Name: "newrelicoracledb.sga_redo_buffers_bytes",
	},
	NewrelicoracledbSgaSharedPoolDictCacheMissRatio: metricInfo{
		Name: "newrelicoracledb.sga_shared_pool_dict_cache_miss_ratio",
	},
	NewrelicoracledbSgaSharedPoolLibraryCacheHitRatio: metricInfo{
		Name: "newrelicoracledb.sga_shared_pool_library_cache_hit_ratio",
	},
	NewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio: metricInfo{
		Name: "newrelicoracledb.sga_shared_pool_library_cache_reload_ratio",
	},
	NewrelicoracledbSortsDisk: metricInfo{
		Name: "newrelicoracledb.sorts_disk",
	},
	NewrelicoracledbSortsMemory: metricInfo{
		Name: "newrelicoracledb.sorts_memory",
	},
	NewrelicoracledbTablespaceDbID: metricInfo{
		Name: "newrelicoracledb.tablespace.db_id",
	},
	NewrelicoracledbTablespaceGlobalName: metricInfo{
		Name: "newrelicoracledb.tablespace.global_name",
	},
	NewrelicoracledbTablespaceIsOffline: metricInfo{
		Name: "newrelicoracledb.tablespace.is_offline",
	},
	NewrelicoracledbTablespaceOfflineCdbDatafiles: metricInfo{
		Name: "newrelicoracledb.tablespace.offline_cdb_datafiles",
	},
	NewrelicoracledbTablespaceOfflinePdbDatafiles: metricInfo{
		Name: "newrelicoracledb.tablespace.offline_pdb_datafiles",
	},
	NewrelicoracledbTablespacePdbNonWriteMode: metricInfo{
		Name: "newrelicoracledb.tablespace.pdb_non_write_mode",
	},
	NewrelicoracledbTablespaceSpaceConsumedBytes: metricInfo{
		Name: "newrelicoracledb.tablespace.space_consumed_bytes",
	},
	NewrelicoracledbTablespaceSpaceReservedBytes: metricInfo{
		Name: "newrelicoracledb.tablespace.space_reserved_bytes",
	},
	NewrelicoracledbTablespaceSpaceUsedPercentage: metricInfo{
		Name: "newrelicoracledb.tablespace.space_used_percentage",
	},
}

type metricsInfo struct {
	NewrelicoracledbDbID                                         metricInfo
	NewrelicoracledbDiskBlocksRead                               metricInfo
	NewrelicoracledbDiskBlocksWritten                            metricInfo
	NewrelicoracledbDiskReadTimeMilliseconds                     metricInfo
	NewrelicoracledbDiskReads                                    metricInfo
	NewrelicoracledbDiskWriteTimeMilliseconds                    metricInfo
	NewrelicoracledbDiskWrites                                   metricInfo
	NewrelicoracledbGlobalName                                   metricInfo
	NewrelicoracledbLockedAccounts                               metricInfo
	NewrelicoracledbLongRunningQueries                           metricInfo
	NewrelicoracledbMemoryPgaAllocatedBytes                      metricInfo
	NewrelicoracledbMemoryPgaFreeableBytes                       metricInfo
	NewrelicoracledbMemoryPgaInUseBytes                          metricInfo
	NewrelicoracledbMemoryPgaMaxSizeBytes                        metricInfo
	NewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes metricInfo
	NewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes     metricInfo
	NewrelicoracledbMemorySgaUgaTotalBytes                       metricInfo
	NewrelicoracledbPdbActiveParallelSessions                    metricInfo
	NewrelicoracledbPdbActiveSerialSessions                      metricInfo
	NewrelicoracledbPdbAverageActiveSessions                     metricInfo
	NewrelicoracledbPdbBackgroundCPUUsagePerSecond               metricInfo
	NewrelicoracledbPdbBackgroundTimePerSecond                   metricInfo
	NewrelicoracledbPdbBlockChangesPerSecond                     metricInfo
	NewrelicoracledbPdbBlockChangesPerTransaction                metricInfo
	NewrelicoracledbPdbCPUTimeRatio                              metricInfo
	NewrelicoracledbPdbCPUUsagePerSecond                         metricInfo
	NewrelicoracledbPdbCPUUsagePerTransaction                    metricInfo
	NewrelicoracledbPdbCurrentLogons                             metricInfo
	NewrelicoracledbPdbCurrentOpenCursors                        metricInfo
	NewrelicoracledbPdbDbPhysicalReadBytesPerSecond              metricInfo
	NewrelicoracledbPdbDbPhysicalReadsPerSecond                  metricInfo
	NewrelicoracledbPdbDbPhysicalWriteBytesPerSecond             metricInfo
	NewrelicoracledbPdbDbPhysicalWritesPerSecond                 metricInfo
	NewrelicoracledbPdbExecuteWithoutParseRatio                  metricInfo
	NewrelicoracledbPdbExecutionsPerSecond                       metricInfo
	NewrelicoracledbPdbExecutionsPerTransaction                  metricInfo
	NewrelicoracledbPdbHardParseCountPerSecond                   metricInfo
	NewrelicoracledbPdbHardParseCountPerTransaction              metricInfo
	NewrelicoracledbPdbLogicalReadsPerSecond                     metricInfo
	NewrelicoracledbPdbLogicalReadsPerTransaction                metricInfo
	NewrelicoracledbPdbLogonsPerSecond                           metricInfo
	NewrelicoracledbPdbLogonsPerTransaction                      metricInfo
	NewrelicoracledbPdbNetworkTrafficBytePerSecond               metricInfo
	NewrelicoracledbPdbOpenCursorsPerSecond                      metricInfo
	NewrelicoracledbPdbOpenCursorsPerTransaction                 metricInfo
	NewrelicoracledbPdbParseFailureCountPerSecond                metricInfo
	NewrelicoracledbPdbPhysicalReadBytesPerSecond                metricInfo
	NewrelicoracledbPdbPhysicalReadsPerTransaction               metricInfo
	NewrelicoracledbPdbPhysicalWriteBytesPerSecond               metricInfo
	NewrelicoracledbPdbPhysicalWritesPerTransaction              metricInfo
	NewrelicoracledbPdbRedoGeneratedBytesPerSecond               metricInfo
	NewrelicoracledbPdbRedoGeneratedBytesPerTransaction          metricInfo
	NewrelicoracledbPdbResponseTimePerTransaction                metricInfo
	NewrelicoracledbPdbSessionCount                              metricInfo
	NewrelicoracledbPdbSoftParseRatio                            metricInfo
	NewrelicoracledbPdbSQLServiceResponseTime                    metricInfo
	NewrelicoracledbPdbTotalParseCountPerSecond                  metricInfo
	NewrelicoracledbPdbTotalParseCountPerTransaction             metricInfo
	NewrelicoracledbPdbTransactionsPerSecond                     metricInfo
	NewrelicoracledbPdbUserCallsPerSecond                        metricInfo
	NewrelicoracledbPdbUserCallsPerTransaction                   metricInfo
	NewrelicoracledbPdbUserCommitsPerSecond                      metricInfo
	NewrelicoracledbPdbUserCommitsPercentage                     metricInfo
	NewrelicoracledbPdbUserRollbacksPerSecond                    metricInfo
	NewrelicoracledbPdbUserRollbacksPercentage                   metricInfo
	NewrelicoracledbPdbWaitTimeRatio                             metricInfo
	NewrelicoracledbRedoLogParallelWriteWaits                    metricInfo
	NewrelicoracledbRedoLogSwitchArchivingNeededWaits            metricInfo
	NewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits       metricInfo
	NewrelicoracledbRedoLogSwitchCompletionWaits                 metricInfo
	NewrelicoracledbRollbackSegmentsGets                         metricInfo
	NewrelicoracledbRollbackSegmentsWaitRatio                    metricInfo
	NewrelicoracledbRollbackSegmentsWaits                        metricInfo
	NewrelicoracledbSessionsCount                                metricInfo
	NewrelicoracledbSgaBufferBusyWaits                           metricInfo
	NewrelicoracledbSgaFixedSizeBytes                            metricInfo
	NewrelicoracledbSgaFreeBufferInspectedWaits                  metricInfo
	NewrelicoracledbSgaFreeBufferWaits                           metricInfo
	NewrelicoracledbSgaHitRatio                                  metricInfo
	NewrelicoracledbSgaLogAllocationRetriesRatio                 metricInfo
	NewrelicoracledbSgaLogBufferRedoAllocationRetries            metricInfo
	NewrelicoracledbSgaLogBufferRedoEntries                      metricInfo
	NewrelicoracledbSgaLogBufferSpaceWaits                       metricInfo
	NewrelicoracledbSgaRedoBuffersBytes                          metricInfo
	NewrelicoracledbSgaSharedPoolDictCacheMissRatio              metricInfo
	NewrelicoracledbSgaSharedPoolLibraryCacheHitRatio            metricInfo
	NewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio         metricInfo
	NewrelicoracledbSortsDisk                                    metricInfo
	NewrelicoracledbSortsMemory                                  metricInfo
	NewrelicoracledbTablespaceDbID                               metricInfo
	NewrelicoracledbTablespaceGlobalName                         metricInfo
	NewrelicoracledbTablespaceIsOffline                          metricInfo
	NewrelicoracledbTablespaceOfflineCdbDatafiles                metricInfo
	NewrelicoracledbTablespaceOfflinePdbDatafiles                metricInfo
	NewrelicoracledbTablespacePdbNonWriteMode                    metricInfo
	NewrelicoracledbTablespaceSpaceConsumedBytes                 metricInfo
	NewrelicoracledbTablespaceSpaceReservedBytes                 metricInfo
	NewrelicoracledbTablespaceSpaceUsedPercentage                metricInfo
}

type metricInfo struct {
	Name string
}

type metricNewrelicoracledbDbID struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.db_id metric with initial data.
func (m *metricNewrelicoracledbDbID) init() {
	m.data.SetName("newrelicoracledb.db_id")
	m.data.SetDescription("Oracle database ID information")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbDbID) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string, dbIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
	dp.Attributes().PutStr("db.id", dbIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbDbID) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbDbID) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbDbID(cfg MetricConfig) metricNewrelicoracledbDbID {
	m := metricNewrelicoracledbDbID{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbDiskBlocksRead struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.disk.blocks_read metric with initial data.
func (m *metricNewrelicoracledbDiskBlocksRead) init() {
	m.data.SetName("newrelicoracledb.disk.blocks_read")
	m.data.SetDescription("Number of physical blocks read from disk")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbDiskBlocksRead) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbDiskBlocksRead) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbDiskBlocksRead) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbDiskBlocksRead(cfg MetricConfig) metricNewrelicoracledbDiskBlocksRead {
	m := metricNewrelicoracledbDiskBlocksRead{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbDiskBlocksWritten struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.disk.blocks_written metric with initial data.
func (m *metricNewrelicoracledbDiskBlocksWritten) init() {
	m.data.SetName("newrelicoracledb.disk.blocks_written")
	m.data.SetDescription("Number of physical blocks written to disk")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbDiskBlocksWritten) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbDiskBlocksWritten) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbDiskBlocksWritten) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbDiskBlocksWritten(cfg MetricConfig) metricNewrelicoracledbDiskBlocksWritten {
	m := metricNewrelicoracledbDiskBlocksWritten{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbDiskReadTimeMilliseconds struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.disk.read_time_milliseconds metric with initial data.
func (m *metricNewrelicoracledbDiskReadTimeMilliseconds) init() {
	m.data.SetName("newrelicoracledb.disk.read_time_milliseconds")
	m.data.SetDescription("Time spent reading from disk in milliseconds")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbDiskReadTimeMilliseconds) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbDiskReadTimeMilliseconds) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbDiskReadTimeMilliseconds) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbDiskReadTimeMilliseconds(cfg MetricConfig) metricNewrelicoracledbDiskReadTimeMilliseconds {
	m := metricNewrelicoracledbDiskReadTimeMilliseconds{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbDiskReads struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.disk.reads metric with initial data.
func (m *metricNewrelicoracledbDiskReads) init() {
	m.data.SetName("newrelicoracledb.disk.reads")
	m.data.SetDescription("Number of physical disk reads")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbDiskReads) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbDiskReads) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbDiskReads) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbDiskReads(cfg MetricConfig) metricNewrelicoracledbDiskReads {
	m := metricNewrelicoracledbDiskReads{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbDiskWriteTimeMilliseconds struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.disk.write_time_milliseconds metric with initial data.
func (m *metricNewrelicoracledbDiskWriteTimeMilliseconds) init() {
	m.data.SetName("newrelicoracledb.disk.write_time_milliseconds")
	m.data.SetDescription("Time spent writing to disk in milliseconds")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbDiskWriteTimeMilliseconds) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbDiskWriteTimeMilliseconds) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbDiskWriteTimeMilliseconds) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbDiskWriteTimeMilliseconds(cfg MetricConfig) metricNewrelicoracledbDiskWriteTimeMilliseconds {
	m := metricNewrelicoracledbDiskWriteTimeMilliseconds{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbDiskWrites struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.disk.writes metric with initial data.
func (m *metricNewrelicoracledbDiskWrites) init() {
	m.data.SetName("newrelicoracledb.disk.writes")
	m.data.SetDescription("Number of physical disk writes")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbDiskWrites) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbDiskWrites) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbDiskWrites) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbDiskWrites(cfg MetricConfig) metricNewrelicoracledbDiskWrites {
	m := metricNewrelicoracledbDiskWrites{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbGlobalName struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.global_name metric with initial data.
func (m *metricNewrelicoracledbGlobalName) init() {
	m.data.SetName("newrelicoracledb.global_name")
	m.data.SetDescription("Oracle database global name information")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbGlobalName) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string, globalNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
	dp.Attributes().PutStr("global.name", globalNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbGlobalName) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbGlobalName) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbGlobalName(cfg MetricConfig) metricNewrelicoracledbGlobalName {
	m := metricNewrelicoracledbGlobalName{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbLockedAccounts struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.locked_accounts metric with initial data.
func (m *metricNewrelicoracledbLockedAccounts) init() {
	m.data.SetName("newrelicoracledb.locked_accounts")
	m.data.SetDescription("Count of locked user accounts in the database")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbLockedAccounts) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbLockedAccounts) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbLockedAccounts) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbLockedAccounts(cfg MetricConfig) metricNewrelicoracledbLockedAccounts {
	m := metricNewrelicoracledbLockedAccounts{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbLongRunningQueries struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.long_running_queries metric with initial data.
func (m *metricNewrelicoracledbLongRunningQueries) init() {
	m.data.SetName("newrelicoracledb.long_running_queries")
	m.data.SetDescription("Number of long running queries (active sessions running for more than 60 seconds)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbLongRunningQueries) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbLongRunningQueries) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbLongRunningQueries) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbLongRunningQueries(cfg MetricConfig) metricNewrelicoracledbLongRunningQueries {
	m := metricNewrelicoracledbLongRunningQueries{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbMemoryPgaAllocatedBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.memory.pga_allocated_bytes metric with initial data.
func (m *metricNewrelicoracledbMemoryPgaAllocatedBytes) init() {
	m.data.SetName("newrelicoracledb.memory.pga_allocated_bytes")
	m.data.SetDescription("Total PGA memory allocated in bytes")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbMemoryPgaAllocatedBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbMemoryPgaAllocatedBytes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbMemoryPgaAllocatedBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbMemoryPgaAllocatedBytes(cfg MetricConfig) metricNewrelicoracledbMemoryPgaAllocatedBytes {
	m := metricNewrelicoracledbMemoryPgaAllocatedBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbMemoryPgaFreeableBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.memory.pga_freeable_bytes metric with initial data.
func (m *metricNewrelicoracledbMemoryPgaFreeableBytes) init() {
	m.data.SetName("newrelicoracledb.memory.pga_freeable_bytes")
	m.data.SetDescription("Total freeable PGA memory in bytes")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbMemoryPgaFreeableBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbMemoryPgaFreeableBytes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbMemoryPgaFreeableBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbMemoryPgaFreeableBytes(cfg MetricConfig) metricNewrelicoracledbMemoryPgaFreeableBytes {
	m := metricNewrelicoracledbMemoryPgaFreeableBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbMemoryPgaInUseBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.memory.pga_in_use_bytes metric with initial data.
func (m *metricNewrelicoracledbMemoryPgaInUseBytes) init() {
	m.data.SetName("newrelicoracledb.memory.pga_in_use_bytes")
	m.data.SetDescription("Total PGA memory currently in use in bytes")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbMemoryPgaInUseBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbMemoryPgaInUseBytes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbMemoryPgaInUseBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbMemoryPgaInUseBytes(cfg MetricConfig) metricNewrelicoracledbMemoryPgaInUseBytes {
	m := metricNewrelicoracledbMemoryPgaInUseBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbMemoryPgaMaxSizeBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.memory.pga_max_size_bytes metric with initial data.
func (m *metricNewrelicoracledbMemoryPgaMaxSizeBytes) init() {
	m.data.SetName("newrelicoracledb.memory.pga_max_size_bytes")
	m.data.SetDescription("Global memory bound for PGA in bytes")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbMemoryPgaMaxSizeBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbMemoryPgaMaxSizeBytes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbMemoryPgaMaxSizeBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbMemoryPgaMaxSizeBytes(cfg MetricConfig) metricNewrelicoracledbMemoryPgaMaxSizeBytes {
	m := metricNewrelicoracledbMemoryPgaMaxSizeBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.memory.sga_shared_pool_library_cache_sharable_bytes metric with initial data.
func (m *metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes) init() {
	m.data.SetName("newrelicoracledb.memory.sga_shared_pool_library_cache_sharable_bytes")
	m.data.SetDescription("SGA shared pool library cache sharable memory in bytes for statements with more than 5 executions")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes(cfg MetricConfig) metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes {
	m := metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.memory.sga_shared_pool_library_cache_user_bytes metric with initial data.
func (m *metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes) init() {
	m.data.SetName("newrelicoracledb.memory.sga_shared_pool_library_cache_user_bytes")
	m.data.SetDescription("SGA shared pool library cache shareable memory per user in bytes (250 * users_opening)")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes(cfg MetricConfig) metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes {
	m := metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbMemorySgaUgaTotalBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.memory.sga_uga_total_bytes metric with initial data.
func (m *metricNewrelicoracledbMemorySgaUgaTotalBytes) init() {
	m.data.SetName("newrelicoracledb.memory.sga_uga_total_bytes")
	m.data.SetDescription("Total SGA UGA memory in bytes (session uga memory max)")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbMemorySgaUgaTotalBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbMemorySgaUgaTotalBytes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbMemorySgaUgaTotalBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbMemorySgaUgaTotalBytes(cfg MetricConfig) metricNewrelicoracledbMemorySgaUgaTotalBytes {
	m := metricNewrelicoracledbMemorySgaUgaTotalBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbActiveParallelSessions struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.active_parallel_sessions metric with initial data.
func (m *metricNewrelicoracledbPdbActiveParallelSessions) init() {
	m.data.SetName("newrelicoracledb.pdb.active_parallel_sessions")
	m.data.SetDescription("Number of active parallel sessions in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbActiveParallelSessions) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbActiveParallelSessions) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbActiveParallelSessions) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbActiveParallelSessions(cfg MetricConfig) metricNewrelicoracledbPdbActiveParallelSessions {
	m := metricNewrelicoracledbPdbActiveParallelSessions{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbActiveSerialSessions struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.active_serial_sessions metric with initial data.
func (m *metricNewrelicoracledbPdbActiveSerialSessions) init() {
	m.data.SetName("newrelicoracledb.pdb.active_serial_sessions")
	m.data.SetDescription("Number of active serial sessions in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbActiveSerialSessions) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbActiveSerialSessions) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbActiveSerialSessions) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbActiveSerialSessions(cfg MetricConfig) metricNewrelicoracledbPdbActiveSerialSessions {
	m := metricNewrelicoracledbPdbActiveSerialSessions{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbAverageActiveSessions struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.average_active_sessions metric with initial data.
func (m *metricNewrelicoracledbPdbAverageActiveSessions) init() {
	m.data.SetName("newrelicoracledb.pdb.average_active_sessions")
	m.data.SetDescription("Average number of active sessions in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbAverageActiveSessions) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbAverageActiveSessions) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbAverageActiveSessions) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbAverageActiveSessions(cfg MetricConfig) metricNewrelicoracledbPdbAverageActiveSessions {
	m := metricNewrelicoracledbPdbAverageActiveSessions{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbBackgroundCPUUsagePerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.background_cpu_usage_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbBackgroundCPUUsagePerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.background_cpu_usage_per_second")
	m.data.SetDescription("Background CPU usage per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbBackgroundCPUUsagePerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbBackgroundCPUUsagePerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbBackgroundCPUUsagePerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbBackgroundCPUUsagePerSecond(cfg MetricConfig) metricNewrelicoracledbPdbBackgroundCPUUsagePerSecond {
	m := metricNewrelicoracledbPdbBackgroundCPUUsagePerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbBackgroundTimePerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.background_time_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbBackgroundTimePerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.background_time_per_second")
	m.data.SetDescription("Background time per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbBackgroundTimePerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbBackgroundTimePerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbBackgroundTimePerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbBackgroundTimePerSecond(cfg MetricConfig) metricNewrelicoracledbPdbBackgroundTimePerSecond {
	m := metricNewrelicoracledbPdbBackgroundTimePerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbBlockChangesPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.block_changes_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbBlockChangesPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.block_changes_per_second")
	m.data.SetDescription("DB block changes per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbBlockChangesPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbBlockChangesPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbBlockChangesPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbBlockChangesPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbBlockChangesPerSecond {
	m := metricNewrelicoracledbPdbBlockChangesPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbBlockChangesPerTransaction struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.block_changes_per_transaction metric with initial data.
func (m *metricNewrelicoracledbPdbBlockChangesPerTransaction) init() {
	m.data.SetName("newrelicoracledb.pdb.block_changes_per_transaction")
	m.data.SetDescription("DB block changes per transaction in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbBlockChangesPerTransaction) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbBlockChangesPerTransaction) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbBlockChangesPerTransaction) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbBlockChangesPerTransaction(cfg MetricConfig) metricNewrelicoracledbPdbBlockChangesPerTransaction {
	m := metricNewrelicoracledbPdbBlockChangesPerTransaction{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbCPUTimeRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.cpu_time_ratio metric with initial data.
func (m *metricNewrelicoracledbPdbCPUTimeRatio) init() {
	m.data.SetName("newrelicoracledb.pdb.cpu_time_ratio")
	m.data.SetDescription("Database CPU time ratio in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbCPUTimeRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbCPUTimeRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbCPUTimeRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbCPUTimeRatio(cfg MetricConfig) metricNewrelicoracledbPdbCPUTimeRatio {
	m := metricNewrelicoracledbPdbCPUTimeRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbCPUUsagePerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.cpu_usage_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbCPUUsagePerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.cpu_usage_per_second")
	m.data.SetDescription("CPU usage per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbCPUUsagePerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbCPUUsagePerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbCPUUsagePerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbCPUUsagePerSecond(cfg MetricConfig) metricNewrelicoracledbPdbCPUUsagePerSecond {
	m := metricNewrelicoracledbPdbCPUUsagePerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbCPUUsagePerTransaction struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.cpu_usage_per_transaction metric with initial data.
func (m *metricNewrelicoracledbPdbCPUUsagePerTransaction) init() {
	m.data.SetName("newrelicoracledb.pdb.cpu_usage_per_transaction")
	m.data.SetDescription("CPU usage per transaction in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbCPUUsagePerTransaction) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbCPUUsagePerTransaction) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbCPUUsagePerTransaction) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbCPUUsagePerTransaction(cfg MetricConfig) metricNewrelicoracledbPdbCPUUsagePerTransaction {
	m := metricNewrelicoracledbPdbCPUUsagePerTransaction{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbCurrentLogons struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.current_logons metric with initial data.
func (m *metricNewrelicoracledbPdbCurrentLogons) init() {
	m.data.SetName("newrelicoracledb.pdb.current_logons")
	m.data.SetDescription("Current number of logons in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbCurrentLogons) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbCurrentLogons) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbCurrentLogons) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbCurrentLogons(cfg MetricConfig) metricNewrelicoracledbPdbCurrentLogons {
	m := metricNewrelicoracledbPdbCurrentLogons{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbCurrentOpenCursors struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.current_open_cursors metric with initial data.
func (m *metricNewrelicoracledbPdbCurrentOpenCursors) init() {
	m.data.SetName("newrelicoracledb.pdb.current_open_cursors")
	m.data.SetDescription("Current number of open cursors in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbCurrentOpenCursors) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbCurrentOpenCursors) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbCurrentOpenCursors) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbCurrentOpenCursors(cfg MetricConfig) metricNewrelicoracledbPdbCurrentOpenCursors {
	m := metricNewrelicoracledbPdbCurrentOpenCursors{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbDbPhysicalReadBytesPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.db_physical_read_bytes_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbDbPhysicalReadBytesPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.db_physical_read_bytes_per_second")
	m.data.SetDescription("Physical read bytes per second in PDB")
	m.data.SetUnit("By/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbDbPhysicalReadBytesPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbDbPhysicalReadBytesPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbDbPhysicalReadBytesPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbDbPhysicalReadBytesPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbDbPhysicalReadBytesPerSecond {
	m := metricNewrelicoracledbPdbDbPhysicalReadBytesPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbDbPhysicalReadsPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.db_physical_reads_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbDbPhysicalReadsPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.db_physical_reads_per_second")
	m.data.SetDescription("Physical reads per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbDbPhysicalReadsPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbDbPhysicalReadsPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbDbPhysicalReadsPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbDbPhysicalReadsPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbDbPhysicalReadsPerSecond {
	m := metricNewrelicoracledbPdbDbPhysicalReadsPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbDbPhysicalWriteBytesPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.db_physical_write_bytes_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbDbPhysicalWriteBytesPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.db_physical_write_bytes_per_second")
	m.data.SetDescription("Physical write bytes per second in PDB")
	m.data.SetUnit("By/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbDbPhysicalWriteBytesPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbDbPhysicalWriteBytesPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbDbPhysicalWriteBytesPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbDbPhysicalWriteBytesPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbDbPhysicalWriteBytesPerSecond {
	m := metricNewrelicoracledbPdbDbPhysicalWriteBytesPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbDbPhysicalWritesPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.db_physical_writes_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbDbPhysicalWritesPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.db_physical_writes_per_second")
	m.data.SetDescription("Physical writes per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbDbPhysicalWritesPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbDbPhysicalWritesPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbDbPhysicalWritesPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbDbPhysicalWritesPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbDbPhysicalWritesPerSecond {
	m := metricNewrelicoracledbPdbDbPhysicalWritesPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbExecuteWithoutParseRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.execute_without_parse_ratio metric with initial data.
func (m *metricNewrelicoracledbPdbExecuteWithoutParseRatio) init() {
	m.data.SetName("newrelicoracledb.pdb.execute_without_parse_ratio")
	m.data.SetDescription("Execute without parse ratio in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbExecuteWithoutParseRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbExecuteWithoutParseRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbExecuteWithoutParseRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbExecuteWithoutParseRatio(cfg MetricConfig) metricNewrelicoracledbPdbExecuteWithoutParseRatio {
	m := metricNewrelicoracledbPdbExecuteWithoutParseRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbExecutionsPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.executions_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbExecutionsPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.executions_per_second")
	m.data.SetDescription("Executions per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbExecutionsPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbExecutionsPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbExecutionsPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbExecutionsPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbExecutionsPerSecond {
	m := metricNewrelicoracledbPdbExecutionsPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbExecutionsPerTransaction struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.executions_per_transaction metric with initial data.
func (m *metricNewrelicoracledbPdbExecutionsPerTransaction) init() {
	m.data.SetName("newrelicoracledb.pdb.executions_per_transaction")
	m.data.SetDescription("Executions per transaction in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbExecutionsPerTransaction) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbExecutionsPerTransaction) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbExecutionsPerTransaction) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbExecutionsPerTransaction(cfg MetricConfig) metricNewrelicoracledbPdbExecutionsPerTransaction {
	m := metricNewrelicoracledbPdbExecutionsPerTransaction{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbHardParseCountPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.hard_parse_count_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbHardParseCountPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.hard_parse_count_per_second")
	m.data.SetDescription("Hard parse count per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbHardParseCountPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbHardParseCountPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbHardParseCountPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbHardParseCountPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbHardParseCountPerSecond {
	m := metricNewrelicoracledbPdbHardParseCountPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbHardParseCountPerTransaction struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.hard_parse_count_per_transaction metric with initial data.
func (m *metricNewrelicoracledbPdbHardParseCountPerTransaction) init() {
	m.data.SetName("newrelicoracledb.pdb.hard_parse_count_per_transaction")
	m.data.SetDescription("Hard parse count per transaction in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbHardParseCountPerTransaction) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbHardParseCountPerTransaction) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbHardParseCountPerTransaction) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbHardParseCountPerTransaction(cfg MetricConfig) metricNewrelicoracledbPdbHardParseCountPerTransaction {
	m := metricNewrelicoracledbPdbHardParseCountPerTransaction{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbLogicalReadsPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.logical_reads_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbLogicalReadsPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.logical_reads_per_second")
	m.data.SetDescription("Logical reads per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbLogicalReadsPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbLogicalReadsPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbLogicalReadsPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbLogicalReadsPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbLogicalReadsPerSecond {
	m := metricNewrelicoracledbPdbLogicalReadsPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbLogicalReadsPerTransaction struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.logical_reads_per_transaction metric with initial data.
func (m *metricNewrelicoracledbPdbLogicalReadsPerTransaction) init() {
	m.data.SetName("newrelicoracledb.pdb.logical_reads_per_transaction")
	m.data.SetDescription("Logical reads per transaction in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbLogicalReadsPerTransaction) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbLogicalReadsPerTransaction) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbLogicalReadsPerTransaction) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbLogicalReadsPerTransaction(cfg MetricConfig) metricNewrelicoracledbPdbLogicalReadsPerTransaction {
	m := metricNewrelicoracledbPdbLogicalReadsPerTransaction{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbLogonsPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.logons_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbLogonsPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.logons_per_second")
	m.data.SetDescription("Logons per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbLogonsPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbLogonsPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbLogonsPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbLogonsPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbLogonsPerSecond {
	m := metricNewrelicoracledbPdbLogonsPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbLogonsPerTransaction struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.logons_per_transaction metric with initial data.
func (m *metricNewrelicoracledbPdbLogonsPerTransaction) init() {
	m.data.SetName("newrelicoracledb.pdb.logons_per_transaction")
	m.data.SetDescription("Logons per transaction in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbLogonsPerTransaction) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbLogonsPerTransaction) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbLogonsPerTransaction) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbLogonsPerTransaction(cfg MetricConfig) metricNewrelicoracledbPdbLogonsPerTransaction {
	m := metricNewrelicoracledbPdbLogonsPerTransaction{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbNetworkTrafficBytePerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.network_traffic_byte_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbNetworkTrafficBytePerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.network_traffic_byte_per_second")
	m.data.SetDescription("Network traffic volume per second in bytes in PDB")
	m.data.SetUnit("By/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbNetworkTrafficBytePerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbNetworkTrafficBytePerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbNetworkTrafficBytePerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbNetworkTrafficBytePerSecond(cfg MetricConfig) metricNewrelicoracledbPdbNetworkTrafficBytePerSecond {
	m := metricNewrelicoracledbPdbNetworkTrafficBytePerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbOpenCursorsPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.open_cursors_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbOpenCursorsPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.open_cursors_per_second")
	m.data.SetDescription("Open cursors per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbOpenCursorsPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbOpenCursorsPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbOpenCursorsPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbOpenCursorsPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbOpenCursorsPerSecond {
	m := metricNewrelicoracledbPdbOpenCursorsPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbOpenCursorsPerTransaction struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.open_cursors_per_transaction metric with initial data.
func (m *metricNewrelicoracledbPdbOpenCursorsPerTransaction) init() {
	m.data.SetName("newrelicoracledb.pdb.open_cursors_per_transaction")
	m.data.SetDescription("Open cursors per transaction in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbOpenCursorsPerTransaction) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbOpenCursorsPerTransaction) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbOpenCursorsPerTransaction) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbOpenCursorsPerTransaction(cfg MetricConfig) metricNewrelicoracledbPdbOpenCursorsPerTransaction {
	m := metricNewrelicoracledbPdbOpenCursorsPerTransaction{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbParseFailureCountPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.parse_failure_count_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbParseFailureCountPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.parse_failure_count_per_second")
	m.data.SetDescription("Parse failure count per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbParseFailureCountPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbParseFailureCountPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbParseFailureCountPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbParseFailureCountPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbParseFailureCountPerSecond {
	m := metricNewrelicoracledbPdbParseFailureCountPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbPhysicalReadBytesPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.physical_read_bytes_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbPhysicalReadBytesPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.physical_read_bytes_per_second")
	m.data.SetDescription("Physical read total bytes per second in PDB")
	m.data.SetUnit("By/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbPhysicalReadBytesPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbPhysicalReadBytesPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbPhysicalReadBytesPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbPhysicalReadBytesPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbPhysicalReadBytesPerSecond {
	m := metricNewrelicoracledbPdbPhysicalReadBytesPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbPhysicalReadsPerTransaction struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.physical_reads_per_transaction metric with initial data.
func (m *metricNewrelicoracledbPdbPhysicalReadsPerTransaction) init() {
	m.data.SetName("newrelicoracledb.pdb.physical_reads_per_transaction")
	m.data.SetDescription("Physical reads per transaction in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbPhysicalReadsPerTransaction) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbPhysicalReadsPerTransaction) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbPhysicalReadsPerTransaction) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbPhysicalReadsPerTransaction(cfg MetricConfig) metricNewrelicoracledbPdbPhysicalReadsPerTransaction {
	m := metricNewrelicoracledbPdbPhysicalReadsPerTransaction{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbPhysicalWriteBytesPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.physical_write_bytes_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbPhysicalWriteBytesPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.physical_write_bytes_per_second")
	m.data.SetDescription("Physical write total bytes per second in PDB")
	m.data.SetUnit("By/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbPhysicalWriteBytesPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbPhysicalWriteBytesPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbPhysicalWriteBytesPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbPhysicalWriteBytesPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbPhysicalWriteBytesPerSecond {
	m := metricNewrelicoracledbPdbPhysicalWriteBytesPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbPhysicalWritesPerTransaction struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.physical_writes_per_transaction metric with initial data.
func (m *metricNewrelicoracledbPdbPhysicalWritesPerTransaction) init() {
	m.data.SetName("newrelicoracledb.pdb.physical_writes_per_transaction")
	m.data.SetDescription("Physical writes per transaction in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbPhysicalWritesPerTransaction) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbPhysicalWritesPerTransaction) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbPhysicalWritesPerTransaction) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbPhysicalWritesPerTransaction(cfg MetricConfig) metricNewrelicoracledbPdbPhysicalWritesPerTransaction {
	m := metricNewrelicoracledbPdbPhysicalWritesPerTransaction{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbRedoGeneratedBytesPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.redo_generated_bytes_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbRedoGeneratedBytesPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.redo_generated_bytes_per_second")
	m.data.SetDescription("Redo generated per second in bytes in PDB")
	m.data.SetUnit("By/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbRedoGeneratedBytesPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbRedoGeneratedBytesPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbRedoGeneratedBytesPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbRedoGeneratedBytesPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbRedoGeneratedBytesPerSecond {
	m := metricNewrelicoracledbPdbRedoGeneratedBytesPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbRedoGeneratedBytesPerTransaction struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.redo_generated_bytes_per_transaction metric with initial data.
func (m *metricNewrelicoracledbPdbRedoGeneratedBytesPerTransaction) init() {
	m.data.SetName("newrelicoracledb.pdb.redo_generated_bytes_per_transaction")
	m.data.SetDescription("Redo generated per transaction in bytes in PDB")
	m.data.SetUnit("By/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbRedoGeneratedBytesPerTransaction) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbRedoGeneratedBytesPerTransaction) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbRedoGeneratedBytesPerTransaction) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbRedoGeneratedBytesPerTransaction(cfg MetricConfig) metricNewrelicoracledbPdbRedoGeneratedBytesPerTransaction {
	m := metricNewrelicoracledbPdbRedoGeneratedBytesPerTransaction{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbResponseTimePerTransaction struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.response_time_per_transaction metric with initial data.
func (m *metricNewrelicoracledbPdbResponseTimePerTransaction) init() {
	m.data.SetName("newrelicoracledb.pdb.response_time_per_transaction")
	m.data.SetDescription("Response time per transaction in PDB")
	m.data.SetUnit("s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbResponseTimePerTransaction) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbResponseTimePerTransaction) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbResponseTimePerTransaction) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbResponseTimePerTransaction(cfg MetricConfig) metricNewrelicoracledbPdbResponseTimePerTransaction {
	m := metricNewrelicoracledbPdbResponseTimePerTransaction{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbSessionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.session_count metric with initial data.
func (m *metricNewrelicoracledbPdbSessionCount) init() {
	m.data.SetName("newrelicoracledb.pdb.session_count")
	m.data.SetDescription("Session count in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbSessionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbSessionCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbSessionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbSessionCount(cfg MetricConfig) metricNewrelicoracledbPdbSessionCount {
	m := metricNewrelicoracledbPdbSessionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbSoftParseRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.soft_parse_ratio metric with initial data.
func (m *metricNewrelicoracledbPdbSoftParseRatio) init() {
	m.data.SetName("newrelicoracledb.pdb.soft_parse_ratio")
	m.data.SetDescription("Soft parse ratio in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbSoftParseRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbSoftParseRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbSoftParseRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbSoftParseRatio(cfg MetricConfig) metricNewrelicoracledbPdbSoftParseRatio {
	m := metricNewrelicoracledbPdbSoftParseRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbSQLServiceResponseTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.sql_service_response_time metric with initial data.
func (m *metricNewrelicoracledbPdbSQLServiceResponseTime) init() {
	m.data.SetName("newrelicoracledb.pdb.sql_service_response_time")
	m.data.SetDescription("SQL service response time in PDB")
	m.data.SetUnit("s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbSQLServiceResponseTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbSQLServiceResponseTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbSQLServiceResponseTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbSQLServiceResponseTime(cfg MetricConfig) metricNewrelicoracledbPdbSQLServiceResponseTime {
	m := metricNewrelicoracledbPdbSQLServiceResponseTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbTotalParseCountPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.total_parse_count_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbTotalParseCountPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.total_parse_count_per_second")
	m.data.SetDescription("Total parse count per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbTotalParseCountPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbTotalParseCountPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbTotalParseCountPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbTotalParseCountPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbTotalParseCountPerSecond {
	m := metricNewrelicoracledbPdbTotalParseCountPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbTotalParseCountPerTransaction struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.total_parse_count_per_transaction metric with initial data.
func (m *metricNewrelicoracledbPdbTotalParseCountPerTransaction) init() {
	m.data.SetName("newrelicoracledb.pdb.total_parse_count_per_transaction")
	m.data.SetDescription("Total parse count per transaction in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbTotalParseCountPerTransaction) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbTotalParseCountPerTransaction) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbTotalParseCountPerTransaction) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbTotalParseCountPerTransaction(cfg MetricConfig) metricNewrelicoracledbPdbTotalParseCountPerTransaction {
	m := metricNewrelicoracledbPdbTotalParseCountPerTransaction{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbTransactionsPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.transactions_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbTransactionsPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.transactions_per_second")
	m.data.SetDescription("User transactions per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbTransactionsPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbTransactionsPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbTransactionsPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbTransactionsPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbTransactionsPerSecond {
	m := metricNewrelicoracledbPdbTransactionsPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbUserCallsPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.user_calls_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbUserCallsPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.user_calls_per_second")
	m.data.SetDescription("User calls per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbUserCallsPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbUserCallsPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbUserCallsPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbUserCallsPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbUserCallsPerSecond {
	m := metricNewrelicoracledbPdbUserCallsPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbUserCallsPerTransaction struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.user_calls_per_transaction metric with initial data.
func (m *metricNewrelicoracledbPdbUserCallsPerTransaction) init() {
	m.data.SetName("newrelicoracledb.pdb.user_calls_per_transaction")
	m.data.SetDescription("User calls per transaction in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbUserCallsPerTransaction) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbUserCallsPerTransaction) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbUserCallsPerTransaction) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbUserCallsPerTransaction(cfg MetricConfig) metricNewrelicoracledbPdbUserCallsPerTransaction {
	m := metricNewrelicoracledbPdbUserCallsPerTransaction{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbUserCommitsPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.user_commits_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbUserCommitsPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.user_commits_per_second")
	m.data.SetDescription("User commits per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbUserCommitsPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbUserCommitsPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbUserCommitsPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbUserCommitsPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbUserCommitsPerSecond {
	m := metricNewrelicoracledbPdbUserCommitsPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbUserCommitsPercentage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.user_commits_percentage metric with initial data.
func (m *metricNewrelicoracledbPdbUserCommitsPercentage) init() {
	m.data.SetName("newrelicoracledb.pdb.user_commits_percentage")
	m.data.SetDescription("User commits percentage in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbUserCommitsPercentage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbUserCommitsPercentage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbUserCommitsPercentage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbUserCommitsPercentage(cfg MetricConfig) metricNewrelicoracledbPdbUserCommitsPercentage {
	m := metricNewrelicoracledbPdbUserCommitsPercentage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbUserRollbacksPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.user_rollbacks_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbUserRollbacksPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.user_rollbacks_per_second")
	m.data.SetDescription("User rollbacks per second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbUserRollbacksPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbUserRollbacksPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbUserRollbacksPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbUserRollbacksPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbUserRollbacksPerSecond {
	m := metricNewrelicoracledbPdbUserRollbacksPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbUserRollbacksPercentage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.user_rollbacks_percentage metric with initial data.
func (m *metricNewrelicoracledbPdbUserRollbacksPercentage) init() {
	m.data.SetName("newrelicoracledb.pdb.user_rollbacks_percentage")
	m.data.SetDescription("User rollbacks percentage in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbUserRollbacksPercentage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbUserRollbacksPercentage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbUserRollbacksPercentage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbUserRollbacksPercentage(cfg MetricConfig) metricNewrelicoracledbPdbUserRollbacksPercentage {
	m := metricNewrelicoracledbPdbUserRollbacksPercentage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbWaitTimeRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.wait_time_ratio metric with initial data.
func (m *metricNewrelicoracledbPdbWaitTimeRatio) init() {
	m.data.SetName("newrelicoracledb.pdb.wait_time_ratio")
	m.data.SetDescription("Database wait time ratio in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbWaitTimeRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbWaitTimeRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbWaitTimeRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbWaitTimeRatio(cfg MetricConfig) metricNewrelicoracledbPdbWaitTimeRatio {
	m := metricNewrelicoracledbPdbWaitTimeRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRedoLogParallelWriteWaits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.redo_log_parallel_write_waits metric with initial data.
func (m *metricNewrelicoracledbRedoLogParallelWriteWaits) init() {
	m.data.SetName("newrelicoracledb.redo_log_parallel_write_waits")
	m.data.SetDescription("Number of waits for log file parallel write events")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRedoLogParallelWriteWaits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRedoLogParallelWriteWaits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRedoLogParallelWriteWaits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRedoLogParallelWriteWaits(cfg MetricConfig) metricNewrelicoracledbRedoLogParallelWriteWaits {
	m := metricNewrelicoracledbRedoLogParallelWriteWaits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRedoLogSwitchArchivingNeededWaits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.redo_log_switch_archiving_needed_waits metric with initial data.
func (m *metricNewrelicoracledbRedoLogSwitchArchivingNeededWaits) init() {
	m.data.SetName("newrelicoracledb.redo_log_switch_archiving_needed_waits")
	m.data.SetDescription("Number of waits for log file switch (archiving needed) events")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRedoLogSwitchArchivingNeededWaits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRedoLogSwitchArchivingNeededWaits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRedoLogSwitchArchivingNeededWaits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRedoLogSwitchArchivingNeededWaits(cfg MetricConfig) metricNewrelicoracledbRedoLogSwitchArchivingNeededWaits {
	m := metricNewrelicoracledbRedoLogSwitchArchivingNeededWaits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.redo_log_switch_checkpoint_incomplete_waits metric with initial data.
func (m *metricNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits) init() {
	m.data.SetName("newrelicoracledb.redo_log_switch_checkpoint_incomplete_waits")
	m.data.SetDescription("Number of waits for log file switch (checkpoint incomplete) events")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits(cfg MetricConfig) metricNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits {
	m := metricNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRedoLogSwitchCompletionWaits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.redo_log_switch_completion_waits metric with initial data.
func (m *metricNewrelicoracledbRedoLogSwitchCompletionWaits) init() {
	m.data.SetName("newrelicoracledb.redo_log_switch_completion_waits")
	m.data.SetDescription("Number of waits for log file switch completion events")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRedoLogSwitchCompletionWaits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRedoLogSwitchCompletionWaits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRedoLogSwitchCompletionWaits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRedoLogSwitchCompletionWaits(cfg MetricConfig) metricNewrelicoracledbRedoLogSwitchCompletionWaits {
	m := metricNewrelicoracledbRedoLogSwitchCompletionWaits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRollbackSegmentsGets struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.rollback_segments_gets metric with initial data.
func (m *metricNewrelicoracledbRollbackSegmentsGets) init() {
	m.data.SetName("newrelicoracledb.rollback_segments_gets")
	m.data.SetDescription("Number of gets on rollback segments")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRollbackSegmentsGets) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRollbackSegmentsGets) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRollbackSegmentsGets) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRollbackSegmentsGets(cfg MetricConfig) metricNewrelicoracledbRollbackSegmentsGets {
	m := metricNewrelicoracledbRollbackSegmentsGets{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRollbackSegmentsWaitRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.rollback_segments_wait_ratio metric with initial data.
func (m *metricNewrelicoracledbRollbackSegmentsWaitRatio) init() {
	m.data.SetName("newrelicoracledb.rollback_segments_wait_ratio")
	m.data.SetDescription("Rollback segments wait ratio (waits/gets)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRollbackSegmentsWaitRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRollbackSegmentsWaitRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRollbackSegmentsWaitRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRollbackSegmentsWaitRatio(cfg MetricConfig) metricNewrelicoracledbRollbackSegmentsWaitRatio {
	m := metricNewrelicoracledbRollbackSegmentsWaitRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRollbackSegmentsWaits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.rollback_segments_waits metric with initial data.
func (m *metricNewrelicoracledbRollbackSegmentsWaits) init() {
	m.data.SetName("newrelicoracledb.rollback_segments_waits")
	m.data.SetDescription("Number of waits on rollback segments")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRollbackSegmentsWaits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRollbackSegmentsWaits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRollbackSegmentsWaits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRollbackSegmentsWaits(cfg MetricConfig) metricNewrelicoracledbRollbackSegmentsWaits {
	m := metricNewrelicoracledbRollbackSegmentsWaits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSessionsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sessions.count metric with initial data.
func (m *metricNewrelicoracledbSessionsCount) init() {
	m.data.SetName("newrelicoracledb.sessions.count")
	m.data.SetDescription("Total number of active Oracle database sessions")
	m.data.SetUnit("{sessions}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSessionsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSessionsCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSessionsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSessionsCount(cfg MetricConfig) metricNewrelicoracledbSessionsCount {
	m := metricNewrelicoracledbSessionsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaBufferBusyWaits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga_buffer_busy_waits metric with initial data.
func (m *metricNewrelicoracledbSgaBufferBusyWaits) init() {
	m.data.SetName("newrelicoracledb.sga_buffer_busy_waits")
	m.data.SetDescription("Number of buffer busy waits events")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaBufferBusyWaits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaBufferBusyWaits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaBufferBusyWaits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaBufferBusyWaits(cfg MetricConfig) metricNewrelicoracledbSgaBufferBusyWaits {
	m := metricNewrelicoracledbSgaBufferBusyWaits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaFixedSizeBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga_fixed_size_bytes metric with initial data.
func (m *metricNewrelicoracledbSgaFixedSizeBytes) init() {
	m.data.SetName("newrelicoracledb.sga_fixed_size_bytes")
	m.data.SetDescription("SGA fixed size memory in bytes")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaFixedSizeBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaFixedSizeBytes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaFixedSizeBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaFixedSizeBytes(cfg MetricConfig) metricNewrelicoracledbSgaFixedSizeBytes {
	m := metricNewrelicoracledbSgaFixedSizeBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaFreeBufferInspectedWaits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga_free_buffer_inspected_waits metric with initial data.
func (m *metricNewrelicoracledbSgaFreeBufferInspectedWaits) init() {
	m.data.SetName("newrelicoracledb.sga_free_buffer_inspected_waits")
	m.data.SetDescription("Number of free buffer inspected waits events")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaFreeBufferInspectedWaits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaFreeBufferInspectedWaits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaFreeBufferInspectedWaits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaFreeBufferInspectedWaits(cfg MetricConfig) metricNewrelicoracledbSgaFreeBufferInspectedWaits {
	m := metricNewrelicoracledbSgaFreeBufferInspectedWaits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaFreeBufferWaits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga_free_buffer_waits metric with initial data.
func (m *metricNewrelicoracledbSgaFreeBufferWaits) init() {
	m.data.SetName("newrelicoracledb.sga_free_buffer_waits")
	m.data.SetDescription("Number of free buffer waits events")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaFreeBufferWaits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaFreeBufferWaits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaFreeBufferWaits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaFreeBufferWaits(cfg MetricConfig) metricNewrelicoracledbSgaFreeBufferWaits {
	m := metricNewrelicoracledbSgaFreeBufferWaits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaHitRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga_hit_ratio metric with initial data.
func (m *metricNewrelicoracledbSgaHitRatio) init() {
	m.data.SetName("newrelicoracledb.sga_hit_ratio")
	m.data.SetDescription("SGA hit ratio (session logical reads minus physical reads / session logical reads)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaHitRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaHitRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaHitRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaHitRatio(cfg MetricConfig) metricNewrelicoracledbSgaHitRatio {
	m := metricNewrelicoracledbSgaHitRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaLogAllocationRetriesRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga_log_allocation_retries_ratio metric with initial data.
func (m *metricNewrelicoracledbSgaLogAllocationRetriesRatio) init() {
	m.data.SetName("newrelicoracledb.sga_log_allocation_retries_ratio")
	m.data.SetDescription("SGA log allocation retries ratio (redo buffer allocation retries / redo entries)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaLogAllocationRetriesRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaLogAllocationRetriesRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaLogAllocationRetriesRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaLogAllocationRetriesRatio(cfg MetricConfig) metricNewrelicoracledbSgaLogAllocationRetriesRatio {
	m := metricNewrelicoracledbSgaLogAllocationRetriesRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaLogBufferRedoAllocationRetries struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga_log_buffer_redo_allocation_retries metric with initial data.
func (m *metricNewrelicoracledbSgaLogBufferRedoAllocationRetries) init() {
	m.data.SetName("newrelicoracledb.sga_log_buffer_redo_allocation_retries")
	m.data.SetDescription("Number of redo buffer allocation retries from sysstat")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaLogBufferRedoAllocationRetries) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaLogBufferRedoAllocationRetries) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaLogBufferRedoAllocationRetries) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaLogBufferRedoAllocationRetries(cfg MetricConfig) metricNewrelicoracledbSgaLogBufferRedoAllocationRetries {
	m := metricNewrelicoracledbSgaLogBufferRedoAllocationRetries{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaLogBufferRedoEntries struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga_log_buffer_redo_entries metric with initial data.
func (m *metricNewrelicoracledbSgaLogBufferRedoEntries) init() {
	m.data.SetName("newrelicoracledb.sga_log_buffer_redo_entries")
	m.data.SetDescription("Number of redo entries from sysstat")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaLogBufferRedoEntries) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaLogBufferRedoEntries) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaLogBufferRedoEntries) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaLogBufferRedoEntries(cfg MetricConfig) metricNewrelicoracledbSgaLogBufferRedoEntries {
	m := metricNewrelicoracledbSgaLogBufferRedoEntries{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaLogBufferSpaceWaits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga_log_buffer_space_waits metric with initial data.
func (m *metricNewrelicoracledbSgaLogBufferSpaceWaits) init() {
	m.data.SetName("newrelicoracledb.sga_log_buffer_space_waits")
	m.data.SetDescription("Number of sessions waiting for log buffer space")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaLogBufferSpaceWaits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaLogBufferSpaceWaits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaLogBufferSpaceWaits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaLogBufferSpaceWaits(cfg MetricConfig) metricNewrelicoracledbSgaLogBufferSpaceWaits {
	m := metricNewrelicoracledbSgaLogBufferSpaceWaits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaRedoBuffersBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga_redo_buffers_bytes metric with initial data.
func (m *metricNewrelicoracledbSgaRedoBuffersBytes) init() {
	m.data.SetName("newrelicoracledb.sga_redo_buffers_bytes")
	m.data.SetDescription("SGA redo buffers memory in bytes")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaRedoBuffersBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaRedoBuffersBytes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaRedoBuffersBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaRedoBuffersBytes(cfg MetricConfig) metricNewrelicoracledbSgaRedoBuffersBytes {
	m := metricNewrelicoracledbSgaRedoBuffersBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaSharedPoolDictCacheMissRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga_shared_pool_dict_cache_miss_ratio metric with initial data.
func (m *metricNewrelicoracledbSgaSharedPoolDictCacheMissRatio) init() {
	m.data.SetName("newrelicoracledb.sga_shared_pool_dict_cache_miss_ratio")
	m.data.SetDescription("SGA shared pool dictionary cache miss ratio (getmisses/gets)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaSharedPoolDictCacheMissRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaSharedPoolDictCacheMissRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaSharedPoolDictCacheMissRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaSharedPoolDictCacheMissRatio(cfg MetricConfig) metricNewrelicoracledbSgaSharedPoolDictCacheMissRatio {
	m := metricNewrelicoracledbSgaSharedPoolDictCacheMissRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaSharedPoolLibraryCacheHitRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga_shared_pool_library_cache_hit_ratio metric with initial data.
func (m *metricNewrelicoracledbSgaSharedPoolLibraryCacheHitRatio) init() {
	m.data.SetName("newrelicoracledb.sga_shared_pool_library_cache_hit_ratio")
	m.data.SetDescription("SGA shared pool library cache hit ratio for SQL AREA namespace")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaSharedPoolLibraryCacheHitRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaSharedPoolLibraryCacheHitRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaSharedPoolLibraryCacheHitRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaSharedPoolLibraryCacheHitRatio(cfg MetricConfig) metricNewrelicoracledbSgaSharedPoolLibraryCacheHitRatio {
	m := metricNewrelicoracledbSgaSharedPoolLibraryCacheHitRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga_shared_pool_library_cache_reload_ratio metric with initial data.
func (m *metricNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio) init() {
	m.data.SetName("newrelicoracledb.sga_shared_pool_library_cache_reload_ratio")
	m.data.SetDescription("SGA shared pool library cache reload ratio (reloads/pins)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio(cfg MetricConfig) metricNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio {
	m := metricNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSortsDisk struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sorts_disk metric with initial data.
func (m *metricNewrelicoracledbSortsDisk) init() {
	m.data.SetName("newrelicoracledb.sorts_disk")
	m.data.SetDescription("Number of sorts performed on disk from sysstat")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSortsDisk) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSortsDisk) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSortsDisk) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSortsDisk(cfg MetricConfig) metricNewrelicoracledbSortsDisk {
	m := metricNewrelicoracledbSortsDisk{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSortsMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sorts_memory metric with initial data.
func (m *metricNewrelicoracledbSortsMemory) init() {
	m.data.SetName("newrelicoracledb.sorts_memory")
	m.data.SetDescription("Number of sorts performed in memory from sysstat")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSortsMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSortsMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSortsMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSortsMemory(cfg MetricConfig) metricNewrelicoracledbSortsMemory {
	m := metricNewrelicoracledbSortsMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceDbID struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.db_id metric with initial data.
func (m *metricNewrelicoracledbTablespaceDbID) init() {
	m.data.SetName("newrelicoracledb.tablespace.db_id")
	m.data.SetDescription("Database ID information for tablespace")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceDbID) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceDbID) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceDbID) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceDbID(cfg MetricConfig) metricNewrelicoracledbTablespaceDbID {
	m := metricNewrelicoracledbTablespaceDbID{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceGlobalName struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.global_name metric with initial data.
func (m *metricNewrelicoracledbTablespaceGlobalName) init() {
	m.data.SetName("newrelicoracledb.tablespace.global_name")
	m.data.SetDescription("Global name information for tablespace")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceGlobalName) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceGlobalName) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceGlobalName) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceGlobalName(cfg MetricConfig) metricNewrelicoracledbTablespaceGlobalName {
	m := metricNewrelicoracledbTablespaceGlobalName{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceIsOffline struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.is_offline metric with initial data.
func (m *metricNewrelicoracledbTablespaceIsOffline) init() {
	m.data.SetName("newrelicoracledb.tablespace.is_offline")
	m.data.SetDescription("Whether the tablespace is offline (1) or online (0)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceIsOffline) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceIsOffline) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceIsOffline) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceIsOffline(cfg MetricConfig) metricNewrelicoracledbTablespaceIsOffline {
	m := metricNewrelicoracledbTablespaceIsOffline{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceOfflineCdbDatafiles struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.offline_cdb_datafiles metric with initial data.
func (m *metricNewrelicoracledbTablespaceOfflineCdbDatafiles) init() {
	m.data.SetName("newrelicoracledb.tablespace.offline_cdb_datafiles")
	m.data.SetDescription("Count of offline CDB datafiles by tablespace")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceOfflineCdbDatafiles) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceOfflineCdbDatafiles) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceOfflineCdbDatafiles) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceOfflineCdbDatafiles(cfg MetricConfig) metricNewrelicoracledbTablespaceOfflineCdbDatafiles {
	m := metricNewrelicoracledbTablespaceOfflineCdbDatafiles{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceOfflinePdbDatafiles struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.offline_pdb_datafiles metric with initial data.
func (m *metricNewrelicoracledbTablespaceOfflinePdbDatafiles) init() {
	m.data.SetName("newrelicoracledb.tablespace.offline_pdb_datafiles")
	m.data.SetDescription("Count of offline PDB datafiles by tablespace")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceOfflinePdbDatafiles) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceOfflinePdbDatafiles) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceOfflinePdbDatafiles) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceOfflinePdbDatafiles(cfg MetricConfig) metricNewrelicoracledbTablespaceOfflinePdbDatafiles {
	m := metricNewrelicoracledbTablespaceOfflinePdbDatafiles{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespacePdbNonWriteMode struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.pdb_non_write_mode metric with initial data.
func (m *metricNewrelicoracledbTablespacePdbNonWriteMode) init() {
	m.data.SetName("newrelicoracledb.tablespace.pdb_non_write_mode")
	m.data.SetDescription("Count of PDB datafiles in non-write mode by tablespace")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespacePdbNonWriteMode) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespacePdbNonWriteMode) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespacePdbNonWriteMode) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespacePdbNonWriteMode(cfg MetricConfig) metricNewrelicoracledbTablespacePdbNonWriteMode {
	m := metricNewrelicoracledbTablespacePdbNonWriteMode{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceSpaceConsumedBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.space_consumed_bytes metric with initial data.
func (m *metricNewrelicoracledbTablespaceSpaceConsumedBytes) init() {
	m.data.SetName("newrelicoracledb.tablespace.space_consumed_bytes")
	m.data.SetDescription("Total bytes consumed by the tablespace")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceSpaceConsumedBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceSpaceConsumedBytes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceSpaceConsumedBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceSpaceConsumedBytes(cfg MetricConfig) metricNewrelicoracledbTablespaceSpaceConsumedBytes {
	m := metricNewrelicoracledbTablespaceSpaceConsumedBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceSpaceReservedBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.space_reserved_bytes metric with initial data.
func (m *metricNewrelicoracledbTablespaceSpaceReservedBytes) init() {
	m.data.SetName("newrelicoracledb.tablespace.space_reserved_bytes")
	m.data.SetDescription("Total bytes reserved by the tablespace")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceSpaceReservedBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceSpaceReservedBytes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceSpaceReservedBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceSpaceReservedBytes(cfg MetricConfig) metricNewrelicoracledbTablespaceSpaceReservedBytes {
	m := metricNewrelicoracledbTablespaceSpaceReservedBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceSpaceUsedPercentage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.space_used_percentage metric with initial data.
func (m *metricNewrelicoracledbTablespaceSpaceUsedPercentage) init() {
	m.data.SetName("newrelicoracledb.tablespace.space_used_percentage")
	m.data.SetDescription("Percentage of tablespace space currently used")
	m.data.SetUnit("%")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceSpaceUsedPercentage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceSpaceUsedPercentage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceSpaceUsedPercentage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceSpaceUsedPercentage(cfg MetricConfig) metricNewrelicoracledbTablespaceSpaceUsedPercentage {
	m := metricNewrelicoracledbTablespaceSpaceUsedPercentage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config                                                             MetricsBuilderConfig // config of the metrics builder.
	startTime                                                          pcommon.Timestamp    // start time that will be applied to all recorded data points.
	metricsCapacity                                                    int                  // maximum observed number of metrics per resource.
	metricsBuffer                                                      pmetric.Metrics      // accumulates metrics data before emitting.
	buildInfo                                                          component.BuildInfo  // contains version information.
	resourceAttributeIncludeFilter                                     map[string]filter.Filter
	resourceAttributeExcludeFilter                                     map[string]filter.Filter
	metricNewrelicoracledbDbID                                         metricNewrelicoracledbDbID
	metricNewrelicoracledbDiskBlocksRead                               metricNewrelicoracledbDiskBlocksRead
	metricNewrelicoracledbDiskBlocksWritten                            metricNewrelicoracledbDiskBlocksWritten
	metricNewrelicoracledbDiskReadTimeMilliseconds                     metricNewrelicoracledbDiskReadTimeMilliseconds
	metricNewrelicoracledbDiskReads                                    metricNewrelicoracledbDiskReads
	metricNewrelicoracledbDiskWriteTimeMilliseconds                    metricNewrelicoracledbDiskWriteTimeMilliseconds
	metricNewrelicoracledbDiskWrites                                   metricNewrelicoracledbDiskWrites
	metricNewrelicoracledbGlobalName                                   metricNewrelicoracledbGlobalName
	metricNewrelicoracledbLockedAccounts                               metricNewrelicoracledbLockedAccounts
	metricNewrelicoracledbLongRunningQueries                           metricNewrelicoracledbLongRunningQueries
	metricNewrelicoracledbMemoryPgaAllocatedBytes                      metricNewrelicoracledbMemoryPgaAllocatedBytes
	metricNewrelicoracledbMemoryPgaFreeableBytes                       metricNewrelicoracledbMemoryPgaFreeableBytes
	metricNewrelicoracledbMemoryPgaInUseBytes                          metricNewrelicoracledbMemoryPgaInUseBytes
	metricNewrelicoracledbMemoryPgaMaxSizeBytes                        metricNewrelicoracledbMemoryPgaMaxSizeBytes
	metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes
	metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes     metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes
	metricNewrelicoracledbMemorySgaUgaTotalBytes                       metricNewrelicoracledbMemorySgaUgaTotalBytes
	metricNewrelicoracledbPdbActiveParallelSessions                    metricNewrelicoracledbPdbActiveParallelSessions
	metricNewrelicoracledbPdbActiveSerialSessions                      metricNewrelicoracledbPdbActiveSerialSessions
	metricNewrelicoracledbPdbAverageActiveSessions                     metricNewrelicoracledbPdbAverageActiveSessions
	metricNewrelicoracledbPdbBackgroundCPUUsagePerSecond               metricNewrelicoracledbPdbBackgroundCPUUsagePerSecond
	metricNewrelicoracledbPdbBackgroundTimePerSecond                   metricNewrelicoracledbPdbBackgroundTimePerSecond
	metricNewrelicoracledbPdbBlockChangesPerSecond                     metricNewrelicoracledbPdbBlockChangesPerSecond
	metricNewrelicoracledbPdbBlockChangesPerTransaction                metricNewrelicoracledbPdbBlockChangesPerTransaction
	metricNewrelicoracledbPdbCPUTimeRatio                              metricNewrelicoracledbPdbCPUTimeRatio
	metricNewrelicoracledbPdbCPUUsagePerSecond                         metricNewrelicoracledbPdbCPUUsagePerSecond
	metricNewrelicoracledbPdbCPUUsagePerTransaction                    metricNewrelicoracledbPdbCPUUsagePerTransaction
	metricNewrelicoracledbPdbCurrentLogons                             metricNewrelicoracledbPdbCurrentLogons
	metricNewrelicoracledbPdbCurrentOpenCursors                        metricNewrelicoracledbPdbCurrentOpenCursors
	metricNewrelicoracledbPdbDbPhysicalReadBytesPerSecond              metricNewrelicoracledbPdbDbPhysicalReadBytesPerSecond
	metricNewrelicoracledbPdbDbPhysicalReadsPerSecond                  metricNewrelicoracledbPdbDbPhysicalReadsPerSecond
	metricNewrelicoracledbPdbDbPhysicalWriteBytesPerSecond             metricNewrelicoracledbPdbDbPhysicalWriteBytesPerSecond
	metricNewrelicoracledbPdbDbPhysicalWritesPerSecond                 metricNewrelicoracledbPdbDbPhysicalWritesPerSecond
	metricNewrelicoracledbPdbExecuteWithoutParseRatio                  metricNewrelicoracledbPdbExecuteWithoutParseRatio
	metricNewrelicoracledbPdbExecutionsPerSecond                       metricNewrelicoracledbPdbExecutionsPerSecond
	metricNewrelicoracledbPdbExecutionsPerTransaction                  metricNewrelicoracledbPdbExecutionsPerTransaction
	metricNewrelicoracledbPdbHardParseCountPerSecond                   metricNewrelicoracledbPdbHardParseCountPerSecond
	metricNewrelicoracledbPdbHardParseCountPerTransaction              metricNewrelicoracledbPdbHardParseCountPerTransaction
	metricNewrelicoracledbPdbLogicalReadsPerSecond                     metricNewrelicoracledbPdbLogicalReadsPerSecond
	metricNewrelicoracledbPdbLogicalReadsPerTransaction                metricNewrelicoracledbPdbLogicalReadsPerTransaction
	metricNewrelicoracledbPdbLogonsPerSecond                           metricNewrelicoracledbPdbLogonsPerSecond
	metricNewrelicoracledbPdbLogonsPerTransaction                      metricNewrelicoracledbPdbLogonsPerTransaction
	metricNewrelicoracledbPdbNetworkTrafficBytePerSecond               metricNewrelicoracledbPdbNetworkTrafficBytePerSecond
	metricNewrelicoracledbPdbOpenCursorsPerSecond                      metricNewrelicoracledbPdbOpenCursorsPerSecond
	metricNewrelicoracledbPdbOpenCursorsPerTransaction                 metricNewrelicoracledbPdbOpenCursorsPerTransaction
	metricNewrelicoracledbPdbParseFailureCountPerSecond                metricNewrelicoracledbPdbParseFailureCountPerSecond
	metricNewrelicoracledbPdbPhysicalReadBytesPerSecond                metricNewrelicoracledbPdbPhysicalReadBytesPerSecond
	metricNewrelicoracledbPdbPhysicalReadsPerTransaction               metricNewrelicoracledbPdbPhysicalReadsPerTransaction
	metricNewrelicoracledbPdbPhysicalWriteBytesPerSecond               metricNewrelicoracledbPdbPhysicalWriteBytesPerSecond
	metricNewrelicoracledbPdbPhysicalWritesPerTransaction              metricNewrelicoracledbPdbPhysicalWritesPerTransaction
	metricNewrelicoracledbPdbRedoGeneratedBytesPerSecond               metricNewrelicoracledbPdbRedoGeneratedBytesPerSecond
	metricNewrelicoracledbPdbRedoGeneratedBytesPerTransaction          metricNewrelicoracledbPdbRedoGeneratedBytesPerTransaction
	metricNewrelicoracledbPdbResponseTimePerTransaction                metricNewrelicoracledbPdbResponseTimePerTransaction
	metricNewrelicoracledbPdbSessionCount                              metricNewrelicoracledbPdbSessionCount
	metricNewrelicoracledbPdbSoftParseRatio                            metricNewrelicoracledbPdbSoftParseRatio
	metricNewrelicoracledbPdbSQLServiceResponseTime                    metricNewrelicoracledbPdbSQLServiceResponseTime
	metricNewrelicoracledbPdbTotalParseCountPerSecond                  metricNewrelicoracledbPdbTotalParseCountPerSecond
	metricNewrelicoracledbPdbTotalParseCountPerTransaction             metricNewrelicoracledbPdbTotalParseCountPerTransaction
	metricNewrelicoracledbPdbTransactionsPerSecond                     metricNewrelicoracledbPdbTransactionsPerSecond
	metricNewrelicoracledbPdbUserCallsPerSecond                        metricNewrelicoracledbPdbUserCallsPerSecond
	metricNewrelicoracledbPdbUserCallsPerTransaction                   metricNewrelicoracledbPdbUserCallsPerTransaction
	metricNewrelicoracledbPdbUserCommitsPerSecond                      metricNewrelicoracledbPdbUserCommitsPerSecond
	metricNewrelicoracledbPdbUserCommitsPercentage                     metricNewrelicoracledbPdbUserCommitsPercentage
	metricNewrelicoracledbPdbUserRollbacksPerSecond                    metricNewrelicoracledbPdbUserRollbacksPerSecond
	metricNewrelicoracledbPdbUserRollbacksPercentage                   metricNewrelicoracledbPdbUserRollbacksPercentage
	metricNewrelicoracledbPdbWaitTimeRatio                             metricNewrelicoracledbPdbWaitTimeRatio
	metricNewrelicoracledbRedoLogParallelWriteWaits                    metricNewrelicoracledbRedoLogParallelWriteWaits
	metricNewrelicoracledbRedoLogSwitchArchivingNeededWaits            metricNewrelicoracledbRedoLogSwitchArchivingNeededWaits
	metricNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits       metricNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits
	metricNewrelicoracledbRedoLogSwitchCompletionWaits                 metricNewrelicoracledbRedoLogSwitchCompletionWaits
	metricNewrelicoracledbRollbackSegmentsGets                         metricNewrelicoracledbRollbackSegmentsGets
	metricNewrelicoracledbRollbackSegmentsWaitRatio                    metricNewrelicoracledbRollbackSegmentsWaitRatio
	metricNewrelicoracledbRollbackSegmentsWaits                        metricNewrelicoracledbRollbackSegmentsWaits
	metricNewrelicoracledbSessionsCount                                metricNewrelicoracledbSessionsCount
	metricNewrelicoracledbSgaBufferBusyWaits                           metricNewrelicoracledbSgaBufferBusyWaits
	metricNewrelicoracledbSgaFixedSizeBytes                            metricNewrelicoracledbSgaFixedSizeBytes
	metricNewrelicoracledbSgaFreeBufferInspectedWaits                  metricNewrelicoracledbSgaFreeBufferInspectedWaits
	metricNewrelicoracledbSgaFreeBufferWaits                           metricNewrelicoracledbSgaFreeBufferWaits
	metricNewrelicoracledbSgaHitRatio                                  metricNewrelicoracledbSgaHitRatio
	metricNewrelicoracledbSgaLogAllocationRetriesRatio                 metricNewrelicoracledbSgaLogAllocationRetriesRatio
	metricNewrelicoracledbSgaLogBufferRedoAllocationRetries            metricNewrelicoracledbSgaLogBufferRedoAllocationRetries
	metricNewrelicoracledbSgaLogBufferRedoEntries                      metricNewrelicoracledbSgaLogBufferRedoEntries
	metricNewrelicoracledbSgaLogBufferSpaceWaits                       metricNewrelicoracledbSgaLogBufferSpaceWaits
	metricNewrelicoracledbSgaRedoBuffersBytes                          metricNewrelicoracledbSgaRedoBuffersBytes
	metricNewrelicoracledbSgaSharedPoolDictCacheMissRatio              metricNewrelicoracledbSgaSharedPoolDictCacheMissRatio
	metricNewrelicoracledbSgaSharedPoolLibraryCacheHitRatio            metricNewrelicoracledbSgaSharedPoolLibraryCacheHitRatio
	metricNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio         metricNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio
	metricNewrelicoracledbSortsDisk                                    metricNewrelicoracledbSortsDisk
	metricNewrelicoracledbSortsMemory                                  metricNewrelicoracledbSortsMemory
	metricNewrelicoracledbTablespaceDbID                               metricNewrelicoracledbTablespaceDbID
	metricNewrelicoracledbTablespaceGlobalName                         metricNewrelicoracledbTablespaceGlobalName
	metricNewrelicoracledbTablespaceIsOffline                          metricNewrelicoracledbTablespaceIsOffline
	metricNewrelicoracledbTablespaceOfflineCdbDatafiles                metricNewrelicoracledbTablespaceOfflineCdbDatafiles
	metricNewrelicoracledbTablespaceOfflinePdbDatafiles                metricNewrelicoracledbTablespaceOfflinePdbDatafiles
	metricNewrelicoracledbTablespacePdbNonWriteMode                    metricNewrelicoracledbTablespacePdbNonWriteMode
	metricNewrelicoracledbTablespaceSpaceConsumedBytes                 metricNewrelicoracledbTablespaceSpaceConsumedBytes
	metricNewrelicoracledbTablespaceSpaceReservedBytes                 metricNewrelicoracledbTablespaceSpaceReservedBytes
	metricNewrelicoracledbTablespaceSpaceUsedPercentage                metricNewrelicoracledbTablespaceSpaceUsedPercentage
}

// MetricBuilderOption applies changes to default metrics builder.
type MetricBuilderOption interface {
	apply(*MetricsBuilder)
}

type metricBuilderOptionFunc func(mb *MetricsBuilder)

func (mbof metricBuilderOptionFunc) apply(mb *MetricsBuilder) {
	mbof(mb)
}

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) MetricBuilderOption {
	return metricBuilderOptionFunc(func(mb *MetricsBuilder) {
		mb.startTime = startTime
	})
}
func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.Settings, options ...MetricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:                                  mbc,
		startTime:                               pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:                           pmetric.NewMetrics(),
		buildInfo:                               settings.BuildInfo,
		metricNewrelicoracledbDbID:              newMetricNewrelicoracledbDbID(mbc.Metrics.NewrelicoracledbDbID),
		metricNewrelicoracledbDiskBlocksRead:    newMetricNewrelicoracledbDiskBlocksRead(mbc.Metrics.NewrelicoracledbDiskBlocksRead),
		metricNewrelicoracledbDiskBlocksWritten: newMetricNewrelicoracledbDiskBlocksWritten(mbc.Metrics.NewrelicoracledbDiskBlocksWritten),
		metricNewrelicoracledbDiskReadTimeMilliseconds:                     newMetricNewrelicoracledbDiskReadTimeMilliseconds(mbc.Metrics.NewrelicoracledbDiskReadTimeMilliseconds),
		metricNewrelicoracledbDiskReads:                                    newMetricNewrelicoracledbDiskReads(mbc.Metrics.NewrelicoracledbDiskReads),
		metricNewrelicoracledbDiskWriteTimeMilliseconds:                    newMetricNewrelicoracledbDiskWriteTimeMilliseconds(mbc.Metrics.NewrelicoracledbDiskWriteTimeMilliseconds),
		metricNewrelicoracledbDiskWrites:                                   newMetricNewrelicoracledbDiskWrites(mbc.Metrics.NewrelicoracledbDiskWrites),
		metricNewrelicoracledbGlobalName:                                   newMetricNewrelicoracledbGlobalName(mbc.Metrics.NewrelicoracledbGlobalName),
		metricNewrelicoracledbLockedAccounts:                               newMetricNewrelicoracledbLockedAccounts(mbc.Metrics.NewrelicoracledbLockedAccounts),
		metricNewrelicoracledbLongRunningQueries:                           newMetricNewrelicoracledbLongRunningQueries(mbc.Metrics.NewrelicoracledbLongRunningQueries),
		metricNewrelicoracledbMemoryPgaAllocatedBytes:                      newMetricNewrelicoracledbMemoryPgaAllocatedBytes(mbc.Metrics.NewrelicoracledbMemoryPgaAllocatedBytes),
		metricNewrelicoracledbMemoryPgaFreeableBytes:                       newMetricNewrelicoracledbMemoryPgaFreeableBytes(mbc.Metrics.NewrelicoracledbMemoryPgaFreeableBytes),
		metricNewrelicoracledbMemoryPgaInUseBytes:                          newMetricNewrelicoracledbMemoryPgaInUseBytes(mbc.Metrics.NewrelicoracledbMemoryPgaInUseBytes),
		metricNewrelicoracledbMemoryPgaMaxSizeBytes:                        newMetricNewrelicoracledbMemoryPgaMaxSizeBytes(mbc.Metrics.NewrelicoracledbMemoryPgaMaxSizeBytes),
		metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes: newMetricNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes(mbc.Metrics.NewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes),
		metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes:     newMetricNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes(mbc.Metrics.NewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes),
		metricNewrelicoracledbMemorySgaUgaTotalBytes:                       newMetricNewrelicoracledbMemorySgaUgaTotalBytes(mbc.Metrics.NewrelicoracledbMemorySgaUgaTotalBytes),
		metricNewrelicoracledbPdbActiveParallelSessions:                    newMetricNewrelicoracledbPdbActiveParallelSessions(mbc.Metrics.NewrelicoracledbPdbActiveParallelSessions),
		metricNewrelicoracledbPdbActiveSerialSessions:                      newMetricNewrelicoracledbPdbActiveSerialSessions(mbc.Metrics.NewrelicoracledbPdbActiveSerialSessions),
		metricNewrelicoracledbPdbAverageActiveSessions:                     newMetricNewrelicoracledbPdbAverageActiveSessions(mbc.Metrics.NewrelicoracledbPdbAverageActiveSessions),
		metricNewrelicoracledbPdbBackgroundCPUUsagePerSecond:               newMetricNewrelicoracledbPdbBackgroundCPUUsagePerSecond(mbc.Metrics.NewrelicoracledbPdbBackgroundCPUUsagePerSecond),
		metricNewrelicoracledbPdbBackgroundTimePerSecond:                   newMetricNewrelicoracledbPdbBackgroundTimePerSecond(mbc.Metrics.NewrelicoracledbPdbBackgroundTimePerSecond),
		metricNewrelicoracledbPdbBlockChangesPerSecond:                     newMetricNewrelicoracledbPdbBlockChangesPerSecond(mbc.Metrics.NewrelicoracledbPdbBlockChangesPerSecond),
		metricNewrelicoracledbPdbBlockChangesPerTransaction:                newMetricNewrelicoracledbPdbBlockChangesPerTransaction(mbc.Metrics.NewrelicoracledbPdbBlockChangesPerTransaction),
		metricNewrelicoracledbPdbCPUTimeRatio:                              newMetricNewrelicoracledbPdbCPUTimeRatio(mbc.Metrics.NewrelicoracledbPdbCPUTimeRatio),
		metricNewrelicoracledbPdbCPUUsagePerSecond:                         newMetricNewrelicoracledbPdbCPUUsagePerSecond(mbc.Metrics.NewrelicoracledbPdbCPUUsagePerSecond),
		metricNewrelicoracledbPdbCPUUsagePerTransaction:                    newMetricNewrelicoracledbPdbCPUUsagePerTransaction(mbc.Metrics.NewrelicoracledbPdbCPUUsagePerTransaction),
		metricNewrelicoracledbPdbCurrentLogons:                             newMetricNewrelicoracledbPdbCurrentLogons(mbc.Metrics.NewrelicoracledbPdbCurrentLogons),
		metricNewrelicoracledbPdbCurrentOpenCursors:                        newMetricNewrelicoracledbPdbCurrentOpenCursors(mbc.Metrics.NewrelicoracledbPdbCurrentOpenCursors),
		metricNewrelicoracledbPdbDbPhysicalReadBytesPerSecond:              newMetricNewrelicoracledbPdbDbPhysicalReadBytesPerSecond(mbc.Metrics.NewrelicoracledbPdbDbPhysicalReadBytesPerSecond),
		metricNewrelicoracledbPdbDbPhysicalReadsPerSecond:                  newMetricNewrelicoracledbPdbDbPhysicalReadsPerSecond(mbc.Metrics.NewrelicoracledbPdbDbPhysicalReadsPerSecond),
		metricNewrelicoracledbPdbDbPhysicalWriteBytesPerSecond:             newMetricNewrelicoracledbPdbDbPhysicalWriteBytesPerSecond(mbc.Metrics.NewrelicoracledbPdbDbPhysicalWriteBytesPerSecond),
		metricNewrelicoracledbPdbDbPhysicalWritesPerSecond:                 newMetricNewrelicoracledbPdbDbPhysicalWritesPerSecond(mbc.Metrics.NewrelicoracledbPdbDbPhysicalWritesPerSecond),
		metricNewrelicoracledbPdbExecuteWithoutParseRatio:                  newMetricNewrelicoracledbPdbExecuteWithoutParseRatio(mbc.Metrics.NewrelicoracledbPdbExecuteWithoutParseRatio),
		metricNewrelicoracledbPdbExecutionsPerSecond:                       newMetricNewrelicoracledbPdbExecutionsPerSecond(mbc.Metrics.NewrelicoracledbPdbExecutionsPerSecond),
		metricNewrelicoracledbPdbExecutionsPerTransaction:                  newMetricNewrelicoracledbPdbExecutionsPerTransaction(mbc.Metrics.NewrelicoracledbPdbExecutionsPerTransaction),
		metricNewrelicoracledbPdbHardParseCountPerSecond:                   newMetricNewrelicoracledbPdbHardParseCountPerSecond(mbc.Metrics.NewrelicoracledbPdbHardParseCountPerSecond),
		metricNewrelicoracledbPdbHardParseCountPerTransaction:              newMetricNewrelicoracledbPdbHardParseCountPerTransaction(mbc.Metrics.NewrelicoracledbPdbHardParseCountPerTransaction),
		metricNewrelicoracledbPdbLogicalReadsPerSecond:                     newMetricNewrelicoracledbPdbLogicalReadsPerSecond(mbc.Metrics.NewrelicoracledbPdbLogicalReadsPerSecond),
		metricNewrelicoracledbPdbLogicalReadsPerTransaction:                newMetricNewrelicoracledbPdbLogicalReadsPerTransaction(mbc.Metrics.NewrelicoracledbPdbLogicalReadsPerTransaction),
		metricNewrelicoracledbPdbLogonsPerSecond:                           newMetricNewrelicoracledbPdbLogonsPerSecond(mbc.Metrics.NewrelicoracledbPdbLogonsPerSecond),
		metricNewrelicoracledbPdbLogonsPerTransaction:                      newMetricNewrelicoracledbPdbLogonsPerTransaction(mbc.Metrics.NewrelicoracledbPdbLogonsPerTransaction),
		metricNewrelicoracledbPdbNetworkTrafficBytePerSecond:               newMetricNewrelicoracledbPdbNetworkTrafficBytePerSecond(mbc.Metrics.NewrelicoracledbPdbNetworkTrafficBytePerSecond),
		metricNewrelicoracledbPdbOpenCursorsPerSecond:                      newMetricNewrelicoracledbPdbOpenCursorsPerSecond(mbc.Metrics.NewrelicoracledbPdbOpenCursorsPerSecond),
		metricNewrelicoracledbPdbOpenCursorsPerTransaction:                 newMetricNewrelicoracledbPdbOpenCursorsPerTransaction(mbc.Metrics.NewrelicoracledbPdbOpenCursorsPerTransaction),
		metricNewrelicoracledbPdbParseFailureCountPerSecond:                newMetricNewrelicoracledbPdbParseFailureCountPerSecond(mbc.Metrics.NewrelicoracledbPdbParseFailureCountPerSecond),
		metricNewrelicoracledbPdbPhysicalReadBytesPerSecond:                newMetricNewrelicoracledbPdbPhysicalReadBytesPerSecond(mbc.Metrics.NewrelicoracledbPdbPhysicalReadBytesPerSecond),
		metricNewrelicoracledbPdbPhysicalReadsPerTransaction:               newMetricNewrelicoracledbPdbPhysicalReadsPerTransaction(mbc.Metrics.NewrelicoracledbPdbPhysicalReadsPerTransaction),
		metricNewrelicoracledbPdbPhysicalWriteBytesPerSecond:               newMetricNewrelicoracledbPdbPhysicalWriteBytesPerSecond(mbc.Metrics.NewrelicoracledbPdbPhysicalWriteBytesPerSecond),
		metricNewrelicoracledbPdbPhysicalWritesPerTransaction:              newMetricNewrelicoracledbPdbPhysicalWritesPerTransaction(mbc.Metrics.NewrelicoracledbPdbPhysicalWritesPerTransaction),
		metricNewrelicoracledbPdbRedoGeneratedBytesPerSecond:               newMetricNewrelicoracledbPdbRedoGeneratedBytesPerSecond(mbc.Metrics.NewrelicoracledbPdbRedoGeneratedBytesPerSecond),
		metricNewrelicoracledbPdbRedoGeneratedBytesPerTransaction:          newMetricNewrelicoracledbPdbRedoGeneratedBytesPerTransaction(mbc.Metrics.NewrelicoracledbPdbRedoGeneratedBytesPerTransaction),
		metricNewrelicoracledbPdbResponseTimePerTransaction:                newMetricNewrelicoracledbPdbResponseTimePerTransaction(mbc.Metrics.NewrelicoracledbPdbResponseTimePerTransaction),
		metricNewrelicoracledbPdbSessionCount:                              newMetricNewrelicoracledbPdbSessionCount(mbc.Metrics.NewrelicoracledbPdbSessionCount),
		metricNewrelicoracledbPdbSoftParseRatio:                            newMetricNewrelicoracledbPdbSoftParseRatio(mbc.Metrics.NewrelicoracledbPdbSoftParseRatio),
		metricNewrelicoracledbPdbSQLServiceResponseTime:                    newMetricNewrelicoracledbPdbSQLServiceResponseTime(mbc.Metrics.NewrelicoracledbPdbSQLServiceResponseTime),
		metricNewrelicoracledbPdbTotalParseCountPerSecond:                  newMetricNewrelicoracledbPdbTotalParseCountPerSecond(mbc.Metrics.NewrelicoracledbPdbTotalParseCountPerSecond),
		metricNewrelicoracledbPdbTotalParseCountPerTransaction:             newMetricNewrelicoracledbPdbTotalParseCountPerTransaction(mbc.Metrics.NewrelicoracledbPdbTotalParseCountPerTransaction),
		metricNewrelicoracledbPdbTransactionsPerSecond:                     newMetricNewrelicoracledbPdbTransactionsPerSecond(mbc.Metrics.NewrelicoracledbPdbTransactionsPerSecond),
		metricNewrelicoracledbPdbUserCallsPerSecond:                        newMetricNewrelicoracledbPdbUserCallsPerSecond(mbc.Metrics.NewrelicoracledbPdbUserCallsPerSecond),
		metricNewrelicoracledbPdbUserCallsPerTransaction:                   newMetricNewrelicoracledbPdbUserCallsPerTransaction(mbc.Metrics.NewrelicoracledbPdbUserCallsPerTransaction),
		metricNewrelicoracledbPdbUserCommitsPerSecond:                      newMetricNewrelicoracledbPdbUserCommitsPerSecond(mbc.Metrics.NewrelicoracledbPdbUserCommitsPerSecond),
		metricNewrelicoracledbPdbUserCommitsPercentage:                     newMetricNewrelicoracledbPdbUserCommitsPercentage(mbc.Metrics.NewrelicoracledbPdbUserCommitsPercentage),
		metricNewrelicoracledbPdbUserRollbacksPerSecond:                    newMetricNewrelicoracledbPdbUserRollbacksPerSecond(mbc.Metrics.NewrelicoracledbPdbUserRollbacksPerSecond),
		metricNewrelicoracledbPdbUserRollbacksPercentage:                   newMetricNewrelicoracledbPdbUserRollbacksPercentage(mbc.Metrics.NewrelicoracledbPdbUserRollbacksPercentage),
		metricNewrelicoracledbPdbWaitTimeRatio:                             newMetricNewrelicoracledbPdbWaitTimeRatio(mbc.Metrics.NewrelicoracledbPdbWaitTimeRatio),
		metricNewrelicoracledbRedoLogParallelWriteWaits:                    newMetricNewrelicoracledbRedoLogParallelWriteWaits(mbc.Metrics.NewrelicoracledbRedoLogParallelWriteWaits),
		metricNewrelicoracledbRedoLogSwitchArchivingNeededWaits:            newMetricNewrelicoracledbRedoLogSwitchArchivingNeededWaits(mbc.Metrics.NewrelicoracledbRedoLogSwitchArchivingNeededWaits),
		metricNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits:       newMetricNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits(mbc.Metrics.NewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits),
		metricNewrelicoracledbRedoLogSwitchCompletionWaits:                 newMetricNewrelicoracledbRedoLogSwitchCompletionWaits(mbc.Metrics.NewrelicoracledbRedoLogSwitchCompletionWaits),
		metricNewrelicoracledbRollbackSegmentsGets:                         newMetricNewrelicoracledbRollbackSegmentsGets(mbc.Metrics.NewrelicoracledbRollbackSegmentsGets),
		metricNewrelicoracledbRollbackSegmentsWaitRatio:                    newMetricNewrelicoracledbRollbackSegmentsWaitRatio(mbc.Metrics.NewrelicoracledbRollbackSegmentsWaitRatio),
		metricNewrelicoracledbRollbackSegmentsWaits:                        newMetricNewrelicoracledbRollbackSegmentsWaits(mbc.Metrics.NewrelicoracledbRollbackSegmentsWaits),
		metricNewrelicoracledbSessionsCount:                                newMetricNewrelicoracledbSessionsCount(mbc.Metrics.NewrelicoracledbSessionsCount),
		metricNewrelicoracledbSgaBufferBusyWaits:                           newMetricNewrelicoracledbSgaBufferBusyWaits(mbc.Metrics.NewrelicoracledbSgaBufferBusyWaits),
		metricNewrelicoracledbSgaFixedSizeBytes:                            newMetricNewrelicoracledbSgaFixedSizeBytes(mbc.Metrics.NewrelicoracledbSgaFixedSizeBytes),
		metricNewrelicoracledbSgaFreeBufferInspectedWaits:                  newMetricNewrelicoracledbSgaFreeBufferInspectedWaits(mbc.Metrics.NewrelicoracledbSgaFreeBufferInspectedWaits),
		metricNewrelicoracledbSgaFreeBufferWaits:                           newMetricNewrelicoracledbSgaFreeBufferWaits(mbc.Metrics.NewrelicoracledbSgaFreeBufferWaits),
		metricNewrelicoracledbSgaHitRatio:                                  newMetricNewrelicoracledbSgaHitRatio(mbc.Metrics.NewrelicoracledbSgaHitRatio),
		metricNewrelicoracledbSgaLogAllocationRetriesRatio:                 newMetricNewrelicoracledbSgaLogAllocationRetriesRatio(mbc.Metrics.NewrelicoracledbSgaLogAllocationRetriesRatio),
		metricNewrelicoracledbSgaLogBufferRedoAllocationRetries:            newMetricNewrelicoracledbSgaLogBufferRedoAllocationRetries(mbc.Metrics.NewrelicoracledbSgaLogBufferRedoAllocationRetries),
		metricNewrelicoracledbSgaLogBufferRedoEntries:                      newMetricNewrelicoracledbSgaLogBufferRedoEntries(mbc.Metrics.NewrelicoracledbSgaLogBufferRedoEntries),
		metricNewrelicoracledbSgaLogBufferSpaceWaits:                       newMetricNewrelicoracledbSgaLogBufferSpaceWaits(mbc.Metrics.NewrelicoracledbSgaLogBufferSpaceWaits),
		metricNewrelicoracledbSgaRedoBuffersBytes:                          newMetricNewrelicoracledbSgaRedoBuffersBytes(mbc.Metrics.NewrelicoracledbSgaRedoBuffersBytes),
		metricNewrelicoracledbSgaSharedPoolDictCacheMissRatio:              newMetricNewrelicoracledbSgaSharedPoolDictCacheMissRatio(mbc.Metrics.NewrelicoracledbSgaSharedPoolDictCacheMissRatio),
		metricNewrelicoracledbSgaSharedPoolLibraryCacheHitRatio:            newMetricNewrelicoracledbSgaSharedPoolLibraryCacheHitRatio(mbc.Metrics.NewrelicoracledbSgaSharedPoolLibraryCacheHitRatio),
		metricNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio:         newMetricNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio(mbc.Metrics.NewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio),
		metricNewrelicoracledbSortsDisk:                                    newMetricNewrelicoracledbSortsDisk(mbc.Metrics.NewrelicoracledbSortsDisk),
		metricNewrelicoracledbSortsMemory:                                  newMetricNewrelicoracledbSortsMemory(mbc.Metrics.NewrelicoracledbSortsMemory),
		metricNewrelicoracledbTablespaceDbID:                               newMetricNewrelicoracledbTablespaceDbID(mbc.Metrics.NewrelicoracledbTablespaceDbID),
		metricNewrelicoracledbTablespaceGlobalName:                         newMetricNewrelicoracledbTablespaceGlobalName(mbc.Metrics.NewrelicoracledbTablespaceGlobalName),
		metricNewrelicoracledbTablespaceIsOffline:                          newMetricNewrelicoracledbTablespaceIsOffline(mbc.Metrics.NewrelicoracledbTablespaceIsOffline),
		metricNewrelicoracledbTablespaceOfflineCdbDatafiles:                newMetricNewrelicoracledbTablespaceOfflineCdbDatafiles(mbc.Metrics.NewrelicoracledbTablespaceOfflineCdbDatafiles),
		metricNewrelicoracledbTablespaceOfflinePdbDatafiles:                newMetricNewrelicoracledbTablespaceOfflinePdbDatafiles(mbc.Metrics.NewrelicoracledbTablespaceOfflinePdbDatafiles),
		metricNewrelicoracledbTablespacePdbNonWriteMode:                    newMetricNewrelicoracledbTablespacePdbNonWriteMode(mbc.Metrics.NewrelicoracledbTablespacePdbNonWriteMode),
		metricNewrelicoracledbTablespaceSpaceConsumedBytes:                 newMetricNewrelicoracledbTablespaceSpaceConsumedBytes(mbc.Metrics.NewrelicoracledbTablespaceSpaceConsumedBytes),
		metricNewrelicoracledbTablespaceSpaceReservedBytes:                 newMetricNewrelicoracledbTablespaceSpaceReservedBytes(mbc.Metrics.NewrelicoracledbTablespaceSpaceReservedBytes),
		metricNewrelicoracledbTablespaceSpaceUsedPercentage:                newMetricNewrelicoracledbTablespaceSpaceUsedPercentage(mbc.Metrics.NewrelicoracledbTablespaceSpaceUsedPercentage),
		resourceAttributeIncludeFilter:                                     make(map[string]filter.Filter),
		resourceAttributeExcludeFilter:                                     make(map[string]filter.Filter),
	}
	if mbc.ResourceAttributes.HostName.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["host.name"] = filter.CreateFilter(mbc.ResourceAttributes.HostName.MetricsInclude)
	}
	if mbc.ResourceAttributes.HostName.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["host.name"] = filter.CreateFilter(mbc.ResourceAttributes.HostName.MetricsExclude)
	}
	if mbc.ResourceAttributes.NewrelicoracledbInstanceName.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["newrelicoracledb.instance.name"] = filter.CreateFilter(mbc.ResourceAttributes.NewrelicoracledbInstanceName.MetricsInclude)
	}
	if mbc.ResourceAttributes.NewrelicoracledbInstanceName.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["newrelicoracledb.instance.name"] = filter.CreateFilter(mbc.ResourceAttributes.NewrelicoracledbInstanceName.MetricsExclude)
	}

	for _, op := range options {
		op.apply(mb)
	}
	return mb
}

// NewResourceBuilder returns a new resource builder that should be used to build a resource associated with for the emitted metrics.
func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	return NewResourceBuilder(mb.config.ResourceAttributes)
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption interface {
	apply(pmetric.ResourceMetrics)
}

type resourceMetricsOptionFunc func(pmetric.ResourceMetrics)

func (rmof resourceMetricsOptionFunc) apply(rm pmetric.ResourceMetrics) {
	rmof(rm)
}

// WithResource sets the provided resource on the emitted ResourceMetrics.
// It's recommended to use ResourceBuilder to create the resource.
func WithResource(res pcommon.Resource) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		res.CopyTo(rm.Resource())
	})
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	})
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(options ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName(ScopeName)
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricNewrelicoracledbDbID.emit(ils.Metrics())
	mb.metricNewrelicoracledbDiskBlocksRead.emit(ils.Metrics())
	mb.metricNewrelicoracledbDiskBlocksWritten.emit(ils.Metrics())
	mb.metricNewrelicoracledbDiskReadTimeMilliseconds.emit(ils.Metrics())
	mb.metricNewrelicoracledbDiskReads.emit(ils.Metrics())
	mb.metricNewrelicoracledbDiskWriteTimeMilliseconds.emit(ils.Metrics())
	mb.metricNewrelicoracledbDiskWrites.emit(ils.Metrics())
	mb.metricNewrelicoracledbGlobalName.emit(ils.Metrics())
	mb.metricNewrelicoracledbLockedAccounts.emit(ils.Metrics())
	mb.metricNewrelicoracledbLongRunningQueries.emit(ils.Metrics())
	mb.metricNewrelicoracledbMemoryPgaAllocatedBytes.emit(ils.Metrics())
	mb.metricNewrelicoracledbMemoryPgaFreeableBytes.emit(ils.Metrics())
	mb.metricNewrelicoracledbMemoryPgaInUseBytes.emit(ils.Metrics())
	mb.metricNewrelicoracledbMemoryPgaMaxSizeBytes.emit(ils.Metrics())
	mb.metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes.emit(ils.Metrics())
	mb.metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes.emit(ils.Metrics())
	mb.metricNewrelicoracledbMemorySgaUgaTotalBytes.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbActiveParallelSessions.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbActiveSerialSessions.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbAverageActiveSessions.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbBackgroundCPUUsagePerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbBackgroundTimePerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbBlockChangesPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbBlockChangesPerTransaction.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbCPUTimeRatio.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbCPUUsagePerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbCPUUsagePerTransaction.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbCurrentLogons.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbCurrentOpenCursors.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbDbPhysicalReadBytesPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbDbPhysicalReadsPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbDbPhysicalWriteBytesPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbDbPhysicalWritesPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbExecuteWithoutParseRatio.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbExecutionsPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbExecutionsPerTransaction.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbHardParseCountPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbHardParseCountPerTransaction.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbLogicalReadsPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbLogicalReadsPerTransaction.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbLogonsPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbLogonsPerTransaction.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbNetworkTrafficBytePerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbOpenCursorsPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbOpenCursorsPerTransaction.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbParseFailureCountPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbPhysicalReadBytesPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbPhysicalReadsPerTransaction.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbPhysicalWriteBytesPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbPhysicalWritesPerTransaction.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbRedoGeneratedBytesPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbRedoGeneratedBytesPerTransaction.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbResponseTimePerTransaction.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbSessionCount.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbSoftParseRatio.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbSQLServiceResponseTime.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbTotalParseCountPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbTotalParseCountPerTransaction.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbTransactionsPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbUserCallsPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbUserCallsPerTransaction.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbUserCommitsPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbUserCommitsPercentage.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbUserRollbacksPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbUserRollbacksPercentage.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbWaitTimeRatio.emit(ils.Metrics())
	mb.metricNewrelicoracledbRedoLogParallelWriteWaits.emit(ils.Metrics())
	mb.metricNewrelicoracledbRedoLogSwitchArchivingNeededWaits.emit(ils.Metrics())
	mb.metricNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits.emit(ils.Metrics())
	mb.metricNewrelicoracledbRedoLogSwitchCompletionWaits.emit(ils.Metrics())
	mb.metricNewrelicoracledbRollbackSegmentsGets.emit(ils.Metrics())
	mb.metricNewrelicoracledbRollbackSegmentsWaitRatio.emit(ils.Metrics())
	mb.metricNewrelicoracledbRollbackSegmentsWaits.emit(ils.Metrics())
	mb.metricNewrelicoracledbSessionsCount.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaBufferBusyWaits.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaFixedSizeBytes.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaFreeBufferInspectedWaits.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaFreeBufferWaits.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaHitRatio.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaLogAllocationRetriesRatio.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaLogBufferRedoAllocationRetries.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaLogBufferRedoEntries.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaLogBufferSpaceWaits.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaRedoBuffersBytes.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaSharedPoolDictCacheMissRatio.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaSharedPoolLibraryCacheHitRatio.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio.emit(ils.Metrics())
	mb.metricNewrelicoracledbSortsDisk.emit(ils.Metrics())
	mb.metricNewrelicoracledbSortsMemory.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceDbID.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceGlobalName.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceIsOffline.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceOfflineCdbDatafiles.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceOfflinePdbDatafiles.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespacePdbNonWriteMode.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceSpaceConsumedBytes.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceSpaceReservedBytes.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceSpaceUsedPercentage.emit(ils.Metrics())

	for _, op := range options {
		op.apply(rm)
	}
	for attr, filter := range mb.resourceAttributeIncludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && !filter.Matches(val.AsString()) {
			return
		}
	}
	for attr, filter := range mb.resourceAttributeExcludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && filter.Matches(val.AsString()) {
			return
		}
	}

	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(options ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(options...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordNewrelicoracledbDbIDDataPoint adds a data point to newrelicoracledb.db_id metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbDbIDDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string, dbIDAttributeValue string) {
	mb.metricNewrelicoracledbDbID.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue, dbIDAttributeValue)
}

// RecordNewrelicoracledbDiskBlocksReadDataPoint adds a data point to newrelicoracledb.disk.blocks_read metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbDiskBlocksReadDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbDiskBlocksRead.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbDiskBlocksWrittenDataPoint adds a data point to newrelicoracledb.disk.blocks_written metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbDiskBlocksWrittenDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbDiskBlocksWritten.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbDiskReadTimeMillisecondsDataPoint adds a data point to newrelicoracledb.disk.read_time_milliseconds metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbDiskReadTimeMillisecondsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbDiskReadTimeMilliseconds.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbDiskReadsDataPoint adds a data point to newrelicoracledb.disk.reads metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbDiskReadsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbDiskReads.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbDiskWriteTimeMillisecondsDataPoint adds a data point to newrelicoracledb.disk.write_time_milliseconds metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbDiskWriteTimeMillisecondsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbDiskWriteTimeMilliseconds.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbDiskWritesDataPoint adds a data point to newrelicoracledb.disk.writes metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbDiskWritesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbDiskWrites.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbGlobalNameDataPoint adds a data point to newrelicoracledb.global_name metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbGlobalNameDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string, globalNameAttributeValue string) {
	mb.metricNewrelicoracledbGlobalName.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue, globalNameAttributeValue)
}

// RecordNewrelicoracledbLockedAccountsDataPoint adds a data point to newrelicoracledb.locked_accounts metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbLockedAccountsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbLockedAccounts.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbLongRunningQueriesDataPoint adds a data point to newrelicoracledb.long_running_queries metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbLongRunningQueriesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbLongRunningQueries.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbMemoryPgaAllocatedBytesDataPoint adds a data point to newrelicoracledb.memory.pga_allocated_bytes metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbMemoryPgaAllocatedBytesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbMemoryPgaAllocatedBytes.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbMemoryPgaFreeableBytesDataPoint adds a data point to newrelicoracledb.memory.pga_freeable_bytes metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbMemoryPgaFreeableBytesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbMemoryPgaFreeableBytes.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbMemoryPgaInUseBytesDataPoint adds a data point to newrelicoracledb.memory.pga_in_use_bytes metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbMemoryPgaInUseBytesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbMemoryPgaInUseBytes.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbMemoryPgaMaxSizeBytesDataPoint adds a data point to newrelicoracledb.memory.pga_max_size_bytes metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbMemoryPgaMaxSizeBytesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbMemoryPgaMaxSizeBytes.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytesDataPoint adds a data point to newrelicoracledb.memory.sga_shared_pool_library_cache_sharable_bytes metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheSharableBytes.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytesDataPoint adds a data point to newrelicoracledb.memory.sga_shared_pool_library_cache_user_bytes metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbMemorySgaSharedPoolLibraryCacheUserBytes.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbMemorySgaUgaTotalBytesDataPoint adds a data point to newrelicoracledb.memory.sga_uga_total_bytes metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbMemorySgaUgaTotalBytesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbMemorySgaUgaTotalBytes.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbActiveParallelSessionsDataPoint adds a data point to newrelicoracledb.pdb.active_parallel_sessions metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbActiveParallelSessionsDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbActiveParallelSessions.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbActiveSerialSessionsDataPoint adds a data point to newrelicoracledb.pdb.active_serial_sessions metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbActiveSerialSessionsDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbActiveSerialSessions.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbAverageActiveSessionsDataPoint adds a data point to newrelicoracledb.pdb.average_active_sessions metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbAverageActiveSessionsDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbAverageActiveSessions.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbBackgroundCPUUsagePerSecondDataPoint adds a data point to newrelicoracledb.pdb.background_cpu_usage_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbBackgroundCPUUsagePerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbBackgroundCPUUsagePerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbBackgroundTimePerSecondDataPoint adds a data point to newrelicoracledb.pdb.background_time_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbBackgroundTimePerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbBackgroundTimePerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbBlockChangesPerSecondDataPoint adds a data point to newrelicoracledb.pdb.block_changes_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbBlockChangesPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbBlockChangesPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbBlockChangesPerTransactionDataPoint adds a data point to newrelicoracledb.pdb.block_changes_per_transaction metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbBlockChangesPerTransactionDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbBlockChangesPerTransaction.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbCPUTimeRatioDataPoint adds a data point to newrelicoracledb.pdb.cpu_time_ratio metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbCPUTimeRatioDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbCPUTimeRatio.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbCPUUsagePerSecondDataPoint adds a data point to newrelicoracledb.pdb.cpu_usage_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbCPUUsagePerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbCPUUsagePerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbCPUUsagePerTransactionDataPoint adds a data point to newrelicoracledb.pdb.cpu_usage_per_transaction metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbCPUUsagePerTransactionDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbCPUUsagePerTransaction.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbCurrentLogonsDataPoint adds a data point to newrelicoracledb.pdb.current_logons metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbCurrentLogonsDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbCurrentLogons.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbCurrentOpenCursorsDataPoint adds a data point to newrelicoracledb.pdb.current_open_cursors metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbCurrentOpenCursorsDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbCurrentOpenCursors.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbDbPhysicalReadBytesPerSecondDataPoint adds a data point to newrelicoracledb.pdb.db_physical_read_bytes_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbDbPhysicalReadBytesPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbDbPhysicalReadBytesPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbDbPhysicalReadsPerSecondDataPoint adds a data point to newrelicoracledb.pdb.db_physical_reads_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbDbPhysicalReadsPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbDbPhysicalReadsPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbDbPhysicalWriteBytesPerSecondDataPoint adds a data point to newrelicoracledb.pdb.db_physical_write_bytes_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbDbPhysicalWriteBytesPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbDbPhysicalWriteBytesPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbDbPhysicalWritesPerSecondDataPoint adds a data point to newrelicoracledb.pdb.db_physical_writes_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbDbPhysicalWritesPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbDbPhysicalWritesPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbExecuteWithoutParseRatioDataPoint adds a data point to newrelicoracledb.pdb.execute_without_parse_ratio metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbExecuteWithoutParseRatioDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbExecuteWithoutParseRatio.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbExecutionsPerSecondDataPoint adds a data point to newrelicoracledb.pdb.executions_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbExecutionsPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbExecutionsPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbExecutionsPerTransactionDataPoint adds a data point to newrelicoracledb.pdb.executions_per_transaction metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbExecutionsPerTransactionDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbExecutionsPerTransaction.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbHardParseCountPerSecondDataPoint adds a data point to newrelicoracledb.pdb.hard_parse_count_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbHardParseCountPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbHardParseCountPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbHardParseCountPerTransactionDataPoint adds a data point to newrelicoracledb.pdb.hard_parse_count_per_transaction metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbHardParseCountPerTransactionDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbHardParseCountPerTransaction.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbLogicalReadsPerSecondDataPoint adds a data point to newrelicoracledb.pdb.logical_reads_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbLogicalReadsPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbLogicalReadsPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbLogicalReadsPerTransactionDataPoint adds a data point to newrelicoracledb.pdb.logical_reads_per_transaction metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbLogicalReadsPerTransactionDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbLogicalReadsPerTransaction.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbLogonsPerSecondDataPoint adds a data point to newrelicoracledb.pdb.logons_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbLogonsPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbLogonsPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbLogonsPerTransactionDataPoint adds a data point to newrelicoracledb.pdb.logons_per_transaction metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbLogonsPerTransactionDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbLogonsPerTransaction.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbNetworkTrafficBytePerSecondDataPoint adds a data point to newrelicoracledb.pdb.network_traffic_byte_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbNetworkTrafficBytePerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbNetworkTrafficBytePerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbOpenCursorsPerSecondDataPoint adds a data point to newrelicoracledb.pdb.open_cursors_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbOpenCursorsPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbOpenCursorsPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbOpenCursorsPerTransactionDataPoint adds a data point to newrelicoracledb.pdb.open_cursors_per_transaction metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbOpenCursorsPerTransactionDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbOpenCursorsPerTransaction.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbParseFailureCountPerSecondDataPoint adds a data point to newrelicoracledb.pdb.parse_failure_count_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbParseFailureCountPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbParseFailureCountPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbPhysicalReadBytesPerSecondDataPoint adds a data point to newrelicoracledb.pdb.physical_read_bytes_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbPhysicalReadBytesPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbPhysicalReadBytesPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbPhysicalReadsPerTransactionDataPoint adds a data point to newrelicoracledb.pdb.physical_reads_per_transaction metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbPhysicalReadsPerTransactionDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbPhysicalReadsPerTransaction.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbPhysicalWriteBytesPerSecondDataPoint adds a data point to newrelicoracledb.pdb.physical_write_bytes_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbPhysicalWriteBytesPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbPhysicalWriteBytesPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbPhysicalWritesPerTransactionDataPoint adds a data point to newrelicoracledb.pdb.physical_writes_per_transaction metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbPhysicalWritesPerTransactionDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbPhysicalWritesPerTransaction.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbRedoGeneratedBytesPerSecondDataPoint adds a data point to newrelicoracledb.pdb.redo_generated_bytes_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbRedoGeneratedBytesPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbRedoGeneratedBytesPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbRedoGeneratedBytesPerTransactionDataPoint adds a data point to newrelicoracledb.pdb.redo_generated_bytes_per_transaction metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbRedoGeneratedBytesPerTransactionDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbRedoGeneratedBytesPerTransaction.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbResponseTimePerTransactionDataPoint adds a data point to newrelicoracledb.pdb.response_time_per_transaction metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbResponseTimePerTransactionDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbResponseTimePerTransaction.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbSessionCountDataPoint adds a data point to newrelicoracledb.pdb.session_count metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbSessionCountDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbSessionCount.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbSoftParseRatioDataPoint adds a data point to newrelicoracledb.pdb.soft_parse_ratio metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbSoftParseRatioDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbSoftParseRatio.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbSQLServiceResponseTimeDataPoint adds a data point to newrelicoracledb.pdb.sql_service_response_time metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbSQLServiceResponseTimeDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbSQLServiceResponseTime.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbTotalParseCountPerSecondDataPoint adds a data point to newrelicoracledb.pdb.total_parse_count_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbTotalParseCountPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbTotalParseCountPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbTotalParseCountPerTransactionDataPoint adds a data point to newrelicoracledb.pdb.total_parse_count_per_transaction metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbTotalParseCountPerTransactionDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbTotalParseCountPerTransaction.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbTransactionsPerSecondDataPoint adds a data point to newrelicoracledb.pdb.transactions_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbTransactionsPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbTransactionsPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbUserCallsPerSecondDataPoint adds a data point to newrelicoracledb.pdb.user_calls_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbUserCallsPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbUserCallsPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbUserCallsPerTransactionDataPoint adds a data point to newrelicoracledb.pdb.user_calls_per_transaction metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbUserCallsPerTransactionDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbUserCallsPerTransaction.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbUserCommitsPerSecondDataPoint adds a data point to newrelicoracledb.pdb.user_commits_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbUserCommitsPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbUserCommitsPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbUserCommitsPercentageDataPoint adds a data point to newrelicoracledb.pdb.user_commits_percentage metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbUserCommitsPercentageDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbUserCommitsPercentage.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbUserRollbacksPerSecondDataPoint adds a data point to newrelicoracledb.pdb.user_rollbacks_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbUserRollbacksPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbUserRollbacksPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbUserRollbacksPercentageDataPoint adds a data point to newrelicoracledb.pdb.user_rollbacks_percentage metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbUserRollbacksPercentageDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbUserRollbacksPercentage.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbWaitTimeRatioDataPoint adds a data point to newrelicoracledb.pdb.wait_time_ratio metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbWaitTimeRatioDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbWaitTimeRatio.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRedoLogParallelWriteWaitsDataPoint adds a data point to newrelicoracledb.redo_log_parallel_write_waits metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRedoLogParallelWriteWaitsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRedoLogParallelWriteWaits.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRedoLogSwitchArchivingNeededWaitsDataPoint adds a data point to newrelicoracledb.redo_log_switch_archiving_needed_waits metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRedoLogSwitchArchivingNeededWaitsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRedoLogSwitchArchivingNeededWaits.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaitsDataPoint adds a data point to newrelicoracledb.redo_log_switch_checkpoint_incomplete_waits metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaitsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRedoLogSwitchCheckpointIncompleteWaits.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRedoLogSwitchCompletionWaitsDataPoint adds a data point to newrelicoracledb.redo_log_switch_completion_waits metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRedoLogSwitchCompletionWaitsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRedoLogSwitchCompletionWaits.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRollbackSegmentsGetsDataPoint adds a data point to newrelicoracledb.rollback_segments_gets metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRollbackSegmentsGetsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRollbackSegmentsGets.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRollbackSegmentsWaitRatioDataPoint adds a data point to newrelicoracledb.rollback_segments_wait_ratio metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRollbackSegmentsWaitRatioDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRollbackSegmentsWaitRatio.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRollbackSegmentsWaitsDataPoint adds a data point to newrelicoracledb.rollback_segments_waits metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRollbackSegmentsWaitsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRollbackSegmentsWaits.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSessionsCountDataPoint adds a data point to newrelicoracledb.sessions.count metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSessionsCountDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string) {
	mb.metricNewrelicoracledbSessionsCount.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue)
}

// RecordNewrelicoracledbSgaBufferBusyWaitsDataPoint adds a data point to newrelicoracledb.sga_buffer_busy_waits metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaBufferBusyWaitsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaBufferBusyWaits.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaFixedSizeBytesDataPoint adds a data point to newrelicoracledb.sga_fixed_size_bytes metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaFixedSizeBytesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaFixedSizeBytes.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaFreeBufferInspectedWaitsDataPoint adds a data point to newrelicoracledb.sga_free_buffer_inspected_waits metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaFreeBufferInspectedWaitsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaFreeBufferInspectedWaits.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaFreeBufferWaitsDataPoint adds a data point to newrelicoracledb.sga_free_buffer_waits metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaFreeBufferWaitsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaFreeBufferWaits.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaHitRatioDataPoint adds a data point to newrelicoracledb.sga_hit_ratio metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaHitRatioDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaHitRatio.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaLogAllocationRetriesRatioDataPoint adds a data point to newrelicoracledb.sga_log_allocation_retries_ratio metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaLogAllocationRetriesRatioDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaLogAllocationRetriesRatio.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaLogBufferRedoAllocationRetriesDataPoint adds a data point to newrelicoracledb.sga_log_buffer_redo_allocation_retries metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaLogBufferRedoAllocationRetriesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaLogBufferRedoAllocationRetries.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaLogBufferRedoEntriesDataPoint adds a data point to newrelicoracledb.sga_log_buffer_redo_entries metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaLogBufferRedoEntriesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaLogBufferRedoEntries.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaLogBufferSpaceWaitsDataPoint adds a data point to newrelicoracledb.sga_log_buffer_space_waits metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaLogBufferSpaceWaitsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaLogBufferSpaceWaits.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaRedoBuffersBytesDataPoint adds a data point to newrelicoracledb.sga_redo_buffers_bytes metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaRedoBuffersBytesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaRedoBuffersBytes.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaSharedPoolDictCacheMissRatioDataPoint adds a data point to newrelicoracledb.sga_shared_pool_dict_cache_miss_ratio metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaSharedPoolDictCacheMissRatioDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaSharedPoolDictCacheMissRatio.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaSharedPoolLibraryCacheHitRatioDataPoint adds a data point to newrelicoracledb.sga_shared_pool_library_cache_hit_ratio metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaSharedPoolLibraryCacheHitRatioDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaSharedPoolLibraryCacheHitRatio.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatioDataPoint adds a data point to newrelicoracledb.sga_shared_pool_library_cache_reload_ratio metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatioDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaSharedPoolLibraryCacheReloadRatio.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSortsDiskDataPoint adds a data point to newrelicoracledb.sorts_disk metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSortsDiskDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSortsDisk.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSortsMemoryDataPoint adds a data point to newrelicoracledb.sorts_memory metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSortsMemoryDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSortsMemory.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbTablespaceDbIDDataPoint adds a data point to newrelicoracledb.tablespace.db_id metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceDbIDDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceDbID.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespaceGlobalNameDataPoint adds a data point to newrelicoracledb.tablespace.global_name metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceGlobalNameDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceGlobalName.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespaceIsOfflineDataPoint adds a data point to newrelicoracledb.tablespace.is_offline metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceIsOfflineDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceIsOffline.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespaceOfflineCdbDatafilesDataPoint adds a data point to newrelicoracledb.tablespace.offline_cdb_datafiles metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceOfflineCdbDatafilesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceOfflineCdbDatafiles.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespaceOfflinePdbDatafilesDataPoint adds a data point to newrelicoracledb.tablespace.offline_pdb_datafiles metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceOfflinePdbDatafilesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceOfflinePdbDatafiles.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespacePdbNonWriteModeDataPoint adds a data point to newrelicoracledb.tablespace.pdb_non_write_mode metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespacePdbNonWriteModeDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespacePdbNonWriteMode.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespaceSpaceConsumedBytesDataPoint adds a data point to newrelicoracledb.tablespace.space_consumed_bytes metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceSpaceConsumedBytesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceSpaceConsumedBytes.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespaceSpaceReservedBytesDataPoint adds a data point to newrelicoracledb.tablespace.space_reserved_bytes metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceSpaceReservedBytesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceSpaceReservedBytes.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespaceSpaceUsedPercentageDataPoint adds a data point to newrelicoracledb.tablespace.space_used_percentage metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceSpaceUsedPercentageDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceSpaceUsedPercentage.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...MetricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op.apply(mb)
	}
}
