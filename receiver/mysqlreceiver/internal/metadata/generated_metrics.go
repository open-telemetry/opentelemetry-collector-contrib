// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"fmt"
	"strconv"
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/confmap"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
)

// MetricSettings provides common settings for a particular metric.
type MetricSettings struct {
	Enabled bool `mapstructure:"enabled"`

	enabledProvidedByUser bool
}

// IsEnabledProvidedByUser returns true if `enabled` option is explicitly set in user settings to any value.
func (ms *MetricSettings) IsEnabledProvidedByUser() bool {
	return ms.enabledProvidedByUser
}

func (ms *MetricSettings) Unmarshal(parser *confmap.Conf) error {
	if parser == nil {
		return nil
	}
	err := parser.Unmarshal(ms, confmap.WithErrorUnused())
	if err != nil {
		return err
	}
	ms.enabledProvidedByUser = parser.IsSet("enabled")
	return nil
}

// MetricsSettings provides settings for mysqlreceiver metrics.
type MetricsSettings struct {
	MysqlBufferPoolDataPages    MetricSettings `mapstructure:"mysql.buffer_pool.data_pages"`
	MysqlBufferPoolLimit        MetricSettings `mapstructure:"mysql.buffer_pool.limit"`
	MysqlBufferPoolOperations   MetricSettings `mapstructure:"mysql.buffer_pool.operations"`
	MysqlBufferPoolPageFlushes  MetricSettings `mapstructure:"mysql.buffer_pool.page_flushes"`
	MysqlBufferPoolPages        MetricSettings `mapstructure:"mysql.buffer_pool.pages"`
	MysqlBufferPoolUsage        MetricSettings `mapstructure:"mysql.buffer_pool.usage"`
	MysqlCommands               MetricSettings `mapstructure:"mysql.commands"`
	MysqlDoubleWrites           MetricSettings `mapstructure:"mysql.double_writes"`
	MysqlHandlers               MetricSettings `mapstructure:"mysql.handlers"`
	MysqlIndexIoWaitCount       MetricSettings `mapstructure:"mysql.index.io.wait.count"`
	MysqlIndexIoWaitTime        MetricSettings `mapstructure:"mysql.index.io.wait.time"`
	MysqlLockedConnects         MetricSettings `mapstructure:"mysql.locked_connects"`
	MysqlLocks                  MetricSettings `mapstructure:"mysql.locks"`
	MysqlLogOperations          MetricSettings `mapstructure:"mysql.log_operations"`
	MysqlMysqlxWorkerThreads    MetricSettings `mapstructure:"mysql.mysqlx_worker_threads"`
	MysqlOpenedResources        MetricSettings `mapstructure:"mysql.opened_resources"`
	MysqlOperations             MetricSettings `mapstructure:"mysql.operations"`
	MysqlPageOperations         MetricSettings `mapstructure:"mysql.page_operations"`
	MysqlRowLocks               MetricSettings `mapstructure:"mysql.row_locks"`
	MysqlRowOperations          MetricSettings `mapstructure:"mysql.row_operations"`
	MysqlSorts                  MetricSettings `mapstructure:"mysql.sorts"`
	MysqlStatementEventCount    MetricSettings `mapstructure:"mysql.statement_event.count"`
	MysqlStatementEventWaitTime MetricSettings `mapstructure:"mysql.statement_event.wait.time"`
	MysqlTableIoWaitCount       MetricSettings `mapstructure:"mysql.table.io.wait.count"`
	MysqlTableIoWaitTime        MetricSettings `mapstructure:"mysql.table.io.wait.time"`
	MysqlThreads                MetricSettings `mapstructure:"mysql.threads"`
	MysqlTmpResources           MetricSettings `mapstructure:"mysql.tmp_resources"`
}

func DefaultMetricsSettings() MetricsSettings {
	return MetricsSettings{
		MysqlBufferPoolDataPages: MetricSettings{
			Enabled: true,
		},
		MysqlBufferPoolLimit: MetricSettings{
			Enabled: true,
		},
		MysqlBufferPoolOperations: MetricSettings{
			Enabled: true,
		},
		MysqlBufferPoolPageFlushes: MetricSettings{
			Enabled: true,
		},
		MysqlBufferPoolPages: MetricSettings{
			Enabled: true,
		},
		MysqlBufferPoolUsage: MetricSettings{
			Enabled: true,
		},
		MysqlCommands: MetricSettings{
			Enabled: true,
		},
		MysqlDoubleWrites: MetricSettings{
			Enabled: true,
		},
		MysqlHandlers: MetricSettings{
			Enabled: true,
		},
		MysqlIndexIoWaitCount: MetricSettings{
			Enabled: true,
		},
		MysqlIndexIoWaitTime: MetricSettings{
			Enabled: true,
		},
		MysqlLockedConnects: MetricSettings{
			Enabled: true,
		},
		MysqlLocks: MetricSettings{
			Enabled: true,
		},
		MysqlLogOperations: MetricSettings{
			Enabled: true,
		},
		MysqlMysqlxWorkerThreads: MetricSettings{
			Enabled: true,
		},
		MysqlOpenedResources: MetricSettings{
			Enabled: true,
		},
		MysqlOperations: MetricSettings{
			Enabled: true,
		},
		MysqlPageOperations: MetricSettings{
			Enabled: true,
		},
		MysqlRowLocks: MetricSettings{
			Enabled: true,
		},
		MysqlRowOperations: MetricSettings{
			Enabled: true,
		},
		MysqlSorts: MetricSettings{
			Enabled: true,
		},
		MysqlStatementEventCount: MetricSettings{
			Enabled: false,
		},
		MysqlStatementEventWaitTime: MetricSettings{
			Enabled: false,
		},
		MysqlTableIoWaitCount: MetricSettings{
			Enabled: true,
		},
		MysqlTableIoWaitTime: MetricSettings{
			Enabled: true,
		},
		MysqlThreads: MetricSettings{
			Enabled: true,
		},
		MysqlTmpResources: MetricSettings{
			Enabled: true,
		},
	}
}

// AttributeBufferPoolData specifies the a value buffer_pool_data attribute.
type AttributeBufferPoolData int

const (
	_ AttributeBufferPoolData = iota
	AttributeBufferPoolDataDirty
	AttributeBufferPoolDataClean
)

// String returns the string representation of the AttributeBufferPoolData.
func (av AttributeBufferPoolData) String() string {
	switch av {
	case AttributeBufferPoolDataDirty:
		return "dirty"
	case AttributeBufferPoolDataClean:
		return "clean"
	}
	return ""
}

// MapAttributeBufferPoolData is a helper map of string to AttributeBufferPoolData attribute value.
var MapAttributeBufferPoolData = map[string]AttributeBufferPoolData{
	"dirty": AttributeBufferPoolDataDirty,
	"clean": AttributeBufferPoolDataClean,
}

// AttributeBufferPoolOperations specifies the a value buffer_pool_operations attribute.
type AttributeBufferPoolOperations int

const (
	_ AttributeBufferPoolOperations = iota
	AttributeBufferPoolOperationsReadAheadRnd
	AttributeBufferPoolOperationsReadAhead
	AttributeBufferPoolOperationsReadAheadEvicted
	AttributeBufferPoolOperationsReadRequests
	AttributeBufferPoolOperationsReads
	AttributeBufferPoolOperationsWaitFree
	AttributeBufferPoolOperationsWriteRequests
)

// String returns the string representation of the AttributeBufferPoolOperations.
func (av AttributeBufferPoolOperations) String() string {
	switch av {
	case AttributeBufferPoolOperationsReadAheadRnd:
		return "read_ahead_rnd"
	case AttributeBufferPoolOperationsReadAhead:
		return "read_ahead"
	case AttributeBufferPoolOperationsReadAheadEvicted:
		return "read_ahead_evicted"
	case AttributeBufferPoolOperationsReadRequests:
		return "read_requests"
	case AttributeBufferPoolOperationsReads:
		return "reads"
	case AttributeBufferPoolOperationsWaitFree:
		return "wait_free"
	case AttributeBufferPoolOperationsWriteRequests:
		return "write_requests"
	}
	return ""
}

// MapAttributeBufferPoolOperations is a helper map of string to AttributeBufferPoolOperations attribute value.
var MapAttributeBufferPoolOperations = map[string]AttributeBufferPoolOperations{
	"read_ahead_rnd":     AttributeBufferPoolOperationsReadAheadRnd,
	"read_ahead":         AttributeBufferPoolOperationsReadAhead,
	"read_ahead_evicted": AttributeBufferPoolOperationsReadAheadEvicted,
	"read_requests":      AttributeBufferPoolOperationsReadRequests,
	"reads":              AttributeBufferPoolOperationsReads,
	"wait_free":          AttributeBufferPoolOperationsWaitFree,
	"write_requests":     AttributeBufferPoolOperationsWriteRequests,
}

// AttributeBufferPoolPages specifies the a value buffer_pool_pages attribute.
type AttributeBufferPoolPages int

const (
	_ AttributeBufferPoolPages = iota
	AttributeBufferPoolPagesData
	AttributeBufferPoolPagesFree
	AttributeBufferPoolPagesMisc
)

// String returns the string representation of the AttributeBufferPoolPages.
func (av AttributeBufferPoolPages) String() string {
	switch av {
	case AttributeBufferPoolPagesData:
		return "data"
	case AttributeBufferPoolPagesFree:
		return "free"
	case AttributeBufferPoolPagesMisc:
		return "misc"
	}
	return ""
}

// MapAttributeBufferPoolPages is a helper map of string to AttributeBufferPoolPages attribute value.
var MapAttributeBufferPoolPages = map[string]AttributeBufferPoolPages{
	"data": AttributeBufferPoolPagesData,
	"free": AttributeBufferPoolPagesFree,
	"misc": AttributeBufferPoolPagesMisc,
}

// AttributeCommand specifies the a value command attribute.
type AttributeCommand int

const (
	_ AttributeCommand = iota
	AttributeCommandExecute
	AttributeCommandClose
	AttributeCommandFetch
	AttributeCommandPrepare
	AttributeCommandReset
	AttributeCommandSendLongData
)

// String returns the string representation of the AttributeCommand.
func (av AttributeCommand) String() string {
	switch av {
	case AttributeCommandExecute:
		return "execute"
	case AttributeCommandClose:
		return "close"
	case AttributeCommandFetch:
		return "fetch"
	case AttributeCommandPrepare:
		return "prepare"
	case AttributeCommandReset:
		return "reset"
	case AttributeCommandSendLongData:
		return "send_long_data"
	}
	return ""
}

// MapAttributeCommand is a helper map of string to AttributeCommand attribute value.
var MapAttributeCommand = map[string]AttributeCommand{
	"execute":        AttributeCommandExecute,
	"close":          AttributeCommandClose,
	"fetch":          AttributeCommandFetch,
	"prepare":        AttributeCommandPrepare,
	"reset":          AttributeCommandReset,
	"send_long_data": AttributeCommandSendLongData,
}

// AttributeDoubleWrites specifies the a value double_writes attribute.
type AttributeDoubleWrites int

const (
	_ AttributeDoubleWrites = iota
	AttributeDoubleWritesPagesWritten
	AttributeDoubleWritesWrites
)

// String returns the string representation of the AttributeDoubleWrites.
func (av AttributeDoubleWrites) String() string {
	switch av {
	case AttributeDoubleWritesPagesWritten:
		return "pages_written"
	case AttributeDoubleWritesWrites:
		return "writes"
	}
	return ""
}

// MapAttributeDoubleWrites is a helper map of string to AttributeDoubleWrites attribute value.
var MapAttributeDoubleWrites = map[string]AttributeDoubleWrites{
	"pages_written": AttributeDoubleWritesPagesWritten,
	"writes":        AttributeDoubleWritesWrites,
}

// AttributeEventState specifies the a value event_state attribute.
type AttributeEventState int

const (
	_ AttributeEventState = iota
	AttributeEventStateErrors
	AttributeEventStateWarnings
	AttributeEventStateRowsAffected
	AttributeEventStateRowsSent
	AttributeEventStateRowsExamined
	AttributeEventStateCreatedTmpDiskTables
	AttributeEventStateCreatedTmpTables
	AttributeEventStateSortMergePasses
	AttributeEventStateSortRows
	AttributeEventStateNoIndexUsed
)

// String returns the string representation of the AttributeEventState.
func (av AttributeEventState) String() string {
	switch av {
	case AttributeEventStateErrors:
		return "errors"
	case AttributeEventStateWarnings:
		return "warnings"
	case AttributeEventStateRowsAffected:
		return "rows_affected"
	case AttributeEventStateRowsSent:
		return "rows_sent"
	case AttributeEventStateRowsExamined:
		return "rows_examined"
	case AttributeEventStateCreatedTmpDiskTables:
		return "created_tmp_disk_tables"
	case AttributeEventStateCreatedTmpTables:
		return "created_tmp_tables"
	case AttributeEventStateSortMergePasses:
		return "sort_merge_passes"
	case AttributeEventStateSortRows:
		return "sort_rows"
	case AttributeEventStateNoIndexUsed:
		return "no_index_used"
	}
	return ""
}

// MapAttributeEventState is a helper map of string to AttributeEventState attribute value.
var MapAttributeEventState = map[string]AttributeEventState{
	"errors":                  AttributeEventStateErrors,
	"warnings":                AttributeEventStateWarnings,
	"rows_affected":           AttributeEventStateRowsAffected,
	"rows_sent":               AttributeEventStateRowsSent,
	"rows_examined":           AttributeEventStateRowsExamined,
	"created_tmp_disk_tables": AttributeEventStateCreatedTmpDiskTables,
	"created_tmp_tables":      AttributeEventStateCreatedTmpTables,
	"sort_merge_passes":       AttributeEventStateSortMergePasses,
	"sort_rows":               AttributeEventStateSortRows,
	"no_index_used":           AttributeEventStateNoIndexUsed,
}

// AttributeHandler specifies the a value handler attribute.
type AttributeHandler int

const (
	_ AttributeHandler = iota
	AttributeHandlerCommit
	AttributeHandlerDelete
	AttributeHandlerDiscover
	AttributeHandlerExternalLock
	AttributeHandlerMrrInit
	AttributeHandlerPrepare
	AttributeHandlerReadFirst
	AttributeHandlerReadKey
	AttributeHandlerReadLast
	AttributeHandlerReadNext
	AttributeHandlerReadPrev
	AttributeHandlerReadRnd
	AttributeHandlerReadRndNext
	AttributeHandlerRollback
	AttributeHandlerSavepoint
	AttributeHandlerSavepointRollback
	AttributeHandlerUpdate
	AttributeHandlerWrite
)

// String returns the string representation of the AttributeHandler.
func (av AttributeHandler) String() string {
	switch av {
	case AttributeHandlerCommit:
		return "commit"
	case AttributeHandlerDelete:
		return "delete"
	case AttributeHandlerDiscover:
		return "discover"
	case AttributeHandlerExternalLock:
		return "external_lock"
	case AttributeHandlerMrrInit:
		return "mrr_init"
	case AttributeHandlerPrepare:
		return "prepare"
	case AttributeHandlerReadFirst:
		return "read_first"
	case AttributeHandlerReadKey:
		return "read_key"
	case AttributeHandlerReadLast:
		return "read_last"
	case AttributeHandlerReadNext:
		return "read_next"
	case AttributeHandlerReadPrev:
		return "read_prev"
	case AttributeHandlerReadRnd:
		return "read_rnd"
	case AttributeHandlerReadRndNext:
		return "read_rnd_next"
	case AttributeHandlerRollback:
		return "rollback"
	case AttributeHandlerSavepoint:
		return "savepoint"
	case AttributeHandlerSavepointRollback:
		return "savepoint_rollback"
	case AttributeHandlerUpdate:
		return "update"
	case AttributeHandlerWrite:
		return "write"
	}
	return ""
}

// MapAttributeHandler is a helper map of string to AttributeHandler attribute value.
var MapAttributeHandler = map[string]AttributeHandler{
	"commit":             AttributeHandlerCommit,
	"delete":             AttributeHandlerDelete,
	"discover":           AttributeHandlerDiscover,
	"external_lock":      AttributeHandlerExternalLock,
	"mrr_init":           AttributeHandlerMrrInit,
	"prepare":            AttributeHandlerPrepare,
	"read_first":         AttributeHandlerReadFirst,
	"read_key":           AttributeHandlerReadKey,
	"read_last":          AttributeHandlerReadLast,
	"read_next":          AttributeHandlerReadNext,
	"read_prev":          AttributeHandlerReadPrev,
	"read_rnd":           AttributeHandlerReadRnd,
	"read_rnd_next":      AttributeHandlerReadRndNext,
	"rollback":           AttributeHandlerRollback,
	"savepoint":          AttributeHandlerSavepoint,
	"savepoint_rollback": AttributeHandlerSavepointRollback,
	"update":             AttributeHandlerUpdate,
	"write":              AttributeHandlerWrite,
}

// AttributeIoWaitsOperations specifies the a value io_waits_operations attribute.
type AttributeIoWaitsOperations int

const (
	_ AttributeIoWaitsOperations = iota
	AttributeIoWaitsOperationsDelete
	AttributeIoWaitsOperationsFetch
	AttributeIoWaitsOperationsInsert
	AttributeIoWaitsOperationsUpdate
)

// String returns the string representation of the AttributeIoWaitsOperations.
func (av AttributeIoWaitsOperations) String() string {
	switch av {
	case AttributeIoWaitsOperationsDelete:
		return "delete"
	case AttributeIoWaitsOperationsFetch:
		return "fetch"
	case AttributeIoWaitsOperationsInsert:
		return "insert"
	case AttributeIoWaitsOperationsUpdate:
		return "update"
	}
	return ""
}

// MapAttributeIoWaitsOperations is a helper map of string to AttributeIoWaitsOperations attribute value.
var MapAttributeIoWaitsOperations = map[string]AttributeIoWaitsOperations{
	"delete": AttributeIoWaitsOperationsDelete,
	"fetch":  AttributeIoWaitsOperationsFetch,
	"insert": AttributeIoWaitsOperationsInsert,
	"update": AttributeIoWaitsOperationsUpdate,
}

// AttributeLocks specifies the a value locks attribute.
type AttributeLocks int

const (
	_ AttributeLocks = iota
	AttributeLocksImmediate
	AttributeLocksWaited
)

// String returns the string representation of the AttributeLocks.
func (av AttributeLocks) String() string {
	switch av {
	case AttributeLocksImmediate:
		return "immediate"
	case AttributeLocksWaited:
		return "waited"
	}
	return ""
}

// MapAttributeLocks is a helper map of string to AttributeLocks attribute value.
var MapAttributeLocks = map[string]AttributeLocks{
	"immediate": AttributeLocksImmediate,
	"waited":    AttributeLocksWaited,
}

// AttributeLogOperations specifies the a value log_operations attribute.
type AttributeLogOperations int

const (
	_ AttributeLogOperations = iota
	AttributeLogOperationsWaits
	AttributeLogOperationsWriteRequests
	AttributeLogOperationsWrites
)

// String returns the string representation of the AttributeLogOperations.
func (av AttributeLogOperations) String() string {
	switch av {
	case AttributeLogOperationsWaits:
		return "waits"
	case AttributeLogOperationsWriteRequests:
		return "write_requests"
	case AttributeLogOperationsWrites:
		return "writes"
	}
	return ""
}

// MapAttributeLogOperations is a helper map of string to AttributeLogOperations attribute value.
var MapAttributeLogOperations = map[string]AttributeLogOperations{
	"waits":          AttributeLogOperationsWaits,
	"write_requests": AttributeLogOperationsWriteRequests,
	"writes":         AttributeLogOperationsWrites,
}

// AttributeMysqlxThreads specifies the a value mysqlx_threads attribute.
type AttributeMysqlxThreads int

const (
	_ AttributeMysqlxThreads = iota
	AttributeMysqlxThreadsAvailable
	AttributeMysqlxThreadsActive
)

// String returns the string representation of the AttributeMysqlxThreads.
func (av AttributeMysqlxThreads) String() string {
	switch av {
	case AttributeMysqlxThreadsAvailable:
		return "available"
	case AttributeMysqlxThreadsActive:
		return "active"
	}
	return ""
}

// MapAttributeMysqlxThreads is a helper map of string to AttributeMysqlxThreads attribute value.
var MapAttributeMysqlxThreads = map[string]AttributeMysqlxThreads{
	"available": AttributeMysqlxThreadsAvailable,
	"active":    AttributeMysqlxThreadsActive,
}

// AttributeOpenedResources specifies the a value opened_resources attribute.
type AttributeOpenedResources int

const (
	_ AttributeOpenedResources = iota
	AttributeOpenedResourcesFile
	AttributeOpenedResourcesTableDefinition
	AttributeOpenedResourcesTable
)

// String returns the string representation of the AttributeOpenedResources.
func (av AttributeOpenedResources) String() string {
	switch av {
	case AttributeOpenedResourcesFile:
		return "file"
	case AttributeOpenedResourcesTableDefinition:
		return "table_definition"
	case AttributeOpenedResourcesTable:
		return "table"
	}
	return ""
}

// MapAttributeOpenedResources is a helper map of string to AttributeOpenedResources attribute value.
var MapAttributeOpenedResources = map[string]AttributeOpenedResources{
	"file":             AttributeOpenedResourcesFile,
	"table_definition": AttributeOpenedResourcesTableDefinition,
	"table":            AttributeOpenedResourcesTable,
}

// AttributeOperations specifies the a value operations attribute.
type AttributeOperations int

const (
	_ AttributeOperations = iota
	AttributeOperationsFsyncs
	AttributeOperationsReads
	AttributeOperationsWrites
)

// String returns the string representation of the AttributeOperations.
func (av AttributeOperations) String() string {
	switch av {
	case AttributeOperationsFsyncs:
		return "fsyncs"
	case AttributeOperationsReads:
		return "reads"
	case AttributeOperationsWrites:
		return "writes"
	}
	return ""
}

// MapAttributeOperations is a helper map of string to AttributeOperations attribute value.
var MapAttributeOperations = map[string]AttributeOperations{
	"fsyncs": AttributeOperationsFsyncs,
	"reads":  AttributeOperationsReads,
	"writes": AttributeOperationsWrites,
}

// AttributePageOperations specifies the a value page_operations attribute.
type AttributePageOperations int

const (
	_ AttributePageOperations = iota
	AttributePageOperationsCreated
	AttributePageOperationsRead
	AttributePageOperationsWritten
)

// String returns the string representation of the AttributePageOperations.
func (av AttributePageOperations) String() string {
	switch av {
	case AttributePageOperationsCreated:
		return "created"
	case AttributePageOperationsRead:
		return "read"
	case AttributePageOperationsWritten:
		return "written"
	}
	return ""
}

// MapAttributePageOperations is a helper map of string to AttributePageOperations attribute value.
var MapAttributePageOperations = map[string]AttributePageOperations{
	"created": AttributePageOperationsCreated,
	"read":    AttributePageOperationsRead,
	"written": AttributePageOperationsWritten,
}

// AttributeRowLocks specifies the a value row_locks attribute.
type AttributeRowLocks int

const (
	_ AttributeRowLocks = iota
	AttributeRowLocksWaits
	AttributeRowLocksTime
)

// String returns the string representation of the AttributeRowLocks.
func (av AttributeRowLocks) String() string {
	switch av {
	case AttributeRowLocksWaits:
		return "waits"
	case AttributeRowLocksTime:
		return "time"
	}
	return ""
}

// MapAttributeRowLocks is a helper map of string to AttributeRowLocks attribute value.
var MapAttributeRowLocks = map[string]AttributeRowLocks{
	"waits": AttributeRowLocksWaits,
	"time":  AttributeRowLocksTime,
}

// AttributeRowOperations specifies the a value row_operations attribute.
type AttributeRowOperations int

const (
	_ AttributeRowOperations = iota
	AttributeRowOperationsDeleted
	AttributeRowOperationsInserted
	AttributeRowOperationsRead
	AttributeRowOperationsUpdated
)

// String returns the string representation of the AttributeRowOperations.
func (av AttributeRowOperations) String() string {
	switch av {
	case AttributeRowOperationsDeleted:
		return "deleted"
	case AttributeRowOperationsInserted:
		return "inserted"
	case AttributeRowOperationsRead:
		return "read"
	case AttributeRowOperationsUpdated:
		return "updated"
	}
	return ""
}

// MapAttributeRowOperations is a helper map of string to AttributeRowOperations attribute value.
var MapAttributeRowOperations = map[string]AttributeRowOperations{
	"deleted":  AttributeRowOperationsDeleted,
	"inserted": AttributeRowOperationsInserted,
	"read":     AttributeRowOperationsRead,
	"updated":  AttributeRowOperationsUpdated,
}

// AttributeSorts specifies the a value sorts attribute.
type AttributeSorts int

const (
	_ AttributeSorts = iota
	AttributeSortsMergePasses
	AttributeSortsRange
	AttributeSortsRows
	AttributeSortsScan
)

// String returns the string representation of the AttributeSorts.
func (av AttributeSorts) String() string {
	switch av {
	case AttributeSortsMergePasses:
		return "merge_passes"
	case AttributeSortsRange:
		return "range"
	case AttributeSortsRows:
		return "rows"
	case AttributeSortsScan:
		return "scan"
	}
	return ""
}

// MapAttributeSorts is a helper map of string to AttributeSorts attribute value.
var MapAttributeSorts = map[string]AttributeSorts{
	"merge_passes": AttributeSortsMergePasses,
	"range":        AttributeSortsRange,
	"rows":         AttributeSortsRows,
	"scan":         AttributeSortsScan,
}

// AttributeThreads specifies the a value threads attribute.
type AttributeThreads int

const (
	_ AttributeThreads = iota
	AttributeThreadsCached
	AttributeThreadsConnected
	AttributeThreadsCreated
	AttributeThreadsRunning
)

// String returns the string representation of the AttributeThreads.
func (av AttributeThreads) String() string {
	switch av {
	case AttributeThreadsCached:
		return "cached"
	case AttributeThreadsConnected:
		return "connected"
	case AttributeThreadsCreated:
		return "created"
	case AttributeThreadsRunning:
		return "running"
	}
	return ""
}

// MapAttributeThreads is a helper map of string to AttributeThreads attribute value.
var MapAttributeThreads = map[string]AttributeThreads{
	"cached":    AttributeThreadsCached,
	"connected": AttributeThreadsConnected,
	"created":   AttributeThreadsCreated,
	"running":   AttributeThreadsRunning,
}

// AttributeTmpResource specifies the a value tmp_resource attribute.
type AttributeTmpResource int

const (
	_ AttributeTmpResource = iota
	AttributeTmpResourceDiskTables
	AttributeTmpResourceFiles
	AttributeTmpResourceTables
)

// String returns the string representation of the AttributeTmpResource.
func (av AttributeTmpResource) String() string {
	switch av {
	case AttributeTmpResourceDiskTables:
		return "disk_tables"
	case AttributeTmpResourceFiles:
		return "files"
	case AttributeTmpResourceTables:
		return "tables"
	}
	return ""
}

// MapAttributeTmpResource is a helper map of string to AttributeTmpResource attribute value.
var MapAttributeTmpResource = map[string]AttributeTmpResource{
	"disk_tables": AttributeTmpResourceDiskTables,
	"files":       AttributeTmpResourceFiles,
	"tables":      AttributeTmpResourceTables,
}

type metricMysqlBufferPoolDataPages struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.data_pages metric with initial data.
func (m *metricMysqlBufferPoolDataPages) init() {
	m.data.SetName("mysql.buffer_pool.data_pages")
	m.data.SetDescription("The number of data pages in the InnoDB buffer pool.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBufferPoolDataPages) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, bufferPoolDataAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("status", bufferPoolDataAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolDataPages) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolDataPages) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolDataPages(settings MetricSettings) metricMysqlBufferPoolDataPages {
	m := metricMysqlBufferPoolDataPages{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.limit metric with initial data.
func (m *metricMysqlBufferPoolLimit) init() {
	m.data.SetName("mysql.buffer_pool.limit")
	m.data.SetDescription("The configured size of the InnoDB buffer pool.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricMysqlBufferPoolLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolLimit) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolLimit) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolLimit(settings MetricSettings) metricMysqlBufferPoolLimit {
	m := metricMysqlBufferPoolLimit{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.operations metric with initial data.
func (m *metricMysqlBufferPoolOperations) init() {
	m.data.SetName("mysql.buffer_pool.operations")
	m.data.SetDescription("The number of operations on the InnoDB buffer pool.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBufferPoolOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, bufferPoolOperationsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("operation", bufferPoolOperationsAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolOperations) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolOperations(settings MetricSettings) metricMysqlBufferPoolOperations {
	m := metricMysqlBufferPoolOperations{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolPageFlushes struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.page_flushes metric with initial data.
func (m *metricMysqlBufferPoolPageFlushes) init() {
	m.data.SetName("mysql.buffer_pool.page_flushes")
	m.data.SetDescription("The number of requests to flush pages from the InnoDB buffer pool.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricMysqlBufferPoolPageFlushes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolPageFlushes) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolPageFlushes) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolPageFlushes(settings MetricSettings) metricMysqlBufferPoolPageFlushes {
	m := metricMysqlBufferPoolPageFlushes{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolPages struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.pages metric with initial data.
func (m *metricMysqlBufferPoolPages) init() {
	m.data.SetName("mysql.buffer_pool.pages")
	m.data.SetDescription("The number of pages in the InnoDB buffer pool.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBufferPoolPages) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, bufferPoolPagesAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("kind", bufferPoolPagesAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolPages) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolPages) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolPages(settings MetricSettings) metricMysqlBufferPoolPages {
	m := metricMysqlBufferPoolPages{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.usage metric with initial data.
func (m *metricMysqlBufferPoolUsage) init() {
	m.data.SetName("mysql.buffer_pool.usage")
	m.data.SetDescription("The number of bytes in the InnoDB buffer pool.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBufferPoolUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, bufferPoolDataAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("status", bufferPoolDataAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolUsage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolUsage(settings MetricSettings) metricMysqlBufferPoolUsage {
	m := metricMysqlBufferPoolUsage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlCommands struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.commands metric with initial data.
func (m *metricMysqlCommands) init() {
	m.data.SetName("mysql.commands")
	m.data.SetDescription("The number of times each type of command has been executed.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlCommands) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, commandAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("command", commandAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlCommands) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlCommands) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlCommands(settings MetricSettings) metricMysqlCommands {
	m := metricMysqlCommands{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlDoubleWrites struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.double_writes metric with initial data.
func (m *metricMysqlDoubleWrites) init() {
	m.data.SetName("mysql.double_writes")
	m.data.SetDescription("The number of writes to the InnoDB doublewrite buffer.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlDoubleWrites) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, doubleWritesAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("kind", doubleWritesAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlDoubleWrites) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlDoubleWrites) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlDoubleWrites(settings MetricSettings) metricMysqlDoubleWrites {
	m := metricMysqlDoubleWrites{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlHandlers struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.handlers metric with initial data.
func (m *metricMysqlHandlers) init() {
	m.data.SetName("mysql.handlers")
	m.data.SetDescription("The number of requests to various MySQL handlers.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlHandlers) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, handlerAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("kind", handlerAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlHandlers) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlHandlers) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlHandlers(settings MetricSettings) metricMysqlHandlers {
	m := metricMysqlHandlers{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlIndexIoWaitCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.index.io.wait.count metric with initial data.
func (m *metricMysqlIndexIoWaitCount) init() {
	m.data.SetName("mysql.index.io.wait.count")
	m.data.SetDescription("The total count of I/O wait events for an index.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlIndexIoWaitCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, ioWaitsOperationsAttributeValue string, tableNameAttributeValue string, schemaAttributeValue string, indexNameAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("operation", ioWaitsOperationsAttributeValue)
	dp.Attributes().PutStr("table", tableNameAttributeValue)
	dp.Attributes().PutStr("schema", schemaAttributeValue)
	dp.Attributes().PutStr("index", indexNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlIndexIoWaitCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlIndexIoWaitCount) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlIndexIoWaitCount(settings MetricSettings) metricMysqlIndexIoWaitCount {
	m := metricMysqlIndexIoWaitCount{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlIndexIoWaitTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.index.io.wait.time metric with initial data.
func (m *metricMysqlIndexIoWaitTime) init() {
	m.data.SetName("mysql.index.io.wait.time")
	m.data.SetDescription("The total time of I/O wait events for an index.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlIndexIoWaitTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, ioWaitsOperationsAttributeValue string, tableNameAttributeValue string, schemaAttributeValue string, indexNameAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("operation", ioWaitsOperationsAttributeValue)
	dp.Attributes().PutStr("table", tableNameAttributeValue)
	dp.Attributes().PutStr("schema", schemaAttributeValue)
	dp.Attributes().PutStr("index", indexNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlIndexIoWaitTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlIndexIoWaitTime) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlIndexIoWaitTime(settings MetricSettings) metricMysqlIndexIoWaitTime {
	m := metricMysqlIndexIoWaitTime{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlLockedConnects struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.locked_connects metric with initial data.
func (m *metricMysqlLockedConnects) init() {
	m.data.SetName("mysql.locked_connects")
	m.data.SetDescription("The number of attempts to connect to locked user accounts.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricMysqlLockedConnects) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlLockedConnects) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlLockedConnects) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlLockedConnects(settings MetricSettings) metricMysqlLockedConnects {
	m := metricMysqlLockedConnects{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlLocks struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.locks metric with initial data.
func (m *metricMysqlLocks) init() {
	m.data.SetName("mysql.locks")
	m.data.SetDescription("The number of MySQL locks.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlLocks) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locksAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("kind", locksAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlLocks) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlLocks) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlLocks(settings MetricSettings) metricMysqlLocks {
	m := metricMysqlLocks{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlLogOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.log_operations metric with initial data.
func (m *metricMysqlLogOperations) init() {
	m.data.SetName("mysql.log_operations")
	m.data.SetDescription("The number of InnoDB log operations.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlLogOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, logOperationsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("operation", logOperationsAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlLogOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlLogOperations) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlLogOperations(settings MetricSettings) metricMysqlLogOperations {
	m := metricMysqlLogOperations{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlMysqlxWorkerThreads struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.mysqlx_worker_threads metric with initial data.
func (m *metricMysqlMysqlxWorkerThreads) init() {
	m.data.SetName("mysql.mysqlx_worker_threads")
	m.data.SetDescription("The number of worker threads available.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlMysqlxWorkerThreads) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, mysqlxThreadsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("kind", mysqlxThreadsAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlMysqlxWorkerThreads) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlMysqlxWorkerThreads) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlMysqlxWorkerThreads(settings MetricSettings) metricMysqlMysqlxWorkerThreads {
	m := metricMysqlMysqlxWorkerThreads{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlOpenedResources struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.opened_resources metric with initial data.
func (m *metricMysqlOpenedResources) init() {
	m.data.SetName("mysql.opened_resources")
	m.data.SetDescription("The number of opened resources.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlOpenedResources) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, openedResourcesAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("kind", openedResourcesAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlOpenedResources) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlOpenedResources) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlOpenedResources(settings MetricSettings) metricMysqlOpenedResources {
	m := metricMysqlOpenedResources{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.operations metric with initial data.
func (m *metricMysqlOperations) init() {
	m.data.SetName("mysql.operations")
	m.data.SetDescription("The number of InnoDB operations.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, operationsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("operation", operationsAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlOperations) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlOperations(settings MetricSettings) metricMysqlOperations {
	m := metricMysqlOperations{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlPageOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.page_operations metric with initial data.
func (m *metricMysqlPageOperations) init() {
	m.data.SetName("mysql.page_operations")
	m.data.SetDescription("The number of InnoDB page operations.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlPageOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, pageOperationsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("operation", pageOperationsAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlPageOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlPageOperations) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlPageOperations(settings MetricSettings) metricMysqlPageOperations {
	m := metricMysqlPageOperations{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlRowLocks struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.row_locks metric with initial data.
func (m *metricMysqlRowLocks) init() {
	m.data.SetName("mysql.row_locks")
	m.data.SetDescription("The number of InnoDB row locks.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlRowLocks) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, rowLocksAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("kind", rowLocksAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlRowLocks) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlRowLocks) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlRowLocks(settings MetricSettings) metricMysqlRowLocks {
	m := metricMysqlRowLocks{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlRowOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.row_operations metric with initial data.
func (m *metricMysqlRowOperations) init() {
	m.data.SetName("mysql.row_operations")
	m.data.SetDescription("The number of InnoDB row operations.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlRowOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, rowOperationsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("operation", rowOperationsAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlRowOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlRowOperations) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlRowOperations(settings MetricSettings) metricMysqlRowOperations {
	m := metricMysqlRowOperations{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlSorts struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.sorts metric with initial data.
func (m *metricMysqlSorts) init() {
	m.data.SetName("mysql.sorts")
	m.data.SetDescription("The number of MySQL sorts.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlSorts) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, sortsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("kind", sortsAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlSorts) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlSorts) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlSorts(settings MetricSettings) metricMysqlSorts {
	m := metricMysqlSorts{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlStatementEventCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.statement_event.count metric with initial data.
func (m *metricMysqlStatementEventCount) init() {
	m.data.SetName("mysql.statement_event.count")
	m.data.SetDescription("Summary of current and recent statement events.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlStatementEventCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, schemaAttributeValue string, digestAttributeValue string, digestTextAttributeValue string, eventStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("schema", schemaAttributeValue)
	dp.Attributes().PutStr("digest", digestAttributeValue)
	dp.Attributes().PutStr("digest_text", digestTextAttributeValue)
	dp.Attributes().PutStr("kind", eventStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlStatementEventCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlStatementEventCount) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlStatementEventCount(settings MetricSettings) metricMysqlStatementEventCount {
	m := metricMysqlStatementEventCount{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlStatementEventWaitTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.statement_event.wait.time metric with initial data.
func (m *metricMysqlStatementEventWaitTime) init() {
	m.data.SetName("mysql.statement_event.wait.time")
	m.data.SetDescription("The total wait time of the summarized timed events.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlStatementEventWaitTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, schemaAttributeValue string, digestAttributeValue string, digestTextAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("schema", schemaAttributeValue)
	dp.Attributes().PutStr("digest", digestAttributeValue)
	dp.Attributes().PutStr("digest_text", digestTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlStatementEventWaitTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlStatementEventWaitTime) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlStatementEventWaitTime(settings MetricSettings) metricMysqlStatementEventWaitTime {
	m := metricMysqlStatementEventWaitTime{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlTableIoWaitCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.table.io.wait.count metric with initial data.
func (m *metricMysqlTableIoWaitCount) init() {
	m.data.SetName("mysql.table.io.wait.count")
	m.data.SetDescription("The total count of I/O wait events for a table.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlTableIoWaitCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, ioWaitsOperationsAttributeValue string, tableNameAttributeValue string, schemaAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("operation", ioWaitsOperationsAttributeValue)
	dp.Attributes().PutStr("table", tableNameAttributeValue)
	dp.Attributes().PutStr("schema", schemaAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlTableIoWaitCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlTableIoWaitCount) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlTableIoWaitCount(settings MetricSettings) metricMysqlTableIoWaitCount {
	m := metricMysqlTableIoWaitCount{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlTableIoWaitTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.table.io.wait.time metric with initial data.
func (m *metricMysqlTableIoWaitTime) init() {
	m.data.SetName("mysql.table.io.wait.time")
	m.data.SetDescription("The total time of I/O wait events for a table.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlTableIoWaitTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, ioWaitsOperationsAttributeValue string, tableNameAttributeValue string, schemaAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("operation", ioWaitsOperationsAttributeValue)
	dp.Attributes().PutStr("table", tableNameAttributeValue)
	dp.Attributes().PutStr("schema", schemaAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlTableIoWaitTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlTableIoWaitTime) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlTableIoWaitTime(settings MetricSettings) metricMysqlTableIoWaitTime {
	m := metricMysqlTableIoWaitTime{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlThreads struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.threads metric with initial data.
func (m *metricMysqlThreads) init() {
	m.data.SetName("mysql.threads")
	m.data.SetDescription("The state of MySQL threads.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlThreads) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, threadsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("kind", threadsAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlThreads) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlThreads) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlThreads(settings MetricSettings) metricMysqlThreads {
	m := metricMysqlThreads{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlTmpResources struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.tmp_resources metric with initial data.
func (m *metricMysqlTmpResources) init() {
	m.data.SetName("mysql.tmp_resources")
	m.data.SetDescription("The number of created temporary resources.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlTmpResources) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, tmpResourceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("resource", tmpResourceAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlTmpResources) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlTmpResources) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlTmpResources(settings MetricSettings) metricMysqlTmpResources {
	m := metricMysqlTmpResources{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user settings.
type MetricsBuilder struct {
	startTime                         pcommon.Timestamp   // start time that will be applied to all recorded data points.
	metricsCapacity                   int                 // maximum observed number of metrics per resource.
	resourceCapacity                  int                 // maximum observed number of resource attributes.
	metricsBuffer                     pmetric.Metrics     // accumulates metrics data before emitting.
	buildInfo                         component.BuildInfo // contains version information
	metricMysqlBufferPoolDataPages    metricMysqlBufferPoolDataPages
	metricMysqlBufferPoolLimit        metricMysqlBufferPoolLimit
	metricMysqlBufferPoolOperations   metricMysqlBufferPoolOperations
	metricMysqlBufferPoolPageFlushes  metricMysqlBufferPoolPageFlushes
	metricMysqlBufferPoolPages        metricMysqlBufferPoolPages
	metricMysqlBufferPoolUsage        metricMysqlBufferPoolUsage
	metricMysqlCommands               metricMysqlCommands
	metricMysqlDoubleWrites           metricMysqlDoubleWrites
	metricMysqlHandlers               metricMysqlHandlers
	metricMysqlIndexIoWaitCount       metricMysqlIndexIoWaitCount
	metricMysqlIndexIoWaitTime        metricMysqlIndexIoWaitTime
	metricMysqlLockedConnects         metricMysqlLockedConnects
	metricMysqlLocks                  metricMysqlLocks
	metricMysqlLogOperations          metricMysqlLogOperations
	metricMysqlMysqlxWorkerThreads    metricMysqlMysqlxWorkerThreads
	metricMysqlOpenedResources        metricMysqlOpenedResources
	metricMysqlOperations             metricMysqlOperations
	metricMysqlPageOperations         metricMysqlPageOperations
	metricMysqlRowLocks               metricMysqlRowLocks
	metricMysqlRowOperations          metricMysqlRowOperations
	metricMysqlSorts                  metricMysqlSorts
	metricMysqlStatementEventCount    metricMysqlStatementEventCount
	metricMysqlStatementEventWaitTime metricMysqlStatementEventWaitTime
	metricMysqlTableIoWaitCount       metricMysqlTableIoWaitCount
	metricMysqlTableIoWaitTime        metricMysqlTableIoWaitTime
	metricMysqlThreads                metricMysqlThreads
	metricMysqlTmpResources           metricMysqlTmpResources
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(settings MetricsSettings, buildInfo component.BuildInfo, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		startTime:                         pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:                     pmetric.NewMetrics(),
		buildInfo:                         buildInfo,
		metricMysqlBufferPoolDataPages:    newMetricMysqlBufferPoolDataPages(settings.MysqlBufferPoolDataPages),
		metricMysqlBufferPoolLimit:        newMetricMysqlBufferPoolLimit(settings.MysqlBufferPoolLimit),
		metricMysqlBufferPoolOperations:   newMetricMysqlBufferPoolOperations(settings.MysqlBufferPoolOperations),
		metricMysqlBufferPoolPageFlushes:  newMetricMysqlBufferPoolPageFlushes(settings.MysqlBufferPoolPageFlushes),
		metricMysqlBufferPoolPages:        newMetricMysqlBufferPoolPages(settings.MysqlBufferPoolPages),
		metricMysqlBufferPoolUsage:        newMetricMysqlBufferPoolUsage(settings.MysqlBufferPoolUsage),
		metricMysqlCommands:               newMetricMysqlCommands(settings.MysqlCommands),
		metricMysqlDoubleWrites:           newMetricMysqlDoubleWrites(settings.MysqlDoubleWrites),
		metricMysqlHandlers:               newMetricMysqlHandlers(settings.MysqlHandlers),
		metricMysqlIndexIoWaitCount:       newMetricMysqlIndexIoWaitCount(settings.MysqlIndexIoWaitCount),
		metricMysqlIndexIoWaitTime:        newMetricMysqlIndexIoWaitTime(settings.MysqlIndexIoWaitTime),
		metricMysqlLockedConnects:         newMetricMysqlLockedConnects(settings.MysqlLockedConnects),
		metricMysqlLocks:                  newMetricMysqlLocks(settings.MysqlLocks),
		metricMysqlLogOperations:          newMetricMysqlLogOperations(settings.MysqlLogOperations),
		metricMysqlMysqlxWorkerThreads:    newMetricMysqlMysqlxWorkerThreads(settings.MysqlMysqlxWorkerThreads),
		metricMysqlOpenedResources:        newMetricMysqlOpenedResources(settings.MysqlOpenedResources),
		metricMysqlOperations:             newMetricMysqlOperations(settings.MysqlOperations),
		metricMysqlPageOperations:         newMetricMysqlPageOperations(settings.MysqlPageOperations),
		metricMysqlRowLocks:               newMetricMysqlRowLocks(settings.MysqlRowLocks),
		metricMysqlRowOperations:          newMetricMysqlRowOperations(settings.MysqlRowOperations),
		metricMysqlSorts:                  newMetricMysqlSorts(settings.MysqlSorts),
		metricMysqlStatementEventCount:    newMetricMysqlStatementEventCount(settings.MysqlStatementEventCount),
		metricMysqlStatementEventWaitTime: newMetricMysqlStatementEventWaitTime(settings.MysqlStatementEventWaitTime),
		metricMysqlTableIoWaitCount:       newMetricMysqlTableIoWaitCount(settings.MysqlTableIoWaitCount),
		metricMysqlTableIoWaitTime:        newMetricMysqlTableIoWaitTime(settings.MysqlTableIoWaitTime),
		metricMysqlThreads:                newMetricMysqlThreads(settings.MysqlThreads),
		metricMysqlTmpResources:           newMetricMysqlTmpResources(settings.MysqlTmpResources),
	}
	for _, op := range options {
		op(mb)
	}
	return mb
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
	if mb.resourceCapacity < rm.Resource().Attributes().Len() {
		mb.resourceCapacity = rm.Resource().Attributes().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption func(pmetric.ResourceMetrics)

// WithMysqlInstanceEndpoint sets provided value as "mysql.instance.endpoint" attribute for current resource.
func WithMysqlInstanceEndpoint(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().PutStr("mysql.instance.endpoint", val)
	}
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	}
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(rmo ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	rm.Resource().Attributes().EnsureCapacity(mb.resourceCapacity)
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName("otelcol/mysqlreceiver")
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricMysqlBufferPoolDataPages.emit(ils.Metrics())
	mb.metricMysqlBufferPoolLimit.emit(ils.Metrics())
	mb.metricMysqlBufferPoolOperations.emit(ils.Metrics())
	mb.metricMysqlBufferPoolPageFlushes.emit(ils.Metrics())
	mb.metricMysqlBufferPoolPages.emit(ils.Metrics())
	mb.metricMysqlBufferPoolUsage.emit(ils.Metrics())
	mb.metricMysqlCommands.emit(ils.Metrics())
	mb.metricMysqlDoubleWrites.emit(ils.Metrics())
	mb.metricMysqlHandlers.emit(ils.Metrics())
	mb.metricMysqlIndexIoWaitCount.emit(ils.Metrics())
	mb.metricMysqlIndexIoWaitTime.emit(ils.Metrics())
	mb.metricMysqlLockedConnects.emit(ils.Metrics())
	mb.metricMysqlLocks.emit(ils.Metrics())
	mb.metricMysqlLogOperations.emit(ils.Metrics())
	mb.metricMysqlMysqlxWorkerThreads.emit(ils.Metrics())
	mb.metricMysqlOpenedResources.emit(ils.Metrics())
	mb.metricMysqlOperations.emit(ils.Metrics())
	mb.metricMysqlPageOperations.emit(ils.Metrics())
	mb.metricMysqlRowLocks.emit(ils.Metrics())
	mb.metricMysqlRowOperations.emit(ils.Metrics())
	mb.metricMysqlSorts.emit(ils.Metrics())
	mb.metricMysqlStatementEventCount.emit(ils.Metrics())
	mb.metricMysqlStatementEventWaitTime.emit(ils.Metrics())
	mb.metricMysqlTableIoWaitCount.emit(ils.Metrics())
	mb.metricMysqlTableIoWaitTime.emit(ils.Metrics())
	mb.metricMysqlThreads.emit(ils.Metrics())
	mb.metricMysqlTmpResources.emit(ils.Metrics())
	for _, op := range rmo {
		op(rm)
	}
	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user settings, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(rmo ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(rmo...)
	metrics := pmetric.NewMetrics()
	mb.metricsBuffer.MoveTo(metrics)
	return metrics
}

// RecordMysqlBufferPoolDataPagesDataPoint adds a data point to mysql.buffer_pool.data_pages metric.
func (mb *MetricsBuilder) RecordMysqlBufferPoolDataPagesDataPoint(ts pcommon.Timestamp, val int64, bufferPoolDataAttributeValue AttributeBufferPoolData) {
	mb.metricMysqlBufferPoolDataPages.recordDataPoint(mb.startTime, ts, val, bufferPoolDataAttributeValue.String())
}

// RecordMysqlBufferPoolLimitDataPoint adds a data point to mysql.buffer_pool.limit metric.
func (mb *MetricsBuilder) RecordMysqlBufferPoolLimitDataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlBufferPoolLimit, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlBufferPoolLimit.recordDataPoint(mb.startTime, ts, val)
	return nil
}

// RecordMysqlBufferPoolOperationsDataPoint adds a data point to mysql.buffer_pool.operations metric.
func (mb *MetricsBuilder) RecordMysqlBufferPoolOperationsDataPoint(ts pcommon.Timestamp, inputVal string, bufferPoolOperationsAttributeValue AttributeBufferPoolOperations) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlBufferPoolOperations, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlBufferPoolOperations.recordDataPoint(mb.startTime, ts, val, bufferPoolOperationsAttributeValue.String())
	return nil
}

// RecordMysqlBufferPoolPageFlushesDataPoint adds a data point to mysql.buffer_pool.page_flushes metric.
func (mb *MetricsBuilder) RecordMysqlBufferPoolPageFlushesDataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlBufferPoolPageFlushes, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlBufferPoolPageFlushes.recordDataPoint(mb.startTime, ts, val)
	return nil
}

// RecordMysqlBufferPoolPagesDataPoint adds a data point to mysql.buffer_pool.pages metric.
func (mb *MetricsBuilder) RecordMysqlBufferPoolPagesDataPoint(ts pcommon.Timestamp, inputVal string, bufferPoolPagesAttributeValue AttributeBufferPoolPages) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlBufferPoolPages, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlBufferPoolPages.recordDataPoint(mb.startTime, ts, val, bufferPoolPagesAttributeValue.String())
	return nil
}

// RecordMysqlBufferPoolUsageDataPoint adds a data point to mysql.buffer_pool.usage metric.
func (mb *MetricsBuilder) RecordMysqlBufferPoolUsageDataPoint(ts pcommon.Timestamp, val int64, bufferPoolDataAttributeValue AttributeBufferPoolData) {
	mb.metricMysqlBufferPoolUsage.recordDataPoint(mb.startTime, ts, val, bufferPoolDataAttributeValue.String())
}

// RecordMysqlCommandsDataPoint adds a data point to mysql.commands metric.
func (mb *MetricsBuilder) RecordMysqlCommandsDataPoint(ts pcommon.Timestamp, inputVal string, commandAttributeValue AttributeCommand) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlCommands, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlCommands.recordDataPoint(mb.startTime, ts, val, commandAttributeValue.String())
	return nil
}

// RecordMysqlDoubleWritesDataPoint adds a data point to mysql.double_writes metric.
func (mb *MetricsBuilder) RecordMysqlDoubleWritesDataPoint(ts pcommon.Timestamp, inputVal string, doubleWritesAttributeValue AttributeDoubleWrites) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlDoubleWrites, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlDoubleWrites.recordDataPoint(mb.startTime, ts, val, doubleWritesAttributeValue.String())
	return nil
}

// RecordMysqlHandlersDataPoint adds a data point to mysql.handlers metric.
func (mb *MetricsBuilder) RecordMysqlHandlersDataPoint(ts pcommon.Timestamp, inputVal string, handlerAttributeValue AttributeHandler) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlHandlers, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlHandlers.recordDataPoint(mb.startTime, ts, val, handlerAttributeValue.String())
	return nil
}

// RecordMysqlIndexIoWaitCountDataPoint adds a data point to mysql.index.io.wait.count metric.
func (mb *MetricsBuilder) RecordMysqlIndexIoWaitCountDataPoint(ts pcommon.Timestamp, val int64, ioWaitsOperationsAttributeValue AttributeIoWaitsOperations, tableNameAttributeValue string, schemaAttributeValue string, indexNameAttributeValue string) {
	mb.metricMysqlIndexIoWaitCount.recordDataPoint(mb.startTime, ts, val, ioWaitsOperationsAttributeValue.String(), tableNameAttributeValue, schemaAttributeValue, indexNameAttributeValue)
}

// RecordMysqlIndexIoWaitTimeDataPoint adds a data point to mysql.index.io.wait.time metric.
func (mb *MetricsBuilder) RecordMysqlIndexIoWaitTimeDataPoint(ts pcommon.Timestamp, val int64, ioWaitsOperationsAttributeValue AttributeIoWaitsOperations, tableNameAttributeValue string, schemaAttributeValue string, indexNameAttributeValue string) {
	mb.metricMysqlIndexIoWaitTime.recordDataPoint(mb.startTime, ts, val, ioWaitsOperationsAttributeValue.String(), tableNameAttributeValue, schemaAttributeValue, indexNameAttributeValue)
}

// RecordMysqlLockedConnectsDataPoint adds a data point to mysql.locked_connects metric.
func (mb *MetricsBuilder) RecordMysqlLockedConnectsDataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlLockedConnects, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlLockedConnects.recordDataPoint(mb.startTime, ts, val)
	return nil
}

// RecordMysqlLocksDataPoint adds a data point to mysql.locks metric.
func (mb *MetricsBuilder) RecordMysqlLocksDataPoint(ts pcommon.Timestamp, inputVal string, locksAttributeValue AttributeLocks) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlLocks, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlLocks.recordDataPoint(mb.startTime, ts, val, locksAttributeValue.String())
	return nil
}

// RecordMysqlLogOperationsDataPoint adds a data point to mysql.log_operations metric.
func (mb *MetricsBuilder) RecordMysqlLogOperationsDataPoint(ts pcommon.Timestamp, inputVal string, logOperationsAttributeValue AttributeLogOperations) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlLogOperations, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlLogOperations.recordDataPoint(mb.startTime, ts, val, logOperationsAttributeValue.String())
	return nil
}

// RecordMysqlMysqlxWorkerThreadsDataPoint adds a data point to mysql.mysqlx_worker_threads metric.
func (mb *MetricsBuilder) RecordMysqlMysqlxWorkerThreadsDataPoint(ts pcommon.Timestamp, inputVal string, mysqlxThreadsAttributeValue AttributeMysqlxThreads) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlMysqlxWorkerThreads, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlMysqlxWorkerThreads.recordDataPoint(mb.startTime, ts, val, mysqlxThreadsAttributeValue.String())
	return nil
}

// RecordMysqlOpenedResourcesDataPoint adds a data point to mysql.opened_resources metric.
func (mb *MetricsBuilder) RecordMysqlOpenedResourcesDataPoint(ts pcommon.Timestamp, inputVal string, openedResourcesAttributeValue AttributeOpenedResources) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlOpenedResources, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlOpenedResources.recordDataPoint(mb.startTime, ts, val, openedResourcesAttributeValue.String())
	return nil
}

// RecordMysqlOperationsDataPoint adds a data point to mysql.operations metric.
func (mb *MetricsBuilder) RecordMysqlOperationsDataPoint(ts pcommon.Timestamp, inputVal string, operationsAttributeValue AttributeOperations) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlOperations, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlOperations.recordDataPoint(mb.startTime, ts, val, operationsAttributeValue.String())
	return nil
}

// RecordMysqlPageOperationsDataPoint adds a data point to mysql.page_operations metric.
func (mb *MetricsBuilder) RecordMysqlPageOperationsDataPoint(ts pcommon.Timestamp, inputVal string, pageOperationsAttributeValue AttributePageOperations) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlPageOperations, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlPageOperations.recordDataPoint(mb.startTime, ts, val, pageOperationsAttributeValue.String())
	return nil
}

// RecordMysqlRowLocksDataPoint adds a data point to mysql.row_locks metric.
func (mb *MetricsBuilder) RecordMysqlRowLocksDataPoint(ts pcommon.Timestamp, inputVal string, rowLocksAttributeValue AttributeRowLocks) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlRowLocks, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlRowLocks.recordDataPoint(mb.startTime, ts, val, rowLocksAttributeValue.String())
	return nil
}

// RecordMysqlRowOperationsDataPoint adds a data point to mysql.row_operations metric.
func (mb *MetricsBuilder) RecordMysqlRowOperationsDataPoint(ts pcommon.Timestamp, inputVal string, rowOperationsAttributeValue AttributeRowOperations) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlRowOperations, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlRowOperations.recordDataPoint(mb.startTime, ts, val, rowOperationsAttributeValue.String())
	return nil
}

// RecordMysqlSortsDataPoint adds a data point to mysql.sorts metric.
func (mb *MetricsBuilder) RecordMysqlSortsDataPoint(ts pcommon.Timestamp, inputVal string, sortsAttributeValue AttributeSorts) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlSorts, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlSorts.recordDataPoint(mb.startTime, ts, val, sortsAttributeValue.String())
	return nil
}

// RecordMysqlStatementEventCountDataPoint adds a data point to mysql.statement_event.count metric.
func (mb *MetricsBuilder) RecordMysqlStatementEventCountDataPoint(ts pcommon.Timestamp, val int64, schemaAttributeValue string, digestAttributeValue string, digestTextAttributeValue string, eventStateAttributeValue AttributeEventState) {
	mb.metricMysqlStatementEventCount.recordDataPoint(mb.startTime, ts, val, schemaAttributeValue, digestAttributeValue, digestTextAttributeValue, eventStateAttributeValue.String())
}

// RecordMysqlStatementEventWaitTimeDataPoint adds a data point to mysql.statement_event.wait.time metric.
func (mb *MetricsBuilder) RecordMysqlStatementEventWaitTimeDataPoint(ts pcommon.Timestamp, val int64, schemaAttributeValue string, digestAttributeValue string, digestTextAttributeValue string) {
	mb.metricMysqlStatementEventWaitTime.recordDataPoint(mb.startTime, ts, val, schemaAttributeValue, digestAttributeValue, digestTextAttributeValue)
}

// RecordMysqlTableIoWaitCountDataPoint adds a data point to mysql.table.io.wait.count metric.
func (mb *MetricsBuilder) RecordMysqlTableIoWaitCountDataPoint(ts pcommon.Timestamp, val int64, ioWaitsOperationsAttributeValue AttributeIoWaitsOperations, tableNameAttributeValue string, schemaAttributeValue string) {
	mb.metricMysqlTableIoWaitCount.recordDataPoint(mb.startTime, ts, val, ioWaitsOperationsAttributeValue.String(), tableNameAttributeValue, schemaAttributeValue)
}

// RecordMysqlTableIoWaitTimeDataPoint adds a data point to mysql.table.io.wait.time metric.
func (mb *MetricsBuilder) RecordMysqlTableIoWaitTimeDataPoint(ts pcommon.Timestamp, val int64, ioWaitsOperationsAttributeValue AttributeIoWaitsOperations, tableNameAttributeValue string, schemaAttributeValue string) {
	mb.metricMysqlTableIoWaitTime.recordDataPoint(mb.startTime, ts, val, ioWaitsOperationsAttributeValue.String(), tableNameAttributeValue, schemaAttributeValue)
}

// RecordMysqlThreadsDataPoint adds a data point to mysql.threads metric.
func (mb *MetricsBuilder) RecordMysqlThreadsDataPoint(ts pcommon.Timestamp, inputVal string, threadsAttributeValue AttributeThreads) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlThreads, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlThreads.recordDataPoint(mb.startTime, ts, val, threadsAttributeValue.String())
	return nil
}

// RecordMysqlTmpResourcesDataPoint adds a data point to mysql.tmp_resources metric.
func (mb *MetricsBuilder) RecordMysqlTmpResourcesDataPoint(ts pcommon.Timestamp, inputVal string, tmpResourceAttributeValue AttributeTmpResource) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for MysqlTmpResources, value was %s: %w", inputVal, err)
	}
	mb.metricMysqlTmpResources.recordDataPoint(mb.startTime, ts, val, tmpResourceAttributeValue.String())
	return nil
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...metricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(mb)
	}
}
