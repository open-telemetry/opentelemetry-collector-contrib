// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"fmt"
	"strconv"
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/filter"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

// AttributeDatabaseStatus specifies the value database.status attribute.
type AttributeDatabaseStatus int

const (
	_ AttributeDatabaseStatus = iota
	AttributeDatabaseStatusOnline
	AttributeDatabaseStatusRestoring
	AttributeDatabaseStatusRecovering
	AttributeDatabaseStatusPendingRecovery
	AttributeDatabaseStatusSuspect
	AttributeDatabaseStatusOffline
)

// String returns the string representation of the AttributeDatabaseStatus.
func (av AttributeDatabaseStatus) String() string {
	switch av {
	case AttributeDatabaseStatusOnline:
		return "online"
	case AttributeDatabaseStatusRestoring:
		return "restoring"
	case AttributeDatabaseStatusRecovering:
		return "recovering"
	case AttributeDatabaseStatusPendingRecovery:
		return "pending_recovery"
	case AttributeDatabaseStatusSuspect:
		return "suspect"
	case AttributeDatabaseStatusOffline:
		return "offline"
	}
	return ""
}

// MapAttributeDatabaseStatus is a helper map of string to AttributeDatabaseStatus attribute value.
var MapAttributeDatabaseStatus = map[string]AttributeDatabaseStatus{
	"online":           AttributeDatabaseStatusOnline,
	"restoring":        AttributeDatabaseStatusRestoring,
	"recovering":       AttributeDatabaseStatusRecovering,
	"pending_recovery": AttributeDatabaseStatusPendingRecovery,
	"suspect":          AttributeDatabaseStatusSuspect,
	"offline":          AttributeDatabaseStatusOffline,
}

// AttributeDirection specifies the value direction attribute.
type AttributeDirection int

const (
	_ AttributeDirection = iota
	AttributeDirectionRead
	AttributeDirectionWrite
)

// String returns the string representation of the AttributeDirection.
func (av AttributeDirection) String() string {
	switch av {
	case AttributeDirectionRead:
		return "read"
	case AttributeDirectionWrite:
		return "write"
	}
	return ""
}

// MapAttributeDirection is a helper map of string to AttributeDirection attribute value.
var MapAttributeDirection = map[string]AttributeDirection{
	"read":  AttributeDirectionRead,
	"write": AttributeDirectionWrite,
}

// AttributePageOperations specifies the value page.operations attribute.
type AttributePageOperations int

const (
	_ AttributePageOperations = iota
	AttributePageOperationsRead
	AttributePageOperationsWrite
)

// String returns the string representation of the AttributePageOperations.
func (av AttributePageOperations) String() string {
	switch av {
	case AttributePageOperationsRead:
		return "read"
	case AttributePageOperationsWrite:
		return "write"
	}
	return ""
}

// MapAttributePageOperations is a helper map of string to AttributePageOperations attribute value.
var MapAttributePageOperations = map[string]AttributePageOperations{
	"read":  AttributePageOperationsRead,
	"write": AttributePageOperationsWrite,
}

// AttributeReplicaDirection specifies the value replica.direction attribute.
type AttributeReplicaDirection int

const (
	_ AttributeReplicaDirection = iota
	AttributeReplicaDirectionTransmit
	AttributeReplicaDirectionReceive
)

// String returns the string representation of the AttributeReplicaDirection.
func (av AttributeReplicaDirection) String() string {
	switch av {
	case AttributeReplicaDirectionTransmit:
		return "transmit"
	case AttributeReplicaDirectionReceive:
		return "receive"
	}
	return ""
}

// MapAttributeReplicaDirection is a helper map of string to AttributeReplicaDirection attribute value.
var MapAttributeReplicaDirection = map[string]AttributeReplicaDirection{
	"transmit": AttributeReplicaDirectionTransmit,
	"receive":  AttributeReplicaDirectionReceive,
}

// AttributeTableState specifies the value table.state attribute.
type AttributeTableState int

const (
	_ AttributeTableState = iota
	AttributeTableStateActive
	AttributeTableStateInactive
)

// String returns the string representation of the AttributeTableState.
func (av AttributeTableState) String() string {
	switch av {
	case AttributeTableStateActive:
		return "active"
	case AttributeTableStateInactive:
		return "inactive"
	}
	return ""
}

// MapAttributeTableState is a helper map of string to AttributeTableState attribute value.
var MapAttributeTableState = map[string]AttributeTableState{
	"active":   AttributeTableStateActive,
	"inactive": AttributeTableStateInactive,
}

// AttributeTableStatus specifies the value table.status attribute.
type AttributeTableStatus int

const (
	_ AttributeTableStatus = iota
	AttributeTableStatusTemporary
	AttributeTableStatusPermanent
)

// String returns the string representation of the AttributeTableStatus.
func (av AttributeTableStatus) String() string {
	switch av {
	case AttributeTableStatusTemporary:
		return "temporary"
	case AttributeTableStatusPermanent:
		return "permanent"
	}
	return ""
}

// MapAttributeTableStatus is a helper map of string to AttributeTableStatus attribute value.
var MapAttributeTableStatus = map[string]AttributeTableStatus{
	"temporary": AttributeTableStatusTemporary,
	"permanent": AttributeTableStatusPermanent,
}

// AttributeTempdbState specifies the value tempdb.state attribute.
type AttributeTempdbState int

const (
	_ AttributeTempdbState = iota
	AttributeTempdbStateFree
	AttributeTempdbStateUsed
)

// String returns the string representation of the AttributeTempdbState.
func (av AttributeTempdbState) String() string {
	switch av {
	case AttributeTempdbStateFree:
		return "free"
	case AttributeTempdbStateUsed:
		return "used"
	}
	return ""
}

// MapAttributeTempdbState is a helper map of string to AttributeTempdbState attribute value.
var MapAttributeTempdbState = map[string]AttributeTempdbState{
	"free": AttributeTempdbStateFree,
	"used": AttributeTempdbStateUsed,
}

var MetricsInfo = metricsInfo{
	SqlserverBatchRequestRate: metricInfo{
		Name: "sqlserver.batch.request.rate",
	},
	SqlserverBatchSQLCompilationRate: metricInfo{
		Name: "sqlserver.batch.sql_compilation.rate",
	},
	SqlserverBatchSQLRecompilationRate: metricInfo{
		Name: "sqlserver.batch.sql_recompilation.rate",
	},
	SqlserverDatabaseBackupOrRestoreRate: metricInfo{
		Name: "sqlserver.database.backup_or_restore.rate",
	},
	SqlserverDatabaseCount: metricInfo{
		Name: "sqlserver.database.count",
	},
	SqlserverDatabaseExecutionErrors: metricInfo{
		Name: "sqlserver.database.execution.errors",
	},
	SqlserverDatabaseFullScanRate: metricInfo{
		Name: "sqlserver.database.full_scan.rate",
	},
	SqlserverDatabaseIo: metricInfo{
		Name: "sqlserver.database.io",
	},
	SqlserverDatabaseLatency: metricInfo{
		Name: "sqlserver.database.latency",
	},
	SqlserverDatabaseOperations: metricInfo{
		Name: "sqlserver.database.operations",
	},
	SqlserverDatabaseTempdbSpace: metricInfo{
		Name: "sqlserver.database.tempdb.space",
	},
	SqlserverDatabaseTempdbVersionStoreSize: metricInfo{
		Name: "sqlserver.database.tempdb.version_store.size",
	},
	SqlserverDeadlockRate: metricInfo{
		Name: "sqlserver.deadlock.rate",
	},
	SqlserverIndexSearchRate: metricInfo{
		Name: "sqlserver.index.search.rate",
	},
	SqlserverLockTimeoutRate: metricInfo{
		Name: "sqlserver.lock.timeout.rate",
	},
	SqlserverLockWaitRate: metricInfo{
		Name: "sqlserver.lock.wait.rate",
	},
	SqlserverLockWaitTimeAvg: metricInfo{
		Name: "sqlserver.lock.wait_time.avg",
	},
	SqlserverLoginRate: metricInfo{
		Name: "sqlserver.login.rate",
	},
	SqlserverLogoutRate: metricInfo{
		Name: "sqlserver.logout.rate",
	},
	SqlserverMemoryGrantsPendingCount: metricInfo{
		Name: "sqlserver.memory.grants.pending.count",
	},
	SqlserverMemoryUsage: metricInfo{
		Name: "sqlserver.memory.usage",
	},
	SqlserverPageBufferCacheFreeListStallsRate: metricInfo{
		Name: "sqlserver.page.buffer_cache.free_list.stalls.rate",
	},
	SqlserverPageBufferCacheHitRatio: metricInfo{
		Name: "sqlserver.page.buffer_cache.hit_ratio",
	},
	SqlserverPageCheckpointFlushRate: metricInfo{
		Name: "sqlserver.page.checkpoint.flush.rate",
	},
	SqlserverPageLazyWriteRate: metricInfo{
		Name: "sqlserver.page.lazy_write.rate",
	},
	SqlserverPageLifeExpectancy: metricInfo{
		Name: "sqlserver.page.life_expectancy",
	},
	SqlserverPageLookupRate: metricInfo{
		Name: "sqlserver.page.lookup.rate",
	},
	SqlserverPageOperationRate: metricInfo{
		Name: "sqlserver.page.operation.rate",
	},
	SqlserverPageSplitRate: metricInfo{
		Name: "sqlserver.page.split.rate",
	},
	SqlserverProcessesBlocked: metricInfo{
		Name: "sqlserver.processes.blocked",
	},
	SqlserverReplicaDataRate: metricInfo{
		Name: "sqlserver.replica.data.rate",
	},
	SqlserverResourcePoolDiskOperations: metricInfo{
		Name: "sqlserver.resource_pool.disk.operations",
	},
	SqlserverResourcePoolDiskThrottledReadRate: metricInfo{
		Name: "sqlserver.resource_pool.disk.throttled.read.rate",
	},
	SqlserverResourcePoolDiskThrottledWriteRate: metricInfo{
		Name: "sqlserver.resource_pool.disk.throttled.write.rate",
	},
	SqlserverTableCount: metricInfo{
		Name: "sqlserver.table.count",
	},
	SqlserverTransactionDelay: metricInfo{
		Name: "sqlserver.transaction.delay",
	},
	SqlserverTransactionMirrorWriteRate: metricInfo{
		Name: "sqlserver.transaction.mirror_write.rate",
	},
	SqlserverTransactionRate: metricInfo{
		Name: "sqlserver.transaction.rate",
	},
	SqlserverTransactionWriteRate: metricInfo{
		Name: "sqlserver.transaction.write.rate",
	},
	SqlserverTransactionLogFlushDataRate: metricInfo{
		Name: "sqlserver.transaction_log.flush.data.rate",
	},
	SqlserverTransactionLogFlushRate: metricInfo{
		Name: "sqlserver.transaction_log.flush.rate",
	},
	SqlserverTransactionLogFlushWaitRate: metricInfo{
		Name: "sqlserver.transaction_log.flush.wait.rate",
	},
	SqlserverTransactionLogGrowthCount: metricInfo{
		Name: "sqlserver.transaction_log.growth.count",
	},
	SqlserverTransactionLogShrinkCount: metricInfo{
		Name: "sqlserver.transaction_log.shrink.count",
	},
	SqlserverTransactionLogUsage: metricInfo{
		Name: "sqlserver.transaction_log.usage",
	},
	SqlserverUserConnectionCount: metricInfo{
		Name: "sqlserver.user.connection.count",
	},
}

type metricsInfo struct {
	SqlserverBatchRequestRate                   metricInfo
	SqlserverBatchSQLCompilationRate            metricInfo
	SqlserverBatchSQLRecompilationRate          metricInfo
	SqlserverDatabaseBackupOrRestoreRate        metricInfo
	SqlserverDatabaseCount                      metricInfo
	SqlserverDatabaseExecutionErrors            metricInfo
	SqlserverDatabaseFullScanRate               metricInfo
	SqlserverDatabaseIo                         metricInfo
	SqlserverDatabaseLatency                    metricInfo
	SqlserverDatabaseOperations                 metricInfo
	SqlserverDatabaseTempdbSpace                metricInfo
	SqlserverDatabaseTempdbVersionStoreSize     metricInfo
	SqlserverDeadlockRate                       metricInfo
	SqlserverIndexSearchRate                    metricInfo
	SqlserverLockTimeoutRate                    metricInfo
	SqlserverLockWaitRate                       metricInfo
	SqlserverLockWaitTimeAvg                    metricInfo
	SqlserverLoginRate                          metricInfo
	SqlserverLogoutRate                         metricInfo
	SqlserverMemoryGrantsPendingCount           metricInfo
	SqlserverMemoryUsage                        metricInfo
	SqlserverPageBufferCacheFreeListStallsRate  metricInfo
	SqlserverPageBufferCacheHitRatio            metricInfo
	SqlserverPageCheckpointFlushRate            metricInfo
	SqlserverPageLazyWriteRate                  metricInfo
	SqlserverPageLifeExpectancy                 metricInfo
	SqlserverPageLookupRate                     metricInfo
	SqlserverPageOperationRate                  metricInfo
	SqlserverPageSplitRate                      metricInfo
	SqlserverProcessesBlocked                   metricInfo
	SqlserverReplicaDataRate                    metricInfo
	SqlserverResourcePoolDiskOperations         metricInfo
	SqlserverResourcePoolDiskThrottledReadRate  metricInfo
	SqlserverResourcePoolDiskThrottledWriteRate metricInfo
	SqlserverTableCount                         metricInfo
	SqlserverTransactionDelay                   metricInfo
	SqlserverTransactionMirrorWriteRate         metricInfo
	SqlserverTransactionRate                    metricInfo
	SqlserverTransactionWriteRate               metricInfo
	SqlserverTransactionLogFlushDataRate        metricInfo
	SqlserverTransactionLogFlushRate            metricInfo
	SqlserverTransactionLogFlushWaitRate        metricInfo
	SqlserverTransactionLogGrowthCount          metricInfo
	SqlserverTransactionLogShrinkCount          metricInfo
	SqlserverTransactionLogUsage                metricInfo
	SqlserverUserConnectionCount                metricInfo
}

type metricInfo struct {
	Name string
}

type metricSqlserverBatchRequestRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.batch.request.rate metric with initial data.
func (m *metricSqlserverBatchRequestRate) init() {
	m.data.SetName("sqlserver.batch.request.rate")
	m.data.SetDescription("Number of batch requests received by SQL Server.")
	m.data.SetUnit("{requests}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverBatchRequestRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverBatchRequestRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverBatchRequestRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverBatchRequestRate(cfg MetricConfig) metricSqlserverBatchRequestRate {
	m := metricSqlserverBatchRequestRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverBatchSQLCompilationRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.batch.sql_compilation.rate metric with initial data.
func (m *metricSqlserverBatchSQLCompilationRate) init() {
	m.data.SetName("sqlserver.batch.sql_compilation.rate")
	m.data.SetDescription("Number of SQL compilations needed.")
	m.data.SetUnit("{compilations}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverBatchSQLCompilationRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverBatchSQLCompilationRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverBatchSQLCompilationRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverBatchSQLCompilationRate(cfg MetricConfig) metricSqlserverBatchSQLCompilationRate {
	m := metricSqlserverBatchSQLCompilationRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverBatchSQLRecompilationRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.batch.sql_recompilation.rate metric with initial data.
func (m *metricSqlserverBatchSQLRecompilationRate) init() {
	m.data.SetName("sqlserver.batch.sql_recompilation.rate")
	m.data.SetDescription("Number of SQL recompilations needed.")
	m.data.SetUnit("{compilations}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverBatchSQLRecompilationRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverBatchSQLRecompilationRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverBatchSQLRecompilationRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverBatchSQLRecompilationRate(cfg MetricConfig) metricSqlserverBatchSQLRecompilationRate {
	m := metricSqlserverBatchSQLRecompilationRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverDatabaseBackupOrRestoreRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.database.backup_or_restore.rate metric with initial data.
func (m *metricSqlserverDatabaseBackupOrRestoreRate) init() {
	m.data.SetName("sqlserver.database.backup_or_restore.rate")
	m.data.SetDescription("Total number of backups/restores.")
	m.data.SetUnit("“{backups_or_restores}/s”")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverDatabaseBackupOrRestoreRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverDatabaseBackupOrRestoreRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverDatabaseBackupOrRestoreRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverDatabaseBackupOrRestoreRate(cfg MetricConfig) metricSqlserverDatabaseBackupOrRestoreRate {
	m := metricSqlserverDatabaseBackupOrRestoreRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverDatabaseCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.database.count metric with initial data.
func (m *metricSqlserverDatabaseCount) init() {
	m.data.SetName("sqlserver.database.count")
	m.data.SetDescription("The number of databases")
	m.data.SetUnit("{databases}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSqlserverDatabaseCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, databaseStatusAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("database.status", databaseStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverDatabaseCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverDatabaseCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverDatabaseCount(cfg MetricConfig) metricSqlserverDatabaseCount {
	m := metricSqlserverDatabaseCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverDatabaseExecutionErrors struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.database.execution.errors metric with initial data.
func (m *metricSqlserverDatabaseExecutionErrors) init() {
	m.data.SetName("sqlserver.database.execution.errors")
	m.data.SetDescription("Number of execution errors.")
	m.data.SetUnit("“{errors}”")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverDatabaseExecutionErrors) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverDatabaseExecutionErrors) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverDatabaseExecutionErrors) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverDatabaseExecutionErrors(cfg MetricConfig) metricSqlserverDatabaseExecutionErrors {
	m := metricSqlserverDatabaseExecutionErrors{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverDatabaseFullScanRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.database.full_scan.rate metric with initial data.
func (m *metricSqlserverDatabaseFullScanRate) init() {
	m.data.SetName("sqlserver.database.full_scan.rate")
	m.data.SetDescription("The number of unrestricted full table or index scans.")
	m.data.SetUnit("{scans}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverDatabaseFullScanRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverDatabaseFullScanRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverDatabaseFullScanRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverDatabaseFullScanRate(cfg MetricConfig) metricSqlserverDatabaseFullScanRate {
	m := metricSqlserverDatabaseFullScanRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverDatabaseIo struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.database.io metric with initial data.
func (m *metricSqlserverDatabaseIo) init() {
	m.data.SetName("sqlserver.database.io")
	m.data.SetDescription("The number of bytes of I/O on this file.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSqlserverDatabaseIo) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, physicalFilenameAttributeValue string, logicalFilenameAttributeValue string, fileTypeAttributeValue string, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("physical_filename", physicalFilenameAttributeValue)
	dp.Attributes().PutStr("logical_filename", logicalFilenameAttributeValue)
	dp.Attributes().PutStr("file_type", fileTypeAttributeValue)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverDatabaseIo) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverDatabaseIo) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverDatabaseIo(cfg MetricConfig) metricSqlserverDatabaseIo {
	m := metricSqlserverDatabaseIo{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverDatabaseLatency struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.database.latency metric with initial data.
func (m *metricSqlserverDatabaseLatency) init() {
	m.data.SetName("sqlserver.database.latency")
	m.data.SetDescription("Total time that the users waited for I/O issued on this file.")
	m.data.SetUnit("s")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSqlserverDatabaseLatency) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, physicalFilenameAttributeValue string, logicalFilenameAttributeValue string, fileTypeAttributeValue string, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("physical_filename", physicalFilenameAttributeValue)
	dp.Attributes().PutStr("logical_filename", logicalFilenameAttributeValue)
	dp.Attributes().PutStr("file_type", fileTypeAttributeValue)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverDatabaseLatency) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverDatabaseLatency) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverDatabaseLatency(cfg MetricConfig) metricSqlserverDatabaseLatency {
	m := metricSqlserverDatabaseLatency{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverDatabaseOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.database.operations metric with initial data.
func (m *metricSqlserverDatabaseOperations) init() {
	m.data.SetName("sqlserver.database.operations")
	m.data.SetDescription("The number of operations issued on the file.")
	m.data.SetUnit("{operations}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSqlserverDatabaseOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, physicalFilenameAttributeValue string, logicalFilenameAttributeValue string, fileTypeAttributeValue string, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("physical_filename", physicalFilenameAttributeValue)
	dp.Attributes().PutStr("logical_filename", logicalFilenameAttributeValue)
	dp.Attributes().PutStr("file_type", fileTypeAttributeValue)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverDatabaseOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverDatabaseOperations) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverDatabaseOperations(cfg MetricConfig) metricSqlserverDatabaseOperations {
	m := metricSqlserverDatabaseOperations{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverDatabaseTempdbSpace struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.database.tempdb.space metric with initial data.
func (m *metricSqlserverDatabaseTempdbSpace) init() {
	m.data.SetName("sqlserver.database.tempdb.space")
	m.data.SetDescription("Total free space in temporary DB.")
	m.data.SetUnit("“KB”")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSqlserverDatabaseTempdbSpace) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, tempdbStateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("tempdb.state", tempdbStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverDatabaseTempdbSpace) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverDatabaseTempdbSpace) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverDatabaseTempdbSpace(cfg MetricConfig) metricSqlserverDatabaseTempdbSpace {
	m := metricSqlserverDatabaseTempdbSpace{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverDatabaseTempdbVersionStoreSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.database.tempdb.version_store.size metric with initial data.
func (m *metricSqlserverDatabaseTempdbVersionStoreSize) init() {
	m.data.SetName("sqlserver.database.tempdb.version_store.size")
	m.data.SetDescription("TempDB version store size.")
	m.data.SetUnit("“KB”")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverDatabaseTempdbVersionStoreSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverDatabaseTempdbVersionStoreSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverDatabaseTempdbVersionStoreSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverDatabaseTempdbVersionStoreSize(cfg MetricConfig) metricSqlserverDatabaseTempdbVersionStoreSize {
	m := metricSqlserverDatabaseTempdbVersionStoreSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverDeadlockRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.deadlock.rate metric with initial data.
func (m *metricSqlserverDeadlockRate) init() {
	m.data.SetName("sqlserver.deadlock.rate")
	m.data.SetDescription("Total number of deadlocks.")
	m.data.SetUnit("“{deadlocks}/s”")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverDeadlockRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverDeadlockRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverDeadlockRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverDeadlockRate(cfg MetricConfig) metricSqlserverDeadlockRate {
	m := metricSqlserverDeadlockRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverIndexSearchRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.index.search.rate metric with initial data.
func (m *metricSqlserverIndexSearchRate) init() {
	m.data.SetName("sqlserver.index.search.rate")
	m.data.SetDescription("Total number of index searches.")
	m.data.SetUnit("“{searches}/s”")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverIndexSearchRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverIndexSearchRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverIndexSearchRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverIndexSearchRate(cfg MetricConfig) metricSqlserverIndexSearchRate {
	m := metricSqlserverIndexSearchRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverLockTimeoutRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.lock.timeout.rate metric with initial data.
func (m *metricSqlserverLockTimeoutRate) init() {
	m.data.SetName("sqlserver.lock.timeout.rate")
	m.data.SetDescription("Total number of lock timeouts.")
	m.data.SetUnit("“{timeouts}/s”")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverLockTimeoutRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverLockTimeoutRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverLockTimeoutRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverLockTimeoutRate(cfg MetricConfig) metricSqlserverLockTimeoutRate {
	m := metricSqlserverLockTimeoutRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverLockWaitRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.lock.wait.rate metric with initial data.
func (m *metricSqlserverLockWaitRate) init() {
	m.data.SetName("sqlserver.lock.wait.rate")
	m.data.SetDescription("Number of lock requests resulting in a wait.")
	m.data.SetUnit("{requests}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverLockWaitRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverLockWaitRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverLockWaitRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverLockWaitRate(cfg MetricConfig) metricSqlserverLockWaitRate {
	m := metricSqlserverLockWaitRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverLockWaitTimeAvg struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.lock.wait_time.avg metric with initial data.
func (m *metricSqlserverLockWaitTimeAvg) init() {
	m.data.SetName("sqlserver.lock.wait_time.avg")
	m.data.SetDescription("Average wait time for all lock requests that had to wait.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverLockWaitTimeAvg) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverLockWaitTimeAvg) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverLockWaitTimeAvg) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverLockWaitTimeAvg(cfg MetricConfig) metricSqlserverLockWaitTimeAvg {
	m := metricSqlserverLockWaitTimeAvg{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverLoginRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.login.rate metric with initial data.
func (m *metricSqlserverLoginRate) init() {
	m.data.SetName("sqlserver.login.rate")
	m.data.SetDescription("Total number of logins.")
	m.data.SetUnit("“{logins}/s”")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverLoginRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverLoginRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverLoginRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverLoginRate(cfg MetricConfig) metricSqlserverLoginRate {
	m := metricSqlserverLoginRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverLogoutRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.logout.rate metric with initial data.
func (m *metricSqlserverLogoutRate) init() {
	m.data.SetName("sqlserver.logout.rate")
	m.data.SetDescription("Total number of logouts.")
	m.data.SetUnit("“{logouts}/s”")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverLogoutRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverLogoutRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverLogoutRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverLogoutRate(cfg MetricConfig) metricSqlserverLogoutRate {
	m := metricSqlserverLogoutRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverMemoryGrantsPendingCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.memory.grants.pending.count metric with initial data.
func (m *metricSqlserverMemoryGrantsPendingCount) init() {
	m.data.SetName("sqlserver.memory.grants.pending.count")
	m.data.SetDescription("Total number of memory grants pending.")
	m.data.SetUnit("“{grants}”")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSqlserverMemoryGrantsPendingCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverMemoryGrantsPendingCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverMemoryGrantsPendingCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverMemoryGrantsPendingCount(cfg MetricConfig) metricSqlserverMemoryGrantsPendingCount {
	m := metricSqlserverMemoryGrantsPendingCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverMemoryUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.memory.usage metric with initial data.
func (m *metricSqlserverMemoryUsage) init() {
	m.data.SetName("sqlserver.memory.usage")
	m.data.SetDescription("Total memory in use.")
	m.data.SetUnit("“KB”")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSqlserverMemoryUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverMemoryUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverMemoryUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverMemoryUsage(cfg MetricConfig) metricSqlserverMemoryUsage {
	m := metricSqlserverMemoryUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverPageBufferCacheFreeListStallsRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.page.buffer_cache.free_list.stalls.rate metric with initial data.
func (m *metricSqlserverPageBufferCacheFreeListStallsRate) init() {
	m.data.SetName("sqlserver.page.buffer_cache.free_list.stalls.rate")
	m.data.SetDescription("Number of free list stalls.")
	m.data.SetUnit("“{stalls}/s”")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverPageBufferCacheFreeListStallsRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverPageBufferCacheFreeListStallsRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverPageBufferCacheFreeListStallsRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverPageBufferCacheFreeListStallsRate(cfg MetricConfig) metricSqlserverPageBufferCacheFreeListStallsRate {
	m := metricSqlserverPageBufferCacheFreeListStallsRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverPageBufferCacheHitRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.page.buffer_cache.hit_ratio metric with initial data.
func (m *metricSqlserverPageBufferCacheHitRatio) init() {
	m.data.SetName("sqlserver.page.buffer_cache.hit_ratio")
	m.data.SetDescription("Pages found in the buffer pool without having to read from disk.")
	m.data.SetUnit("%")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverPageBufferCacheHitRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverPageBufferCacheHitRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverPageBufferCacheHitRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverPageBufferCacheHitRatio(cfg MetricConfig) metricSqlserverPageBufferCacheHitRatio {
	m := metricSqlserverPageBufferCacheHitRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverPageCheckpointFlushRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.page.checkpoint.flush.rate metric with initial data.
func (m *metricSqlserverPageCheckpointFlushRate) init() {
	m.data.SetName("sqlserver.page.checkpoint.flush.rate")
	m.data.SetDescription("Number of pages flushed by operations requiring dirty pages to be flushed.")
	m.data.SetUnit("{pages}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverPageCheckpointFlushRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverPageCheckpointFlushRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverPageCheckpointFlushRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverPageCheckpointFlushRate(cfg MetricConfig) metricSqlserverPageCheckpointFlushRate {
	m := metricSqlserverPageCheckpointFlushRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverPageLazyWriteRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.page.lazy_write.rate metric with initial data.
func (m *metricSqlserverPageLazyWriteRate) init() {
	m.data.SetName("sqlserver.page.lazy_write.rate")
	m.data.SetDescription("Number of lazy writes moving dirty pages to disk.")
	m.data.SetUnit("{writes}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverPageLazyWriteRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverPageLazyWriteRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverPageLazyWriteRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverPageLazyWriteRate(cfg MetricConfig) metricSqlserverPageLazyWriteRate {
	m := metricSqlserverPageLazyWriteRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverPageLifeExpectancy struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.page.life_expectancy metric with initial data.
func (m *metricSqlserverPageLifeExpectancy) init() {
	m.data.SetName("sqlserver.page.life_expectancy")
	m.data.SetDescription("Time a page will stay in the buffer pool.")
	m.data.SetUnit("s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverPageLifeExpectancy) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverPageLifeExpectancy) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverPageLifeExpectancy) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverPageLifeExpectancy(cfg MetricConfig) metricSqlserverPageLifeExpectancy {
	m := metricSqlserverPageLifeExpectancy{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverPageLookupRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.page.lookup.rate metric with initial data.
func (m *metricSqlserverPageLookupRate) init() {
	m.data.SetName("sqlserver.page.lookup.rate")
	m.data.SetDescription("Total number of page lookups.")
	m.data.SetUnit("“{lookups}/s”")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverPageLookupRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverPageLookupRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverPageLookupRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverPageLookupRate(cfg MetricConfig) metricSqlserverPageLookupRate {
	m := metricSqlserverPageLookupRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverPageOperationRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.page.operation.rate metric with initial data.
func (m *metricSqlserverPageOperationRate) init() {
	m.data.SetName("sqlserver.page.operation.rate")
	m.data.SetDescription("Number of physical database page operations issued.")
	m.data.SetUnit("{operations}/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSqlserverPageOperationRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, pageOperationsAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("type", pageOperationsAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverPageOperationRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverPageOperationRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverPageOperationRate(cfg MetricConfig) metricSqlserverPageOperationRate {
	m := metricSqlserverPageOperationRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverPageSplitRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.page.split.rate metric with initial data.
func (m *metricSqlserverPageSplitRate) init() {
	m.data.SetName("sqlserver.page.split.rate")
	m.data.SetDescription("Number of pages split as a result of overflowing index pages.")
	m.data.SetUnit("{pages}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverPageSplitRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverPageSplitRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverPageSplitRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverPageSplitRate(cfg MetricConfig) metricSqlserverPageSplitRate {
	m := metricSqlserverPageSplitRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverProcessesBlocked struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.processes.blocked metric with initial data.
func (m *metricSqlserverProcessesBlocked) init() {
	m.data.SetName("sqlserver.processes.blocked")
	m.data.SetDescription("The number of processes that are currently blocked")
	m.data.SetUnit("{processes}")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverProcessesBlocked) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverProcessesBlocked) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverProcessesBlocked) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverProcessesBlocked(cfg MetricConfig) metricSqlserverProcessesBlocked {
	m := metricSqlserverProcessesBlocked{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverReplicaDataRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.replica.data.rate metric with initial data.
func (m *metricSqlserverReplicaDataRate) init() {
	m.data.SetName("sqlserver.replica.data.rate")
	m.data.SetDescription("Throughput rate of replica data.")
	m.data.SetUnit("By/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSqlserverReplicaDataRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, replicaDirectionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("replica.direction", replicaDirectionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverReplicaDataRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverReplicaDataRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverReplicaDataRate(cfg MetricConfig) metricSqlserverReplicaDataRate {
	m := metricSqlserverReplicaDataRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverResourcePoolDiskOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.resource_pool.disk.operations metric with initial data.
func (m *metricSqlserverResourcePoolDiskOperations) init() {
	m.data.SetName("sqlserver.resource_pool.disk.operations")
	m.data.SetDescription("The rate of operations issued.")
	m.data.SetUnit("{operations}/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSqlserverResourcePoolDiskOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverResourcePoolDiskOperations) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverResourcePoolDiskOperations) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverResourcePoolDiskOperations(cfg MetricConfig) metricSqlserverResourcePoolDiskOperations {
	m := metricSqlserverResourcePoolDiskOperations{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverResourcePoolDiskThrottledReadRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.resource_pool.disk.throttled.read.rate metric with initial data.
func (m *metricSqlserverResourcePoolDiskThrottledReadRate) init() {
	m.data.SetName("sqlserver.resource_pool.disk.throttled.read.rate")
	m.data.SetDescription("The number of read operations that were throttled in the last second")
	m.data.SetUnit("{reads}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverResourcePoolDiskThrottledReadRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverResourcePoolDiskThrottledReadRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverResourcePoolDiskThrottledReadRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverResourcePoolDiskThrottledReadRate(cfg MetricConfig) metricSqlserverResourcePoolDiskThrottledReadRate {
	m := metricSqlserverResourcePoolDiskThrottledReadRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverResourcePoolDiskThrottledWriteRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.resource_pool.disk.throttled.write.rate metric with initial data.
func (m *metricSqlserverResourcePoolDiskThrottledWriteRate) init() {
	m.data.SetName("sqlserver.resource_pool.disk.throttled.write.rate")
	m.data.SetDescription("The number of write operations that were throttled in the last second")
	m.data.SetUnit("{writes}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverResourcePoolDiskThrottledWriteRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverResourcePoolDiskThrottledWriteRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverResourcePoolDiskThrottledWriteRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverResourcePoolDiskThrottledWriteRate(cfg MetricConfig) metricSqlserverResourcePoolDiskThrottledWriteRate {
	m := metricSqlserverResourcePoolDiskThrottledWriteRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTableCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.table.count metric with initial data.
func (m *metricSqlserverTableCount) init() {
	m.data.SetName("sqlserver.table.count")
	m.data.SetDescription("The number of tables.")
	m.data.SetUnit("“{tables}”")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSqlserverTableCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, tableStateAttributeValue string, tableStatusAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("table.state", tableStateAttributeValue)
	dp.Attributes().PutStr("table.status", tableStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTableCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTableCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTableCount(cfg MetricConfig) metricSqlserverTableCount {
	m := metricSqlserverTableCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionDelay struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction.delay metric with initial data.
func (m *metricSqlserverTransactionDelay) init() {
	m.data.SetName("sqlserver.transaction.delay")
	m.data.SetDescription("Time consumed in transaction delays.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSqlserverTransactionDelay) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionDelay) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionDelay) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionDelay(cfg MetricConfig) metricSqlserverTransactionDelay {
	m := metricSqlserverTransactionDelay{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionMirrorWriteRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction.mirror_write.rate metric with initial data.
func (m *metricSqlserverTransactionMirrorWriteRate) init() {
	m.data.SetName("sqlserver.transaction.mirror_write.rate")
	m.data.SetDescription("Total number of mirror write transactions.")
	m.data.SetUnit("“{transactions}/s”")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverTransactionMirrorWriteRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionMirrorWriteRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionMirrorWriteRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionMirrorWriteRate(cfg MetricConfig) metricSqlserverTransactionMirrorWriteRate {
	m := metricSqlserverTransactionMirrorWriteRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction.rate metric with initial data.
func (m *metricSqlserverTransactionRate) init() {
	m.data.SetName("sqlserver.transaction.rate")
	m.data.SetDescription("Number of transactions started for the database (not including XTP-only transactions).")
	m.data.SetUnit("{transactions}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverTransactionRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionRate(cfg MetricConfig) metricSqlserverTransactionRate {
	m := metricSqlserverTransactionRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionWriteRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction.write.rate metric with initial data.
func (m *metricSqlserverTransactionWriteRate) init() {
	m.data.SetName("sqlserver.transaction.write.rate")
	m.data.SetDescription("Number of transactions that wrote to the database and committed.")
	m.data.SetUnit("{transactions}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverTransactionWriteRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionWriteRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionWriteRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionWriteRate(cfg MetricConfig) metricSqlserverTransactionWriteRate {
	m := metricSqlserverTransactionWriteRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionLogFlushDataRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction_log.flush.data.rate metric with initial data.
func (m *metricSqlserverTransactionLogFlushDataRate) init() {
	m.data.SetName("sqlserver.transaction_log.flush.data.rate")
	m.data.SetDescription("Total number of log bytes flushed.")
	m.data.SetUnit("By/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverTransactionLogFlushDataRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionLogFlushDataRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionLogFlushDataRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionLogFlushDataRate(cfg MetricConfig) metricSqlserverTransactionLogFlushDataRate {
	m := metricSqlserverTransactionLogFlushDataRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionLogFlushRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction_log.flush.rate metric with initial data.
func (m *metricSqlserverTransactionLogFlushRate) init() {
	m.data.SetName("sqlserver.transaction_log.flush.rate")
	m.data.SetDescription("Number of log flushes.")
	m.data.SetUnit("{flushes}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverTransactionLogFlushRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionLogFlushRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionLogFlushRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionLogFlushRate(cfg MetricConfig) metricSqlserverTransactionLogFlushRate {
	m := metricSqlserverTransactionLogFlushRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionLogFlushWaitRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction_log.flush.wait.rate metric with initial data.
func (m *metricSqlserverTransactionLogFlushWaitRate) init() {
	m.data.SetName("sqlserver.transaction_log.flush.wait.rate")
	m.data.SetDescription("Number of commits waiting for a transaction log flush.")
	m.data.SetUnit("{commits}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverTransactionLogFlushWaitRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionLogFlushWaitRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionLogFlushWaitRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionLogFlushWaitRate(cfg MetricConfig) metricSqlserverTransactionLogFlushWaitRate {
	m := metricSqlserverTransactionLogFlushWaitRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionLogGrowthCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction_log.growth.count metric with initial data.
func (m *metricSqlserverTransactionLogGrowthCount) init() {
	m.data.SetName("sqlserver.transaction_log.growth.count")
	m.data.SetDescription("Total number of transaction log expansions for a database.")
	m.data.SetUnit("{growths}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSqlserverTransactionLogGrowthCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionLogGrowthCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionLogGrowthCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionLogGrowthCount(cfg MetricConfig) metricSqlserverTransactionLogGrowthCount {
	m := metricSqlserverTransactionLogGrowthCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionLogShrinkCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction_log.shrink.count metric with initial data.
func (m *metricSqlserverTransactionLogShrinkCount) init() {
	m.data.SetName("sqlserver.transaction_log.shrink.count")
	m.data.SetDescription("Total number of transaction log shrinks for a database.")
	m.data.SetUnit("{shrinks}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSqlserverTransactionLogShrinkCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionLogShrinkCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionLogShrinkCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionLogShrinkCount(cfg MetricConfig) metricSqlserverTransactionLogShrinkCount {
	m := metricSqlserverTransactionLogShrinkCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionLogUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction_log.usage metric with initial data.
func (m *metricSqlserverTransactionLogUsage) init() {
	m.data.SetName("sqlserver.transaction_log.usage")
	m.data.SetDescription("Percent of transaction log space used.")
	m.data.SetUnit("%")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverTransactionLogUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionLogUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionLogUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionLogUsage(cfg MetricConfig) metricSqlserverTransactionLogUsage {
	m := metricSqlserverTransactionLogUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverUserConnectionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.user.connection.count metric with initial data.
func (m *metricSqlserverUserConnectionCount) init() {
	m.data.SetName("sqlserver.user.connection.count")
	m.data.SetDescription("Number of users connected to the SQL Server.")
	m.data.SetUnit("{connections}")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverUserConnectionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverUserConnectionCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverUserConnectionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverUserConnectionCount(cfg MetricConfig) metricSqlserverUserConnectionCount {
	m := metricSqlserverUserConnectionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config                                            MetricsBuilderConfig // config of the metrics builder.
	startTime                                         pcommon.Timestamp    // start time that will be applied to all recorded data points.
	metricsCapacity                                   int                  // maximum observed number of metrics per resource.
	metricsBuffer                                     pmetric.Metrics      // accumulates metrics data before emitting.
	buildInfo                                         component.BuildInfo  // contains version information.
	resourceAttributeIncludeFilter                    map[string]filter.Filter
	resourceAttributeExcludeFilter                    map[string]filter.Filter
	metricSqlserverBatchRequestRate                   metricSqlserverBatchRequestRate
	metricSqlserverBatchSQLCompilationRate            metricSqlserverBatchSQLCompilationRate
	metricSqlserverBatchSQLRecompilationRate          metricSqlserverBatchSQLRecompilationRate
	metricSqlserverDatabaseBackupOrRestoreRate        metricSqlserverDatabaseBackupOrRestoreRate
	metricSqlserverDatabaseCount                      metricSqlserverDatabaseCount
	metricSqlserverDatabaseExecutionErrors            metricSqlserverDatabaseExecutionErrors
	metricSqlserverDatabaseFullScanRate               metricSqlserverDatabaseFullScanRate
	metricSqlserverDatabaseIo                         metricSqlserverDatabaseIo
	metricSqlserverDatabaseLatency                    metricSqlserverDatabaseLatency
	metricSqlserverDatabaseOperations                 metricSqlserverDatabaseOperations
	metricSqlserverDatabaseTempdbSpace                metricSqlserverDatabaseTempdbSpace
	metricSqlserverDatabaseTempdbVersionStoreSize     metricSqlserverDatabaseTempdbVersionStoreSize
	metricSqlserverDeadlockRate                       metricSqlserverDeadlockRate
	metricSqlserverIndexSearchRate                    metricSqlserverIndexSearchRate
	metricSqlserverLockTimeoutRate                    metricSqlserverLockTimeoutRate
	metricSqlserverLockWaitRate                       metricSqlserverLockWaitRate
	metricSqlserverLockWaitTimeAvg                    metricSqlserverLockWaitTimeAvg
	metricSqlserverLoginRate                          metricSqlserverLoginRate
	metricSqlserverLogoutRate                         metricSqlserverLogoutRate
	metricSqlserverMemoryGrantsPendingCount           metricSqlserverMemoryGrantsPendingCount
	metricSqlserverMemoryUsage                        metricSqlserverMemoryUsage
	metricSqlserverPageBufferCacheFreeListStallsRate  metricSqlserverPageBufferCacheFreeListStallsRate
	metricSqlserverPageBufferCacheHitRatio            metricSqlserverPageBufferCacheHitRatio
	metricSqlserverPageCheckpointFlushRate            metricSqlserverPageCheckpointFlushRate
	metricSqlserverPageLazyWriteRate                  metricSqlserverPageLazyWriteRate
	metricSqlserverPageLifeExpectancy                 metricSqlserverPageLifeExpectancy
	metricSqlserverPageLookupRate                     metricSqlserverPageLookupRate
	metricSqlserverPageOperationRate                  metricSqlserverPageOperationRate
	metricSqlserverPageSplitRate                      metricSqlserverPageSplitRate
	metricSqlserverProcessesBlocked                   metricSqlserverProcessesBlocked
	metricSqlserverReplicaDataRate                    metricSqlserverReplicaDataRate
	metricSqlserverResourcePoolDiskOperations         metricSqlserverResourcePoolDiskOperations
	metricSqlserverResourcePoolDiskThrottledReadRate  metricSqlserverResourcePoolDiskThrottledReadRate
	metricSqlserverResourcePoolDiskThrottledWriteRate metricSqlserverResourcePoolDiskThrottledWriteRate
	metricSqlserverTableCount                         metricSqlserverTableCount
	metricSqlserverTransactionDelay                   metricSqlserverTransactionDelay
	metricSqlserverTransactionMirrorWriteRate         metricSqlserverTransactionMirrorWriteRate
	metricSqlserverTransactionRate                    metricSqlserverTransactionRate
	metricSqlserverTransactionWriteRate               metricSqlserverTransactionWriteRate
	metricSqlserverTransactionLogFlushDataRate        metricSqlserverTransactionLogFlushDataRate
	metricSqlserverTransactionLogFlushRate            metricSqlserverTransactionLogFlushRate
	metricSqlserverTransactionLogFlushWaitRate        metricSqlserverTransactionLogFlushWaitRate
	metricSqlserverTransactionLogGrowthCount          metricSqlserverTransactionLogGrowthCount
	metricSqlserverTransactionLogShrinkCount          metricSqlserverTransactionLogShrinkCount
	metricSqlserverTransactionLogUsage                metricSqlserverTransactionLogUsage
	metricSqlserverUserConnectionCount                metricSqlserverUserConnectionCount
}

// MetricBuilderOption applies changes to default metrics builder.
type MetricBuilderOption interface {
	apply(*MetricsBuilder)
}

type metricBuilderOptionFunc func(mb *MetricsBuilder)

func (mbof metricBuilderOptionFunc) apply(mb *MetricsBuilder) {
	mbof(mb)
}

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) MetricBuilderOption {
	return metricBuilderOptionFunc(func(mb *MetricsBuilder) {
		mb.startTime = startTime
	})
}
func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.Settings, options ...MetricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:                                   mbc,
		startTime:                                pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:                            pmetric.NewMetrics(),
		buildInfo:                                settings.BuildInfo,
		metricSqlserverBatchRequestRate:          newMetricSqlserverBatchRequestRate(mbc.Metrics.SqlserverBatchRequestRate),
		metricSqlserverBatchSQLCompilationRate:   newMetricSqlserverBatchSQLCompilationRate(mbc.Metrics.SqlserverBatchSQLCompilationRate),
		metricSqlserverBatchSQLRecompilationRate: newMetricSqlserverBatchSQLRecompilationRate(mbc.Metrics.SqlserverBatchSQLRecompilationRate),
		metricSqlserverDatabaseBackupOrRestoreRate:        newMetricSqlserverDatabaseBackupOrRestoreRate(mbc.Metrics.SqlserverDatabaseBackupOrRestoreRate),
		metricSqlserverDatabaseCount:                      newMetricSqlserverDatabaseCount(mbc.Metrics.SqlserverDatabaseCount),
		metricSqlserverDatabaseExecutionErrors:            newMetricSqlserverDatabaseExecutionErrors(mbc.Metrics.SqlserverDatabaseExecutionErrors),
		metricSqlserverDatabaseFullScanRate:               newMetricSqlserverDatabaseFullScanRate(mbc.Metrics.SqlserverDatabaseFullScanRate),
		metricSqlserverDatabaseIo:                         newMetricSqlserverDatabaseIo(mbc.Metrics.SqlserverDatabaseIo),
		metricSqlserverDatabaseLatency:                    newMetricSqlserverDatabaseLatency(mbc.Metrics.SqlserverDatabaseLatency),
		metricSqlserverDatabaseOperations:                 newMetricSqlserverDatabaseOperations(mbc.Metrics.SqlserverDatabaseOperations),
		metricSqlserverDatabaseTempdbSpace:                newMetricSqlserverDatabaseTempdbSpace(mbc.Metrics.SqlserverDatabaseTempdbSpace),
		metricSqlserverDatabaseTempdbVersionStoreSize:     newMetricSqlserverDatabaseTempdbVersionStoreSize(mbc.Metrics.SqlserverDatabaseTempdbVersionStoreSize),
		metricSqlserverDeadlockRate:                       newMetricSqlserverDeadlockRate(mbc.Metrics.SqlserverDeadlockRate),
		metricSqlserverIndexSearchRate:                    newMetricSqlserverIndexSearchRate(mbc.Metrics.SqlserverIndexSearchRate),
		metricSqlserverLockTimeoutRate:                    newMetricSqlserverLockTimeoutRate(mbc.Metrics.SqlserverLockTimeoutRate),
		metricSqlserverLockWaitRate:                       newMetricSqlserverLockWaitRate(mbc.Metrics.SqlserverLockWaitRate),
		metricSqlserverLockWaitTimeAvg:                    newMetricSqlserverLockWaitTimeAvg(mbc.Metrics.SqlserverLockWaitTimeAvg),
		metricSqlserverLoginRate:                          newMetricSqlserverLoginRate(mbc.Metrics.SqlserverLoginRate),
		metricSqlserverLogoutRate:                         newMetricSqlserverLogoutRate(mbc.Metrics.SqlserverLogoutRate),
		metricSqlserverMemoryGrantsPendingCount:           newMetricSqlserverMemoryGrantsPendingCount(mbc.Metrics.SqlserverMemoryGrantsPendingCount),
		metricSqlserverMemoryUsage:                        newMetricSqlserverMemoryUsage(mbc.Metrics.SqlserverMemoryUsage),
		metricSqlserverPageBufferCacheFreeListStallsRate:  newMetricSqlserverPageBufferCacheFreeListStallsRate(mbc.Metrics.SqlserverPageBufferCacheFreeListStallsRate),
		metricSqlserverPageBufferCacheHitRatio:            newMetricSqlserverPageBufferCacheHitRatio(mbc.Metrics.SqlserverPageBufferCacheHitRatio),
		metricSqlserverPageCheckpointFlushRate:            newMetricSqlserverPageCheckpointFlushRate(mbc.Metrics.SqlserverPageCheckpointFlushRate),
		metricSqlserverPageLazyWriteRate:                  newMetricSqlserverPageLazyWriteRate(mbc.Metrics.SqlserverPageLazyWriteRate),
		metricSqlserverPageLifeExpectancy:                 newMetricSqlserverPageLifeExpectancy(mbc.Metrics.SqlserverPageLifeExpectancy),
		metricSqlserverPageLookupRate:                     newMetricSqlserverPageLookupRate(mbc.Metrics.SqlserverPageLookupRate),
		metricSqlserverPageOperationRate:                  newMetricSqlserverPageOperationRate(mbc.Metrics.SqlserverPageOperationRate),
		metricSqlserverPageSplitRate:                      newMetricSqlserverPageSplitRate(mbc.Metrics.SqlserverPageSplitRate),
		metricSqlserverProcessesBlocked:                   newMetricSqlserverProcessesBlocked(mbc.Metrics.SqlserverProcessesBlocked),
		metricSqlserverReplicaDataRate:                    newMetricSqlserverReplicaDataRate(mbc.Metrics.SqlserverReplicaDataRate),
		metricSqlserverResourcePoolDiskOperations:         newMetricSqlserverResourcePoolDiskOperations(mbc.Metrics.SqlserverResourcePoolDiskOperations),
		metricSqlserverResourcePoolDiskThrottledReadRate:  newMetricSqlserverResourcePoolDiskThrottledReadRate(mbc.Metrics.SqlserverResourcePoolDiskThrottledReadRate),
		metricSqlserverResourcePoolDiskThrottledWriteRate: newMetricSqlserverResourcePoolDiskThrottledWriteRate(mbc.Metrics.SqlserverResourcePoolDiskThrottledWriteRate),
		metricSqlserverTableCount:                         newMetricSqlserverTableCount(mbc.Metrics.SqlserverTableCount),
		metricSqlserverTransactionDelay:                   newMetricSqlserverTransactionDelay(mbc.Metrics.SqlserverTransactionDelay),
		metricSqlserverTransactionMirrorWriteRate:         newMetricSqlserverTransactionMirrorWriteRate(mbc.Metrics.SqlserverTransactionMirrorWriteRate),
		metricSqlserverTransactionRate:                    newMetricSqlserverTransactionRate(mbc.Metrics.SqlserverTransactionRate),
		metricSqlserverTransactionWriteRate:               newMetricSqlserverTransactionWriteRate(mbc.Metrics.SqlserverTransactionWriteRate),
		metricSqlserverTransactionLogFlushDataRate:        newMetricSqlserverTransactionLogFlushDataRate(mbc.Metrics.SqlserverTransactionLogFlushDataRate),
		metricSqlserverTransactionLogFlushRate:            newMetricSqlserverTransactionLogFlushRate(mbc.Metrics.SqlserverTransactionLogFlushRate),
		metricSqlserverTransactionLogFlushWaitRate:        newMetricSqlserverTransactionLogFlushWaitRate(mbc.Metrics.SqlserverTransactionLogFlushWaitRate),
		metricSqlserverTransactionLogGrowthCount:          newMetricSqlserverTransactionLogGrowthCount(mbc.Metrics.SqlserverTransactionLogGrowthCount),
		metricSqlserverTransactionLogShrinkCount:          newMetricSqlserverTransactionLogShrinkCount(mbc.Metrics.SqlserverTransactionLogShrinkCount),
		metricSqlserverTransactionLogUsage:                newMetricSqlserverTransactionLogUsage(mbc.Metrics.SqlserverTransactionLogUsage),
		metricSqlserverUserConnectionCount:                newMetricSqlserverUserConnectionCount(mbc.Metrics.SqlserverUserConnectionCount),
		resourceAttributeIncludeFilter:                    make(map[string]filter.Filter),
		resourceAttributeExcludeFilter:                    make(map[string]filter.Filter),
	}
	if mbc.ResourceAttributes.ServerAddress.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["server.address"] = filter.CreateFilter(mbc.ResourceAttributes.ServerAddress.MetricsInclude)
	}
	if mbc.ResourceAttributes.ServerAddress.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["server.address"] = filter.CreateFilter(mbc.ResourceAttributes.ServerAddress.MetricsExclude)
	}
	if mbc.ResourceAttributes.ServerPort.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["server.port"] = filter.CreateFilter(mbc.ResourceAttributes.ServerPort.MetricsInclude)
	}
	if mbc.ResourceAttributes.ServerPort.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["server.port"] = filter.CreateFilter(mbc.ResourceAttributes.ServerPort.MetricsExclude)
	}
	if mbc.ResourceAttributes.SqlserverComputerName.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["sqlserver.computer.name"] = filter.CreateFilter(mbc.ResourceAttributes.SqlserverComputerName.MetricsInclude)
	}
	if mbc.ResourceAttributes.SqlserverComputerName.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["sqlserver.computer.name"] = filter.CreateFilter(mbc.ResourceAttributes.SqlserverComputerName.MetricsExclude)
	}
	if mbc.ResourceAttributes.SqlserverDatabaseName.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["sqlserver.database.name"] = filter.CreateFilter(mbc.ResourceAttributes.SqlserverDatabaseName.MetricsInclude)
	}
	if mbc.ResourceAttributes.SqlserverDatabaseName.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["sqlserver.database.name"] = filter.CreateFilter(mbc.ResourceAttributes.SqlserverDatabaseName.MetricsExclude)
	}
	if mbc.ResourceAttributes.SqlserverInstanceName.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["sqlserver.instance.name"] = filter.CreateFilter(mbc.ResourceAttributes.SqlserverInstanceName.MetricsInclude)
	}
	if mbc.ResourceAttributes.SqlserverInstanceName.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["sqlserver.instance.name"] = filter.CreateFilter(mbc.ResourceAttributes.SqlserverInstanceName.MetricsExclude)
	}

	for _, op := range options {
		op.apply(mb)
	}
	return mb
}

// NewResourceBuilder returns a new resource builder that should be used to build a resource associated with for the emitted metrics.
func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	return NewResourceBuilder(mb.config.ResourceAttributes)
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption interface {
	apply(pmetric.ResourceMetrics)
}

type resourceMetricsOptionFunc func(pmetric.ResourceMetrics)

func (rmof resourceMetricsOptionFunc) apply(rm pmetric.ResourceMetrics) {
	rmof(rm)
}

// WithResource sets the provided resource on the emitted ResourceMetrics.
// It's recommended to use ResourceBuilder to create the resource.
func WithResource(res pcommon.Resource) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		res.CopyTo(rm.Resource())
	})
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	})
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(options ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName(ScopeName)
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricSqlserverBatchRequestRate.emit(ils.Metrics())
	mb.metricSqlserverBatchSQLCompilationRate.emit(ils.Metrics())
	mb.metricSqlserverBatchSQLRecompilationRate.emit(ils.Metrics())
	mb.metricSqlserverDatabaseBackupOrRestoreRate.emit(ils.Metrics())
	mb.metricSqlserverDatabaseCount.emit(ils.Metrics())
	mb.metricSqlserverDatabaseExecutionErrors.emit(ils.Metrics())
	mb.metricSqlserverDatabaseFullScanRate.emit(ils.Metrics())
	mb.metricSqlserverDatabaseIo.emit(ils.Metrics())
	mb.metricSqlserverDatabaseLatency.emit(ils.Metrics())
	mb.metricSqlserverDatabaseOperations.emit(ils.Metrics())
	mb.metricSqlserverDatabaseTempdbSpace.emit(ils.Metrics())
	mb.metricSqlserverDatabaseTempdbVersionStoreSize.emit(ils.Metrics())
	mb.metricSqlserverDeadlockRate.emit(ils.Metrics())
	mb.metricSqlserverIndexSearchRate.emit(ils.Metrics())
	mb.metricSqlserverLockTimeoutRate.emit(ils.Metrics())
	mb.metricSqlserverLockWaitRate.emit(ils.Metrics())
	mb.metricSqlserverLockWaitTimeAvg.emit(ils.Metrics())
	mb.metricSqlserverLoginRate.emit(ils.Metrics())
	mb.metricSqlserverLogoutRate.emit(ils.Metrics())
	mb.metricSqlserverMemoryGrantsPendingCount.emit(ils.Metrics())
	mb.metricSqlserverMemoryUsage.emit(ils.Metrics())
	mb.metricSqlserverPageBufferCacheFreeListStallsRate.emit(ils.Metrics())
	mb.metricSqlserverPageBufferCacheHitRatio.emit(ils.Metrics())
	mb.metricSqlserverPageCheckpointFlushRate.emit(ils.Metrics())
	mb.metricSqlserverPageLazyWriteRate.emit(ils.Metrics())
	mb.metricSqlserverPageLifeExpectancy.emit(ils.Metrics())
	mb.metricSqlserverPageLookupRate.emit(ils.Metrics())
	mb.metricSqlserverPageOperationRate.emit(ils.Metrics())
	mb.metricSqlserverPageSplitRate.emit(ils.Metrics())
	mb.metricSqlserverProcessesBlocked.emit(ils.Metrics())
	mb.metricSqlserverReplicaDataRate.emit(ils.Metrics())
	mb.metricSqlserverResourcePoolDiskOperations.emit(ils.Metrics())
	mb.metricSqlserverResourcePoolDiskThrottledReadRate.emit(ils.Metrics())
	mb.metricSqlserverResourcePoolDiskThrottledWriteRate.emit(ils.Metrics())
	mb.metricSqlserverTableCount.emit(ils.Metrics())
	mb.metricSqlserverTransactionDelay.emit(ils.Metrics())
	mb.metricSqlserverTransactionMirrorWriteRate.emit(ils.Metrics())
	mb.metricSqlserverTransactionRate.emit(ils.Metrics())
	mb.metricSqlserverTransactionWriteRate.emit(ils.Metrics())
	mb.metricSqlserverTransactionLogFlushDataRate.emit(ils.Metrics())
	mb.metricSqlserverTransactionLogFlushRate.emit(ils.Metrics())
	mb.metricSqlserverTransactionLogFlushWaitRate.emit(ils.Metrics())
	mb.metricSqlserverTransactionLogGrowthCount.emit(ils.Metrics())
	mb.metricSqlserverTransactionLogShrinkCount.emit(ils.Metrics())
	mb.metricSqlserverTransactionLogUsage.emit(ils.Metrics())
	mb.metricSqlserverUserConnectionCount.emit(ils.Metrics())

	for _, op := range options {
		op.apply(rm)
	}
	for attr, filter := range mb.resourceAttributeIncludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && !filter.Matches(val.AsString()) {
			return
		}
	}
	for attr, filter := range mb.resourceAttributeExcludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && filter.Matches(val.AsString()) {
			return
		}
	}

	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(options ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(options...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordSqlserverBatchRequestRateDataPoint adds a data point to sqlserver.batch.request.rate metric.
func (mb *MetricsBuilder) RecordSqlserverBatchRequestRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverBatchRequestRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverBatchSQLCompilationRateDataPoint adds a data point to sqlserver.batch.sql_compilation.rate metric.
func (mb *MetricsBuilder) RecordSqlserverBatchSQLCompilationRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverBatchSQLCompilationRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverBatchSQLRecompilationRateDataPoint adds a data point to sqlserver.batch.sql_recompilation.rate metric.
func (mb *MetricsBuilder) RecordSqlserverBatchSQLRecompilationRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverBatchSQLRecompilationRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverDatabaseBackupOrRestoreRateDataPoint adds a data point to sqlserver.database.backup_or_restore.rate metric.
func (mb *MetricsBuilder) RecordSqlserverDatabaseBackupOrRestoreRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverDatabaseBackupOrRestoreRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverDatabaseCountDataPoint adds a data point to sqlserver.database.count metric.
func (mb *MetricsBuilder) RecordSqlserverDatabaseCountDataPoint(ts pcommon.Timestamp, inputVal string, databaseStatusAttributeValue AttributeDatabaseStatus) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for SqlserverDatabaseCount, value was %s: %w", inputVal, err)
	}
	mb.metricSqlserverDatabaseCount.recordDataPoint(mb.startTime, ts, val, databaseStatusAttributeValue.String())
	return nil
}

// RecordSqlserverDatabaseExecutionErrorsDataPoint adds a data point to sqlserver.database.execution.errors metric.
func (mb *MetricsBuilder) RecordSqlserverDatabaseExecutionErrorsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSqlserverDatabaseExecutionErrors.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverDatabaseFullScanRateDataPoint adds a data point to sqlserver.database.full_scan.rate metric.
func (mb *MetricsBuilder) RecordSqlserverDatabaseFullScanRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverDatabaseFullScanRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverDatabaseIoDataPoint adds a data point to sqlserver.database.io metric.
func (mb *MetricsBuilder) RecordSqlserverDatabaseIoDataPoint(ts pcommon.Timestamp, inputVal string, physicalFilenameAttributeValue string, logicalFilenameAttributeValue string, fileTypeAttributeValue string, directionAttributeValue AttributeDirection) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for SqlserverDatabaseIo, value was %s: %w", inputVal, err)
	}
	mb.metricSqlserverDatabaseIo.recordDataPoint(mb.startTime, ts, val, physicalFilenameAttributeValue, logicalFilenameAttributeValue, fileTypeAttributeValue, directionAttributeValue.String())
	return nil
}

// RecordSqlserverDatabaseLatencyDataPoint adds a data point to sqlserver.database.latency metric.
func (mb *MetricsBuilder) RecordSqlserverDatabaseLatencyDataPoint(ts pcommon.Timestamp, val float64, physicalFilenameAttributeValue string, logicalFilenameAttributeValue string, fileTypeAttributeValue string, directionAttributeValue AttributeDirection) {
	mb.metricSqlserverDatabaseLatency.recordDataPoint(mb.startTime, ts, val, physicalFilenameAttributeValue, logicalFilenameAttributeValue, fileTypeAttributeValue, directionAttributeValue.String())
}

// RecordSqlserverDatabaseOperationsDataPoint adds a data point to sqlserver.database.operations metric.
func (mb *MetricsBuilder) RecordSqlserverDatabaseOperationsDataPoint(ts pcommon.Timestamp, inputVal string, physicalFilenameAttributeValue string, logicalFilenameAttributeValue string, fileTypeAttributeValue string, directionAttributeValue AttributeDirection) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for SqlserverDatabaseOperations, value was %s: %w", inputVal, err)
	}
	mb.metricSqlserverDatabaseOperations.recordDataPoint(mb.startTime, ts, val, physicalFilenameAttributeValue, logicalFilenameAttributeValue, fileTypeAttributeValue, directionAttributeValue.String())
	return nil
}

// RecordSqlserverDatabaseTempdbSpaceDataPoint adds a data point to sqlserver.database.tempdb.space metric.
func (mb *MetricsBuilder) RecordSqlserverDatabaseTempdbSpaceDataPoint(ts pcommon.Timestamp, val int64, tempdbStateAttributeValue AttributeTempdbState) {
	mb.metricSqlserverDatabaseTempdbSpace.recordDataPoint(mb.startTime, ts, val, tempdbStateAttributeValue.String())
}

// RecordSqlserverDatabaseTempdbVersionStoreSizeDataPoint adds a data point to sqlserver.database.tempdb.version_store.size metric.
func (mb *MetricsBuilder) RecordSqlserverDatabaseTempdbVersionStoreSizeDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverDatabaseTempdbVersionStoreSize.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverDeadlockRateDataPoint adds a data point to sqlserver.deadlock.rate metric.
func (mb *MetricsBuilder) RecordSqlserverDeadlockRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverDeadlockRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverIndexSearchRateDataPoint adds a data point to sqlserver.index.search.rate metric.
func (mb *MetricsBuilder) RecordSqlserverIndexSearchRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverIndexSearchRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverLockTimeoutRateDataPoint adds a data point to sqlserver.lock.timeout.rate metric.
func (mb *MetricsBuilder) RecordSqlserverLockTimeoutRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverLockTimeoutRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverLockWaitRateDataPoint adds a data point to sqlserver.lock.wait.rate metric.
func (mb *MetricsBuilder) RecordSqlserverLockWaitRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverLockWaitRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverLockWaitTimeAvgDataPoint adds a data point to sqlserver.lock.wait_time.avg metric.
func (mb *MetricsBuilder) RecordSqlserverLockWaitTimeAvgDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverLockWaitTimeAvg.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverLoginRateDataPoint adds a data point to sqlserver.login.rate metric.
func (mb *MetricsBuilder) RecordSqlserverLoginRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverLoginRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverLogoutRateDataPoint adds a data point to sqlserver.logout.rate metric.
func (mb *MetricsBuilder) RecordSqlserverLogoutRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverLogoutRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverMemoryGrantsPendingCountDataPoint adds a data point to sqlserver.memory.grants.pending.count metric.
func (mb *MetricsBuilder) RecordSqlserverMemoryGrantsPendingCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSqlserverMemoryGrantsPendingCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverMemoryUsageDataPoint adds a data point to sqlserver.memory.usage metric.
func (mb *MetricsBuilder) RecordSqlserverMemoryUsageDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverMemoryUsage.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverPageBufferCacheFreeListStallsRateDataPoint adds a data point to sqlserver.page.buffer_cache.free_list.stalls.rate metric.
func (mb *MetricsBuilder) RecordSqlserverPageBufferCacheFreeListStallsRateDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSqlserverPageBufferCacheFreeListStallsRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverPageBufferCacheHitRatioDataPoint adds a data point to sqlserver.page.buffer_cache.hit_ratio metric.
func (mb *MetricsBuilder) RecordSqlserverPageBufferCacheHitRatioDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverPageBufferCacheHitRatio.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverPageCheckpointFlushRateDataPoint adds a data point to sqlserver.page.checkpoint.flush.rate metric.
func (mb *MetricsBuilder) RecordSqlserverPageCheckpointFlushRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverPageCheckpointFlushRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverPageLazyWriteRateDataPoint adds a data point to sqlserver.page.lazy_write.rate metric.
func (mb *MetricsBuilder) RecordSqlserverPageLazyWriteRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverPageLazyWriteRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverPageLifeExpectancyDataPoint adds a data point to sqlserver.page.life_expectancy metric.
func (mb *MetricsBuilder) RecordSqlserverPageLifeExpectancyDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSqlserverPageLifeExpectancy.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverPageLookupRateDataPoint adds a data point to sqlserver.page.lookup.rate metric.
func (mb *MetricsBuilder) RecordSqlserverPageLookupRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverPageLookupRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverPageOperationRateDataPoint adds a data point to sqlserver.page.operation.rate metric.
func (mb *MetricsBuilder) RecordSqlserverPageOperationRateDataPoint(ts pcommon.Timestamp, val float64, pageOperationsAttributeValue AttributePageOperations) {
	mb.metricSqlserverPageOperationRate.recordDataPoint(mb.startTime, ts, val, pageOperationsAttributeValue.String())
}

// RecordSqlserverPageSplitRateDataPoint adds a data point to sqlserver.page.split.rate metric.
func (mb *MetricsBuilder) RecordSqlserverPageSplitRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverPageSplitRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverProcessesBlockedDataPoint adds a data point to sqlserver.processes.blocked metric.
func (mb *MetricsBuilder) RecordSqlserverProcessesBlockedDataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for SqlserverProcessesBlocked, value was %s: %w", inputVal, err)
	}
	mb.metricSqlserverProcessesBlocked.recordDataPoint(mb.startTime, ts, val)
	return nil
}

// RecordSqlserverReplicaDataRateDataPoint adds a data point to sqlserver.replica.data.rate metric.
func (mb *MetricsBuilder) RecordSqlserverReplicaDataRateDataPoint(ts pcommon.Timestamp, val float64, replicaDirectionAttributeValue AttributeReplicaDirection) {
	mb.metricSqlserverReplicaDataRate.recordDataPoint(mb.startTime, ts, val, replicaDirectionAttributeValue.String())
}

// RecordSqlserverResourcePoolDiskOperationsDataPoint adds a data point to sqlserver.resource_pool.disk.operations metric.
func (mb *MetricsBuilder) RecordSqlserverResourcePoolDiskOperationsDataPoint(ts pcommon.Timestamp, val float64, directionAttributeValue AttributeDirection) {
	mb.metricSqlserverResourcePoolDiskOperations.recordDataPoint(mb.startTime, ts, val, directionAttributeValue.String())
}

// RecordSqlserverResourcePoolDiskThrottledReadRateDataPoint adds a data point to sqlserver.resource_pool.disk.throttled.read.rate metric.
func (mb *MetricsBuilder) RecordSqlserverResourcePoolDiskThrottledReadRateDataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for SqlserverResourcePoolDiskThrottledReadRate, value was %s: %w", inputVal, err)
	}
	mb.metricSqlserverResourcePoolDiskThrottledReadRate.recordDataPoint(mb.startTime, ts, val)
	return nil
}

// RecordSqlserverResourcePoolDiskThrottledWriteRateDataPoint adds a data point to sqlserver.resource_pool.disk.throttled.write.rate metric.
func (mb *MetricsBuilder) RecordSqlserverResourcePoolDiskThrottledWriteRateDataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseFloat(inputVal, 64)
	if err != nil {
		return fmt.Errorf("failed to parse float64 for SqlserverResourcePoolDiskThrottledWriteRate, value was %s: %w", inputVal, err)
	}
	mb.metricSqlserverResourcePoolDiskThrottledWriteRate.recordDataPoint(mb.startTime, ts, val)
	return nil
}

// RecordSqlserverTableCountDataPoint adds a data point to sqlserver.table.count metric.
func (mb *MetricsBuilder) RecordSqlserverTableCountDataPoint(ts pcommon.Timestamp, val int64, tableStateAttributeValue AttributeTableState, tableStatusAttributeValue AttributeTableStatus) {
	mb.metricSqlserverTableCount.recordDataPoint(mb.startTime, ts, val, tableStateAttributeValue.String(), tableStatusAttributeValue.String())
}

// RecordSqlserverTransactionDelayDataPoint adds a data point to sqlserver.transaction.delay metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionDelayDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverTransactionDelay.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionMirrorWriteRateDataPoint adds a data point to sqlserver.transaction.mirror_write.rate metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionMirrorWriteRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverTransactionMirrorWriteRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionRateDataPoint adds a data point to sqlserver.transaction.rate metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverTransactionRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionWriteRateDataPoint adds a data point to sqlserver.transaction.write.rate metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionWriteRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverTransactionWriteRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionLogFlushDataRateDataPoint adds a data point to sqlserver.transaction_log.flush.data.rate metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionLogFlushDataRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverTransactionLogFlushDataRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionLogFlushRateDataPoint adds a data point to sqlserver.transaction_log.flush.rate metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionLogFlushRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverTransactionLogFlushRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionLogFlushWaitRateDataPoint adds a data point to sqlserver.transaction_log.flush.wait.rate metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionLogFlushWaitRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverTransactionLogFlushWaitRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionLogGrowthCountDataPoint adds a data point to sqlserver.transaction_log.growth.count metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionLogGrowthCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSqlserverTransactionLogGrowthCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionLogShrinkCountDataPoint adds a data point to sqlserver.transaction_log.shrink.count metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionLogShrinkCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSqlserverTransactionLogShrinkCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionLogUsageDataPoint adds a data point to sqlserver.transaction_log.usage metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionLogUsageDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSqlserverTransactionLogUsage.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverUserConnectionCountDataPoint adds a data point to sqlserver.user.connection.count metric.
func (mb *MetricsBuilder) RecordSqlserverUserConnectionCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSqlserverUserConnectionCount.recordDataPoint(mb.startTime, ts, val)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...MetricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op.apply(mb)
	}
}
