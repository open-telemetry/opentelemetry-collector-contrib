// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

// AttributePageOperations specifies the a value page.operations attribute.
type AttributePageOperations int

const (
	_ AttributePageOperations = iota
	AttributePageOperationsRead
	AttributePageOperationsWrite
)

// String returns the string representation of the AttributePageOperations.
func (av AttributePageOperations) String() string {
	switch av {
	case AttributePageOperationsRead:
		return "read"
	case AttributePageOperationsWrite:
		return "write"
	}
	return ""
}

// MapAttributePageOperations is a helper map of string to AttributePageOperations attribute value.
var MapAttributePageOperations = map[string]AttributePageOperations{
	"read":  AttributePageOperationsRead,
	"write": AttributePageOperationsWrite,
}

type metricSqlserverBatchRequestRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.batch.request.rate metric with initial data.
func (m *metricSqlserverBatchRequestRate) init() {
	m.data.SetName("sqlserver.batch.request.rate")
	m.data.SetDescription("Number of batch requests received by SQL Server.")
	m.data.SetUnit("{requests}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverBatchRequestRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverBatchRequestRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverBatchRequestRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverBatchRequestRate(cfg MetricConfig) metricSqlserverBatchRequestRate {
	m := metricSqlserverBatchRequestRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverBatchSQLCompilationRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.batch.sql_compilation.rate metric with initial data.
func (m *metricSqlserverBatchSQLCompilationRate) init() {
	m.data.SetName("sqlserver.batch.sql_compilation.rate")
	m.data.SetDescription("Number of SQL compilations needed.")
	m.data.SetUnit("{compilations}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverBatchSQLCompilationRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverBatchSQLCompilationRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverBatchSQLCompilationRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverBatchSQLCompilationRate(cfg MetricConfig) metricSqlserverBatchSQLCompilationRate {
	m := metricSqlserverBatchSQLCompilationRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverBatchSQLRecompilationRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.batch.sql_recompilation.rate metric with initial data.
func (m *metricSqlserverBatchSQLRecompilationRate) init() {
	m.data.SetName("sqlserver.batch.sql_recompilation.rate")
	m.data.SetDescription("Number of SQL recompilations needed.")
	m.data.SetUnit("{compilations}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverBatchSQLRecompilationRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverBatchSQLRecompilationRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverBatchSQLRecompilationRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverBatchSQLRecompilationRate(cfg MetricConfig) metricSqlserverBatchSQLRecompilationRate {
	m := metricSqlserverBatchSQLRecompilationRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverLockWaitRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.lock.wait.rate metric with initial data.
func (m *metricSqlserverLockWaitRate) init() {
	m.data.SetName("sqlserver.lock.wait.rate")
	m.data.SetDescription("Number of lock requests resulting in a wait.")
	m.data.SetUnit("{requests}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverLockWaitRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverLockWaitRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverLockWaitRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverLockWaitRate(cfg MetricConfig) metricSqlserverLockWaitRate {
	m := metricSqlserverLockWaitRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverLockWaitTimeAvg struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.lock.wait_time.avg metric with initial data.
func (m *metricSqlserverLockWaitTimeAvg) init() {
	m.data.SetName("sqlserver.lock.wait_time.avg")
	m.data.SetDescription("Average wait time for all lock requests that had to wait.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverLockWaitTimeAvg) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverLockWaitTimeAvg) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverLockWaitTimeAvg) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverLockWaitTimeAvg(cfg MetricConfig) metricSqlserverLockWaitTimeAvg {
	m := metricSqlserverLockWaitTimeAvg{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverPageBufferCacheHitRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.page.buffer_cache.hit_ratio metric with initial data.
func (m *metricSqlserverPageBufferCacheHitRatio) init() {
	m.data.SetName("sqlserver.page.buffer_cache.hit_ratio")
	m.data.SetDescription("Pages found in the buffer pool without having to read from disk.")
	m.data.SetUnit("%")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverPageBufferCacheHitRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverPageBufferCacheHitRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverPageBufferCacheHitRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverPageBufferCacheHitRatio(cfg MetricConfig) metricSqlserverPageBufferCacheHitRatio {
	m := metricSqlserverPageBufferCacheHitRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverPageCheckpointFlushRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.page.checkpoint.flush.rate metric with initial data.
func (m *metricSqlserverPageCheckpointFlushRate) init() {
	m.data.SetName("sqlserver.page.checkpoint.flush.rate")
	m.data.SetDescription("Number of pages flushed by operations requiring dirty pages to be flushed.")
	m.data.SetUnit("{pages}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverPageCheckpointFlushRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverPageCheckpointFlushRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverPageCheckpointFlushRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverPageCheckpointFlushRate(cfg MetricConfig) metricSqlserverPageCheckpointFlushRate {
	m := metricSqlserverPageCheckpointFlushRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverPageLazyWriteRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.page.lazy_write.rate metric with initial data.
func (m *metricSqlserverPageLazyWriteRate) init() {
	m.data.SetName("sqlserver.page.lazy_write.rate")
	m.data.SetDescription("Number of lazy writes moving dirty pages to disk.")
	m.data.SetUnit("{writes}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverPageLazyWriteRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverPageLazyWriteRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverPageLazyWriteRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverPageLazyWriteRate(cfg MetricConfig) metricSqlserverPageLazyWriteRate {
	m := metricSqlserverPageLazyWriteRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverPageLifeExpectancy struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.page.life_expectancy metric with initial data.
func (m *metricSqlserverPageLifeExpectancy) init() {
	m.data.SetName("sqlserver.page.life_expectancy")
	m.data.SetDescription("Time a page will stay in the buffer pool.")
	m.data.SetUnit("s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverPageLifeExpectancy) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverPageLifeExpectancy) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverPageLifeExpectancy) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverPageLifeExpectancy(cfg MetricConfig) metricSqlserverPageLifeExpectancy {
	m := metricSqlserverPageLifeExpectancy{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverPageOperationRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.page.operation.rate metric with initial data.
func (m *metricSqlserverPageOperationRate) init() {
	m.data.SetName("sqlserver.page.operation.rate")
	m.data.SetDescription("Number of physical database page operations issued.")
	m.data.SetUnit("{operations}/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSqlserverPageOperationRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, pageOperationsAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("type", pageOperationsAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverPageOperationRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverPageOperationRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverPageOperationRate(cfg MetricConfig) metricSqlserverPageOperationRate {
	m := metricSqlserverPageOperationRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverPageSplitRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.page.split.rate metric with initial data.
func (m *metricSqlserverPageSplitRate) init() {
	m.data.SetName("sqlserver.page.split.rate")
	m.data.SetDescription("Number of pages split as a result of overflowing index pages.")
	m.data.SetUnit("{pages}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverPageSplitRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverPageSplitRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverPageSplitRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverPageSplitRate(cfg MetricConfig) metricSqlserverPageSplitRate {
	m := metricSqlserverPageSplitRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction.rate metric with initial data.
func (m *metricSqlserverTransactionRate) init() {
	m.data.SetName("sqlserver.transaction.rate")
	m.data.SetDescription("Number of transactions started for the database (not including XTP-only transactions).")
	m.data.SetUnit("{transactions}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverTransactionRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionRate(cfg MetricConfig) metricSqlserverTransactionRate {
	m := metricSqlserverTransactionRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionWriteRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction.write.rate metric with initial data.
func (m *metricSqlserverTransactionWriteRate) init() {
	m.data.SetName("sqlserver.transaction.write.rate")
	m.data.SetDescription("Number of transactions that wrote to the database and committed.")
	m.data.SetUnit("{transactions}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverTransactionWriteRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionWriteRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionWriteRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionWriteRate(cfg MetricConfig) metricSqlserverTransactionWriteRate {
	m := metricSqlserverTransactionWriteRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionLogFlushDataRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction_log.flush.data.rate metric with initial data.
func (m *metricSqlserverTransactionLogFlushDataRate) init() {
	m.data.SetName("sqlserver.transaction_log.flush.data.rate")
	m.data.SetDescription("Total number of log bytes flushed.")
	m.data.SetUnit("By/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverTransactionLogFlushDataRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionLogFlushDataRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionLogFlushDataRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionLogFlushDataRate(cfg MetricConfig) metricSqlserverTransactionLogFlushDataRate {
	m := metricSqlserverTransactionLogFlushDataRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionLogFlushRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction_log.flush.rate metric with initial data.
func (m *metricSqlserverTransactionLogFlushRate) init() {
	m.data.SetName("sqlserver.transaction_log.flush.rate")
	m.data.SetDescription("Number of log flushes.")
	m.data.SetUnit("{flushes}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverTransactionLogFlushRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionLogFlushRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionLogFlushRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionLogFlushRate(cfg MetricConfig) metricSqlserverTransactionLogFlushRate {
	m := metricSqlserverTransactionLogFlushRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionLogFlushWaitRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction_log.flush.wait.rate metric with initial data.
func (m *metricSqlserverTransactionLogFlushWaitRate) init() {
	m.data.SetName("sqlserver.transaction_log.flush.wait.rate")
	m.data.SetDescription("Number of commits waiting for a transaction log flush.")
	m.data.SetUnit("{commits}/s")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverTransactionLogFlushWaitRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionLogFlushWaitRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionLogFlushWaitRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionLogFlushWaitRate(cfg MetricConfig) metricSqlserverTransactionLogFlushWaitRate {
	m := metricSqlserverTransactionLogFlushWaitRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionLogGrowthCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction_log.growth.count metric with initial data.
func (m *metricSqlserverTransactionLogGrowthCount) init() {
	m.data.SetName("sqlserver.transaction_log.growth.count")
	m.data.SetDescription("Total number of transaction log expansions for a database.")
	m.data.SetUnit("{growths}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSqlserverTransactionLogGrowthCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionLogGrowthCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionLogGrowthCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionLogGrowthCount(cfg MetricConfig) metricSqlserverTransactionLogGrowthCount {
	m := metricSqlserverTransactionLogGrowthCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionLogShrinkCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction_log.shrink.count metric with initial data.
func (m *metricSqlserverTransactionLogShrinkCount) init() {
	m.data.SetName("sqlserver.transaction_log.shrink.count")
	m.data.SetDescription("Total number of transaction log shrinks for a database.")
	m.data.SetUnit("{shrinks}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSqlserverTransactionLogShrinkCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionLogShrinkCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionLogShrinkCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionLogShrinkCount(cfg MetricConfig) metricSqlserverTransactionLogShrinkCount {
	m := metricSqlserverTransactionLogShrinkCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverTransactionLogUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.transaction_log.usage metric with initial data.
func (m *metricSqlserverTransactionLogUsage) init() {
	m.data.SetName("sqlserver.transaction_log.usage")
	m.data.SetDescription("Percent of transaction log space used.")
	m.data.SetUnit("%")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverTransactionLogUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverTransactionLogUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverTransactionLogUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverTransactionLogUsage(cfg MetricConfig) metricSqlserverTransactionLogUsage {
	m := metricSqlserverTransactionLogUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSqlserverUserConnectionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills sqlserver.user.connection.count metric with initial data.
func (m *metricSqlserverUserConnectionCount) init() {
	m.data.SetName("sqlserver.user.connection.count")
	m.data.SetDescription("Number of users connected to the SQL Server.")
	m.data.SetUnit("{connections}")
	m.data.SetEmptyGauge()
}

func (m *metricSqlserverUserConnectionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSqlserverUserConnectionCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSqlserverUserConnectionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSqlserverUserConnectionCount(cfg MetricConfig) metricSqlserverUserConnectionCount {
	m := metricSqlserverUserConnectionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	startTime                                  pcommon.Timestamp   // start time that will be applied to all recorded data points.
	metricsCapacity                            int                 // maximum observed number of metrics per resource.
	resourceCapacity                           int                 // maximum observed number of resource attributes.
	metricsBuffer                              pmetric.Metrics     // accumulates metrics data before emitting.
	buildInfo                                  component.BuildInfo // contains version information
	resourceAttributesConfig                   ResourceAttributesConfig
	metricSqlserverBatchRequestRate            metricSqlserverBatchRequestRate
	metricSqlserverBatchSQLCompilationRate     metricSqlserverBatchSQLCompilationRate
	metricSqlserverBatchSQLRecompilationRate   metricSqlserverBatchSQLRecompilationRate
	metricSqlserverLockWaitRate                metricSqlserverLockWaitRate
	metricSqlserverLockWaitTimeAvg             metricSqlserverLockWaitTimeAvg
	metricSqlserverPageBufferCacheHitRatio     metricSqlserverPageBufferCacheHitRatio
	metricSqlserverPageCheckpointFlushRate     metricSqlserverPageCheckpointFlushRate
	metricSqlserverPageLazyWriteRate           metricSqlserverPageLazyWriteRate
	metricSqlserverPageLifeExpectancy          metricSqlserverPageLifeExpectancy
	metricSqlserverPageOperationRate           metricSqlserverPageOperationRate
	metricSqlserverPageSplitRate               metricSqlserverPageSplitRate
	metricSqlserverTransactionRate             metricSqlserverTransactionRate
	metricSqlserverTransactionWriteRate        metricSqlserverTransactionWriteRate
	metricSqlserverTransactionLogFlushDataRate metricSqlserverTransactionLogFlushDataRate
	metricSqlserverTransactionLogFlushRate     metricSqlserverTransactionLogFlushRate
	metricSqlserverTransactionLogFlushWaitRate metricSqlserverTransactionLogFlushWaitRate
	metricSqlserverTransactionLogGrowthCount   metricSqlserverTransactionLogGrowthCount
	metricSqlserverTransactionLogShrinkCount   metricSqlserverTransactionLogShrinkCount
	metricSqlserverTransactionLogUsage         metricSqlserverTransactionLogUsage
	metricSqlserverUserConnectionCount         metricSqlserverUserConnectionCount
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.CreateSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		startTime:                                  pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:                              pmetric.NewMetrics(),
		buildInfo:                                  settings.BuildInfo,
		resourceAttributesConfig:                   mbc.ResourceAttributes,
		metricSqlserverBatchRequestRate:            newMetricSqlserverBatchRequestRate(mbc.Metrics.SqlserverBatchRequestRate),
		metricSqlserverBatchSQLCompilationRate:     newMetricSqlserverBatchSQLCompilationRate(mbc.Metrics.SqlserverBatchSQLCompilationRate),
		metricSqlserverBatchSQLRecompilationRate:   newMetricSqlserverBatchSQLRecompilationRate(mbc.Metrics.SqlserverBatchSQLRecompilationRate),
		metricSqlserverLockWaitRate:                newMetricSqlserverLockWaitRate(mbc.Metrics.SqlserverLockWaitRate),
		metricSqlserverLockWaitTimeAvg:             newMetricSqlserverLockWaitTimeAvg(mbc.Metrics.SqlserverLockWaitTimeAvg),
		metricSqlserverPageBufferCacheHitRatio:     newMetricSqlserverPageBufferCacheHitRatio(mbc.Metrics.SqlserverPageBufferCacheHitRatio),
		metricSqlserverPageCheckpointFlushRate:     newMetricSqlserverPageCheckpointFlushRate(mbc.Metrics.SqlserverPageCheckpointFlushRate),
		metricSqlserverPageLazyWriteRate:           newMetricSqlserverPageLazyWriteRate(mbc.Metrics.SqlserverPageLazyWriteRate),
		metricSqlserverPageLifeExpectancy:          newMetricSqlserverPageLifeExpectancy(mbc.Metrics.SqlserverPageLifeExpectancy),
		metricSqlserverPageOperationRate:           newMetricSqlserverPageOperationRate(mbc.Metrics.SqlserverPageOperationRate),
		metricSqlserverPageSplitRate:               newMetricSqlserverPageSplitRate(mbc.Metrics.SqlserverPageSplitRate),
		metricSqlserverTransactionRate:             newMetricSqlserverTransactionRate(mbc.Metrics.SqlserverTransactionRate),
		metricSqlserverTransactionWriteRate:        newMetricSqlserverTransactionWriteRate(mbc.Metrics.SqlserverTransactionWriteRate),
		metricSqlserverTransactionLogFlushDataRate: newMetricSqlserverTransactionLogFlushDataRate(mbc.Metrics.SqlserverTransactionLogFlushDataRate),
		metricSqlserverTransactionLogFlushRate:     newMetricSqlserverTransactionLogFlushRate(mbc.Metrics.SqlserverTransactionLogFlushRate),
		metricSqlserverTransactionLogFlushWaitRate: newMetricSqlserverTransactionLogFlushWaitRate(mbc.Metrics.SqlserverTransactionLogFlushWaitRate),
		metricSqlserverTransactionLogGrowthCount:   newMetricSqlserverTransactionLogGrowthCount(mbc.Metrics.SqlserverTransactionLogGrowthCount),
		metricSqlserverTransactionLogShrinkCount:   newMetricSqlserverTransactionLogShrinkCount(mbc.Metrics.SqlserverTransactionLogShrinkCount),
		metricSqlserverTransactionLogUsage:         newMetricSqlserverTransactionLogUsage(mbc.Metrics.SqlserverTransactionLogUsage),
		metricSqlserverUserConnectionCount:         newMetricSqlserverUserConnectionCount(mbc.Metrics.SqlserverUserConnectionCount),
	}
	for _, op := range options {
		op(mb)
	}
	return mb
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
	if mb.resourceCapacity < rm.Resource().Attributes().Len() {
		mb.resourceCapacity = rm.Resource().Attributes().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption func(ResourceAttributesConfig, pmetric.ResourceMetrics)

// WithSqlserverComputerName sets provided value as "sqlserver.computer.name" attribute for current resource.
func WithSqlserverComputerName(val string) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SqlserverComputerName.Enabled {
			rm.Resource().Attributes().PutStr("sqlserver.computer.name", val)
		}
	}
}

// WithSqlserverDatabaseName sets provided value as "sqlserver.database.name" attribute for current resource.
func WithSqlserverDatabaseName(val string) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SqlserverDatabaseName.Enabled {
			rm.Resource().Attributes().PutStr("sqlserver.database.name", val)
		}
	}
}

// WithSqlserverInstanceName sets provided value as "sqlserver.instance.name" attribute for current resource.
func WithSqlserverInstanceName(val string) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SqlserverInstanceName.Enabled {
			rm.Resource().Attributes().PutStr("sqlserver.instance.name", val)
		}
	}
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return func(_ ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	}
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(rmo ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	rm.Resource().Attributes().EnsureCapacity(mb.resourceCapacity)
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName("otelcol/sqlserverreceiver")
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricSqlserverBatchRequestRate.emit(ils.Metrics())
	mb.metricSqlserverBatchSQLCompilationRate.emit(ils.Metrics())
	mb.metricSqlserverBatchSQLRecompilationRate.emit(ils.Metrics())
	mb.metricSqlserverLockWaitRate.emit(ils.Metrics())
	mb.metricSqlserverLockWaitTimeAvg.emit(ils.Metrics())
	mb.metricSqlserverPageBufferCacheHitRatio.emit(ils.Metrics())
	mb.metricSqlserverPageCheckpointFlushRate.emit(ils.Metrics())
	mb.metricSqlserverPageLazyWriteRate.emit(ils.Metrics())
	mb.metricSqlserverPageLifeExpectancy.emit(ils.Metrics())
	mb.metricSqlserverPageOperationRate.emit(ils.Metrics())
	mb.metricSqlserverPageSplitRate.emit(ils.Metrics())
	mb.metricSqlserverTransactionRate.emit(ils.Metrics())
	mb.metricSqlserverTransactionWriteRate.emit(ils.Metrics())
	mb.metricSqlserverTransactionLogFlushDataRate.emit(ils.Metrics())
	mb.metricSqlserverTransactionLogFlushRate.emit(ils.Metrics())
	mb.metricSqlserverTransactionLogFlushWaitRate.emit(ils.Metrics())
	mb.metricSqlserverTransactionLogGrowthCount.emit(ils.Metrics())
	mb.metricSqlserverTransactionLogShrinkCount.emit(ils.Metrics())
	mb.metricSqlserverTransactionLogUsage.emit(ils.Metrics())
	mb.metricSqlserverUserConnectionCount.emit(ils.Metrics())

	for _, op := range rmo {
		op(mb.resourceAttributesConfig, rm)
	}
	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(rmo ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(rmo...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordSqlserverBatchRequestRateDataPoint adds a data point to sqlserver.batch.request.rate metric.
func (mb *MetricsBuilder) RecordSqlserverBatchRequestRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverBatchRequestRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverBatchSQLCompilationRateDataPoint adds a data point to sqlserver.batch.sql_compilation.rate metric.
func (mb *MetricsBuilder) RecordSqlserverBatchSQLCompilationRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverBatchSQLCompilationRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverBatchSQLRecompilationRateDataPoint adds a data point to sqlserver.batch.sql_recompilation.rate metric.
func (mb *MetricsBuilder) RecordSqlserverBatchSQLRecompilationRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverBatchSQLRecompilationRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverLockWaitRateDataPoint adds a data point to sqlserver.lock.wait.rate metric.
func (mb *MetricsBuilder) RecordSqlserverLockWaitRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverLockWaitRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverLockWaitTimeAvgDataPoint adds a data point to sqlserver.lock.wait_time.avg metric.
func (mb *MetricsBuilder) RecordSqlserverLockWaitTimeAvgDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverLockWaitTimeAvg.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverPageBufferCacheHitRatioDataPoint adds a data point to sqlserver.page.buffer_cache.hit_ratio metric.
func (mb *MetricsBuilder) RecordSqlserverPageBufferCacheHitRatioDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverPageBufferCacheHitRatio.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverPageCheckpointFlushRateDataPoint adds a data point to sqlserver.page.checkpoint.flush.rate metric.
func (mb *MetricsBuilder) RecordSqlserverPageCheckpointFlushRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverPageCheckpointFlushRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverPageLazyWriteRateDataPoint adds a data point to sqlserver.page.lazy_write.rate metric.
func (mb *MetricsBuilder) RecordSqlserverPageLazyWriteRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverPageLazyWriteRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverPageLifeExpectancyDataPoint adds a data point to sqlserver.page.life_expectancy metric.
func (mb *MetricsBuilder) RecordSqlserverPageLifeExpectancyDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSqlserverPageLifeExpectancy.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverPageOperationRateDataPoint adds a data point to sqlserver.page.operation.rate metric.
func (mb *MetricsBuilder) RecordSqlserverPageOperationRateDataPoint(ts pcommon.Timestamp, val float64, pageOperationsAttributeValue AttributePageOperations) {
	mb.metricSqlserverPageOperationRate.recordDataPoint(mb.startTime, ts, val, pageOperationsAttributeValue.String())
}

// RecordSqlserverPageSplitRateDataPoint adds a data point to sqlserver.page.split.rate metric.
func (mb *MetricsBuilder) RecordSqlserverPageSplitRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverPageSplitRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionRateDataPoint adds a data point to sqlserver.transaction.rate metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverTransactionRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionWriteRateDataPoint adds a data point to sqlserver.transaction.write.rate metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionWriteRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverTransactionWriteRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionLogFlushDataRateDataPoint adds a data point to sqlserver.transaction_log.flush.data.rate metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionLogFlushDataRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverTransactionLogFlushDataRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionLogFlushRateDataPoint adds a data point to sqlserver.transaction_log.flush.rate metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionLogFlushRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverTransactionLogFlushRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionLogFlushWaitRateDataPoint adds a data point to sqlserver.transaction_log.flush.wait.rate metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionLogFlushWaitRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSqlserverTransactionLogFlushWaitRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionLogGrowthCountDataPoint adds a data point to sqlserver.transaction_log.growth.count metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionLogGrowthCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSqlserverTransactionLogGrowthCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionLogShrinkCountDataPoint adds a data point to sqlserver.transaction_log.shrink.count metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionLogShrinkCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSqlserverTransactionLogShrinkCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverTransactionLogUsageDataPoint adds a data point to sqlserver.transaction_log.usage metric.
func (mb *MetricsBuilder) RecordSqlserverTransactionLogUsageDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSqlserverTransactionLogUsage.recordDataPoint(mb.startTime, ts, val)
}

// RecordSqlserverUserConnectionCountDataPoint adds a data point to sqlserver.user.connection.count metric.
func (mb *MetricsBuilder) RecordSqlserverUserConnectionCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSqlserverUserConnectionCount.recordDataPoint(mb.startTime, ts, val)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...metricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(mb)
	}
}
