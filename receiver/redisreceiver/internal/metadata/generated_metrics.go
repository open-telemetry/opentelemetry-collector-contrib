// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/filter"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

// AttributeClusterState specifies the value cluster_state attribute.
type AttributeClusterState int

const (
	_ AttributeClusterState = iota
	AttributeClusterStateOk
	AttributeClusterStateFail
)

// String returns the string representation of the AttributeClusterState.
func (av AttributeClusterState) String() string {
	switch av {
	case AttributeClusterStateOk:
		return "ok"
	case AttributeClusterStateFail:
		return "fail"
	}
	return ""
}

// MapAttributeClusterState is a helper map of string to AttributeClusterState attribute value.
var MapAttributeClusterState = map[string]AttributeClusterState{
	"ok":   AttributeClusterStateOk,
	"fail": AttributeClusterStateFail,
}

// AttributePercentile specifies the value percentile attribute.
type AttributePercentile int

const (
	_ AttributePercentile = iota
	AttributePercentileP50
	AttributePercentileP99
	AttributePercentileP999
)

// String returns the string representation of the AttributePercentile.
func (av AttributePercentile) String() string {
	switch av {
	case AttributePercentileP50:
		return "p50"
	case AttributePercentileP99:
		return "p99"
	case AttributePercentileP999:
		return "p99.9"
	}
	return ""
}

// MapAttributePercentile is a helper map of string to AttributePercentile attribute value.
var MapAttributePercentile = map[string]AttributePercentile{
	"p50":   AttributePercentileP50,
	"p99":   AttributePercentileP99,
	"p99.9": AttributePercentileP999,
}

// AttributeRole specifies the value role attribute.
type AttributeRole int

const (
	_ AttributeRole = iota
	AttributeRoleReplica
	AttributeRolePrimary
)

// String returns the string representation of the AttributeRole.
func (av AttributeRole) String() string {
	switch av {
	case AttributeRoleReplica:
		return "replica"
	case AttributeRolePrimary:
		return "primary"
	}
	return ""
}

// MapAttributeRole is a helper map of string to AttributeRole attribute value.
var MapAttributeRole = map[string]AttributeRole{
	"replica": AttributeRoleReplica,
	"primary": AttributeRolePrimary,
}

// AttributeState specifies the value state attribute.
type AttributeState int

const (
	_ AttributeState = iota
	AttributeStateSys
	AttributeStateSysChildren
	AttributeStateSysMainThread
	AttributeStateUser
	AttributeStateUserChildren
	AttributeStateUserMainThread
)

// String returns the string representation of the AttributeState.
func (av AttributeState) String() string {
	switch av {
	case AttributeStateSys:
		return "sys"
	case AttributeStateSysChildren:
		return "sys_children"
	case AttributeStateSysMainThread:
		return "sys_main_thread"
	case AttributeStateUser:
		return "user"
	case AttributeStateUserChildren:
		return "user_children"
	case AttributeStateUserMainThread:
		return "user_main_thread"
	}
	return ""
}

// MapAttributeState is a helper map of string to AttributeState attribute value.
var MapAttributeState = map[string]AttributeState{
	"sys":              AttributeStateSys,
	"sys_children":     AttributeStateSysChildren,
	"sys_main_thread":  AttributeStateSysMainThread,
	"user":             AttributeStateUser,
	"user_children":    AttributeStateUserChildren,
	"user_main_thread": AttributeStateUserMainThread,
}

var MetricsInfo = metricsInfo{
	RedisClientsBlocked: metricInfo{
		Name: "redis.clients.blocked",
	},
	RedisClientsConnected: metricInfo{
		Name: "redis.clients.connected",
	},
	RedisClientsMaxInputBuffer: metricInfo{
		Name: "redis.clients.max_input_buffer",
	},
	RedisClientsMaxOutputBuffer: metricInfo{
		Name: "redis.clients.max_output_buffer",
	},
	RedisClusterKnownNodes: metricInfo{
		Name: "redis.cluster.known_nodes",
	},
	RedisClusterLinksBufferLimitExceededCount: metricInfo{
		Name: "redis.cluster.links_buffer_limit_exceeded.count",
	},
	RedisClusterNodeCount: metricInfo{
		Name: "redis.cluster.node.count",
	},
	RedisClusterNodeUptime: metricInfo{
		Name: "redis.cluster.node.uptime",
	},
	RedisClusterSlotsAssigned: metricInfo{
		Name: "redis.cluster.slots_assigned",
	},
	RedisClusterSlotsFail: metricInfo{
		Name: "redis.cluster.slots_fail",
	},
	RedisClusterSlotsOk: metricInfo{
		Name: "redis.cluster.slots_ok",
	},
	RedisClusterSlotsPfail: metricInfo{
		Name: "redis.cluster.slots_pfail",
	},
	RedisClusterState: metricInfo{
		Name: "redis.cluster.state",
	},
	RedisClusterStatsMessagesReceived: metricInfo{
		Name: "redis.cluster.stats_messages_received",
	},
	RedisClusterStatsMessagesSent: metricInfo{
		Name: "redis.cluster.stats_messages_sent",
	},
	RedisClusterUptime: metricInfo{
		Name: "redis.cluster.uptime",
	},
	RedisCmdCalls: metricInfo{
		Name: "redis.cmd.calls",
	},
	RedisCmdLatency: metricInfo{
		Name: "redis.cmd.latency",
	},
	RedisCmdUsec: metricInfo{
		Name: "redis.cmd.usec",
	},
	RedisCommands: metricInfo{
		Name: "redis.commands",
	},
	RedisCommandsProcessed: metricInfo{
		Name: "redis.commands.processed",
	},
	RedisConnectionsReceived: metricInfo{
		Name: "redis.connections.received",
	},
	RedisConnectionsRejected: metricInfo{
		Name: "redis.connections.rejected",
	},
	RedisCPUTime: metricInfo{
		Name: "redis.cpu.time",
	},
	RedisDbAvgTTL: metricInfo{
		Name: "redis.db.avg_ttl",
	},
	RedisDbExpires: metricInfo{
		Name: "redis.db.expires",
	},
	RedisDbKeys: metricInfo{
		Name: "redis.db.keys",
	},
	RedisKeysEvicted: metricInfo{
		Name: "redis.keys.evicted",
	},
	RedisKeysExpired: metricInfo{
		Name: "redis.keys.expired",
	},
	RedisKeyspaceHits: metricInfo{
		Name: "redis.keyspace.hits",
	},
	RedisKeyspaceMisses: metricInfo{
		Name: "redis.keyspace.misses",
	},
	RedisLatestFork: metricInfo{
		Name: "redis.latest_fork",
	},
	RedisMaxmemory: metricInfo{
		Name: "redis.maxmemory",
	},
	RedisMemoryFragmentationRatio: metricInfo{
		Name: "redis.memory.fragmentation_ratio",
	},
	RedisMemoryLua: metricInfo{
		Name: "redis.memory.lua",
	},
	RedisMemoryPeak: metricInfo{
		Name: "redis.memory.peak",
	},
	RedisMemoryRss: metricInfo{
		Name: "redis.memory.rss",
	},
	RedisMemoryUsed: metricInfo{
		Name: "redis.memory.used",
	},
	RedisNetInput: metricInfo{
		Name: "redis.net.input",
	},
	RedisNetOutput: metricInfo{
		Name: "redis.net.output",
	},
	RedisRdbChangesSinceLastSave: metricInfo{
		Name: "redis.rdb.changes_since_last_save",
	},
	RedisReplicationBacklogFirstByteOffset: metricInfo{
		Name: "redis.replication.backlog_first_byte_offset",
	},
	RedisReplicationOffset: metricInfo{
		Name: "redis.replication.offset",
	},
	RedisReplicationReplicaOffset: metricInfo{
		Name: "redis.replication.replica_offset",
	},
	RedisRole: metricInfo{
		Name: "redis.role",
	},
	RedisSlavesConnected: metricInfo{
		Name: "redis.slaves.connected",
	},
	RedisUptime: metricInfo{
		Name: "redis.uptime",
	},
}

type metricsInfo struct {
	RedisClientsBlocked                       metricInfo
	RedisClientsConnected                     metricInfo
	RedisClientsMaxInputBuffer                metricInfo
	RedisClientsMaxOutputBuffer               metricInfo
	RedisClusterKnownNodes                    metricInfo
	RedisClusterLinksBufferLimitExceededCount metricInfo
	RedisClusterNodeCount                     metricInfo
	RedisClusterNodeUptime                    metricInfo
	RedisClusterSlotsAssigned                 metricInfo
	RedisClusterSlotsFail                     metricInfo
	RedisClusterSlotsOk                       metricInfo
	RedisClusterSlotsPfail                    metricInfo
	RedisClusterState                         metricInfo
	RedisClusterStatsMessagesReceived         metricInfo
	RedisClusterStatsMessagesSent             metricInfo
	RedisClusterUptime                        metricInfo
	RedisCmdCalls                             metricInfo
	RedisCmdLatency                           metricInfo
	RedisCmdUsec                              metricInfo
	RedisCommands                             metricInfo
	RedisCommandsProcessed                    metricInfo
	RedisConnectionsReceived                  metricInfo
	RedisConnectionsRejected                  metricInfo
	RedisCPUTime                              metricInfo
	RedisDbAvgTTL                             metricInfo
	RedisDbExpires                            metricInfo
	RedisDbKeys                               metricInfo
	RedisKeysEvicted                          metricInfo
	RedisKeysExpired                          metricInfo
	RedisKeyspaceHits                         metricInfo
	RedisKeyspaceMisses                       metricInfo
	RedisLatestFork                           metricInfo
	RedisMaxmemory                            metricInfo
	RedisMemoryFragmentationRatio             metricInfo
	RedisMemoryLua                            metricInfo
	RedisMemoryPeak                           metricInfo
	RedisMemoryRss                            metricInfo
	RedisMemoryUsed                           metricInfo
	RedisNetInput                             metricInfo
	RedisNetOutput                            metricInfo
	RedisRdbChangesSinceLastSave              metricInfo
	RedisReplicationBacklogFirstByteOffset    metricInfo
	RedisReplicationOffset                    metricInfo
	RedisReplicationReplicaOffset             metricInfo
	RedisRole                                 metricInfo
	RedisSlavesConnected                      metricInfo
	RedisUptime                               metricInfo
}

type metricInfo struct {
	Name string
}

type metricRedisClientsBlocked struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.clients.blocked metric with initial data.
func (m *metricRedisClientsBlocked) init() {
	m.data.SetName("redis.clients.blocked")
	m.data.SetDescription("Number of clients pending on a blocking call")
	m.data.SetUnit("{client}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisClientsBlocked) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClientsBlocked) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClientsBlocked) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClientsBlocked(cfg MetricConfig) metricRedisClientsBlocked {
	m := metricRedisClientsBlocked{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClientsConnected struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.clients.connected metric with initial data.
func (m *metricRedisClientsConnected) init() {
	m.data.SetName("redis.clients.connected")
	m.data.SetDescription("Number of client connections (excluding connections from replicas)")
	m.data.SetUnit("{client}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisClientsConnected) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClientsConnected) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClientsConnected) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClientsConnected(cfg MetricConfig) metricRedisClientsConnected {
	m := metricRedisClientsConnected{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClientsMaxInputBuffer struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.clients.max_input_buffer metric with initial data.
func (m *metricRedisClientsMaxInputBuffer) init() {
	m.data.SetName("redis.clients.max_input_buffer")
	m.data.SetDescription("Biggest input buffer among current client connections")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricRedisClientsMaxInputBuffer) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClientsMaxInputBuffer) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClientsMaxInputBuffer) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClientsMaxInputBuffer(cfg MetricConfig) metricRedisClientsMaxInputBuffer {
	m := metricRedisClientsMaxInputBuffer{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClientsMaxOutputBuffer struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.clients.max_output_buffer metric with initial data.
func (m *metricRedisClientsMaxOutputBuffer) init() {
	m.data.SetName("redis.clients.max_output_buffer")
	m.data.SetDescription("Longest output list among current client connections")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricRedisClientsMaxOutputBuffer) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClientsMaxOutputBuffer) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClientsMaxOutputBuffer) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClientsMaxOutputBuffer(cfg MetricConfig) metricRedisClientsMaxOutputBuffer {
	m := metricRedisClientsMaxOutputBuffer{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClusterKnownNodes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cluster.known_nodes metric with initial data.
func (m *metricRedisClusterKnownNodes) init() {
	m.data.SetName("redis.cluster.known_nodes")
	m.data.SetDescription("Number of known nodes in the cluster")
	m.data.SetUnit("{node}")
	m.data.SetEmptyGauge()
}

func (m *metricRedisClusterKnownNodes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClusterKnownNodes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClusterKnownNodes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClusterKnownNodes(cfg MetricConfig) metricRedisClusterKnownNodes {
	m := metricRedisClusterKnownNodes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClusterLinksBufferLimitExceededCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cluster.links_buffer_limit_exceeded.count metric with initial data.
func (m *metricRedisClusterLinksBufferLimitExceededCount) init() {
	m.data.SetName("redis.cluster.links_buffer_limit_exceeded.count")
	m.data.SetDescription("Total number of times the cluster links buffer limit was exceeded")
	m.data.SetUnit("{count}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisClusterLinksBufferLimitExceededCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClusterLinksBufferLimitExceededCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClusterLinksBufferLimitExceededCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClusterLinksBufferLimitExceededCount(cfg MetricConfig) metricRedisClusterLinksBufferLimitExceededCount {
	m := metricRedisClusterLinksBufferLimitExceededCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClusterNodeCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cluster.node.count metric with initial data.
func (m *metricRedisClusterNodeCount) init() {
	m.data.SetName("redis.cluster.node.count")
	m.data.SetDescription("Number of master nodes in the cluster")
	m.data.SetUnit("{node}")
	m.data.SetEmptyGauge()
}

func (m *metricRedisClusterNodeCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClusterNodeCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClusterNodeCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClusterNodeCount(cfg MetricConfig) metricRedisClusterNodeCount {
	m := metricRedisClusterNodeCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClusterNodeUptime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cluster.node.uptime metric with initial data.
func (m *metricRedisClusterNodeUptime) init() {
	m.data.SetName("redis.cluster.node.uptime")
	m.data.SetDescription("The node's current epoch")
	m.data.SetUnit("s")
	m.data.SetEmptyGauge()
}

func (m *metricRedisClusterNodeUptime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClusterNodeUptime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClusterNodeUptime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClusterNodeUptime(cfg MetricConfig) metricRedisClusterNodeUptime {
	m := metricRedisClusterNodeUptime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClusterSlotsAssigned struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cluster.slots_assigned metric with initial data.
func (m *metricRedisClusterSlotsAssigned) init() {
	m.data.SetName("redis.cluster.slots_assigned")
	m.data.SetDescription("Number of slots assigned in the cluster")
	m.data.SetUnit("{slot}")
	m.data.SetEmptyGauge()
}

func (m *metricRedisClusterSlotsAssigned) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClusterSlotsAssigned) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClusterSlotsAssigned) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClusterSlotsAssigned(cfg MetricConfig) metricRedisClusterSlotsAssigned {
	m := metricRedisClusterSlotsAssigned{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClusterSlotsFail struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cluster.slots_fail metric with initial data.
func (m *metricRedisClusterSlotsFail) init() {
	m.data.SetName("redis.cluster.slots_fail")
	m.data.SetDescription("Number of slots in the cluster that are in a failing state")
	m.data.SetUnit("{slot}")
	m.data.SetEmptyGauge()
}

func (m *metricRedisClusterSlotsFail) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClusterSlotsFail) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClusterSlotsFail) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClusterSlotsFail(cfg MetricConfig) metricRedisClusterSlotsFail {
	m := metricRedisClusterSlotsFail{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClusterSlotsOk struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cluster.slots_ok metric with initial data.
func (m *metricRedisClusterSlotsOk) init() {
	m.data.SetName("redis.cluster.slots_ok")
	m.data.SetDescription("Number of slots in the cluster that are ok")
	m.data.SetUnit("{slot}")
	m.data.SetEmptyGauge()
}

func (m *metricRedisClusterSlotsOk) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClusterSlotsOk) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClusterSlotsOk) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClusterSlotsOk(cfg MetricConfig) metricRedisClusterSlotsOk {
	m := metricRedisClusterSlotsOk{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClusterSlotsPfail struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cluster.slots_pfail metric with initial data.
func (m *metricRedisClusterSlotsPfail) init() {
	m.data.SetName("redis.cluster.slots_pfail")
	m.data.SetDescription("Number of slots in the cluster that are in a 'potentially failing' state")
	m.data.SetUnit("{slot}")
	m.data.SetEmptyGauge()
}

func (m *metricRedisClusterSlotsPfail) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClusterSlotsPfail) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClusterSlotsPfail) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClusterSlotsPfail(cfg MetricConfig) metricRedisClusterSlotsPfail {
	m := metricRedisClusterSlotsPfail{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClusterState struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cluster.state metric with initial data.
func (m *metricRedisClusterState) init() {
	m.data.SetName("redis.cluster.state")
	m.data.SetDescription("State of the cluster")
	m.data.SetUnit("{state}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricRedisClusterState) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterStateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster_state", clusterStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClusterState) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClusterState) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClusterState(cfg MetricConfig) metricRedisClusterState {
	m := metricRedisClusterState{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClusterStatsMessagesReceived struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cluster.stats_messages_received metric with initial data.
func (m *metricRedisClusterStatsMessagesReceived) init() {
	m.data.SetName("redis.cluster.stats_messages_received")
	m.data.SetDescription("Total number of messages received by the cluster")
	m.data.SetUnit("{message}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisClusterStatsMessagesReceived) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClusterStatsMessagesReceived) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClusterStatsMessagesReceived) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClusterStatsMessagesReceived(cfg MetricConfig) metricRedisClusterStatsMessagesReceived {
	m := metricRedisClusterStatsMessagesReceived{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClusterStatsMessagesSent struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cluster.stats_messages_sent metric with initial data.
func (m *metricRedisClusterStatsMessagesSent) init() {
	m.data.SetName("redis.cluster.stats_messages_sent")
	m.data.SetDescription("Total number of messages sent by the cluster")
	m.data.SetUnit("{message}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisClusterStatsMessagesSent) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClusterStatsMessagesSent) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClusterStatsMessagesSent) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClusterStatsMessagesSent(cfg MetricConfig) metricRedisClusterStatsMessagesSent {
	m := metricRedisClusterStatsMessagesSent{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisClusterUptime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cluster.uptime metric with initial data.
func (m *metricRedisClusterUptime) init() {
	m.data.SetName("redis.cluster.uptime")
	m.data.SetDescription("Current epoch of the cluster")
	m.data.SetUnit("s")
	m.data.SetEmptyGauge()
}

func (m *metricRedisClusterUptime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisClusterUptime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisClusterUptime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisClusterUptime(cfg MetricConfig) metricRedisClusterUptime {
	m := metricRedisClusterUptime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisCmdCalls struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cmd.calls metric with initial data.
func (m *metricRedisCmdCalls) init() {
	m.data.SetName("redis.cmd.calls")
	m.data.SetDescription("Total number of calls for a command")
	m.data.SetUnit("{call}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricRedisCmdCalls) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, cmdAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cmd", cmdAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisCmdCalls) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisCmdCalls) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisCmdCalls(cfg MetricConfig) metricRedisCmdCalls {
	m := metricRedisCmdCalls{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisCmdLatency struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cmd.latency metric with initial data.
func (m *metricRedisCmdLatency) init() {
	m.data.SetName("redis.cmd.latency")
	m.data.SetDescription("Command execution latency")
	m.data.SetUnit("s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricRedisCmdLatency) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cmdAttributeValue string, percentileAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cmd", cmdAttributeValue)
	dp.Attributes().PutStr("percentile", percentileAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisCmdLatency) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisCmdLatency) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisCmdLatency(cfg MetricConfig) metricRedisCmdLatency {
	m := metricRedisCmdLatency{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisCmdUsec struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cmd.usec metric with initial data.
func (m *metricRedisCmdUsec) init() {
	m.data.SetName("redis.cmd.usec")
	m.data.SetDescription("Total time for all executions of this command")
	m.data.SetUnit("us")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricRedisCmdUsec) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, cmdAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cmd", cmdAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisCmdUsec) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisCmdUsec) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisCmdUsec(cfg MetricConfig) metricRedisCmdUsec {
	m := metricRedisCmdUsec{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisCommands struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.commands metric with initial data.
func (m *metricRedisCommands) init() {
	m.data.SetName("redis.commands")
	m.data.SetDescription("Number of commands processed per second")
	m.data.SetUnit("{ops}/s")
	m.data.SetEmptyGauge()
}

func (m *metricRedisCommands) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisCommands) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisCommands) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisCommands(cfg MetricConfig) metricRedisCommands {
	m := metricRedisCommands{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisCommandsProcessed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.commands.processed metric with initial data.
func (m *metricRedisCommandsProcessed) init() {
	m.data.SetName("redis.commands.processed")
	m.data.SetDescription("Total number of commands processed by the server")
	m.data.SetUnit("{command}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisCommandsProcessed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisCommandsProcessed) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisCommandsProcessed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisCommandsProcessed(cfg MetricConfig) metricRedisCommandsProcessed {
	m := metricRedisCommandsProcessed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisConnectionsReceived struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.connections.received metric with initial data.
func (m *metricRedisConnectionsReceived) init() {
	m.data.SetName("redis.connections.received")
	m.data.SetDescription("Total number of connections accepted by the server")
	m.data.SetUnit("{connection}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisConnectionsReceived) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisConnectionsReceived) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisConnectionsReceived) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisConnectionsReceived(cfg MetricConfig) metricRedisConnectionsReceived {
	m := metricRedisConnectionsReceived{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisConnectionsRejected struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.connections.rejected metric with initial data.
func (m *metricRedisConnectionsRejected) init() {
	m.data.SetName("redis.connections.rejected")
	m.data.SetDescription("Number of connections rejected because of maxclients limit")
	m.data.SetUnit("{connection}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisConnectionsRejected) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisConnectionsRejected) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisConnectionsRejected) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisConnectionsRejected(cfg MetricConfig) metricRedisConnectionsRejected {
	m := metricRedisConnectionsRejected{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisCPUTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.cpu.time metric with initial data.
func (m *metricRedisCPUTime) init() {
	m.data.SetName("redis.cpu.time")
	m.data.SetDescription("System CPU consumed by the Redis server in seconds since server start")
	m.data.SetUnit("s")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricRedisCPUTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, stateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("state", stateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisCPUTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisCPUTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisCPUTime(cfg MetricConfig) metricRedisCPUTime {
	m := metricRedisCPUTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisDbAvgTTL struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.db.avg_ttl metric with initial data.
func (m *metricRedisDbAvgTTL) init() {
	m.data.SetName("redis.db.avg_ttl")
	m.data.SetDescription("Average keyspace keys TTL")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricRedisDbAvgTTL) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, dbAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("db", dbAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisDbAvgTTL) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisDbAvgTTL) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisDbAvgTTL(cfg MetricConfig) metricRedisDbAvgTTL {
	m := metricRedisDbAvgTTL{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisDbExpires struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.db.expires metric with initial data.
func (m *metricRedisDbExpires) init() {
	m.data.SetName("redis.db.expires")
	m.data.SetDescription("Number of keyspace keys with an expiration")
	m.data.SetUnit("{key}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricRedisDbExpires) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, dbAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("db", dbAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisDbExpires) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisDbExpires) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisDbExpires(cfg MetricConfig) metricRedisDbExpires {
	m := metricRedisDbExpires{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisDbKeys struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.db.keys metric with initial data.
func (m *metricRedisDbKeys) init() {
	m.data.SetName("redis.db.keys")
	m.data.SetDescription("Number of keyspace keys")
	m.data.SetUnit("{key}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricRedisDbKeys) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, dbAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("db", dbAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisDbKeys) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisDbKeys) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisDbKeys(cfg MetricConfig) metricRedisDbKeys {
	m := metricRedisDbKeys{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisKeysEvicted struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.keys.evicted metric with initial data.
func (m *metricRedisKeysEvicted) init() {
	m.data.SetName("redis.keys.evicted")
	m.data.SetDescription("Number of evicted keys due to maxmemory limit")
	m.data.SetUnit("{key}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisKeysEvicted) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisKeysEvicted) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisKeysEvicted) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisKeysEvicted(cfg MetricConfig) metricRedisKeysEvicted {
	m := metricRedisKeysEvicted{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisKeysExpired struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.keys.expired metric with initial data.
func (m *metricRedisKeysExpired) init() {
	m.data.SetName("redis.keys.expired")
	m.data.SetDescription("Total number of key expiration events")
	m.data.SetUnit("{event}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisKeysExpired) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisKeysExpired) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisKeysExpired) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisKeysExpired(cfg MetricConfig) metricRedisKeysExpired {
	m := metricRedisKeysExpired{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisKeyspaceHits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.keyspace.hits metric with initial data.
func (m *metricRedisKeyspaceHits) init() {
	m.data.SetName("redis.keyspace.hits")
	m.data.SetDescription("Number of successful lookup of keys in the main dictionary")
	m.data.SetUnit("{hit}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisKeyspaceHits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisKeyspaceHits) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisKeyspaceHits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisKeyspaceHits(cfg MetricConfig) metricRedisKeyspaceHits {
	m := metricRedisKeyspaceHits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisKeyspaceMisses struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.keyspace.misses metric with initial data.
func (m *metricRedisKeyspaceMisses) init() {
	m.data.SetName("redis.keyspace.misses")
	m.data.SetDescription("Number of failed lookup of keys in the main dictionary")
	m.data.SetUnit("{miss}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisKeyspaceMisses) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisKeyspaceMisses) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisKeyspaceMisses) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisKeyspaceMisses(cfg MetricConfig) metricRedisKeyspaceMisses {
	m := metricRedisKeyspaceMisses{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisLatestFork struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.latest_fork metric with initial data.
func (m *metricRedisLatestFork) init() {
	m.data.SetName("redis.latest_fork")
	m.data.SetDescription("Duration of the latest fork operation in microseconds")
	m.data.SetUnit("us")
	m.data.SetEmptyGauge()
}

func (m *metricRedisLatestFork) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisLatestFork) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisLatestFork) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisLatestFork(cfg MetricConfig) metricRedisLatestFork {
	m := metricRedisLatestFork{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisMaxmemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.maxmemory metric with initial data.
func (m *metricRedisMaxmemory) init() {
	m.data.SetName("redis.maxmemory")
	m.data.SetDescription("The value of the maxmemory configuration directive")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricRedisMaxmemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisMaxmemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisMaxmemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisMaxmemory(cfg MetricConfig) metricRedisMaxmemory {
	m := metricRedisMaxmemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisMemoryFragmentationRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.memory.fragmentation_ratio metric with initial data.
func (m *metricRedisMemoryFragmentationRatio) init() {
	m.data.SetName("redis.memory.fragmentation_ratio")
	m.data.SetDescription("Ratio between used_memory_rss and used_memory")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
}

func (m *metricRedisMemoryFragmentationRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisMemoryFragmentationRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisMemoryFragmentationRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisMemoryFragmentationRatio(cfg MetricConfig) metricRedisMemoryFragmentationRatio {
	m := metricRedisMemoryFragmentationRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisMemoryLua struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.memory.lua metric with initial data.
func (m *metricRedisMemoryLua) init() {
	m.data.SetName("redis.memory.lua")
	m.data.SetDescription("Number of bytes used by the Lua engine")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricRedisMemoryLua) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisMemoryLua) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisMemoryLua) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisMemoryLua(cfg MetricConfig) metricRedisMemoryLua {
	m := metricRedisMemoryLua{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisMemoryPeak struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.memory.peak metric with initial data.
func (m *metricRedisMemoryPeak) init() {
	m.data.SetName("redis.memory.peak")
	m.data.SetDescription("Peak memory consumed by Redis (in bytes)")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricRedisMemoryPeak) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisMemoryPeak) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisMemoryPeak) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisMemoryPeak(cfg MetricConfig) metricRedisMemoryPeak {
	m := metricRedisMemoryPeak{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisMemoryRss struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.memory.rss metric with initial data.
func (m *metricRedisMemoryRss) init() {
	m.data.SetName("redis.memory.rss")
	m.data.SetDescription("Number of bytes that Redis allocated as seen by the operating system")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricRedisMemoryRss) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisMemoryRss) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisMemoryRss) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisMemoryRss(cfg MetricConfig) metricRedisMemoryRss {
	m := metricRedisMemoryRss{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisMemoryUsed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.memory.used metric with initial data.
func (m *metricRedisMemoryUsed) init() {
	m.data.SetName("redis.memory.used")
	m.data.SetDescription("Total number of bytes allocated by Redis using its allocator")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricRedisMemoryUsed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisMemoryUsed) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisMemoryUsed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisMemoryUsed(cfg MetricConfig) metricRedisMemoryUsed {
	m := metricRedisMemoryUsed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisNetInput struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.net.input metric with initial data.
func (m *metricRedisNetInput) init() {
	m.data.SetName("redis.net.input")
	m.data.SetDescription("The total number of bytes read from the network")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisNetInput) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisNetInput) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisNetInput) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisNetInput(cfg MetricConfig) metricRedisNetInput {
	m := metricRedisNetInput{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisNetOutput struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.net.output metric with initial data.
func (m *metricRedisNetOutput) init() {
	m.data.SetName("redis.net.output")
	m.data.SetDescription("The total number of bytes written to the network")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisNetOutput) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisNetOutput) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisNetOutput) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisNetOutput(cfg MetricConfig) metricRedisNetOutput {
	m := metricRedisNetOutput{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisRdbChangesSinceLastSave struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.rdb.changes_since_last_save metric with initial data.
func (m *metricRedisRdbChangesSinceLastSave) init() {
	m.data.SetName("redis.rdb.changes_since_last_save")
	m.data.SetDescription("Number of changes since the last dump")
	m.data.SetUnit("{change}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisRdbChangesSinceLastSave) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisRdbChangesSinceLastSave) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisRdbChangesSinceLastSave) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisRdbChangesSinceLastSave(cfg MetricConfig) metricRedisRdbChangesSinceLastSave {
	m := metricRedisRdbChangesSinceLastSave{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisReplicationBacklogFirstByteOffset struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.replication.backlog_first_byte_offset metric with initial data.
func (m *metricRedisReplicationBacklogFirstByteOffset) init() {
	m.data.SetName("redis.replication.backlog_first_byte_offset")
	m.data.SetDescription("The master offset of the replication backlog buffer")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricRedisReplicationBacklogFirstByteOffset) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisReplicationBacklogFirstByteOffset) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisReplicationBacklogFirstByteOffset) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisReplicationBacklogFirstByteOffset(cfg MetricConfig) metricRedisReplicationBacklogFirstByteOffset {
	m := metricRedisReplicationBacklogFirstByteOffset{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisReplicationOffset struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.replication.offset metric with initial data.
func (m *metricRedisReplicationOffset) init() {
	m.data.SetName("redis.replication.offset")
	m.data.SetDescription("The server's current replication offset")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricRedisReplicationOffset) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisReplicationOffset) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisReplicationOffset) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisReplicationOffset(cfg MetricConfig) metricRedisReplicationOffset {
	m := metricRedisReplicationOffset{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisReplicationReplicaOffset struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.replication.replica_offset metric with initial data.
func (m *metricRedisReplicationReplicaOffset) init() {
	m.data.SetName("redis.replication.replica_offset")
	m.data.SetDescription("Offset for redis replica")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricRedisReplicationReplicaOffset) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisReplicationReplicaOffset) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisReplicationReplicaOffset) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisReplicationReplicaOffset(cfg MetricConfig) metricRedisReplicationReplicaOffset {
	m := metricRedisReplicationReplicaOffset{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisRole struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.role metric with initial data.
func (m *metricRedisRole) init() {
	m.data.SetName("redis.role")
	m.data.SetDescription("Redis node's role")
	m.data.SetUnit("{role}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricRedisRole) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, roleAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("role", roleAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisRole) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisRole) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisRole(cfg MetricConfig) metricRedisRole {
	m := metricRedisRole{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisSlavesConnected struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.slaves.connected metric with initial data.
func (m *metricRedisSlavesConnected) init() {
	m.data.SetName("redis.slaves.connected")
	m.data.SetDescription("Number of connected replicas")
	m.data.SetUnit("{replica}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisSlavesConnected) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisSlavesConnected) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisSlavesConnected) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisSlavesConnected(cfg MetricConfig) metricRedisSlavesConnected {
	m := metricRedisSlavesConnected{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricRedisUptime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills redis.uptime metric with initial data.
func (m *metricRedisUptime) init() {
	m.data.SetName("redis.uptime")
	m.data.SetDescription("Number of seconds since Redis server start")
	m.data.SetUnit("s")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricRedisUptime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricRedisUptime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricRedisUptime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricRedisUptime(cfg MetricConfig) metricRedisUptime {
	m := metricRedisUptime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config                                          MetricsBuilderConfig // config of the metrics builder.
	startTime                                       pcommon.Timestamp    // start time that will be applied to all recorded data points.
	metricsCapacity                                 int                  // maximum observed number of metrics per resource.
	metricsBuffer                                   pmetric.Metrics      // accumulates metrics data before emitting.
	buildInfo                                       component.BuildInfo  // contains version information.
	resourceAttributeIncludeFilter                  map[string]filter.Filter
	resourceAttributeExcludeFilter                  map[string]filter.Filter
	metricRedisClientsBlocked                       metricRedisClientsBlocked
	metricRedisClientsConnected                     metricRedisClientsConnected
	metricRedisClientsMaxInputBuffer                metricRedisClientsMaxInputBuffer
	metricRedisClientsMaxOutputBuffer               metricRedisClientsMaxOutputBuffer
	metricRedisClusterKnownNodes                    metricRedisClusterKnownNodes
	metricRedisClusterLinksBufferLimitExceededCount metricRedisClusterLinksBufferLimitExceededCount
	metricRedisClusterNodeCount                     metricRedisClusterNodeCount
	metricRedisClusterNodeUptime                    metricRedisClusterNodeUptime
	metricRedisClusterSlotsAssigned                 metricRedisClusterSlotsAssigned
	metricRedisClusterSlotsFail                     metricRedisClusterSlotsFail
	metricRedisClusterSlotsOk                       metricRedisClusterSlotsOk
	metricRedisClusterSlotsPfail                    metricRedisClusterSlotsPfail
	metricRedisClusterState                         metricRedisClusterState
	metricRedisClusterStatsMessagesReceived         metricRedisClusterStatsMessagesReceived
	metricRedisClusterStatsMessagesSent             metricRedisClusterStatsMessagesSent
	metricRedisClusterUptime                        metricRedisClusterUptime
	metricRedisCmdCalls                             metricRedisCmdCalls
	metricRedisCmdLatency                           metricRedisCmdLatency
	metricRedisCmdUsec                              metricRedisCmdUsec
	metricRedisCommands                             metricRedisCommands
	metricRedisCommandsProcessed                    metricRedisCommandsProcessed
	metricRedisConnectionsReceived                  metricRedisConnectionsReceived
	metricRedisConnectionsRejected                  metricRedisConnectionsRejected
	metricRedisCPUTime                              metricRedisCPUTime
	metricRedisDbAvgTTL                             metricRedisDbAvgTTL
	metricRedisDbExpires                            metricRedisDbExpires
	metricRedisDbKeys                               metricRedisDbKeys
	metricRedisKeysEvicted                          metricRedisKeysEvicted
	metricRedisKeysExpired                          metricRedisKeysExpired
	metricRedisKeyspaceHits                         metricRedisKeyspaceHits
	metricRedisKeyspaceMisses                       metricRedisKeyspaceMisses
	metricRedisLatestFork                           metricRedisLatestFork
	metricRedisMaxmemory                            metricRedisMaxmemory
	metricRedisMemoryFragmentationRatio             metricRedisMemoryFragmentationRatio
	metricRedisMemoryLua                            metricRedisMemoryLua
	metricRedisMemoryPeak                           metricRedisMemoryPeak
	metricRedisMemoryRss                            metricRedisMemoryRss
	metricRedisMemoryUsed                           metricRedisMemoryUsed
	metricRedisNetInput                             metricRedisNetInput
	metricRedisNetOutput                            metricRedisNetOutput
	metricRedisRdbChangesSinceLastSave              metricRedisRdbChangesSinceLastSave
	metricRedisReplicationBacklogFirstByteOffset    metricRedisReplicationBacklogFirstByteOffset
	metricRedisReplicationOffset                    metricRedisReplicationOffset
	metricRedisReplicationReplicaOffset             metricRedisReplicationReplicaOffset
	metricRedisRole                                 metricRedisRole
	metricRedisSlavesConnected                      metricRedisSlavesConnected
	metricRedisUptime                               metricRedisUptime
}

// MetricBuilderOption applies changes to default metrics builder.
type MetricBuilderOption interface {
	apply(*MetricsBuilder)
}

type metricBuilderOptionFunc func(mb *MetricsBuilder)

func (mbof metricBuilderOptionFunc) apply(mb *MetricsBuilder) {
	mbof(mb)
}

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) MetricBuilderOption {
	return metricBuilderOptionFunc(func(mb *MetricsBuilder) {
		mb.startTime = startTime
	})
}
func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.Settings, options ...MetricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:                            mbc,
		startTime:                         pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:                     pmetric.NewMetrics(),
		buildInfo:                         settings.BuildInfo,
		metricRedisClientsBlocked:         newMetricRedisClientsBlocked(mbc.Metrics.RedisClientsBlocked),
		metricRedisClientsConnected:       newMetricRedisClientsConnected(mbc.Metrics.RedisClientsConnected),
		metricRedisClientsMaxInputBuffer:  newMetricRedisClientsMaxInputBuffer(mbc.Metrics.RedisClientsMaxInputBuffer),
		metricRedisClientsMaxOutputBuffer: newMetricRedisClientsMaxOutputBuffer(mbc.Metrics.RedisClientsMaxOutputBuffer),
		metricRedisClusterKnownNodes:      newMetricRedisClusterKnownNodes(mbc.Metrics.RedisClusterKnownNodes),
		metricRedisClusterLinksBufferLimitExceededCount: newMetricRedisClusterLinksBufferLimitExceededCount(mbc.Metrics.RedisClusterLinksBufferLimitExceededCount),
		metricRedisClusterNodeCount:                     newMetricRedisClusterNodeCount(mbc.Metrics.RedisClusterNodeCount),
		metricRedisClusterNodeUptime:                    newMetricRedisClusterNodeUptime(mbc.Metrics.RedisClusterNodeUptime),
		metricRedisClusterSlotsAssigned:                 newMetricRedisClusterSlotsAssigned(mbc.Metrics.RedisClusterSlotsAssigned),
		metricRedisClusterSlotsFail:                     newMetricRedisClusterSlotsFail(mbc.Metrics.RedisClusterSlotsFail),
		metricRedisClusterSlotsOk:                       newMetricRedisClusterSlotsOk(mbc.Metrics.RedisClusterSlotsOk),
		metricRedisClusterSlotsPfail:                    newMetricRedisClusterSlotsPfail(mbc.Metrics.RedisClusterSlotsPfail),
		metricRedisClusterState:                         newMetricRedisClusterState(mbc.Metrics.RedisClusterState),
		metricRedisClusterStatsMessagesReceived:         newMetricRedisClusterStatsMessagesReceived(mbc.Metrics.RedisClusterStatsMessagesReceived),
		metricRedisClusterStatsMessagesSent:             newMetricRedisClusterStatsMessagesSent(mbc.Metrics.RedisClusterStatsMessagesSent),
		metricRedisClusterUptime:                        newMetricRedisClusterUptime(mbc.Metrics.RedisClusterUptime),
		metricRedisCmdCalls:                             newMetricRedisCmdCalls(mbc.Metrics.RedisCmdCalls),
		metricRedisCmdLatency:                           newMetricRedisCmdLatency(mbc.Metrics.RedisCmdLatency),
		metricRedisCmdUsec:                              newMetricRedisCmdUsec(mbc.Metrics.RedisCmdUsec),
		metricRedisCommands:                             newMetricRedisCommands(mbc.Metrics.RedisCommands),
		metricRedisCommandsProcessed:                    newMetricRedisCommandsProcessed(mbc.Metrics.RedisCommandsProcessed),
		metricRedisConnectionsReceived:                  newMetricRedisConnectionsReceived(mbc.Metrics.RedisConnectionsReceived),
		metricRedisConnectionsRejected:                  newMetricRedisConnectionsRejected(mbc.Metrics.RedisConnectionsRejected),
		metricRedisCPUTime:                              newMetricRedisCPUTime(mbc.Metrics.RedisCPUTime),
		metricRedisDbAvgTTL:                             newMetricRedisDbAvgTTL(mbc.Metrics.RedisDbAvgTTL),
		metricRedisDbExpires:                            newMetricRedisDbExpires(mbc.Metrics.RedisDbExpires),
		metricRedisDbKeys:                               newMetricRedisDbKeys(mbc.Metrics.RedisDbKeys),
		metricRedisKeysEvicted:                          newMetricRedisKeysEvicted(mbc.Metrics.RedisKeysEvicted),
		metricRedisKeysExpired:                          newMetricRedisKeysExpired(mbc.Metrics.RedisKeysExpired),
		metricRedisKeyspaceHits:                         newMetricRedisKeyspaceHits(mbc.Metrics.RedisKeyspaceHits),
		metricRedisKeyspaceMisses:                       newMetricRedisKeyspaceMisses(mbc.Metrics.RedisKeyspaceMisses),
		metricRedisLatestFork:                           newMetricRedisLatestFork(mbc.Metrics.RedisLatestFork),
		metricRedisMaxmemory:                            newMetricRedisMaxmemory(mbc.Metrics.RedisMaxmemory),
		metricRedisMemoryFragmentationRatio:             newMetricRedisMemoryFragmentationRatio(mbc.Metrics.RedisMemoryFragmentationRatio),
		metricRedisMemoryLua:                            newMetricRedisMemoryLua(mbc.Metrics.RedisMemoryLua),
		metricRedisMemoryPeak:                           newMetricRedisMemoryPeak(mbc.Metrics.RedisMemoryPeak),
		metricRedisMemoryRss:                            newMetricRedisMemoryRss(mbc.Metrics.RedisMemoryRss),
		metricRedisMemoryUsed:                           newMetricRedisMemoryUsed(mbc.Metrics.RedisMemoryUsed),
		metricRedisNetInput:                             newMetricRedisNetInput(mbc.Metrics.RedisNetInput),
		metricRedisNetOutput:                            newMetricRedisNetOutput(mbc.Metrics.RedisNetOutput),
		metricRedisRdbChangesSinceLastSave:              newMetricRedisRdbChangesSinceLastSave(mbc.Metrics.RedisRdbChangesSinceLastSave),
		metricRedisReplicationBacklogFirstByteOffset:    newMetricRedisReplicationBacklogFirstByteOffset(mbc.Metrics.RedisReplicationBacklogFirstByteOffset),
		metricRedisReplicationOffset:                    newMetricRedisReplicationOffset(mbc.Metrics.RedisReplicationOffset),
		metricRedisReplicationReplicaOffset:             newMetricRedisReplicationReplicaOffset(mbc.Metrics.RedisReplicationReplicaOffset),
		metricRedisRole:                                 newMetricRedisRole(mbc.Metrics.RedisRole),
		metricRedisSlavesConnected:                      newMetricRedisSlavesConnected(mbc.Metrics.RedisSlavesConnected),
		metricRedisUptime:                               newMetricRedisUptime(mbc.Metrics.RedisUptime),
		resourceAttributeIncludeFilter:                  make(map[string]filter.Filter),
		resourceAttributeExcludeFilter:                  make(map[string]filter.Filter),
	}
	if mbc.ResourceAttributes.RedisVersion.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["redis.version"] = filter.CreateFilter(mbc.ResourceAttributes.RedisVersion.MetricsInclude)
	}
	if mbc.ResourceAttributes.RedisVersion.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["redis.version"] = filter.CreateFilter(mbc.ResourceAttributes.RedisVersion.MetricsExclude)
	}
	if mbc.ResourceAttributes.ServerAddress.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["server.address"] = filter.CreateFilter(mbc.ResourceAttributes.ServerAddress.MetricsInclude)
	}
	if mbc.ResourceAttributes.ServerAddress.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["server.address"] = filter.CreateFilter(mbc.ResourceAttributes.ServerAddress.MetricsExclude)
	}
	if mbc.ResourceAttributes.ServerPort.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["server.port"] = filter.CreateFilter(mbc.ResourceAttributes.ServerPort.MetricsInclude)
	}
	if mbc.ResourceAttributes.ServerPort.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["server.port"] = filter.CreateFilter(mbc.ResourceAttributes.ServerPort.MetricsExclude)
	}

	for _, op := range options {
		op.apply(mb)
	}
	return mb
}

// NewResourceBuilder returns a new resource builder that should be used to build a resource associated with for the emitted metrics.
func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	return NewResourceBuilder(mb.config.ResourceAttributes)
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption interface {
	apply(pmetric.ResourceMetrics)
}

type resourceMetricsOptionFunc func(pmetric.ResourceMetrics)

func (rmof resourceMetricsOptionFunc) apply(rm pmetric.ResourceMetrics) {
	rmof(rm)
}

// WithResource sets the provided resource on the emitted ResourceMetrics.
// It's recommended to use ResourceBuilder to create the resource.
func WithResource(res pcommon.Resource) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		res.CopyTo(rm.Resource())
	})
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	})
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(options ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName(ScopeName)
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricRedisClientsBlocked.emit(ils.Metrics())
	mb.metricRedisClientsConnected.emit(ils.Metrics())
	mb.metricRedisClientsMaxInputBuffer.emit(ils.Metrics())
	mb.metricRedisClientsMaxOutputBuffer.emit(ils.Metrics())
	mb.metricRedisClusterKnownNodes.emit(ils.Metrics())
	mb.metricRedisClusterLinksBufferLimitExceededCount.emit(ils.Metrics())
	mb.metricRedisClusterNodeCount.emit(ils.Metrics())
	mb.metricRedisClusterNodeUptime.emit(ils.Metrics())
	mb.metricRedisClusterSlotsAssigned.emit(ils.Metrics())
	mb.metricRedisClusterSlotsFail.emit(ils.Metrics())
	mb.metricRedisClusterSlotsOk.emit(ils.Metrics())
	mb.metricRedisClusterSlotsPfail.emit(ils.Metrics())
	mb.metricRedisClusterState.emit(ils.Metrics())
	mb.metricRedisClusterStatsMessagesReceived.emit(ils.Metrics())
	mb.metricRedisClusterStatsMessagesSent.emit(ils.Metrics())
	mb.metricRedisClusterUptime.emit(ils.Metrics())
	mb.metricRedisCmdCalls.emit(ils.Metrics())
	mb.metricRedisCmdLatency.emit(ils.Metrics())
	mb.metricRedisCmdUsec.emit(ils.Metrics())
	mb.metricRedisCommands.emit(ils.Metrics())
	mb.metricRedisCommandsProcessed.emit(ils.Metrics())
	mb.metricRedisConnectionsReceived.emit(ils.Metrics())
	mb.metricRedisConnectionsRejected.emit(ils.Metrics())
	mb.metricRedisCPUTime.emit(ils.Metrics())
	mb.metricRedisDbAvgTTL.emit(ils.Metrics())
	mb.metricRedisDbExpires.emit(ils.Metrics())
	mb.metricRedisDbKeys.emit(ils.Metrics())
	mb.metricRedisKeysEvicted.emit(ils.Metrics())
	mb.metricRedisKeysExpired.emit(ils.Metrics())
	mb.metricRedisKeyspaceHits.emit(ils.Metrics())
	mb.metricRedisKeyspaceMisses.emit(ils.Metrics())
	mb.metricRedisLatestFork.emit(ils.Metrics())
	mb.metricRedisMaxmemory.emit(ils.Metrics())
	mb.metricRedisMemoryFragmentationRatio.emit(ils.Metrics())
	mb.metricRedisMemoryLua.emit(ils.Metrics())
	mb.metricRedisMemoryPeak.emit(ils.Metrics())
	mb.metricRedisMemoryRss.emit(ils.Metrics())
	mb.metricRedisMemoryUsed.emit(ils.Metrics())
	mb.metricRedisNetInput.emit(ils.Metrics())
	mb.metricRedisNetOutput.emit(ils.Metrics())
	mb.metricRedisRdbChangesSinceLastSave.emit(ils.Metrics())
	mb.metricRedisReplicationBacklogFirstByteOffset.emit(ils.Metrics())
	mb.metricRedisReplicationOffset.emit(ils.Metrics())
	mb.metricRedisReplicationReplicaOffset.emit(ils.Metrics())
	mb.metricRedisRole.emit(ils.Metrics())
	mb.metricRedisSlavesConnected.emit(ils.Metrics())
	mb.metricRedisUptime.emit(ils.Metrics())

	for _, op := range options {
		op.apply(rm)
	}
	for attr, filter := range mb.resourceAttributeIncludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && !filter.Matches(val.AsString()) {
			return
		}
	}
	for attr, filter := range mb.resourceAttributeExcludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && filter.Matches(val.AsString()) {
			return
		}
	}

	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(options ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(options...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordRedisClientsBlockedDataPoint adds a data point to redis.clients.blocked metric.
func (mb *MetricsBuilder) RecordRedisClientsBlockedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisClientsBlocked.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClientsConnectedDataPoint adds a data point to redis.clients.connected metric.
func (mb *MetricsBuilder) RecordRedisClientsConnectedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisClientsConnected.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClientsMaxInputBufferDataPoint adds a data point to redis.clients.max_input_buffer metric.
func (mb *MetricsBuilder) RecordRedisClientsMaxInputBufferDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisClientsMaxInputBuffer.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClientsMaxOutputBufferDataPoint adds a data point to redis.clients.max_output_buffer metric.
func (mb *MetricsBuilder) RecordRedisClientsMaxOutputBufferDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisClientsMaxOutputBuffer.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClusterKnownNodesDataPoint adds a data point to redis.cluster.known_nodes metric.
func (mb *MetricsBuilder) RecordRedisClusterKnownNodesDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisClusterKnownNodes.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClusterLinksBufferLimitExceededCountDataPoint adds a data point to redis.cluster.links_buffer_limit_exceeded.count metric.
func (mb *MetricsBuilder) RecordRedisClusterLinksBufferLimitExceededCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisClusterLinksBufferLimitExceededCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClusterNodeCountDataPoint adds a data point to redis.cluster.node.count metric.
func (mb *MetricsBuilder) RecordRedisClusterNodeCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisClusterNodeCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClusterNodeUptimeDataPoint adds a data point to redis.cluster.node.uptime metric.
func (mb *MetricsBuilder) RecordRedisClusterNodeUptimeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisClusterNodeUptime.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClusterSlotsAssignedDataPoint adds a data point to redis.cluster.slots_assigned metric.
func (mb *MetricsBuilder) RecordRedisClusterSlotsAssignedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisClusterSlotsAssigned.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClusterSlotsFailDataPoint adds a data point to redis.cluster.slots_fail metric.
func (mb *MetricsBuilder) RecordRedisClusterSlotsFailDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisClusterSlotsFail.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClusterSlotsOkDataPoint adds a data point to redis.cluster.slots_ok metric.
func (mb *MetricsBuilder) RecordRedisClusterSlotsOkDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisClusterSlotsOk.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClusterSlotsPfailDataPoint adds a data point to redis.cluster.slots_pfail metric.
func (mb *MetricsBuilder) RecordRedisClusterSlotsPfailDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisClusterSlotsPfail.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClusterStateDataPoint adds a data point to redis.cluster.state metric.
func (mb *MetricsBuilder) RecordRedisClusterStateDataPoint(ts pcommon.Timestamp, val int64, clusterStateAttributeValue AttributeClusterState) {
	mb.metricRedisClusterState.recordDataPoint(mb.startTime, ts, val, clusterStateAttributeValue.String())
}

// RecordRedisClusterStatsMessagesReceivedDataPoint adds a data point to redis.cluster.stats_messages_received metric.
func (mb *MetricsBuilder) RecordRedisClusterStatsMessagesReceivedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisClusterStatsMessagesReceived.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClusterStatsMessagesSentDataPoint adds a data point to redis.cluster.stats_messages_sent metric.
func (mb *MetricsBuilder) RecordRedisClusterStatsMessagesSentDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisClusterStatsMessagesSent.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisClusterUptimeDataPoint adds a data point to redis.cluster.uptime metric.
func (mb *MetricsBuilder) RecordRedisClusterUptimeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisClusterUptime.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisCmdCallsDataPoint adds a data point to redis.cmd.calls metric.
func (mb *MetricsBuilder) RecordRedisCmdCallsDataPoint(ts pcommon.Timestamp, val int64, cmdAttributeValue string) {
	mb.metricRedisCmdCalls.recordDataPoint(mb.startTime, ts, val, cmdAttributeValue)
}

// RecordRedisCmdLatencyDataPoint adds a data point to redis.cmd.latency metric.
func (mb *MetricsBuilder) RecordRedisCmdLatencyDataPoint(ts pcommon.Timestamp, val float64, cmdAttributeValue string, percentileAttributeValue AttributePercentile) {
	mb.metricRedisCmdLatency.recordDataPoint(mb.startTime, ts, val, cmdAttributeValue, percentileAttributeValue.String())
}

// RecordRedisCmdUsecDataPoint adds a data point to redis.cmd.usec metric.
func (mb *MetricsBuilder) RecordRedisCmdUsecDataPoint(ts pcommon.Timestamp, val int64, cmdAttributeValue string) {
	mb.metricRedisCmdUsec.recordDataPoint(mb.startTime, ts, val, cmdAttributeValue)
}

// RecordRedisCommandsDataPoint adds a data point to redis.commands metric.
func (mb *MetricsBuilder) RecordRedisCommandsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisCommands.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisCommandsProcessedDataPoint adds a data point to redis.commands.processed metric.
func (mb *MetricsBuilder) RecordRedisCommandsProcessedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisCommandsProcessed.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisConnectionsReceivedDataPoint adds a data point to redis.connections.received metric.
func (mb *MetricsBuilder) RecordRedisConnectionsReceivedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisConnectionsReceived.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisConnectionsRejectedDataPoint adds a data point to redis.connections.rejected metric.
func (mb *MetricsBuilder) RecordRedisConnectionsRejectedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisConnectionsRejected.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisCPUTimeDataPoint adds a data point to redis.cpu.time metric.
func (mb *MetricsBuilder) RecordRedisCPUTimeDataPoint(ts pcommon.Timestamp, val float64, stateAttributeValue AttributeState) {
	mb.metricRedisCPUTime.recordDataPoint(mb.startTime, ts, val, stateAttributeValue.String())
}

// RecordRedisDbAvgTTLDataPoint adds a data point to redis.db.avg_ttl metric.
func (mb *MetricsBuilder) RecordRedisDbAvgTTLDataPoint(ts pcommon.Timestamp, val int64, dbAttributeValue string) {
	mb.metricRedisDbAvgTTL.recordDataPoint(mb.startTime, ts, val, dbAttributeValue)
}

// RecordRedisDbExpiresDataPoint adds a data point to redis.db.expires metric.
func (mb *MetricsBuilder) RecordRedisDbExpiresDataPoint(ts pcommon.Timestamp, val int64, dbAttributeValue string) {
	mb.metricRedisDbExpires.recordDataPoint(mb.startTime, ts, val, dbAttributeValue)
}

// RecordRedisDbKeysDataPoint adds a data point to redis.db.keys metric.
func (mb *MetricsBuilder) RecordRedisDbKeysDataPoint(ts pcommon.Timestamp, val int64, dbAttributeValue string) {
	mb.metricRedisDbKeys.recordDataPoint(mb.startTime, ts, val, dbAttributeValue)
}

// RecordRedisKeysEvictedDataPoint adds a data point to redis.keys.evicted metric.
func (mb *MetricsBuilder) RecordRedisKeysEvictedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisKeysEvicted.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisKeysExpiredDataPoint adds a data point to redis.keys.expired metric.
func (mb *MetricsBuilder) RecordRedisKeysExpiredDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisKeysExpired.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisKeyspaceHitsDataPoint adds a data point to redis.keyspace.hits metric.
func (mb *MetricsBuilder) RecordRedisKeyspaceHitsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisKeyspaceHits.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisKeyspaceMissesDataPoint adds a data point to redis.keyspace.misses metric.
func (mb *MetricsBuilder) RecordRedisKeyspaceMissesDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisKeyspaceMisses.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisLatestForkDataPoint adds a data point to redis.latest_fork metric.
func (mb *MetricsBuilder) RecordRedisLatestForkDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisLatestFork.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisMaxmemoryDataPoint adds a data point to redis.maxmemory metric.
func (mb *MetricsBuilder) RecordRedisMaxmemoryDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisMaxmemory.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisMemoryFragmentationRatioDataPoint adds a data point to redis.memory.fragmentation_ratio metric.
func (mb *MetricsBuilder) RecordRedisMemoryFragmentationRatioDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricRedisMemoryFragmentationRatio.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisMemoryLuaDataPoint adds a data point to redis.memory.lua metric.
func (mb *MetricsBuilder) RecordRedisMemoryLuaDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisMemoryLua.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisMemoryPeakDataPoint adds a data point to redis.memory.peak metric.
func (mb *MetricsBuilder) RecordRedisMemoryPeakDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisMemoryPeak.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisMemoryRssDataPoint adds a data point to redis.memory.rss metric.
func (mb *MetricsBuilder) RecordRedisMemoryRssDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisMemoryRss.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisMemoryUsedDataPoint adds a data point to redis.memory.used metric.
func (mb *MetricsBuilder) RecordRedisMemoryUsedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisMemoryUsed.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisNetInputDataPoint adds a data point to redis.net.input metric.
func (mb *MetricsBuilder) RecordRedisNetInputDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisNetInput.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisNetOutputDataPoint adds a data point to redis.net.output metric.
func (mb *MetricsBuilder) RecordRedisNetOutputDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisNetOutput.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisRdbChangesSinceLastSaveDataPoint adds a data point to redis.rdb.changes_since_last_save metric.
func (mb *MetricsBuilder) RecordRedisRdbChangesSinceLastSaveDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisRdbChangesSinceLastSave.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisReplicationBacklogFirstByteOffsetDataPoint adds a data point to redis.replication.backlog_first_byte_offset metric.
func (mb *MetricsBuilder) RecordRedisReplicationBacklogFirstByteOffsetDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisReplicationBacklogFirstByteOffset.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisReplicationOffsetDataPoint adds a data point to redis.replication.offset metric.
func (mb *MetricsBuilder) RecordRedisReplicationOffsetDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisReplicationOffset.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisReplicationReplicaOffsetDataPoint adds a data point to redis.replication.replica_offset metric.
func (mb *MetricsBuilder) RecordRedisReplicationReplicaOffsetDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisReplicationReplicaOffset.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisRoleDataPoint adds a data point to redis.role metric.
func (mb *MetricsBuilder) RecordRedisRoleDataPoint(ts pcommon.Timestamp, val int64, roleAttributeValue AttributeRole) {
	mb.metricRedisRole.recordDataPoint(mb.startTime, ts, val, roleAttributeValue.String())
}

// RecordRedisSlavesConnectedDataPoint adds a data point to redis.slaves.connected metric.
func (mb *MetricsBuilder) RecordRedisSlavesConnectedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisSlavesConnected.recordDataPoint(mb.startTime, ts, val)
}

// RecordRedisUptimeDataPoint adds a data point to redis.uptime metric.
func (mb *MetricsBuilder) RecordRedisUptimeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricRedisUptime.recordDataPoint(mb.startTime, ts, val)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...MetricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op.apply(mb)
	}
}
