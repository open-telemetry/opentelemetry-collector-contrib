# AWS Lambda Receiver
<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [development]: logs, metrics   |
| Distributions | [] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aopen%20label%3Areceiver%2Fawslambda%20&label=open&color=orange&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aopen+is%3Aissue+label%3Areceiver%2Fawslambda) [![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aclosed%20label%3Areceiver%2Fawslambda%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aclosed+is%3Aissue+label%3Areceiver%2Fawslambda) |
| Code coverage | [![codecov](https://codecov.io/github/open-telemetry/opentelemetry-collector-contrib/graph/main/badge.svg?component=receiver_awslambda)](https://app.codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/tree/main/?components%5B0%5D=receiver_awslambda&displayType=list) |
| [Code Owners](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/CONTRIBUTING.md#becoming-a-code-owner)    | [@MichaelKatsoulis](https://www.github.com/MichaelKatsoulis), [@Kavindu-Dodan](https://www.github.com/Kavindu-Dodan), [@axw](https://www.github.com/axw), [@pjanotti](https://www.github.com/pjanotti) |

[development]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/component-stability.md#development
<!-- end autogenerated section -->

## Overview

A receiver for collecting logs & metrics from AWS services via Lambda invocations. 
AWS Lambda is a popular serverless service used extensively for event-driven architectures. 
Many AWS services (S3, CloudWatch, SNS, SQS) can trigger Lambda functions, making it an ideal entry point for collecting data from AWS services.
This receiver is designed to run as part of an OpenTelemetry Collector deployed as an AWS Lambda function.

The `awslambdareceiver` enables users to:

- Collect logs & metrics stored at various AWS services as OTel native log records & metric data points
- Collect custom logs via AWS services that can trigger Lambda functions
- Decode/Unmarshal AWS-specific log formats using OpenTelemetry encoding extensions
- Leverage OpenTelemetry's processors to further enrich, filter, or transform collected data before exporting

## How It Works

The `awslambdareceiver` operates as follows:

1. Accepts Lambda Invocations
2. Identifies the event source (S3, CloudWatch, etc.)
3. Uses configured encoding extensions to parse the data
4. Creates OpenTelemetry records matching the data type (logs, metrics)
5. Forward derived records to the next component in the pipeline (processors, exporters)

## Event handling

The receiver automatically detects the event source based on the Lambda invocation message format.
Table below summarizes supported signals and their sources:

| Signal  | Sources                          |
|---------|----------------------------------|
| Logs    | S3, CloudWatch Logs subscription |
| Metrics | S3                               |

Sections below summarize how each event source is handled.

### S3 Event handling

S3 events are handled in the following manner:

- Received S3 event notification (for example, using Lambda trigger on `s3:ObjectCreated:*`)
- Download S3 object payload
- Decode payload using the configured encoding extension
  - Default encoding: Preserve S3 object content as-is
  - Custom encoding: Use specified encoding extension (for example, `awslogs_encoding` for AWS log formats)
  - Metrics use `awscloudwatchmetricstreams_encoding` extension by default

### CloudWatch Logs subscription

CloudWatch Logs events are handled in the following manner:

- Receive CloudWatch Logs subscription filter event
- Parse the CloudWatch Logs message (note - unlike S3 events, the payload is included in the event)
- Decode payload using the configured encoding extension
  - Default encoding: Parse CloudWatch Logs messages to OpenTelemetry log records
  - Custom encoding: Use specified encoding extension (for example, `awslogs_encoding` for AWS log formats)

### Configurations

The following receiver configuration parameters are supported.

| Name                   | Description                                             |
|:-----------------------|:--------------------------------------------------------|
| `s3::encoding`         | Optional encoder to use for S3 event processing         | 
| `cloudwatch::encoding` | Optional encoder to use for CloudWatch event processing | 

Consider following notes on default behaviors:

- When `s3::encoding` is not specified, the receiver defaults to preserving the S3 object content as-is for logs.
  - The log record's `Body` field will be a string type where the S3 object content is valid UTF-8, and otherwise will be a byte array.
- When `cloudwatch::encoding` is not specified, the receiver defaults to parsing CloudWatch Logs messages to OpenTelemetry log records.
- For metrics, the default behavior is to decode using `awscloudwatchmetricstreams_encoding` extension.

Given below are example configurations for various use cases.

### Example 1: VPC Flow Logs from S3

```yaml
receivers:
  awslambda:
    s3:
      encoding: awslogs_encoding

extensions:
  awslogs_encoding:
    format: vpcflow
    vpcflow:
      file_format: plain-text

exporters:
  otlphttp:
    endpoint: "https://my-backend:443"

service:
  extensions:
    - awslogs_encoding
  pipelines:
    logs:
      receivers: [awslambda]
      exporters: [otlphttp]
```

In this example, the `awslambdareceiver` is expected to be triggered when a VPC flow log is created at S3 bucket.
The receiver retrieves the log file from S3 and decodes it using the `awslogs_encoding` extension with the `vpcflow` format.
Parsed logs are forwarded to an OTLP listener via the `otlphttp` exporter.

### Example 2: ELB Access Logs from S3

```yaml
receivers:
  awslambda:
    s3:
      encoding: awslogs_encoding

extensions:
  awslogs_encoding:
    format: elbaccess
    elbaccess:
      file_format: plain-text

exporters:
  otlphttp:
    endpoint: "https://my-backend:443"

service:
  extensions:
    - awslogs_encoding
  pipelines:
    logs:
      receivers: [awslambda]
      exporters: [otlphttp]
```

Similar to the first example, this configuration is for collecting ELB access logs stored in S3.

### Example 3: CloudWatch Logs using CloudWatch Subscription Filters

```yaml
receivers:
  awslambda:

exporters:
  otlphttp:
    endpoint: "https://my-backend:443"

service:
  pipelines:
    logs:
      receivers: [awslambda]
      exporters: [otlphttp]
```

For this deployment configuration, when receiver is triggered by a CloudWatch Logs subscription filter, the CloudWatch 
messages will be extracted and converted to an OpenTelemetry log record. 
These logs then get forwarded to an OTLP listener via the `otlphttp` exporter.

### Example 4: Arbitrary S3 content (logs or metrics)

```yaml
receivers:
  awslambda:

exporters:
  otlphttp:
    endpoint: "https://my-backend:443"

service:
  pipelines:
    logs:
      receivers: [awslambda]
      exporters: [otlphttp]
```

For this deployment configuration, when receiver is triggered by an S3 event, 

- Logs: Content of the S3 object will be added to an OpenTelemetry log record. If content is string, then it will be added as-is.
- Metrics: Metrics will be decoded using `awscloudwatchmetricstreams_encoding` extension.

## AWS Permissions

The Lambda function requires the following IAM permissions:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject"
      ],
      "Resource": "arn:aws:s3:::your-log-bucket/*"
    }
  ]
}
```

## Error Handling

- Detailed error information is logged for troubleshooting
   
  These logs can be views via the configured CloudWatch Logs group for the Lambda function.

- Error retrying 

  Error retrying can be configured through the Lambda deployment setting.
  Read more about at [AWS error handling for asynchronous invocations](https://docs.aws.amazon.com/lambda/latest/dg/invocation-async-configuring.html).

- Retaining failed records

  This component supports replaying retained failure records stored at S3.
  Read more about retaining records at [Capture records of Lambda Async Invocations](https://docs.aws.amazon.com/lambda/latest/dg/invocation-async-retain-records.html).

### Error replaying from S3

When an S3 bucket is configured as the destination for retaining failed Lambda records, the receiver supports replaying those failed events for reprocessing.
To enable this feature, set the `failure_bucket_arn` configuration to the ARN of your S3 bucket used as the Lambda failure destination.

```yaml
receivers:
  awslambda:
    s3:
      encoding: awslogs_encoding
    failure_bucket_arn: "arn:aws:s3:::example"
```

With required configuration present, receiver accepts a custom event to trigger replaying failed events.
Consider the event structure below,

```json
{
  "replayFailedEvents": {
    "dryrun": false,
    "removeOnSuccess": true
  }
}
```

JSON key `replayFailedEvents` defines the custom event type for replaying failed events.
The table below explains supported options,

| Option          | Description                                                                                    | Default |
|-----------------|------------------------------------------------------------------------------------------------|---------|
| dryrun          | Run the command without processing. Useful to understand details about replaying error files   | false   |
| removeOnSuccess | Configure whether to remove error event from S3 error destination, if processing is successful | true    |

> [!NOTE]  
> It is recommended to use "dryrun" mode to validate the number of replayable errors in the error destination bucket.
> If there are many errors, the Lambda invocation may time out before processing all error entries.
> If a timeout occur, you will need to run the custom event multiple times to fully process all error events from the bucket.

### Running with AWS CLI

First, obtain the name of the deployed Lambda function from your deployment.
Then, invoke the Lambda with the following command:

```shell
aws lambda invoke \
  --function-name <LAMBDA_DEPLOYMENT_NAME> \
  --payload '{ "replayFailedEvents": {}}' \
  --cli-binary-format raw-in-base64-out /dev/null
```

If successful, you should see `"StatusCode": 200` in the output.
Check the CloudWatch logs for detailed information.

> [!NOTE]
> Using AWS CLI, you can use `--timeout` option to increase currently configured Lambda timeout for custom invocations.
> Also note that errors resulting from this manual trigger are not retained back to S3 failure destination. 
> This is because Lambda only retains errors for asynchronous invocations.

To perform a dry run, use the following command with `dryrun` set to `true`:

```shell
aws lambda invoke \
  --function-name <LAMBDA_DEPLOYMENT_NAME> \
  --payload '{ "replayFailedEvents": { "dryrun": true }}' \
  --cli-binary-format raw-in-base64-out /dev/null
```

This allows you to see how many error events are available for replay without actually processing them.
