// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/confmap"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
	conventions "go.opentelemetry.io/collector/semconv/v1.6.1"
)

// MetricSettings provides common settings for a particular metric.
type MetricSettings struct {
	Enabled bool `mapstructure:"enabled"`

	enabledProvidedByUser bool
}

// IsEnabledProvidedByUser returns true if `enabled` option is explicitly set in user settings to any value.
func (ms *MetricSettings) IsEnabledProvidedByUser() bool {
	return ms.enabledProvidedByUser
}

func (ms *MetricSettings) Unmarshal(parser *confmap.Conf) error {
	if parser == nil {
		return nil
	}
	err := parser.Unmarshal(ms, confmap.WithErrorUnused())
	if err != nil {
		return err
	}
	ms.enabledProvidedByUser = parser.IsSet("enabled")
	return nil
}

// MetricsSettings provides settings for dockerstatsreceiver metrics.
type MetricsSettings struct {
	ContainerBlockioIoMergedRecursive          MetricSettings `mapstructure:"container.blockio.io_merged_recursive"`
	ContainerBlockioIoQueuedRecursive          MetricSettings `mapstructure:"container.blockio.io_queued_recursive"`
	ContainerBlockioIoServiceBytesRecursive    MetricSettings `mapstructure:"container.blockio.io_service_bytes_recursive"`
	ContainerBlockioIoServiceTimeRecursive     MetricSettings `mapstructure:"container.blockio.io_service_time_recursive"`
	ContainerBlockioIoServicedRecursive        MetricSettings `mapstructure:"container.blockio.io_serviced_recursive"`
	ContainerBlockioIoTimeRecursive            MetricSettings `mapstructure:"container.blockio.io_time_recursive"`
	ContainerBlockioIoWaitTimeRecursive        MetricSettings `mapstructure:"container.blockio.io_wait_time_recursive"`
	ContainerBlockioSectorsRecursive           MetricSettings `mapstructure:"container.blockio.sectors_recursive"`
	ContainerCPUPercent                        MetricSettings `mapstructure:"container.cpu.percent"`
	ContainerCPUThrottlingDataPeriods          MetricSettings `mapstructure:"container.cpu.throttling_data.periods"`
	ContainerCPUThrottlingDataThrottledPeriods MetricSettings `mapstructure:"container.cpu.throttling_data.throttled_periods"`
	ContainerCPUThrottlingDataThrottledTime    MetricSettings `mapstructure:"container.cpu.throttling_data.throttled_time"`
	ContainerCPUUsageKernelmode                MetricSettings `mapstructure:"container.cpu.usage.kernelmode"`
	ContainerCPUUsagePercpu                    MetricSettings `mapstructure:"container.cpu.usage.percpu"`
	ContainerCPUUsageSystem                    MetricSettings `mapstructure:"container.cpu.usage.system"`
	ContainerCPUUsageTotal                     MetricSettings `mapstructure:"container.cpu.usage.total"`
	ContainerCPUUsageUsermode                  MetricSettings `mapstructure:"container.cpu.usage.usermode"`
	ContainerMemoryActiveAnon                  MetricSettings `mapstructure:"container.memory.active_anon"`
	ContainerMemoryActiveFile                  MetricSettings `mapstructure:"container.memory.active_file"`
	ContainerMemoryCache                       MetricSettings `mapstructure:"container.memory.cache"`
	ContainerMemoryDirty                       MetricSettings `mapstructure:"container.memory.dirty"`
	ContainerMemoryHierarchicalMemoryLimit     MetricSettings `mapstructure:"container.memory.hierarchical_memory_limit"`
	ContainerMemoryHierarchicalMemswLimit      MetricSettings `mapstructure:"container.memory.hierarchical_memsw_limit"`
	ContainerMemoryInactiveAnon                MetricSettings `mapstructure:"container.memory.inactive_anon"`
	ContainerMemoryInactiveFile                MetricSettings `mapstructure:"container.memory.inactive_file"`
	ContainerMemoryMappedFile                  MetricSettings `mapstructure:"container.memory.mapped_file"`
	ContainerMemoryPercent                     MetricSettings `mapstructure:"container.memory.percent"`
	ContainerMemoryPgfault                     MetricSettings `mapstructure:"container.memory.pgfault"`
	ContainerMemoryPgmajfault                  MetricSettings `mapstructure:"container.memory.pgmajfault"`
	ContainerMemoryPgpgin                      MetricSettings `mapstructure:"container.memory.pgpgin"`
	ContainerMemoryPgpgout                     MetricSettings `mapstructure:"container.memory.pgpgout"`
	ContainerMemoryRss                         MetricSettings `mapstructure:"container.memory.rss"`
	ContainerMemoryRssHuge                     MetricSettings `mapstructure:"container.memory.rss_huge"`
	ContainerMemorySwap                        MetricSettings `mapstructure:"container.memory.swap"`
	ContainerMemoryTotalActiveAnon             MetricSettings `mapstructure:"container.memory.total_active_anon"`
	ContainerMemoryTotalActiveFile             MetricSettings `mapstructure:"container.memory.total_active_file"`
	ContainerMemoryTotalCache                  MetricSettings `mapstructure:"container.memory.total_cache"`
	ContainerMemoryTotalDirty                  MetricSettings `mapstructure:"container.memory.total_dirty"`
	ContainerMemoryTotalInactiveAnon           MetricSettings `mapstructure:"container.memory.total_inactive_anon"`
	ContainerMemoryTotalInactiveFile           MetricSettings `mapstructure:"container.memory.total_inactive_file"`
	ContainerMemoryTotalMappedFile             MetricSettings `mapstructure:"container.memory.total_mapped_file"`
	ContainerMemoryTotalPgfault                MetricSettings `mapstructure:"container.memory.total_pgfault"`
	ContainerMemoryTotalPgmajfault             MetricSettings `mapstructure:"container.memory.total_pgmajfault"`
	ContainerMemoryTotalPgpgin                 MetricSettings `mapstructure:"container.memory.total_pgpgin"`
	ContainerMemoryTotalPgpgout                MetricSettings `mapstructure:"container.memory.total_pgpgout"`
	ContainerMemoryTotalRss                    MetricSettings `mapstructure:"container.memory.total_rss"`
	ContainerMemoryTotalRssHuge                MetricSettings `mapstructure:"container.memory.total_rss_huge"`
	ContainerMemoryTotalSwap                   MetricSettings `mapstructure:"container.memory.total_swap"`
	ContainerMemoryTotalUnevictable            MetricSettings `mapstructure:"container.memory.total_unevictable"`
	ContainerMemoryTotalWriteback              MetricSettings `mapstructure:"container.memory.total_writeback"`
	ContainerMemoryUnevictable                 MetricSettings `mapstructure:"container.memory.unevictable"`
	ContainerMemoryUsageLimit                  MetricSettings `mapstructure:"container.memory.usage.limit"`
	ContainerMemoryUsageMax                    MetricSettings `mapstructure:"container.memory.usage.max"`
	ContainerMemoryUsageTotal                  MetricSettings `mapstructure:"container.memory.usage.total"`
	ContainerMemoryWriteback                   MetricSettings `mapstructure:"container.memory.writeback"`
	ContainerNetworkIoUsageRxBytes             MetricSettings `mapstructure:"container.network.io.usage.rx_bytes"`
	ContainerNetworkIoUsageRxDropped           MetricSettings `mapstructure:"container.network.io.usage.rx_dropped"`
	ContainerNetworkIoUsageRxErrors            MetricSettings `mapstructure:"container.network.io.usage.rx_errors"`
	ContainerNetworkIoUsageRxPackets           MetricSettings `mapstructure:"container.network.io.usage.rx_packets"`
	ContainerNetworkIoUsageTxBytes             MetricSettings `mapstructure:"container.network.io.usage.tx_bytes"`
	ContainerNetworkIoUsageTxDropped           MetricSettings `mapstructure:"container.network.io.usage.tx_dropped"`
	ContainerNetworkIoUsageTxErrors            MetricSettings `mapstructure:"container.network.io.usage.tx_errors"`
	ContainerNetworkIoUsageTxPackets           MetricSettings `mapstructure:"container.network.io.usage.tx_packets"`
}

func DefaultMetricsSettings() MetricsSettings {
	return MetricsSettings{
		ContainerBlockioIoMergedRecursive: MetricSettings{
			Enabled: false,
		},
		ContainerBlockioIoQueuedRecursive: MetricSettings{
			Enabled: false,
		},
		ContainerBlockioIoServiceBytesRecursive: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServiceTimeRecursive: MetricSettings{
			Enabled: false,
		},
		ContainerBlockioIoServicedRecursive: MetricSettings{
			Enabled: false,
		},
		ContainerBlockioIoTimeRecursive: MetricSettings{
			Enabled: false,
		},
		ContainerBlockioIoWaitTimeRecursive: MetricSettings{
			Enabled: false,
		},
		ContainerBlockioSectorsRecursive: MetricSettings{
			Enabled: false,
		},
		ContainerCPUPercent: MetricSettings{
			Enabled: true,
		},
		ContainerCPUThrottlingDataPeriods: MetricSettings{
			Enabled: false,
		},
		ContainerCPUThrottlingDataThrottledPeriods: MetricSettings{
			Enabled: false,
		},
		ContainerCPUThrottlingDataThrottledTime: MetricSettings{
			Enabled: false,
		},
		ContainerCPUUsageKernelmode: MetricSettings{
			Enabled: true,
		},
		ContainerCPUUsagePercpu: MetricSettings{
			Enabled: false,
		},
		ContainerCPUUsageSystem: MetricSettings{
			Enabled: false,
		},
		ContainerCPUUsageTotal: MetricSettings{
			Enabled: true,
		},
		ContainerCPUUsageUsermode: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryActiveAnon: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryActiveFile: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryCache: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryDirty: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryHierarchicalMemoryLimit: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryHierarchicalMemswLimit: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryInactiveAnon: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryInactiveFile: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryMappedFile: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryPercent: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryPgfault: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryPgmajfault: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryPgpgin: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryPgpgout: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryRss: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryRssHuge: MetricSettings{
			Enabled: false,
		},
		ContainerMemorySwap: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryTotalActiveAnon: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryTotalActiveFile: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryTotalCache: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalDirty: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryTotalInactiveAnon: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryTotalInactiveFile: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryTotalMappedFile: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryTotalPgfault: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryTotalPgmajfault: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryTotalPgpgin: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryTotalPgpgout: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryTotalRss: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryTotalRssHuge: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryTotalSwap: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryTotalUnevictable: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryTotalWriteback: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryUnevictable: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryUsageLimit: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryUsageMax: MetricSettings{
			Enabled: false,
		},
		ContainerMemoryUsageTotal: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryWriteback: MetricSettings{
			Enabled: false,
		},
		ContainerNetworkIoUsageRxBytes: MetricSettings{
			Enabled: true,
		},
		ContainerNetworkIoUsageRxDropped: MetricSettings{
			Enabled: true,
		},
		ContainerNetworkIoUsageRxErrors: MetricSettings{
			Enabled: false,
		},
		ContainerNetworkIoUsageRxPackets: MetricSettings{
			Enabled: false,
		},
		ContainerNetworkIoUsageTxBytes: MetricSettings{
			Enabled: true,
		},
		ContainerNetworkIoUsageTxDropped: MetricSettings{
			Enabled: true,
		},
		ContainerNetworkIoUsageTxErrors: MetricSettings{
			Enabled: false,
		},
		ContainerNetworkIoUsageTxPackets: MetricSettings{
			Enabled: false,
		},
	}
}

type metricContainerBlockioIoMergedRecursive struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_merged_recursive metric with initial data.
func (m *metricContainerBlockioIoMergedRecursive) init() {
	m.data.SetName("container.blockio.io_merged_recursive")
	m.data.SetDescription("Number of bios/requests merged into requests belonging to this cgroup and its descendant cgroups.")
	m.data.SetUnit("{operations}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoMergedRecursive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("device_major", deviceMajorAttributeValue)
	dp.Attributes().PutStr("device_minor", deviceMinorAttributeValue)
	dp.Attributes().PutStr("operation", operationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoMergedRecursive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoMergedRecursive) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoMergedRecursive(settings MetricSettings) metricContainerBlockioIoMergedRecursive {
	m := metricContainerBlockioIoMergedRecursive{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoQueuedRecursive struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_queued_recursive metric with initial data.
func (m *metricContainerBlockioIoQueuedRecursive) init() {
	m.data.SetName("container.blockio.io_queued_recursive")
	m.data.SetDescription("Number of requests queued up for this cgroup and its descendant cgroups.")
	m.data.SetUnit("{operations}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoQueuedRecursive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("device_major", deviceMajorAttributeValue)
	dp.Attributes().PutStr("device_minor", deviceMinorAttributeValue)
	dp.Attributes().PutStr("operation", operationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoQueuedRecursive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoQueuedRecursive) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoQueuedRecursive(settings MetricSettings) metricContainerBlockioIoQueuedRecursive {
	m := metricContainerBlockioIoQueuedRecursive{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServiceBytesRecursive struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_service_bytes_recursive metric with initial data.
func (m *metricContainerBlockioIoServiceBytesRecursive) init() {
	m.data.SetName("container.blockio.io_service_bytes_recursive")
	m.data.SetDescription("Number of bytes transferred to/from the disk by the group and descendant groups.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServiceBytesRecursive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("device_major", deviceMajorAttributeValue)
	dp.Attributes().PutStr("device_minor", deviceMinorAttributeValue)
	dp.Attributes().PutStr("operation", operationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServiceBytesRecursive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServiceBytesRecursive) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServiceBytesRecursive(settings MetricSettings) metricContainerBlockioIoServiceBytesRecursive {
	m := metricContainerBlockioIoServiceBytesRecursive{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServiceTimeRecursive struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_service_time_recursive metric with initial data.
func (m *metricContainerBlockioIoServiceTimeRecursive) init() {
	m.data.SetName("container.blockio.io_service_time_recursive")
	m.data.SetDescription("Total amount of time in nanoseconds between request dispatch and request completion for the IOs done by this cgroup and descendant cgroups.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServiceTimeRecursive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("device_major", deviceMajorAttributeValue)
	dp.Attributes().PutStr("device_minor", deviceMinorAttributeValue)
	dp.Attributes().PutStr("operation", operationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServiceTimeRecursive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServiceTimeRecursive) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServiceTimeRecursive(settings MetricSettings) metricContainerBlockioIoServiceTimeRecursive {
	m := metricContainerBlockioIoServiceTimeRecursive{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServicedRecursive struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_serviced_recursive metric with initial data.
func (m *metricContainerBlockioIoServicedRecursive) init() {
	m.data.SetName("container.blockio.io_serviced_recursive")
	m.data.SetDescription("Number of IOs (bio) issued to the disk by the group and descendant groups.")
	m.data.SetUnit("{operations}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServicedRecursive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("device_major", deviceMajorAttributeValue)
	dp.Attributes().PutStr("device_minor", deviceMinorAttributeValue)
	dp.Attributes().PutStr("operation", operationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServicedRecursive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServicedRecursive) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServicedRecursive(settings MetricSettings) metricContainerBlockioIoServicedRecursive {
	m := metricContainerBlockioIoServicedRecursive{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoTimeRecursive struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_time_recursive metric with initial data.
func (m *metricContainerBlockioIoTimeRecursive) init() {
	m.data.SetName("container.blockio.io_time_recursive")
	m.data.SetDescription("Disk time allocated to cgroup (and descendant cgroups) per device in milliseconds.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoTimeRecursive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("device_major", deviceMajorAttributeValue)
	dp.Attributes().PutStr("device_minor", deviceMinorAttributeValue)
	dp.Attributes().PutStr("operation", operationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoTimeRecursive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoTimeRecursive) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoTimeRecursive(settings MetricSettings) metricContainerBlockioIoTimeRecursive {
	m := metricContainerBlockioIoTimeRecursive{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoWaitTimeRecursive struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_wait_time_recursive metric with initial data.
func (m *metricContainerBlockioIoWaitTimeRecursive) init() {
	m.data.SetName("container.blockio.io_wait_time_recursive")
	m.data.SetDescription("Total amount of time the IOs for this cgroup (and descendant cgroups) spent waiting in the scheduler queues for service.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoWaitTimeRecursive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("device_major", deviceMajorAttributeValue)
	dp.Attributes().PutStr("device_minor", deviceMinorAttributeValue)
	dp.Attributes().PutStr("operation", operationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoWaitTimeRecursive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoWaitTimeRecursive) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoWaitTimeRecursive(settings MetricSettings) metricContainerBlockioIoWaitTimeRecursive {
	m := metricContainerBlockioIoWaitTimeRecursive{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioSectorsRecursive struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.sectors_recursive metric with initial data.
func (m *metricContainerBlockioSectorsRecursive) init() {
	m.data.SetName("container.blockio.sectors_recursive")
	m.data.SetDescription("Number of sectors transferred to/from disk by the group and descendant groups.")
	m.data.SetUnit("{sectors}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioSectorsRecursive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("device_major", deviceMajorAttributeValue)
	dp.Attributes().PutStr("device_minor", deviceMinorAttributeValue)
	dp.Attributes().PutStr("operation", operationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioSectorsRecursive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioSectorsRecursive) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioSectorsRecursive(settings MetricSettings) metricContainerBlockioSectorsRecursive {
	m := metricContainerBlockioSectorsRecursive{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUPercent struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.percent metric with initial data.
func (m *metricContainerCPUPercent) init() {
	m.data.SetName("container.cpu.percent")
	m.data.SetDescription("Percent of CPU used by the container.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
}

func (m *metricContainerCPUPercent) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUPercent) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUPercent) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUPercent(settings MetricSettings) metricContainerCPUPercent {
	m := metricContainerCPUPercent{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUThrottlingDataPeriods struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.throttling_data.periods metric with initial data.
func (m *metricContainerCPUThrottlingDataPeriods) init() {
	m.data.SetName("container.cpu.throttling_data.periods")
	m.data.SetDescription("Number of periods with throttling active.")
	m.data.SetUnit("{periods}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerCPUThrottlingDataPeriods) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUThrottlingDataPeriods) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUThrottlingDataPeriods) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUThrottlingDataPeriods(settings MetricSettings) metricContainerCPUThrottlingDataPeriods {
	m := metricContainerCPUThrottlingDataPeriods{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUThrottlingDataThrottledPeriods struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.throttling_data.throttled_periods metric with initial data.
func (m *metricContainerCPUThrottlingDataThrottledPeriods) init() {
	m.data.SetName("container.cpu.throttling_data.throttled_periods")
	m.data.SetDescription("Number of periods when the container hits its throttling limit.")
	m.data.SetUnit("{periods}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerCPUThrottlingDataThrottledPeriods) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUThrottlingDataThrottledPeriods) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUThrottlingDataThrottledPeriods) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUThrottlingDataThrottledPeriods(settings MetricSettings) metricContainerCPUThrottlingDataThrottledPeriods {
	m := metricContainerCPUThrottlingDataThrottledPeriods{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUThrottlingDataThrottledTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.throttling_data.throttled_time metric with initial data.
func (m *metricContainerCPUThrottlingDataThrottledTime) init() {
	m.data.SetName("container.cpu.throttling_data.throttled_time")
	m.data.SetDescription("Aggregate time the container was throttled.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerCPUThrottlingDataThrottledTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUThrottlingDataThrottledTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUThrottlingDataThrottledTime) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUThrottlingDataThrottledTime(settings MetricSettings) metricContainerCPUThrottlingDataThrottledTime {
	m := metricContainerCPUThrottlingDataThrottledTime{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUUsageKernelmode struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.usage.kernelmode metric with initial data.
func (m *metricContainerCPUUsageKernelmode) init() {
	m.data.SetName("container.cpu.usage.kernelmode")
	m.data.SetDescription("Time spent by tasks of the cgroup in kernel mode (Linux).  Time spent by all container processes in kernel mode (Windows).")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerCPUUsageKernelmode) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUUsageKernelmode) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUUsageKernelmode) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUUsageKernelmode(settings MetricSettings) metricContainerCPUUsageKernelmode {
	m := metricContainerCPUUsageKernelmode{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUUsagePercpu struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.usage.percpu metric with initial data.
func (m *metricContainerCPUUsagePercpu) init() {
	m.data.SetName("container.cpu.usage.percpu")
	m.data.SetDescription("Per-core CPU usage by the container.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerCPUUsagePercpu) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, coreAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("core", coreAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUUsagePercpu) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUUsagePercpu) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUUsagePercpu(settings MetricSettings) metricContainerCPUUsagePercpu {
	m := metricContainerCPUUsagePercpu{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUUsageSystem struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.usage.system metric with initial data.
func (m *metricContainerCPUUsageSystem) init() {
	m.data.SetName("container.cpu.usage.system")
	m.data.SetDescription("System CPU usage, as reported by docker.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerCPUUsageSystem) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUUsageSystem) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUUsageSystem) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUUsageSystem(settings MetricSettings) metricContainerCPUUsageSystem {
	m := metricContainerCPUUsageSystem{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUUsageTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.usage.total metric with initial data.
func (m *metricContainerCPUUsageTotal) init() {
	m.data.SetName("container.cpu.usage.total")
	m.data.SetDescription("Total CPU time consumed.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerCPUUsageTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUUsageTotal) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUUsageTotal) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUUsageTotal(settings MetricSettings) metricContainerCPUUsageTotal {
	m := metricContainerCPUUsageTotal{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUUsageUsermode struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.usage.usermode metric with initial data.
func (m *metricContainerCPUUsageUsermode) init() {
	m.data.SetName("container.cpu.usage.usermode")
	m.data.SetDescription("Time spent by tasks of the cgroup in user mode (Linux).  Time spent by all container processes in user mode (Windows).")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerCPUUsageUsermode) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUUsageUsermode) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUUsageUsermode) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUUsageUsermode(settings MetricSettings) metricContainerCPUUsageUsermode {
	m := metricContainerCPUUsageUsermode{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryActiveAnon struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.active_anon metric with initial data.
func (m *metricContainerMemoryActiveAnon) init() {
	m.data.SetName("container.memory.active_anon")
	m.data.SetDescription("The amount of anonymous memory that has been identified as active by the kernel.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryActiveAnon) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryActiveAnon) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryActiveAnon) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryActiveAnon(settings MetricSettings) metricContainerMemoryActiveAnon {
	m := metricContainerMemoryActiveAnon{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryActiveFile struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.active_file metric with initial data.
func (m *metricContainerMemoryActiveFile) init() {
	m.data.SetName("container.memory.active_file")
	m.data.SetDescription("Cache memory that has been identified as active by the kernel.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryActiveFile) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryActiveFile) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryActiveFile) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryActiveFile(settings MetricSettings) metricContainerMemoryActiveFile {
	m := metricContainerMemoryActiveFile{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryCache struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.cache metric with initial data.
func (m *metricContainerMemoryCache) init() {
	m.data.SetName("container.memory.cache")
	m.data.SetDescription("The amount of memory used by the processes of this control group that can be associated precisely with a block on a block device.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryCache) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryCache) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryCache) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryCache(settings MetricSettings) metricContainerMemoryCache {
	m := metricContainerMemoryCache{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryDirty struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.dirty metric with initial data.
func (m *metricContainerMemoryDirty) init() {
	m.data.SetName("container.memory.dirty")
	m.data.SetDescription("Bytes that are waiting to get written back to the disk, from this cgroup.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryDirty) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryDirty) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryDirty) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryDirty(settings MetricSettings) metricContainerMemoryDirty {
	m := metricContainerMemoryDirty{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryHierarchicalMemoryLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.hierarchical_memory_limit metric with initial data.
func (m *metricContainerMemoryHierarchicalMemoryLimit) init() {
	m.data.SetName("container.memory.hierarchical_memory_limit")
	m.data.SetDescription("The maximum amount of physical memory that can be used by the processes of this control group.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryHierarchicalMemoryLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryHierarchicalMemoryLimit) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryHierarchicalMemoryLimit) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryHierarchicalMemoryLimit(settings MetricSettings) metricContainerMemoryHierarchicalMemoryLimit {
	m := metricContainerMemoryHierarchicalMemoryLimit{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryHierarchicalMemswLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.hierarchical_memsw_limit metric with initial data.
func (m *metricContainerMemoryHierarchicalMemswLimit) init() {
	m.data.SetName("container.memory.hierarchical_memsw_limit")
	m.data.SetDescription("The maximum amount of RAM + swap that can be used by the processes of this control group.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryHierarchicalMemswLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryHierarchicalMemswLimit) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryHierarchicalMemswLimit) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryHierarchicalMemswLimit(settings MetricSettings) metricContainerMemoryHierarchicalMemswLimit {
	m := metricContainerMemoryHierarchicalMemswLimit{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryInactiveAnon struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.inactive_anon metric with initial data.
func (m *metricContainerMemoryInactiveAnon) init() {
	m.data.SetName("container.memory.inactive_anon")
	m.data.SetDescription("The amount of anonymous memory that has been identified as inactive by the kernel.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryInactiveAnon) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryInactiveAnon) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryInactiveAnon) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryInactiveAnon(settings MetricSettings) metricContainerMemoryInactiveAnon {
	m := metricContainerMemoryInactiveAnon{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryInactiveFile struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.inactive_file metric with initial data.
func (m *metricContainerMemoryInactiveFile) init() {
	m.data.SetName("container.memory.inactive_file")
	m.data.SetDescription("Cache memory that has been identified as inactive by the kernel.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryInactiveFile) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryInactiveFile) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryInactiveFile) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryInactiveFile(settings MetricSettings) metricContainerMemoryInactiveFile {
	m := metricContainerMemoryInactiveFile{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryMappedFile struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.mapped_file metric with initial data.
func (m *metricContainerMemoryMappedFile) init() {
	m.data.SetName("container.memory.mapped_file")
	m.data.SetDescription("Indicates the amount of memory mapped by the processes in the control group.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryMappedFile) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryMappedFile) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryMappedFile) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryMappedFile(settings MetricSettings) metricContainerMemoryMappedFile {
	m := metricContainerMemoryMappedFile{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryPercent struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.percent metric with initial data.
func (m *metricContainerMemoryPercent) init() {
	m.data.SetName("container.memory.percent")
	m.data.SetDescription("Percentage of memory used.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
}

func (m *metricContainerMemoryPercent) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryPercent) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryPercent) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryPercent(settings MetricSettings) metricContainerMemoryPercent {
	m := metricContainerMemoryPercent{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryPgfault struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.pgfault metric with initial data.
func (m *metricContainerMemoryPgfault) init() {
	m.data.SetName("container.memory.pgfault")
	m.data.SetDescription("Indicate the number of times that a process of the cgroup triggered a page fault.")
	m.data.SetUnit("{faults}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryPgfault) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryPgfault) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryPgfault) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryPgfault(settings MetricSettings) metricContainerMemoryPgfault {
	m := metricContainerMemoryPgfault{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryPgmajfault struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.pgmajfault metric with initial data.
func (m *metricContainerMemoryPgmajfault) init() {
	m.data.SetName("container.memory.pgmajfault")
	m.data.SetDescription("Indicate the number of times that a process of the cgroup triggered a major fault.")
	m.data.SetUnit("{faults}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryPgmajfault) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryPgmajfault) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryPgmajfault) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryPgmajfault(settings MetricSettings) metricContainerMemoryPgmajfault {
	m := metricContainerMemoryPgmajfault{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryPgpgin struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.pgpgin metric with initial data.
func (m *metricContainerMemoryPgpgin) init() {
	m.data.SetName("container.memory.pgpgin")
	m.data.SetDescription("Number of pages read from disk by the cgroup.")
	m.data.SetUnit("{operations}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryPgpgin) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryPgpgin) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryPgpgin) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryPgpgin(settings MetricSettings) metricContainerMemoryPgpgin {
	m := metricContainerMemoryPgpgin{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryPgpgout struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.pgpgout metric with initial data.
func (m *metricContainerMemoryPgpgout) init() {
	m.data.SetName("container.memory.pgpgout")
	m.data.SetDescription("Number of pages written to disk by the cgroup.")
	m.data.SetUnit("{operations}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryPgpgout) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryPgpgout) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryPgpgout) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryPgpgout(settings MetricSettings) metricContainerMemoryPgpgout {
	m := metricContainerMemoryPgpgout{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryRss struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.rss metric with initial data.
func (m *metricContainerMemoryRss) init() {
	m.data.SetName("container.memory.rss")
	m.data.SetDescription("The amount of memory that doesnt correspond to anything on disk: stacks, heaps, and anonymous memory maps.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryRss) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryRss) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryRss) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryRss(settings MetricSettings) metricContainerMemoryRss {
	m := metricContainerMemoryRss{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryRssHuge struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.rss_huge metric with initial data.
func (m *metricContainerMemoryRssHuge) init() {
	m.data.SetName("container.memory.rss_huge")
	m.data.SetDescription("Number of bytes of anonymous transparent hugepages in this cgroup.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryRssHuge) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryRssHuge) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryRssHuge) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryRssHuge(settings MetricSettings) metricContainerMemoryRssHuge {
	m := metricContainerMemoryRssHuge{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemorySwap struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.swap metric with initial data.
func (m *metricContainerMemorySwap) init() {
	m.data.SetName("container.memory.swap")
	m.data.SetDescription("The amount of swap currently used by the processes in this cgroup.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemorySwap) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemorySwap) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemorySwap) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemorySwap(settings MetricSettings) metricContainerMemorySwap {
	m := metricContainerMemorySwap{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalActiveAnon struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_active_anon metric with initial data.
func (m *metricContainerMemoryTotalActiveAnon) init() {
	m.data.SetName("container.memory.total_active_anon")
	m.data.SetDescription("The amount of anonymous memory that has been identified as active by the kernel. Includes descendant cgroups.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalActiveAnon) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalActiveAnon) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalActiveAnon) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalActiveAnon(settings MetricSettings) metricContainerMemoryTotalActiveAnon {
	m := metricContainerMemoryTotalActiveAnon{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalActiveFile struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_active_file metric with initial data.
func (m *metricContainerMemoryTotalActiveFile) init() {
	m.data.SetName("container.memory.total_active_file")
	m.data.SetDescription("Cache memory that has been identified as active by the kernel. Includes descendant cgroups.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalActiveFile) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalActiveFile) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalActiveFile) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalActiveFile(settings MetricSettings) metricContainerMemoryTotalActiveFile {
	m := metricContainerMemoryTotalActiveFile{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalCache struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_cache metric with initial data.
func (m *metricContainerMemoryTotalCache) init() {
	m.data.SetName("container.memory.total_cache")
	m.data.SetDescription("Total amount of memory used by the processes of this cgroup (and descendants) that can be associated with a block on a block device. Also accounts for memory used by tmpfs.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalCache) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalCache) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalCache) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalCache(settings MetricSettings) metricContainerMemoryTotalCache {
	m := metricContainerMemoryTotalCache{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalDirty struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_dirty metric with initial data.
func (m *metricContainerMemoryTotalDirty) init() {
	m.data.SetName("container.memory.total_dirty")
	m.data.SetDescription("Bytes that are waiting to get written back to the disk, from this cgroup and descendants.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalDirty) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalDirty) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalDirty) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalDirty(settings MetricSettings) metricContainerMemoryTotalDirty {
	m := metricContainerMemoryTotalDirty{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalInactiveAnon struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_inactive_anon metric with initial data.
func (m *metricContainerMemoryTotalInactiveAnon) init() {
	m.data.SetName("container.memory.total_inactive_anon")
	m.data.SetDescription("The amount of anonymous memory that has been identified as inactive by the kernel. Includes descendant cgroups.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalInactiveAnon) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalInactiveAnon) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalInactiveAnon) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalInactiveAnon(settings MetricSettings) metricContainerMemoryTotalInactiveAnon {
	m := metricContainerMemoryTotalInactiveAnon{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalInactiveFile struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_inactive_file metric with initial data.
func (m *metricContainerMemoryTotalInactiveFile) init() {
	m.data.SetName("container.memory.total_inactive_file")
	m.data.SetDescription("Cache memory that has been identified as inactive by the kernel. Includes descendant cgroups.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalInactiveFile) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalInactiveFile) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalInactiveFile) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalInactiveFile(settings MetricSettings) metricContainerMemoryTotalInactiveFile {
	m := metricContainerMemoryTotalInactiveFile{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalMappedFile struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_mapped_file metric with initial data.
func (m *metricContainerMemoryTotalMappedFile) init() {
	m.data.SetName("container.memory.total_mapped_file")
	m.data.SetDescription("Indicates the amount of memory mapped by the processes in the control group and descendant groups.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalMappedFile) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalMappedFile) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalMappedFile) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalMappedFile(settings MetricSettings) metricContainerMemoryTotalMappedFile {
	m := metricContainerMemoryTotalMappedFile{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalPgfault struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_pgfault metric with initial data.
func (m *metricContainerMemoryTotalPgfault) init() {
	m.data.SetName("container.memory.total_pgfault")
	m.data.SetDescription("Indicate the number of times that a process of the cgroup (or descendant cgroups) triggered a page fault.")
	m.data.SetUnit("{faults}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalPgfault) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalPgfault) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalPgfault) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalPgfault(settings MetricSettings) metricContainerMemoryTotalPgfault {
	m := metricContainerMemoryTotalPgfault{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalPgmajfault struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_pgmajfault metric with initial data.
func (m *metricContainerMemoryTotalPgmajfault) init() {
	m.data.SetName("container.memory.total_pgmajfault")
	m.data.SetDescription("Indicate the number of times that a process of the cgroup (or descendant cgroups) triggered a major fault.")
	m.data.SetUnit("{faults}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalPgmajfault) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalPgmajfault) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalPgmajfault) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalPgmajfault(settings MetricSettings) metricContainerMemoryTotalPgmajfault {
	m := metricContainerMemoryTotalPgmajfault{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalPgpgin struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_pgpgin metric with initial data.
func (m *metricContainerMemoryTotalPgpgin) init() {
	m.data.SetName("container.memory.total_pgpgin")
	m.data.SetDescription("Number of pages read from disk by the cgroup and descendant groups.")
	m.data.SetUnit("{operations}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalPgpgin) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalPgpgin) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalPgpgin) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalPgpgin(settings MetricSettings) metricContainerMemoryTotalPgpgin {
	m := metricContainerMemoryTotalPgpgin{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalPgpgout struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_pgpgout metric with initial data.
func (m *metricContainerMemoryTotalPgpgout) init() {
	m.data.SetName("container.memory.total_pgpgout")
	m.data.SetDescription("Number of pages written to disk by the cgroup and descendant groups.")
	m.data.SetUnit("{operations}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalPgpgout) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalPgpgout) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalPgpgout) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalPgpgout(settings MetricSettings) metricContainerMemoryTotalPgpgout {
	m := metricContainerMemoryTotalPgpgout{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalRss struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_rss metric with initial data.
func (m *metricContainerMemoryTotalRss) init() {
	m.data.SetName("container.memory.total_rss")
	m.data.SetDescription("The amount of memory that doesnt correspond to anything on disk: stacks, heaps, and anonymous memory maps. Includes descendant cgroups.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalRss) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalRss) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalRss) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalRss(settings MetricSettings) metricContainerMemoryTotalRss {
	m := metricContainerMemoryTotalRss{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalRssHuge struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_rss_huge metric with initial data.
func (m *metricContainerMemoryTotalRssHuge) init() {
	m.data.SetName("container.memory.total_rss_huge")
	m.data.SetDescription("Number of bytes of anonymous transparent hugepages in this cgroup and descendant cgroups.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalRssHuge) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalRssHuge) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalRssHuge) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalRssHuge(settings MetricSettings) metricContainerMemoryTotalRssHuge {
	m := metricContainerMemoryTotalRssHuge{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalSwap struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_swap metric with initial data.
func (m *metricContainerMemoryTotalSwap) init() {
	m.data.SetName("container.memory.total_swap")
	m.data.SetDescription("The amount of swap currently used by the processes in this cgroup and descendant groups.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalSwap) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalSwap) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalSwap) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalSwap(settings MetricSettings) metricContainerMemoryTotalSwap {
	m := metricContainerMemoryTotalSwap{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalUnevictable struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_unevictable metric with initial data.
func (m *metricContainerMemoryTotalUnevictable) init() {
	m.data.SetName("container.memory.total_unevictable")
	m.data.SetDescription("The amount of memory that cannot be reclaimed. Includes descendant cgroups.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalUnevictable) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalUnevictable) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalUnevictable) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalUnevictable(settings MetricSettings) metricContainerMemoryTotalUnevictable {
	m := metricContainerMemoryTotalUnevictable{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalWriteback struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_writeback metric with initial data.
func (m *metricContainerMemoryTotalWriteback) init() {
	m.data.SetName("container.memory.total_writeback")
	m.data.SetDescription("Number of bytes of file/anon cache that are queued for syncing to disk in this cgroup and descendants.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalWriteback) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalWriteback) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalWriteback) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalWriteback(settings MetricSettings) metricContainerMemoryTotalWriteback {
	m := metricContainerMemoryTotalWriteback{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryUnevictable struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.unevictable metric with initial data.
func (m *metricContainerMemoryUnevictable) init() {
	m.data.SetName("container.memory.unevictable")
	m.data.SetDescription("The amount of memory that cannot be reclaimed.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryUnevictable) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryUnevictable) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryUnevictable) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryUnevictable(settings MetricSettings) metricContainerMemoryUnevictable {
	m := metricContainerMemoryUnevictable{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryUsageLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.usage.limit metric with initial data.
func (m *metricContainerMemoryUsageLimit) init() {
	m.data.SetName("container.memory.usage.limit")
	m.data.SetDescription("Memory limit of the container.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryUsageLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryUsageLimit) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryUsageLimit) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryUsageLimit(settings MetricSettings) metricContainerMemoryUsageLimit {
	m := metricContainerMemoryUsageLimit{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryUsageMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.usage.max metric with initial data.
func (m *metricContainerMemoryUsageMax) init() {
	m.data.SetName("container.memory.usage.max")
	m.data.SetDescription("Maximum memory usage.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryUsageMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryUsageMax) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryUsageMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryUsageMax(settings MetricSettings) metricContainerMemoryUsageMax {
	m := metricContainerMemoryUsageMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryUsageTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.usage.total metric with initial data.
func (m *metricContainerMemoryUsageTotal) init() {
	m.data.SetName("container.memory.usage.total")
	m.data.SetDescription("Memory usage of the container. This excludes the total cache.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryUsageTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryUsageTotal) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryUsageTotal) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryUsageTotal(settings MetricSettings) metricContainerMemoryUsageTotal {
	m := metricContainerMemoryUsageTotal{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryWriteback struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.writeback metric with initial data.
func (m *metricContainerMemoryWriteback) init() {
	m.data.SetName("container.memory.writeback")
	m.data.SetDescription("Number of bytes of file/anon cache that are queued for syncing to disk in this cgroup.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricContainerMemoryWriteback) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryWriteback) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryWriteback) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryWriteback(settings MetricSettings) metricContainerMemoryWriteback {
	m := metricContainerMemoryWriteback{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageRxBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.rx_bytes metric with initial data.
func (m *metricContainerNetworkIoUsageRxBytes) init() {
	m.data.SetName("container.network.io.usage.rx_bytes")
	m.data.SetDescription("Bytes received by the container.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageRxBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("interface", interfaceAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageRxBytes) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageRxBytes) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageRxBytes(settings MetricSettings) metricContainerNetworkIoUsageRxBytes {
	m := metricContainerNetworkIoUsageRxBytes{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageRxDropped struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.rx_dropped metric with initial data.
func (m *metricContainerNetworkIoUsageRxDropped) init() {
	m.data.SetName("container.network.io.usage.rx_dropped")
	m.data.SetDescription("Incoming packets dropped.")
	m.data.SetUnit("{packets}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageRxDropped) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("interface", interfaceAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageRxDropped) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageRxDropped) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageRxDropped(settings MetricSettings) metricContainerNetworkIoUsageRxDropped {
	m := metricContainerNetworkIoUsageRxDropped{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageRxErrors struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.rx_errors metric with initial data.
func (m *metricContainerNetworkIoUsageRxErrors) init() {
	m.data.SetName("container.network.io.usage.rx_errors")
	m.data.SetDescription("Received errors.")
	m.data.SetUnit("{errors}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageRxErrors) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("interface", interfaceAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageRxErrors) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageRxErrors) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageRxErrors(settings MetricSettings) metricContainerNetworkIoUsageRxErrors {
	m := metricContainerNetworkIoUsageRxErrors{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageRxPackets struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.rx_packets metric with initial data.
func (m *metricContainerNetworkIoUsageRxPackets) init() {
	m.data.SetName("container.network.io.usage.rx_packets")
	m.data.SetDescription("Packets received.")
	m.data.SetUnit("{packets}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageRxPackets) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("interface", interfaceAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageRxPackets) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageRxPackets) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageRxPackets(settings MetricSettings) metricContainerNetworkIoUsageRxPackets {
	m := metricContainerNetworkIoUsageRxPackets{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageTxBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.tx_bytes metric with initial data.
func (m *metricContainerNetworkIoUsageTxBytes) init() {
	m.data.SetName("container.network.io.usage.tx_bytes")
	m.data.SetDescription("Bytes sent.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageTxBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("interface", interfaceAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageTxBytes) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageTxBytes) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageTxBytes(settings MetricSettings) metricContainerNetworkIoUsageTxBytes {
	m := metricContainerNetworkIoUsageTxBytes{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageTxDropped struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.tx_dropped metric with initial data.
func (m *metricContainerNetworkIoUsageTxDropped) init() {
	m.data.SetName("container.network.io.usage.tx_dropped")
	m.data.SetDescription("Outgoing packets dropped.")
	m.data.SetUnit("{packets}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageTxDropped) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("interface", interfaceAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageTxDropped) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageTxDropped) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageTxDropped(settings MetricSettings) metricContainerNetworkIoUsageTxDropped {
	m := metricContainerNetworkIoUsageTxDropped{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageTxErrors struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.tx_errors metric with initial data.
func (m *metricContainerNetworkIoUsageTxErrors) init() {
	m.data.SetName("container.network.io.usage.tx_errors")
	m.data.SetDescription("Sent errors.")
	m.data.SetUnit("{errors}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageTxErrors) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("interface", interfaceAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageTxErrors) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageTxErrors) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageTxErrors(settings MetricSettings) metricContainerNetworkIoUsageTxErrors {
	m := metricContainerNetworkIoUsageTxErrors{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageTxPackets struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.tx_packets metric with initial data.
func (m *metricContainerNetworkIoUsageTxPackets) init() {
	m.data.SetName("container.network.io.usage.tx_packets")
	m.data.SetDescription("Packets sent.")
	m.data.SetUnit("{packets}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageTxPackets) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("interface", interfaceAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageTxPackets) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageTxPackets) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageTxPackets(settings MetricSettings) metricContainerNetworkIoUsageTxPackets {
	m := metricContainerNetworkIoUsageTxPackets{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user settings.
type MetricsBuilder struct {
	startTime                                        pcommon.Timestamp   // start time that will be applied to all recorded data points.
	metricsCapacity                                  int                 // maximum observed number of metrics per resource.
	resourceCapacity                                 int                 // maximum observed number of resource attributes.
	metricsBuffer                                    pmetric.Metrics     // accumulates metrics data before emitting.
	buildInfo                                        component.BuildInfo // contains version information
	metricContainerBlockioIoMergedRecursive          metricContainerBlockioIoMergedRecursive
	metricContainerBlockioIoQueuedRecursive          metricContainerBlockioIoQueuedRecursive
	metricContainerBlockioIoServiceBytesRecursive    metricContainerBlockioIoServiceBytesRecursive
	metricContainerBlockioIoServiceTimeRecursive     metricContainerBlockioIoServiceTimeRecursive
	metricContainerBlockioIoServicedRecursive        metricContainerBlockioIoServicedRecursive
	metricContainerBlockioIoTimeRecursive            metricContainerBlockioIoTimeRecursive
	metricContainerBlockioIoWaitTimeRecursive        metricContainerBlockioIoWaitTimeRecursive
	metricContainerBlockioSectorsRecursive           metricContainerBlockioSectorsRecursive
	metricContainerCPUPercent                        metricContainerCPUPercent
	metricContainerCPUThrottlingDataPeriods          metricContainerCPUThrottlingDataPeriods
	metricContainerCPUThrottlingDataThrottledPeriods metricContainerCPUThrottlingDataThrottledPeriods
	metricContainerCPUThrottlingDataThrottledTime    metricContainerCPUThrottlingDataThrottledTime
	metricContainerCPUUsageKernelmode                metricContainerCPUUsageKernelmode
	metricContainerCPUUsagePercpu                    metricContainerCPUUsagePercpu
	metricContainerCPUUsageSystem                    metricContainerCPUUsageSystem
	metricContainerCPUUsageTotal                     metricContainerCPUUsageTotal
	metricContainerCPUUsageUsermode                  metricContainerCPUUsageUsermode
	metricContainerMemoryActiveAnon                  metricContainerMemoryActiveAnon
	metricContainerMemoryActiveFile                  metricContainerMemoryActiveFile
	metricContainerMemoryCache                       metricContainerMemoryCache
	metricContainerMemoryDirty                       metricContainerMemoryDirty
	metricContainerMemoryHierarchicalMemoryLimit     metricContainerMemoryHierarchicalMemoryLimit
	metricContainerMemoryHierarchicalMemswLimit      metricContainerMemoryHierarchicalMemswLimit
	metricContainerMemoryInactiveAnon                metricContainerMemoryInactiveAnon
	metricContainerMemoryInactiveFile                metricContainerMemoryInactiveFile
	metricContainerMemoryMappedFile                  metricContainerMemoryMappedFile
	metricContainerMemoryPercent                     metricContainerMemoryPercent
	metricContainerMemoryPgfault                     metricContainerMemoryPgfault
	metricContainerMemoryPgmajfault                  metricContainerMemoryPgmajfault
	metricContainerMemoryPgpgin                      metricContainerMemoryPgpgin
	metricContainerMemoryPgpgout                     metricContainerMemoryPgpgout
	metricContainerMemoryRss                         metricContainerMemoryRss
	metricContainerMemoryRssHuge                     metricContainerMemoryRssHuge
	metricContainerMemorySwap                        metricContainerMemorySwap
	metricContainerMemoryTotalActiveAnon             metricContainerMemoryTotalActiveAnon
	metricContainerMemoryTotalActiveFile             metricContainerMemoryTotalActiveFile
	metricContainerMemoryTotalCache                  metricContainerMemoryTotalCache
	metricContainerMemoryTotalDirty                  metricContainerMemoryTotalDirty
	metricContainerMemoryTotalInactiveAnon           metricContainerMemoryTotalInactiveAnon
	metricContainerMemoryTotalInactiveFile           metricContainerMemoryTotalInactiveFile
	metricContainerMemoryTotalMappedFile             metricContainerMemoryTotalMappedFile
	metricContainerMemoryTotalPgfault                metricContainerMemoryTotalPgfault
	metricContainerMemoryTotalPgmajfault             metricContainerMemoryTotalPgmajfault
	metricContainerMemoryTotalPgpgin                 metricContainerMemoryTotalPgpgin
	metricContainerMemoryTotalPgpgout                metricContainerMemoryTotalPgpgout
	metricContainerMemoryTotalRss                    metricContainerMemoryTotalRss
	metricContainerMemoryTotalRssHuge                metricContainerMemoryTotalRssHuge
	metricContainerMemoryTotalSwap                   metricContainerMemoryTotalSwap
	metricContainerMemoryTotalUnevictable            metricContainerMemoryTotalUnevictable
	metricContainerMemoryTotalWriteback              metricContainerMemoryTotalWriteback
	metricContainerMemoryUnevictable                 metricContainerMemoryUnevictable
	metricContainerMemoryUsageLimit                  metricContainerMemoryUsageLimit
	metricContainerMemoryUsageMax                    metricContainerMemoryUsageMax
	metricContainerMemoryUsageTotal                  metricContainerMemoryUsageTotal
	metricContainerMemoryWriteback                   metricContainerMemoryWriteback
	metricContainerNetworkIoUsageRxBytes             metricContainerNetworkIoUsageRxBytes
	metricContainerNetworkIoUsageRxDropped           metricContainerNetworkIoUsageRxDropped
	metricContainerNetworkIoUsageRxErrors            metricContainerNetworkIoUsageRxErrors
	metricContainerNetworkIoUsageRxPackets           metricContainerNetworkIoUsageRxPackets
	metricContainerNetworkIoUsageTxBytes             metricContainerNetworkIoUsageTxBytes
	metricContainerNetworkIoUsageTxDropped           metricContainerNetworkIoUsageTxDropped
	metricContainerNetworkIoUsageTxErrors            metricContainerNetworkIoUsageTxErrors
	metricContainerNetworkIoUsageTxPackets           metricContainerNetworkIoUsageTxPackets
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(ms MetricsSettings, settings receiver.CreateSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		startTime:                               pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:                           pmetric.NewMetrics(),
		buildInfo:                               settings.BuildInfo,
		metricContainerBlockioIoMergedRecursive: newMetricContainerBlockioIoMergedRecursive(ms.ContainerBlockioIoMergedRecursive),
		metricContainerBlockioIoQueuedRecursive: newMetricContainerBlockioIoQueuedRecursive(ms.ContainerBlockioIoQueuedRecursive),
		metricContainerBlockioIoServiceBytesRecursive:    newMetricContainerBlockioIoServiceBytesRecursive(ms.ContainerBlockioIoServiceBytesRecursive),
		metricContainerBlockioIoServiceTimeRecursive:     newMetricContainerBlockioIoServiceTimeRecursive(ms.ContainerBlockioIoServiceTimeRecursive),
		metricContainerBlockioIoServicedRecursive:        newMetricContainerBlockioIoServicedRecursive(ms.ContainerBlockioIoServicedRecursive),
		metricContainerBlockioIoTimeRecursive:            newMetricContainerBlockioIoTimeRecursive(ms.ContainerBlockioIoTimeRecursive),
		metricContainerBlockioIoWaitTimeRecursive:        newMetricContainerBlockioIoWaitTimeRecursive(ms.ContainerBlockioIoWaitTimeRecursive),
		metricContainerBlockioSectorsRecursive:           newMetricContainerBlockioSectorsRecursive(ms.ContainerBlockioSectorsRecursive),
		metricContainerCPUPercent:                        newMetricContainerCPUPercent(ms.ContainerCPUPercent),
		metricContainerCPUThrottlingDataPeriods:          newMetricContainerCPUThrottlingDataPeriods(ms.ContainerCPUThrottlingDataPeriods),
		metricContainerCPUThrottlingDataThrottledPeriods: newMetricContainerCPUThrottlingDataThrottledPeriods(ms.ContainerCPUThrottlingDataThrottledPeriods),
		metricContainerCPUThrottlingDataThrottledTime:    newMetricContainerCPUThrottlingDataThrottledTime(ms.ContainerCPUThrottlingDataThrottledTime),
		metricContainerCPUUsageKernelmode:                newMetricContainerCPUUsageKernelmode(ms.ContainerCPUUsageKernelmode),
		metricContainerCPUUsagePercpu:                    newMetricContainerCPUUsagePercpu(ms.ContainerCPUUsagePercpu),
		metricContainerCPUUsageSystem:                    newMetricContainerCPUUsageSystem(ms.ContainerCPUUsageSystem),
		metricContainerCPUUsageTotal:                     newMetricContainerCPUUsageTotal(ms.ContainerCPUUsageTotal),
		metricContainerCPUUsageUsermode:                  newMetricContainerCPUUsageUsermode(ms.ContainerCPUUsageUsermode),
		metricContainerMemoryActiveAnon:                  newMetricContainerMemoryActiveAnon(ms.ContainerMemoryActiveAnon),
		metricContainerMemoryActiveFile:                  newMetricContainerMemoryActiveFile(ms.ContainerMemoryActiveFile),
		metricContainerMemoryCache:                       newMetricContainerMemoryCache(ms.ContainerMemoryCache),
		metricContainerMemoryDirty:                       newMetricContainerMemoryDirty(ms.ContainerMemoryDirty),
		metricContainerMemoryHierarchicalMemoryLimit:     newMetricContainerMemoryHierarchicalMemoryLimit(ms.ContainerMemoryHierarchicalMemoryLimit),
		metricContainerMemoryHierarchicalMemswLimit:      newMetricContainerMemoryHierarchicalMemswLimit(ms.ContainerMemoryHierarchicalMemswLimit),
		metricContainerMemoryInactiveAnon:                newMetricContainerMemoryInactiveAnon(ms.ContainerMemoryInactiveAnon),
		metricContainerMemoryInactiveFile:                newMetricContainerMemoryInactiveFile(ms.ContainerMemoryInactiveFile),
		metricContainerMemoryMappedFile:                  newMetricContainerMemoryMappedFile(ms.ContainerMemoryMappedFile),
		metricContainerMemoryPercent:                     newMetricContainerMemoryPercent(ms.ContainerMemoryPercent),
		metricContainerMemoryPgfault:                     newMetricContainerMemoryPgfault(ms.ContainerMemoryPgfault),
		metricContainerMemoryPgmajfault:                  newMetricContainerMemoryPgmajfault(ms.ContainerMemoryPgmajfault),
		metricContainerMemoryPgpgin:                      newMetricContainerMemoryPgpgin(ms.ContainerMemoryPgpgin),
		metricContainerMemoryPgpgout:                     newMetricContainerMemoryPgpgout(ms.ContainerMemoryPgpgout),
		metricContainerMemoryRss:                         newMetricContainerMemoryRss(ms.ContainerMemoryRss),
		metricContainerMemoryRssHuge:                     newMetricContainerMemoryRssHuge(ms.ContainerMemoryRssHuge),
		metricContainerMemorySwap:                        newMetricContainerMemorySwap(ms.ContainerMemorySwap),
		metricContainerMemoryTotalActiveAnon:             newMetricContainerMemoryTotalActiveAnon(ms.ContainerMemoryTotalActiveAnon),
		metricContainerMemoryTotalActiveFile:             newMetricContainerMemoryTotalActiveFile(ms.ContainerMemoryTotalActiveFile),
		metricContainerMemoryTotalCache:                  newMetricContainerMemoryTotalCache(ms.ContainerMemoryTotalCache),
		metricContainerMemoryTotalDirty:                  newMetricContainerMemoryTotalDirty(ms.ContainerMemoryTotalDirty),
		metricContainerMemoryTotalInactiveAnon:           newMetricContainerMemoryTotalInactiveAnon(ms.ContainerMemoryTotalInactiveAnon),
		metricContainerMemoryTotalInactiveFile:           newMetricContainerMemoryTotalInactiveFile(ms.ContainerMemoryTotalInactiveFile),
		metricContainerMemoryTotalMappedFile:             newMetricContainerMemoryTotalMappedFile(ms.ContainerMemoryTotalMappedFile),
		metricContainerMemoryTotalPgfault:                newMetricContainerMemoryTotalPgfault(ms.ContainerMemoryTotalPgfault),
		metricContainerMemoryTotalPgmajfault:             newMetricContainerMemoryTotalPgmajfault(ms.ContainerMemoryTotalPgmajfault),
		metricContainerMemoryTotalPgpgin:                 newMetricContainerMemoryTotalPgpgin(ms.ContainerMemoryTotalPgpgin),
		metricContainerMemoryTotalPgpgout:                newMetricContainerMemoryTotalPgpgout(ms.ContainerMemoryTotalPgpgout),
		metricContainerMemoryTotalRss:                    newMetricContainerMemoryTotalRss(ms.ContainerMemoryTotalRss),
		metricContainerMemoryTotalRssHuge:                newMetricContainerMemoryTotalRssHuge(ms.ContainerMemoryTotalRssHuge),
		metricContainerMemoryTotalSwap:                   newMetricContainerMemoryTotalSwap(ms.ContainerMemoryTotalSwap),
		metricContainerMemoryTotalUnevictable:            newMetricContainerMemoryTotalUnevictable(ms.ContainerMemoryTotalUnevictable),
		metricContainerMemoryTotalWriteback:              newMetricContainerMemoryTotalWriteback(ms.ContainerMemoryTotalWriteback),
		metricContainerMemoryUnevictable:                 newMetricContainerMemoryUnevictable(ms.ContainerMemoryUnevictable),
		metricContainerMemoryUsageLimit:                  newMetricContainerMemoryUsageLimit(ms.ContainerMemoryUsageLimit),
		metricContainerMemoryUsageMax:                    newMetricContainerMemoryUsageMax(ms.ContainerMemoryUsageMax),
		metricContainerMemoryUsageTotal:                  newMetricContainerMemoryUsageTotal(ms.ContainerMemoryUsageTotal),
		metricContainerMemoryWriteback:                   newMetricContainerMemoryWriteback(ms.ContainerMemoryWriteback),
		metricContainerNetworkIoUsageRxBytes:             newMetricContainerNetworkIoUsageRxBytes(ms.ContainerNetworkIoUsageRxBytes),
		metricContainerNetworkIoUsageRxDropped:           newMetricContainerNetworkIoUsageRxDropped(ms.ContainerNetworkIoUsageRxDropped),
		metricContainerNetworkIoUsageRxErrors:            newMetricContainerNetworkIoUsageRxErrors(ms.ContainerNetworkIoUsageRxErrors),
		metricContainerNetworkIoUsageRxPackets:           newMetricContainerNetworkIoUsageRxPackets(ms.ContainerNetworkIoUsageRxPackets),
		metricContainerNetworkIoUsageTxBytes:             newMetricContainerNetworkIoUsageTxBytes(ms.ContainerNetworkIoUsageTxBytes),
		metricContainerNetworkIoUsageTxDropped:           newMetricContainerNetworkIoUsageTxDropped(ms.ContainerNetworkIoUsageTxDropped),
		metricContainerNetworkIoUsageTxErrors:            newMetricContainerNetworkIoUsageTxErrors(ms.ContainerNetworkIoUsageTxErrors),
		metricContainerNetworkIoUsageTxPackets:           newMetricContainerNetworkIoUsageTxPackets(ms.ContainerNetworkIoUsageTxPackets),
	}
	for _, op := range options {
		op(mb)
	}
	return mb
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
	if mb.resourceCapacity < rm.Resource().Attributes().Len() {
		mb.resourceCapacity = rm.Resource().Attributes().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption func(pmetric.ResourceMetrics)

// WithContainerHostname sets provided value as "container.hostname" attribute for current resource.
func WithContainerHostname(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().PutStr("container.hostname", val)
	}
}

// WithContainerID sets provided value as "container.id" attribute for current resource.
func WithContainerID(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().PutStr("container.id", val)
	}
}

// WithContainerImageName sets provided value as "container.image.name" attribute for current resource.
func WithContainerImageName(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().PutStr("container.image.name", val)
	}
}

// WithContainerName sets provided value as "container.name" attribute for current resource.
func WithContainerName(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().PutStr("container.name", val)
	}
}

// WithContainerRuntime sets provided value as "container.runtime" attribute for current resource.
func WithContainerRuntime(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().PutStr("container.runtime", val)
	}
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	}
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(rmo ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	rm.SetSchemaUrl(conventions.SchemaURL)
	rm.Resource().Attributes().EnsureCapacity(mb.resourceCapacity)
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName("otelcol/dockerstatsreceiver")
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricContainerBlockioIoMergedRecursive.emit(ils.Metrics())
	mb.metricContainerBlockioIoQueuedRecursive.emit(ils.Metrics())
	mb.metricContainerBlockioIoServiceBytesRecursive.emit(ils.Metrics())
	mb.metricContainerBlockioIoServiceTimeRecursive.emit(ils.Metrics())
	mb.metricContainerBlockioIoServicedRecursive.emit(ils.Metrics())
	mb.metricContainerBlockioIoTimeRecursive.emit(ils.Metrics())
	mb.metricContainerBlockioIoWaitTimeRecursive.emit(ils.Metrics())
	mb.metricContainerBlockioSectorsRecursive.emit(ils.Metrics())
	mb.metricContainerCPUPercent.emit(ils.Metrics())
	mb.metricContainerCPUThrottlingDataPeriods.emit(ils.Metrics())
	mb.metricContainerCPUThrottlingDataThrottledPeriods.emit(ils.Metrics())
	mb.metricContainerCPUThrottlingDataThrottledTime.emit(ils.Metrics())
	mb.metricContainerCPUUsageKernelmode.emit(ils.Metrics())
	mb.metricContainerCPUUsagePercpu.emit(ils.Metrics())
	mb.metricContainerCPUUsageSystem.emit(ils.Metrics())
	mb.metricContainerCPUUsageTotal.emit(ils.Metrics())
	mb.metricContainerCPUUsageUsermode.emit(ils.Metrics())
	mb.metricContainerMemoryActiveAnon.emit(ils.Metrics())
	mb.metricContainerMemoryActiveFile.emit(ils.Metrics())
	mb.metricContainerMemoryCache.emit(ils.Metrics())
	mb.metricContainerMemoryDirty.emit(ils.Metrics())
	mb.metricContainerMemoryHierarchicalMemoryLimit.emit(ils.Metrics())
	mb.metricContainerMemoryHierarchicalMemswLimit.emit(ils.Metrics())
	mb.metricContainerMemoryInactiveAnon.emit(ils.Metrics())
	mb.metricContainerMemoryInactiveFile.emit(ils.Metrics())
	mb.metricContainerMemoryMappedFile.emit(ils.Metrics())
	mb.metricContainerMemoryPercent.emit(ils.Metrics())
	mb.metricContainerMemoryPgfault.emit(ils.Metrics())
	mb.metricContainerMemoryPgmajfault.emit(ils.Metrics())
	mb.metricContainerMemoryPgpgin.emit(ils.Metrics())
	mb.metricContainerMemoryPgpgout.emit(ils.Metrics())
	mb.metricContainerMemoryRss.emit(ils.Metrics())
	mb.metricContainerMemoryRssHuge.emit(ils.Metrics())
	mb.metricContainerMemorySwap.emit(ils.Metrics())
	mb.metricContainerMemoryTotalActiveAnon.emit(ils.Metrics())
	mb.metricContainerMemoryTotalActiveFile.emit(ils.Metrics())
	mb.metricContainerMemoryTotalCache.emit(ils.Metrics())
	mb.metricContainerMemoryTotalDirty.emit(ils.Metrics())
	mb.metricContainerMemoryTotalInactiveAnon.emit(ils.Metrics())
	mb.metricContainerMemoryTotalInactiveFile.emit(ils.Metrics())
	mb.metricContainerMemoryTotalMappedFile.emit(ils.Metrics())
	mb.metricContainerMemoryTotalPgfault.emit(ils.Metrics())
	mb.metricContainerMemoryTotalPgmajfault.emit(ils.Metrics())
	mb.metricContainerMemoryTotalPgpgin.emit(ils.Metrics())
	mb.metricContainerMemoryTotalPgpgout.emit(ils.Metrics())
	mb.metricContainerMemoryTotalRss.emit(ils.Metrics())
	mb.metricContainerMemoryTotalRssHuge.emit(ils.Metrics())
	mb.metricContainerMemoryTotalSwap.emit(ils.Metrics())
	mb.metricContainerMemoryTotalUnevictable.emit(ils.Metrics())
	mb.metricContainerMemoryTotalWriteback.emit(ils.Metrics())
	mb.metricContainerMemoryUnevictable.emit(ils.Metrics())
	mb.metricContainerMemoryUsageLimit.emit(ils.Metrics())
	mb.metricContainerMemoryUsageMax.emit(ils.Metrics())
	mb.metricContainerMemoryUsageTotal.emit(ils.Metrics())
	mb.metricContainerMemoryWriteback.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageRxBytes.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageRxDropped.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageRxErrors.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageRxPackets.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageTxBytes.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageTxDropped.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageTxErrors.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageTxPackets.emit(ils.Metrics())
	for _, op := range rmo {
		op(rm)
	}
	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user settings, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(rmo ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(rmo...)
	metrics := pmetric.NewMetrics()
	mb.metricsBuffer.MoveTo(metrics)
	return metrics
}

// RecordContainerBlockioIoMergedRecursiveDataPoint adds a data point to container.blockio.io_merged_recursive metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoMergedRecursiveDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	mb.metricContainerBlockioIoMergedRecursive.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue, operationAttributeValue)
}

// RecordContainerBlockioIoQueuedRecursiveDataPoint adds a data point to container.blockio.io_queued_recursive metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoQueuedRecursiveDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	mb.metricContainerBlockioIoQueuedRecursive.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue, operationAttributeValue)
}

// RecordContainerBlockioIoServiceBytesRecursiveDataPoint adds a data point to container.blockio.io_service_bytes_recursive metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServiceBytesRecursiveDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	mb.metricContainerBlockioIoServiceBytesRecursive.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue, operationAttributeValue)
}

// RecordContainerBlockioIoServiceTimeRecursiveDataPoint adds a data point to container.blockio.io_service_time_recursive metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServiceTimeRecursiveDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	mb.metricContainerBlockioIoServiceTimeRecursive.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue, operationAttributeValue)
}

// RecordContainerBlockioIoServicedRecursiveDataPoint adds a data point to container.blockio.io_serviced_recursive metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServicedRecursiveDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	mb.metricContainerBlockioIoServicedRecursive.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue, operationAttributeValue)
}

// RecordContainerBlockioIoTimeRecursiveDataPoint adds a data point to container.blockio.io_time_recursive metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoTimeRecursiveDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	mb.metricContainerBlockioIoTimeRecursive.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue, operationAttributeValue)
}

// RecordContainerBlockioIoWaitTimeRecursiveDataPoint adds a data point to container.blockio.io_wait_time_recursive metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoWaitTimeRecursiveDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	mb.metricContainerBlockioIoWaitTimeRecursive.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue, operationAttributeValue)
}

// RecordContainerBlockioSectorsRecursiveDataPoint adds a data point to container.blockio.sectors_recursive metric.
func (mb *MetricsBuilder) RecordContainerBlockioSectorsRecursiveDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string, operationAttributeValue string) {
	mb.metricContainerBlockioSectorsRecursive.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue, operationAttributeValue)
}

// RecordContainerCPUPercentDataPoint adds a data point to container.cpu.percent metric.
func (mb *MetricsBuilder) RecordContainerCPUPercentDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricContainerCPUPercent.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerCPUThrottlingDataPeriodsDataPoint adds a data point to container.cpu.throttling_data.periods metric.
func (mb *MetricsBuilder) RecordContainerCPUThrottlingDataPeriodsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerCPUThrottlingDataPeriods.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerCPUThrottlingDataThrottledPeriodsDataPoint adds a data point to container.cpu.throttling_data.throttled_periods metric.
func (mb *MetricsBuilder) RecordContainerCPUThrottlingDataThrottledPeriodsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerCPUThrottlingDataThrottledPeriods.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerCPUThrottlingDataThrottledTimeDataPoint adds a data point to container.cpu.throttling_data.throttled_time metric.
func (mb *MetricsBuilder) RecordContainerCPUThrottlingDataThrottledTimeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerCPUThrottlingDataThrottledTime.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerCPUUsageKernelmodeDataPoint adds a data point to container.cpu.usage.kernelmode metric.
func (mb *MetricsBuilder) RecordContainerCPUUsageKernelmodeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerCPUUsageKernelmode.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerCPUUsagePercpuDataPoint adds a data point to container.cpu.usage.percpu metric.
func (mb *MetricsBuilder) RecordContainerCPUUsagePercpuDataPoint(ts pcommon.Timestamp, val int64, coreAttributeValue string) {
	mb.metricContainerCPUUsagePercpu.recordDataPoint(mb.startTime, ts, val, coreAttributeValue)
}

// RecordContainerCPUUsageSystemDataPoint adds a data point to container.cpu.usage.system metric.
func (mb *MetricsBuilder) RecordContainerCPUUsageSystemDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerCPUUsageSystem.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerCPUUsageTotalDataPoint adds a data point to container.cpu.usage.total metric.
func (mb *MetricsBuilder) RecordContainerCPUUsageTotalDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerCPUUsageTotal.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerCPUUsageUsermodeDataPoint adds a data point to container.cpu.usage.usermode metric.
func (mb *MetricsBuilder) RecordContainerCPUUsageUsermodeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerCPUUsageUsermode.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryActiveAnonDataPoint adds a data point to container.memory.active_anon metric.
func (mb *MetricsBuilder) RecordContainerMemoryActiveAnonDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryActiveAnon.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryActiveFileDataPoint adds a data point to container.memory.active_file metric.
func (mb *MetricsBuilder) RecordContainerMemoryActiveFileDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryActiveFile.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryCacheDataPoint adds a data point to container.memory.cache metric.
func (mb *MetricsBuilder) RecordContainerMemoryCacheDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryCache.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryDirtyDataPoint adds a data point to container.memory.dirty metric.
func (mb *MetricsBuilder) RecordContainerMemoryDirtyDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryDirty.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryHierarchicalMemoryLimitDataPoint adds a data point to container.memory.hierarchical_memory_limit metric.
func (mb *MetricsBuilder) RecordContainerMemoryHierarchicalMemoryLimitDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryHierarchicalMemoryLimit.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryHierarchicalMemswLimitDataPoint adds a data point to container.memory.hierarchical_memsw_limit metric.
func (mb *MetricsBuilder) RecordContainerMemoryHierarchicalMemswLimitDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryHierarchicalMemswLimit.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryInactiveAnonDataPoint adds a data point to container.memory.inactive_anon metric.
func (mb *MetricsBuilder) RecordContainerMemoryInactiveAnonDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryInactiveAnon.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryInactiveFileDataPoint adds a data point to container.memory.inactive_file metric.
func (mb *MetricsBuilder) RecordContainerMemoryInactiveFileDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryInactiveFile.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryMappedFileDataPoint adds a data point to container.memory.mapped_file metric.
func (mb *MetricsBuilder) RecordContainerMemoryMappedFileDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryMappedFile.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryPercentDataPoint adds a data point to container.memory.percent metric.
func (mb *MetricsBuilder) RecordContainerMemoryPercentDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricContainerMemoryPercent.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryPgfaultDataPoint adds a data point to container.memory.pgfault metric.
func (mb *MetricsBuilder) RecordContainerMemoryPgfaultDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryPgfault.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryPgmajfaultDataPoint adds a data point to container.memory.pgmajfault metric.
func (mb *MetricsBuilder) RecordContainerMemoryPgmajfaultDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryPgmajfault.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryPgpginDataPoint adds a data point to container.memory.pgpgin metric.
func (mb *MetricsBuilder) RecordContainerMemoryPgpginDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryPgpgin.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryPgpgoutDataPoint adds a data point to container.memory.pgpgout metric.
func (mb *MetricsBuilder) RecordContainerMemoryPgpgoutDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryPgpgout.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryRssDataPoint adds a data point to container.memory.rss metric.
func (mb *MetricsBuilder) RecordContainerMemoryRssDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryRss.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryRssHugeDataPoint adds a data point to container.memory.rss_huge metric.
func (mb *MetricsBuilder) RecordContainerMemoryRssHugeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryRssHuge.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemorySwapDataPoint adds a data point to container.memory.swap metric.
func (mb *MetricsBuilder) RecordContainerMemorySwapDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemorySwap.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalActiveAnonDataPoint adds a data point to container.memory.total_active_anon metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalActiveAnonDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalActiveAnon.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalActiveFileDataPoint adds a data point to container.memory.total_active_file metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalActiveFileDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalActiveFile.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalCacheDataPoint adds a data point to container.memory.total_cache metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalCacheDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalCache.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalDirtyDataPoint adds a data point to container.memory.total_dirty metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalDirtyDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalDirty.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalInactiveAnonDataPoint adds a data point to container.memory.total_inactive_anon metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalInactiveAnonDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalInactiveAnon.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalInactiveFileDataPoint adds a data point to container.memory.total_inactive_file metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalInactiveFileDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalInactiveFile.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalMappedFileDataPoint adds a data point to container.memory.total_mapped_file metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalMappedFileDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalMappedFile.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalPgfaultDataPoint adds a data point to container.memory.total_pgfault metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalPgfaultDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalPgfault.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalPgmajfaultDataPoint adds a data point to container.memory.total_pgmajfault metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalPgmajfaultDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalPgmajfault.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalPgpginDataPoint adds a data point to container.memory.total_pgpgin metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalPgpginDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalPgpgin.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalPgpgoutDataPoint adds a data point to container.memory.total_pgpgout metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalPgpgoutDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalPgpgout.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalRssDataPoint adds a data point to container.memory.total_rss metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalRssDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalRss.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalRssHugeDataPoint adds a data point to container.memory.total_rss_huge metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalRssHugeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalRssHuge.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalSwapDataPoint adds a data point to container.memory.total_swap metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalSwapDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalSwap.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalUnevictableDataPoint adds a data point to container.memory.total_unevictable metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalUnevictableDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalUnevictable.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalWritebackDataPoint adds a data point to container.memory.total_writeback metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalWritebackDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalWriteback.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryUnevictableDataPoint adds a data point to container.memory.unevictable metric.
func (mb *MetricsBuilder) RecordContainerMemoryUnevictableDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryUnevictable.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryUsageLimitDataPoint adds a data point to container.memory.usage.limit metric.
func (mb *MetricsBuilder) RecordContainerMemoryUsageLimitDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryUsageLimit.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryUsageMaxDataPoint adds a data point to container.memory.usage.max metric.
func (mb *MetricsBuilder) RecordContainerMemoryUsageMaxDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryUsageMax.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryUsageTotalDataPoint adds a data point to container.memory.usage.total metric.
func (mb *MetricsBuilder) RecordContainerMemoryUsageTotalDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryUsageTotal.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryWritebackDataPoint adds a data point to container.memory.writeback metric.
func (mb *MetricsBuilder) RecordContainerMemoryWritebackDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryWriteback.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerNetworkIoUsageRxBytesDataPoint adds a data point to container.network.io.usage.rx_bytes metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageRxBytesDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageRxBytes.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// RecordContainerNetworkIoUsageRxDroppedDataPoint adds a data point to container.network.io.usage.rx_dropped metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageRxDroppedDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageRxDropped.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// RecordContainerNetworkIoUsageRxErrorsDataPoint adds a data point to container.network.io.usage.rx_errors metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageRxErrorsDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageRxErrors.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// RecordContainerNetworkIoUsageRxPacketsDataPoint adds a data point to container.network.io.usage.rx_packets metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageRxPacketsDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageRxPackets.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// RecordContainerNetworkIoUsageTxBytesDataPoint adds a data point to container.network.io.usage.tx_bytes metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageTxBytesDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageTxBytes.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// RecordContainerNetworkIoUsageTxDroppedDataPoint adds a data point to container.network.io.usage.tx_dropped metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageTxDroppedDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageTxDropped.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// RecordContainerNetworkIoUsageTxErrorsDataPoint adds a data point to container.network.io.usage.tx_errors metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageTxErrorsDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageTxErrors.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// RecordContainerNetworkIoUsageTxPacketsDataPoint adds a data point to container.network.io.usage.tx_packets metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageTxPacketsDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageTxPackets.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...metricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(mb)
	}
}
