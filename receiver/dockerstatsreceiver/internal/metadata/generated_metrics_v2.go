// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	conventions "go.opentelemetry.io/collector/semconv/v1.6.1"
)

// MetricSettings provides common settings for a particular metric.
type MetricSettings struct {
	Enabled bool `mapstructure:"enabled"`
}

// MetricsSettings provides settings for dockerstatsreceiver metrics.
type MetricsSettings struct {
	ContainerBlockioIoMergedRecursiveAsync         MetricSettings `mapstructure:"container.blockio.io_merged_recursive.async"`
	ContainerBlockioIoMergedRecursiveDiscard       MetricSettings `mapstructure:"container.blockio.io_merged_recursive.discard"`
	ContainerBlockioIoMergedRecursiveRead          MetricSettings `mapstructure:"container.blockio.io_merged_recursive.read"`
	ContainerBlockioIoMergedRecursiveSync          MetricSettings `mapstructure:"container.blockio.io_merged_recursive.sync"`
	ContainerBlockioIoMergedRecursiveTotal         MetricSettings `mapstructure:"container.blockio.io_merged_recursive.total"`
	ContainerBlockioIoMergedRecursiveWrite         MetricSettings `mapstructure:"container.blockio.io_merged_recursive.write"`
	ContainerBlockioIoQueuedRecursiveAsync         MetricSettings `mapstructure:"container.blockio.io_queued_recursive.async"`
	ContainerBlockioIoQueuedRecursiveDiscard       MetricSettings `mapstructure:"container.blockio.io_queued_recursive.discard"`
	ContainerBlockioIoQueuedRecursiveRead          MetricSettings `mapstructure:"container.blockio.io_queued_recursive.read"`
	ContainerBlockioIoQueuedRecursiveSync          MetricSettings `mapstructure:"container.blockio.io_queued_recursive.sync"`
	ContainerBlockioIoQueuedRecursiveTotal         MetricSettings `mapstructure:"container.blockio.io_queued_recursive.total"`
	ContainerBlockioIoQueuedRecursiveWrite         MetricSettings `mapstructure:"container.blockio.io_queued_recursive.write"`
	ContainerBlockioIoServiceBytesRecursiveAsync   MetricSettings `mapstructure:"container.blockio.io_service_bytes_recursive.async"`
	ContainerBlockioIoServiceBytesRecursiveDiscard MetricSettings `mapstructure:"container.blockio.io_service_bytes_recursive.discard"`
	ContainerBlockioIoServiceBytesRecursiveRead    MetricSettings `mapstructure:"container.blockio.io_service_bytes_recursive.read"`
	ContainerBlockioIoServiceBytesRecursiveSync    MetricSettings `mapstructure:"container.blockio.io_service_bytes_recursive.sync"`
	ContainerBlockioIoServiceBytesRecursiveTotal   MetricSettings `mapstructure:"container.blockio.io_service_bytes_recursive.total"`
	ContainerBlockioIoServiceBytesRecursiveWrite   MetricSettings `mapstructure:"container.blockio.io_service_bytes_recursive.write"`
	ContainerBlockioIoServiceTimeRecursiveAsync    MetricSettings `mapstructure:"container.blockio.io_service_time_recursive.async"`
	ContainerBlockioIoServiceTimeRecursiveDiscard  MetricSettings `mapstructure:"container.blockio.io_service_time_recursive.discard"`
	ContainerBlockioIoServiceTimeRecursiveRead     MetricSettings `mapstructure:"container.blockio.io_service_time_recursive.read"`
	ContainerBlockioIoServiceTimeRecursiveSync     MetricSettings `mapstructure:"container.blockio.io_service_time_recursive.sync"`
	ContainerBlockioIoServiceTimeRecursiveTotal    MetricSettings `mapstructure:"container.blockio.io_service_time_recursive.total"`
	ContainerBlockioIoServiceTimeRecursiveWrite    MetricSettings `mapstructure:"container.blockio.io_service_time_recursive.write"`
	ContainerBlockioIoServicedRecursiveAsync       MetricSettings `mapstructure:"container.blockio.io_serviced_recursive.async"`
	ContainerBlockioIoServicedRecursiveDiscard     MetricSettings `mapstructure:"container.blockio.io_serviced_recursive.discard"`
	ContainerBlockioIoServicedRecursiveRead        MetricSettings `mapstructure:"container.blockio.io_serviced_recursive.read"`
	ContainerBlockioIoServicedRecursiveSync        MetricSettings `mapstructure:"container.blockio.io_serviced_recursive.sync"`
	ContainerBlockioIoServicedRecursiveTotal       MetricSettings `mapstructure:"container.blockio.io_serviced_recursive.total"`
	ContainerBlockioIoServicedRecursiveWrite       MetricSettings `mapstructure:"container.blockio.io_serviced_recursive.write"`
	ContainerBlockioIoTimeRecursiveAsync           MetricSettings `mapstructure:"container.blockio.io_time_recursive.async"`
	ContainerBlockioIoTimeRecursiveDiscard         MetricSettings `mapstructure:"container.blockio.io_time_recursive.discard"`
	ContainerBlockioIoTimeRecursiveRead            MetricSettings `mapstructure:"container.blockio.io_time_recursive.read"`
	ContainerBlockioIoTimeRecursiveSync            MetricSettings `mapstructure:"container.blockio.io_time_recursive.sync"`
	ContainerBlockioIoTimeRecursiveTotal           MetricSettings `mapstructure:"container.blockio.io_time_recursive.total"`
	ContainerBlockioIoTimeRecursiveWrite           MetricSettings `mapstructure:"container.blockio.io_time_recursive.write"`
	ContainerBlockioIoWaitTimeRecursiveAsync       MetricSettings `mapstructure:"container.blockio.io_wait_time_recursive.async"`
	ContainerBlockioIoWaitTimeRecursiveDiscard     MetricSettings `mapstructure:"container.blockio.io_wait_time_recursive.discard"`
	ContainerBlockioIoWaitTimeRecursiveRead        MetricSettings `mapstructure:"container.blockio.io_wait_time_recursive.read"`
	ContainerBlockioIoWaitTimeRecursiveSync        MetricSettings `mapstructure:"container.blockio.io_wait_time_recursive.sync"`
	ContainerBlockioIoWaitTimeRecursiveTotal       MetricSettings `mapstructure:"container.blockio.io_wait_time_recursive.total"`
	ContainerBlockioIoWaitTimeRecursiveWrite       MetricSettings `mapstructure:"container.blockio.io_wait_time_recursive.write"`
	ContainerBlockioSectorsRecursiveAsync          MetricSettings `mapstructure:"container.blockio.sectors_recursive.async"`
	ContainerBlockioSectorsRecursiveDiscard        MetricSettings `mapstructure:"container.blockio.sectors_recursive.discard"`
	ContainerBlockioSectorsRecursiveRead           MetricSettings `mapstructure:"container.blockio.sectors_recursive.read"`
	ContainerBlockioSectorsRecursiveSync           MetricSettings `mapstructure:"container.blockio.sectors_recursive.sync"`
	ContainerBlockioSectorsRecursiveTotal          MetricSettings `mapstructure:"container.blockio.sectors_recursive.total"`
	ContainerBlockioSectorsRecursiveWrite          MetricSettings `mapstructure:"container.blockio.sectors_recursive.write"`
	ContainerCPUPercent                            MetricSettings `mapstructure:"container.cpu.percent"`
	ContainerCPUThrottlingDataPeriods              MetricSettings `mapstructure:"container.cpu.throttling_data.periods"`
	ContainerCPUThrottlingDataThrottledPeriods     MetricSettings `mapstructure:"container.cpu.throttling_data.throttled_periods"`
	ContainerCPUThrottlingDataThrottledTime        MetricSettings `mapstructure:"container.cpu.throttling_data.throttled_time"`
	ContainerCPUUsageKernelmode                    MetricSettings `mapstructure:"container.cpu.usage.kernelmode"`
	ContainerCPUUsagePercpu                        MetricSettings `mapstructure:"container.cpu.usage.percpu"`
	ContainerCPUUsageSystem                        MetricSettings `mapstructure:"container.cpu.usage.system"`
	ContainerCPUUsageTotal                         MetricSettings `mapstructure:"container.cpu.usage.total"`
	ContainerCPUUsageUsermode                      MetricSettings `mapstructure:"container.cpu.usage.usermode"`
	ContainerMemoryActiveAnon                      MetricSettings `mapstructure:"container.memory.active_anon"`
	ContainerMemoryActiveFile                      MetricSettings `mapstructure:"container.memory.active_file"`
	ContainerMemoryCache                           MetricSettings `mapstructure:"container.memory.cache"`
	ContainerMemoryDirty                           MetricSettings `mapstructure:"container.memory.dirty"`
	ContainerMemoryHierarchicalMemoryLimit         MetricSettings `mapstructure:"container.memory.hierarchical_memory_limit"`
	ContainerMemoryHierarchicalMemswLimit          MetricSettings `mapstructure:"container.memory.hierarchical_memsw_limit"`
	ContainerMemoryInactiveAnon                    MetricSettings `mapstructure:"container.memory.inactive_anon"`
	ContainerMemoryInactiveFile                    MetricSettings `mapstructure:"container.memory.inactive_file"`
	ContainerMemoryMappedFile                      MetricSettings `mapstructure:"container.memory.mapped_file"`
	ContainerMemoryPercent                         MetricSettings `mapstructure:"container.memory.percent"`
	ContainerMemoryPgfault                         MetricSettings `mapstructure:"container.memory.pgfault"`
	ContainerMemoryPgmajfault                      MetricSettings `mapstructure:"container.memory.pgmajfault"`
	ContainerMemoryPgpgin                          MetricSettings `mapstructure:"container.memory.pgpgin"`
	ContainerMemoryPgpgout                         MetricSettings `mapstructure:"container.memory.pgpgout"`
	ContainerMemoryRss                             MetricSettings `mapstructure:"container.memory.rss"`
	ContainerMemoryRssHuge                         MetricSettings `mapstructure:"container.memory.rss_huge"`
	ContainerMemorySwap                            MetricSettings `mapstructure:"container.memory.swap"`
	ContainerMemoryTotalActiveAnon                 MetricSettings `mapstructure:"container.memory.total_active_anon"`
	ContainerMemoryTotalActiveFile                 MetricSettings `mapstructure:"container.memory.total_active_file"`
	ContainerMemoryTotalCache                      MetricSettings `mapstructure:"container.memory.total_cache"`
	ContainerMemoryTotalDirty                      MetricSettings `mapstructure:"container.memory.total_dirty"`
	ContainerMemoryTotalInactiveAnon               MetricSettings `mapstructure:"container.memory.total_inactive_anon"`
	ContainerMemoryTotalInactiveFile               MetricSettings `mapstructure:"container.memory.total_inactive_file"`
	ContainerMemoryTotalMappedFile                 MetricSettings `mapstructure:"container.memory.total_mapped_file"`
	ContainerMemoryTotalPgfault                    MetricSettings `mapstructure:"container.memory.total_pgfault"`
	ContainerMemoryTotalPgmajfault                 MetricSettings `mapstructure:"container.memory.total_pgmajfault"`
	ContainerMemoryTotalPgpgin                     MetricSettings `mapstructure:"container.memory.total_pgpgin"`
	ContainerMemoryTotalPgpgout                    MetricSettings `mapstructure:"container.memory.total_pgpgout"`
	ContainerMemoryTotalRss                        MetricSettings `mapstructure:"container.memory.total_rss"`
	ContainerMemoryTotalRssHuge                    MetricSettings `mapstructure:"container.memory.total_rss_huge"`
	ContainerMemoryTotalSwap                       MetricSettings `mapstructure:"container.memory.total_swap"`
	ContainerMemoryTotalUnevictable                MetricSettings `mapstructure:"container.memory.total_unevictable"`
	ContainerMemoryTotalWriteback                  MetricSettings `mapstructure:"container.memory.total_writeback"`
	ContainerMemoryUnevictable                     MetricSettings `mapstructure:"container.memory.unevictable"`
	ContainerMemoryUsageLimit                      MetricSettings `mapstructure:"container.memory.usage.limit"`
	ContainerMemoryUsageMax                        MetricSettings `mapstructure:"container.memory.usage.max"`
	ContainerMemoryUsageTotal                      MetricSettings `mapstructure:"container.memory.usage.total"`
	ContainerMemoryWriteback                       MetricSettings `mapstructure:"container.memory.writeback"`
	ContainerNetworkIoUsageRxBytes                 MetricSettings `mapstructure:"container.network.io.usage.rx_bytes"`
	ContainerNetworkIoUsageRxDropped               MetricSettings `mapstructure:"container.network.io.usage.rx_dropped"`
	ContainerNetworkIoUsageRxErrors                MetricSettings `mapstructure:"container.network.io.usage.rx_errors"`
	ContainerNetworkIoUsageRxPackets               MetricSettings `mapstructure:"container.network.io.usage.rx_packets"`
	ContainerNetworkIoUsageTxBytes                 MetricSettings `mapstructure:"container.network.io.usage.tx_bytes"`
	ContainerNetworkIoUsageTxDropped               MetricSettings `mapstructure:"container.network.io.usage.tx_dropped"`
	ContainerNetworkIoUsageTxErrors                MetricSettings `mapstructure:"container.network.io.usage.tx_errors"`
	ContainerNetworkIoUsageTxPackets               MetricSettings `mapstructure:"container.network.io.usage.tx_packets"`
}

func DefaultMetricsSettings() MetricsSettings {
	return MetricsSettings{
		ContainerBlockioIoMergedRecursiveAsync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoMergedRecursiveDiscard: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoMergedRecursiveRead: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoMergedRecursiveSync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoMergedRecursiveTotal: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoMergedRecursiveWrite: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoQueuedRecursiveAsync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoQueuedRecursiveDiscard: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoQueuedRecursiveRead: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoQueuedRecursiveSync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoQueuedRecursiveTotal: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoQueuedRecursiveWrite: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServiceBytesRecursiveAsync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServiceBytesRecursiveDiscard: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServiceBytesRecursiveRead: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServiceBytesRecursiveSync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServiceBytesRecursiveTotal: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServiceBytesRecursiveWrite: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServiceTimeRecursiveAsync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServiceTimeRecursiveDiscard: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServiceTimeRecursiveRead: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServiceTimeRecursiveSync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServiceTimeRecursiveTotal: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServiceTimeRecursiveWrite: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServicedRecursiveAsync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServicedRecursiveDiscard: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServicedRecursiveRead: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServicedRecursiveSync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServicedRecursiveTotal: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoServicedRecursiveWrite: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoTimeRecursiveAsync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoTimeRecursiveDiscard: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoTimeRecursiveRead: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoTimeRecursiveSync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoTimeRecursiveTotal: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoTimeRecursiveWrite: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoWaitTimeRecursiveAsync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoWaitTimeRecursiveDiscard: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoWaitTimeRecursiveRead: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoWaitTimeRecursiveSync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoWaitTimeRecursiveTotal: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioIoWaitTimeRecursiveWrite: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioSectorsRecursiveAsync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioSectorsRecursiveDiscard: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioSectorsRecursiveRead: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioSectorsRecursiveSync: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioSectorsRecursiveTotal: MetricSettings{
			Enabled: true,
		},
		ContainerBlockioSectorsRecursiveWrite: MetricSettings{
			Enabled: true,
		},
		ContainerCPUPercent: MetricSettings{
			Enabled: true,
		},
		ContainerCPUThrottlingDataPeriods: MetricSettings{
			Enabled: true,
		},
		ContainerCPUThrottlingDataThrottledPeriods: MetricSettings{
			Enabled: true,
		},
		ContainerCPUThrottlingDataThrottledTime: MetricSettings{
			Enabled: true,
		},
		ContainerCPUUsageKernelmode: MetricSettings{
			Enabled: true,
		},
		ContainerCPUUsagePercpu: MetricSettings{
			Enabled: false,
		},
		ContainerCPUUsageSystem: MetricSettings{
			Enabled: true,
		},
		ContainerCPUUsageTotal: MetricSettings{
			Enabled: true,
		},
		ContainerCPUUsageUsermode: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryActiveAnon: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryActiveFile: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryCache: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryDirty: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryHierarchicalMemoryLimit: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryHierarchicalMemswLimit: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryInactiveAnon: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryInactiveFile: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryMappedFile: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryPercent: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryPgfault: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryPgmajfault: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryPgpgin: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryPgpgout: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryRss: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryRssHuge: MetricSettings{
			Enabled: true,
		},
		ContainerMemorySwap: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalActiveAnon: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalActiveFile: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalCache: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalDirty: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalInactiveAnon: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalInactiveFile: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalMappedFile: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalPgfault: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalPgmajfault: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalPgpgin: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalPgpgout: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalRss: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalRssHuge: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalSwap: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalUnevictable: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryTotalWriteback: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryUnevictable: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryUsageLimit: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryUsageMax: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryUsageTotal: MetricSettings{
			Enabled: true,
		},
		ContainerMemoryWriteback: MetricSettings{
			Enabled: true,
		},
		ContainerNetworkIoUsageRxBytes: MetricSettings{
			Enabled: true,
		},
		ContainerNetworkIoUsageRxDropped: MetricSettings{
			Enabled: true,
		},
		ContainerNetworkIoUsageRxErrors: MetricSettings{
			Enabled: true,
		},
		ContainerNetworkIoUsageRxPackets: MetricSettings{
			Enabled: true,
		},
		ContainerNetworkIoUsageTxBytes: MetricSettings{
			Enabled: true,
		},
		ContainerNetworkIoUsageTxDropped: MetricSettings{
			Enabled: true,
		},
		ContainerNetworkIoUsageTxErrors: MetricSettings{
			Enabled: true,
		},
		ContainerNetworkIoUsageTxPackets: MetricSettings{
			Enabled: true,
		},
	}
}

type metricContainerBlockioIoMergedRecursiveAsync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_merged_recursive.async metric with initial data.
func (m *metricContainerBlockioIoMergedRecursiveAsync) init() {
	m.data.SetName("container.blockio.io_merged_recursive.async")
	m.data.SetDescription("Number of bios/requests merged into requests belonging to this cgroup and its descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoMergedRecursiveAsync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoMergedRecursiveAsync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoMergedRecursiveAsync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoMergedRecursiveAsync(settings MetricSettings) metricContainerBlockioIoMergedRecursiveAsync {
	m := metricContainerBlockioIoMergedRecursiveAsync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoMergedRecursiveDiscard struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_merged_recursive.discard metric with initial data.
func (m *metricContainerBlockioIoMergedRecursiveDiscard) init() {
	m.data.SetName("container.blockio.io_merged_recursive.discard")
	m.data.SetDescription("Number of bios/requests merged into requests belonging to this cgroup and its descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoMergedRecursiveDiscard) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoMergedRecursiveDiscard) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoMergedRecursiveDiscard) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoMergedRecursiveDiscard(settings MetricSettings) metricContainerBlockioIoMergedRecursiveDiscard {
	m := metricContainerBlockioIoMergedRecursiveDiscard{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoMergedRecursiveRead struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_merged_recursive.read metric with initial data.
func (m *metricContainerBlockioIoMergedRecursiveRead) init() {
	m.data.SetName("container.blockio.io_merged_recursive.read")
	m.data.SetDescription("Number of bios/requests merged into requests belonging to this cgroup and its descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoMergedRecursiveRead) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoMergedRecursiveRead) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoMergedRecursiveRead) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoMergedRecursiveRead(settings MetricSettings) metricContainerBlockioIoMergedRecursiveRead {
	m := metricContainerBlockioIoMergedRecursiveRead{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoMergedRecursiveSync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_merged_recursive.sync metric with initial data.
func (m *metricContainerBlockioIoMergedRecursiveSync) init() {
	m.data.SetName("container.blockio.io_merged_recursive.sync")
	m.data.SetDescription("Number of bios/requests merged into requests belonging to this cgroup and its descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoMergedRecursiveSync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoMergedRecursiveSync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoMergedRecursiveSync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoMergedRecursiveSync(settings MetricSettings) metricContainerBlockioIoMergedRecursiveSync {
	m := metricContainerBlockioIoMergedRecursiveSync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoMergedRecursiveTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_merged_recursive.total metric with initial data.
func (m *metricContainerBlockioIoMergedRecursiveTotal) init() {
	m.data.SetName("container.blockio.io_merged_recursive.total")
	m.data.SetDescription("Number of bios/requests merged into requests belonging to this cgroup and its descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoMergedRecursiveTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoMergedRecursiveTotal) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoMergedRecursiveTotal) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoMergedRecursiveTotal(settings MetricSettings) metricContainerBlockioIoMergedRecursiveTotal {
	m := metricContainerBlockioIoMergedRecursiveTotal{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoMergedRecursiveWrite struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_merged_recursive.write metric with initial data.
func (m *metricContainerBlockioIoMergedRecursiveWrite) init() {
	m.data.SetName("container.blockio.io_merged_recursive.write")
	m.data.SetDescription("Number of bios/requests merged into requests belonging to this cgroup and its descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoMergedRecursiveWrite) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoMergedRecursiveWrite) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoMergedRecursiveWrite) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoMergedRecursiveWrite(settings MetricSettings) metricContainerBlockioIoMergedRecursiveWrite {
	m := metricContainerBlockioIoMergedRecursiveWrite{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoQueuedRecursiveAsync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_queued_recursive.async metric with initial data.
func (m *metricContainerBlockioIoQueuedRecursiveAsync) init() {
	m.data.SetName("container.blockio.io_queued_recursive.async")
	m.data.SetDescription("Number of requests queued up for this cgroup and its descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoQueuedRecursiveAsync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoQueuedRecursiveAsync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoQueuedRecursiveAsync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoQueuedRecursiveAsync(settings MetricSettings) metricContainerBlockioIoQueuedRecursiveAsync {
	m := metricContainerBlockioIoQueuedRecursiveAsync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoQueuedRecursiveDiscard struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_queued_recursive.discard metric with initial data.
func (m *metricContainerBlockioIoQueuedRecursiveDiscard) init() {
	m.data.SetName("container.blockio.io_queued_recursive.discard")
	m.data.SetDescription("Number of requests queued up for this cgroup and its descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoQueuedRecursiveDiscard) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoQueuedRecursiveDiscard) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoQueuedRecursiveDiscard) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoQueuedRecursiveDiscard(settings MetricSettings) metricContainerBlockioIoQueuedRecursiveDiscard {
	m := metricContainerBlockioIoQueuedRecursiveDiscard{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoQueuedRecursiveRead struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_queued_recursive.read metric with initial data.
func (m *metricContainerBlockioIoQueuedRecursiveRead) init() {
	m.data.SetName("container.blockio.io_queued_recursive.read")
	m.data.SetDescription("Number of requests queued up for this cgroup and its descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoQueuedRecursiveRead) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoQueuedRecursiveRead) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoQueuedRecursiveRead) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoQueuedRecursiveRead(settings MetricSettings) metricContainerBlockioIoQueuedRecursiveRead {
	m := metricContainerBlockioIoQueuedRecursiveRead{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoQueuedRecursiveSync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_queued_recursive.sync metric with initial data.
func (m *metricContainerBlockioIoQueuedRecursiveSync) init() {
	m.data.SetName("container.blockio.io_queued_recursive.sync")
	m.data.SetDescription("Number of requests queued up for this cgroup and its descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoQueuedRecursiveSync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoQueuedRecursiveSync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoQueuedRecursiveSync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoQueuedRecursiveSync(settings MetricSettings) metricContainerBlockioIoQueuedRecursiveSync {
	m := metricContainerBlockioIoQueuedRecursiveSync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoQueuedRecursiveTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_queued_recursive.total metric with initial data.
func (m *metricContainerBlockioIoQueuedRecursiveTotal) init() {
	m.data.SetName("container.blockio.io_queued_recursive.total")
	m.data.SetDescription("Number of requests queued up for this cgroup and its descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoQueuedRecursiveTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoQueuedRecursiveTotal) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoQueuedRecursiveTotal) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoQueuedRecursiveTotal(settings MetricSettings) metricContainerBlockioIoQueuedRecursiveTotal {
	m := metricContainerBlockioIoQueuedRecursiveTotal{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoQueuedRecursiveWrite struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_queued_recursive.write metric with initial data.
func (m *metricContainerBlockioIoQueuedRecursiveWrite) init() {
	m.data.SetName("container.blockio.io_queued_recursive.write")
	m.data.SetDescription("Number of requests queued up for this cgroup and its descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoQueuedRecursiveWrite) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoQueuedRecursiveWrite) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoQueuedRecursiveWrite) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoQueuedRecursiveWrite(settings MetricSettings) metricContainerBlockioIoQueuedRecursiveWrite {
	m := metricContainerBlockioIoQueuedRecursiveWrite{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServiceBytesRecursiveAsync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_service_bytes_recursive.async metric with initial data.
func (m *metricContainerBlockioIoServiceBytesRecursiveAsync) init() {
	m.data.SetName("container.blockio.io_service_bytes_recursive.async")
	m.data.SetDescription("Number of bytes transferred to/from the disk by the group and descendant groups.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServiceBytesRecursiveAsync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServiceBytesRecursiveAsync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServiceBytesRecursiveAsync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServiceBytesRecursiveAsync(settings MetricSettings) metricContainerBlockioIoServiceBytesRecursiveAsync {
	m := metricContainerBlockioIoServiceBytesRecursiveAsync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServiceBytesRecursiveDiscard struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_service_bytes_recursive.discard metric with initial data.
func (m *metricContainerBlockioIoServiceBytesRecursiveDiscard) init() {
	m.data.SetName("container.blockio.io_service_bytes_recursive.discard")
	m.data.SetDescription("Number of bytes transferred to/from the disk by the group and descendant groups.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServiceBytesRecursiveDiscard) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServiceBytesRecursiveDiscard) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServiceBytesRecursiveDiscard) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServiceBytesRecursiveDiscard(settings MetricSettings) metricContainerBlockioIoServiceBytesRecursiveDiscard {
	m := metricContainerBlockioIoServiceBytesRecursiveDiscard{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServiceBytesRecursiveRead struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_service_bytes_recursive.read metric with initial data.
func (m *metricContainerBlockioIoServiceBytesRecursiveRead) init() {
	m.data.SetName("container.blockio.io_service_bytes_recursive.read")
	m.data.SetDescription("Number of bytes transferred to/from the disk by the group and descendant groups.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServiceBytesRecursiveRead) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServiceBytesRecursiveRead) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServiceBytesRecursiveRead) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServiceBytesRecursiveRead(settings MetricSettings) metricContainerBlockioIoServiceBytesRecursiveRead {
	m := metricContainerBlockioIoServiceBytesRecursiveRead{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServiceBytesRecursiveSync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_service_bytes_recursive.sync metric with initial data.
func (m *metricContainerBlockioIoServiceBytesRecursiveSync) init() {
	m.data.SetName("container.blockio.io_service_bytes_recursive.sync")
	m.data.SetDescription("Number of bytes transferred to/from the disk by the group and descendant groups.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServiceBytesRecursiveSync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServiceBytesRecursiveSync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServiceBytesRecursiveSync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServiceBytesRecursiveSync(settings MetricSettings) metricContainerBlockioIoServiceBytesRecursiveSync {
	m := metricContainerBlockioIoServiceBytesRecursiveSync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServiceBytesRecursiveTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_service_bytes_recursive.total metric with initial data.
func (m *metricContainerBlockioIoServiceBytesRecursiveTotal) init() {
	m.data.SetName("container.blockio.io_service_bytes_recursive.total")
	m.data.SetDescription("Number of bytes transferred to/from the disk by the group and descendant groups.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServiceBytesRecursiveTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServiceBytesRecursiveTotal) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServiceBytesRecursiveTotal) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServiceBytesRecursiveTotal(settings MetricSettings) metricContainerBlockioIoServiceBytesRecursiveTotal {
	m := metricContainerBlockioIoServiceBytesRecursiveTotal{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServiceBytesRecursiveWrite struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_service_bytes_recursive.write metric with initial data.
func (m *metricContainerBlockioIoServiceBytesRecursiveWrite) init() {
	m.data.SetName("container.blockio.io_service_bytes_recursive.write")
	m.data.SetDescription("Number of bytes transferred to/from the disk by the group and descendant groups.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServiceBytesRecursiveWrite) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServiceBytesRecursiveWrite) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServiceBytesRecursiveWrite) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServiceBytesRecursiveWrite(settings MetricSettings) metricContainerBlockioIoServiceBytesRecursiveWrite {
	m := metricContainerBlockioIoServiceBytesRecursiveWrite{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServiceTimeRecursiveAsync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_service_time_recursive.async metric with initial data.
func (m *metricContainerBlockioIoServiceTimeRecursiveAsync) init() {
	m.data.SetName("container.blockio.io_service_time_recursive.async")
	m.data.SetDescription("Total amount of time in nanoseconds between request dispatch and request completion for the IOs done by this cgroup and descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServiceTimeRecursiveAsync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServiceTimeRecursiveAsync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServiceTimeRecursiveAsync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServiceTimeRecursiveAsync(settings MetricSettings) metricContainerBlockioIoServiceTimeRecursiveAsync {
	m := metricContainerBlockioIoServiceTimeRecursiveAsync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServiceTimeRecursiveDiscard struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_service_time_recursive.discard metric with initial data.
func (m *metricContainerBlockioIoServiceTimeRecursiveDiscard) init() {
	m.data.SetName("container.blockio.io_service_time_recursive.discard")
	m.data.SetDescription("Total amount of time in nanoseconds between request dispatch and request completion for the IOs done by this cgroup and descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServiceTimeRecursiveDiscard) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServiceTimeRecursiveDiscard) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServiceTimeRecursiveDiscard) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServiceTimeRecursiveDiscard(settings MetricSettings) metricContainerBlockioIoServiceTimeRecursiveDiscard {
	m := metricContainerBlockioIoServiceTimeRecursiveDiscard{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServiceTimeRecursiveRead struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_service_time_recursive.read metric with initial data.
func (m *metricContainerBlockioIoServiceTimeRecursiveRead) init() {
	m.data.SetName("container.blockio.io_service_time_recursive.read")
	m.data.SetDescription("Total amount of time in nanoseconds between request dispatch and request completion for the IOs done by this cgroup and descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServiceTimeRecursiveRead) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServiceTimeRecursiveRead) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServiceTimeRecursiveRead) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServiceTimeRecursiveRead(settings MetricSettings) metricContainerBlockioIoServiceTimeRecursiveRead {
	m := metricContainerBlockioIoServiceTimeRecursiveRead{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServiceTimeRecursiveSync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_service_time_recursive.sync metric with initial data.
func (m *metricContainerBlockioIoServiceTimeRecursiveSync) init() {
	m.data.SetName("container.blockio.io_service_time_recursive.sync")
	m.data.SetDescription("Total amount of time in nanoseconds between request dispatch and request completion for the IOs done by this cgroup and descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServiceTimeRecursiveSync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServiceTimeRecursiveSync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServiceTimeRecursiveSync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServiceTimeRecursiveSync(settings MetricSettings) metricContainerBlockioIoServiceTimeRecursiveSync {
	m := metricContainerBlockioIoServiceTimeRecursiveSync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServiceTimeRecursiveTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_service_time_recursive.total metric with initial data.
func (m *metricContainerBlockioIoServiceTimeRecursiveTotal) init() {
	m.data.SetName("container.blockio.io_service_time_recursive.total")
	m.data.SetDescription("Total amount of time in nanoseconds between request dispatch and request completion for the IOs done by this cgroup and descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServiceTimeRecursiveTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServiceTimeRecursiveTotal) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServiceTimeRecursiveTotal) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServiceTimeRecursiveTotal(settings MetricSettings) metricContainerBlockioIoServiceTimeRecursiveTotal {
	m := metricContainerBlockioIoServiceTimeRecursiveTotal{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServiceTimeRecursiveWrite struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_service_time_recursive.write metric with initial data.
func (m *metricContainerBlockioIoServiceTimeRecursiveWrite) init() {
	m.data.SetName("container.blockio.io_service_time_recursive.write")
	m.data.SetDescription("Total amount of time in nanoseconds between request dispatch and request completion for the IOs done by this cgroup and descendant cgroups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServiceTimeRecursiveWrite) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServiceTimeRecursiveWrite) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServiceTimeRecursiveWrite) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServiceTimeRecursiveWrite(settings MetricSettings) metricContainerBlockioIoServiceTimeRecursiveWrite {
	m := metricContainerBlockioIoServiceTimeRecursiveWrite{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServicedRecursiveAsync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_serviced_recursive.async metric with initial data.
func (m *metricContainerBlockioIoServicedRecursiveAsync) init() {
	m.data.SetName("container.blockio.io_serviced_recursive.async")
	m.data.SetDescription("Number of IOs (bio) issued to the disk by the group and descendant groups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServicedRecursiveAsync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServicedRecursiveAsync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServicedRecursiveAsync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServicedRecursiveAsync(settings MetricSettings) metricContainerBlockioIoServicedRecursiveAsync {
	m := metricContainerBlockioIoServicedRecursiveAsync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServicedRecursiveDiscard struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_serviced_recursive.discard metric with initial data.
func (m *metricContainerBlockioIoServicedRecursiveDiscard) init() {
	m.data.SetName("container.blockio.io_serviced_recursive.discard")
	m.data.SetDescription("Number of IOs (bio) issued to the disk by the group and descendant groups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServicedRecursiveDiscard) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServicedRecursiveDiscard) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServicedRecursiveDiscard) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServicedRecursiveDiscard(settings MetricSettings) metricContainerBlockioIoServicedRecursiveDiscard {
	m := metricContainerBlockioIoServicedRecursiveDiscard{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServicedRecursiveRead struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_serviced_recursive.read metric with initial data.
func (m *metricContainerBlockioIoServicedRecursiveRead) init() {
	m.data.SetName("container.blockio.io_serviced_recursive.read")
	m.data.SetDescription("Number of IOs (bio) issued to the disk by the group and descendant groups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServicedRecursiveRead) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServicedRecursiveRead) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServicedRecursiveRead) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServicedRecursiveRead(settings MetricSettings) metricContainerBlockioIoServicedRecursiveRead {
	m := metricContainerBlockioIoServicedRecursiveRead{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServicedRecursiveSync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_serviced_recursive.sync metric with initial data.
func (m *metricContainerBlockioIoServicedRecursiveSync) init() {
	m.data.SetName("container.blockio.io_serviced_recursive.sync")
	m.data.SetDescription("Number of IOs (bio) issued to the disk by the group and descendant groups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServicedRecursiveSync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServicedRecursiveSync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServicedRecursiveSync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServicedRecursiveSync(settings MetricSettings) metricContainerBlockioIoServicedRecursiveSync {
	m := metricContainerBlockioIoServicedRecursiveSync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServicedRecursiveTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_serviced_recursive.total metric with initial data.
func (m *metricContainerBlockioIoServicedRecursiveTotal) init() {
	m.data.SetName("container.blockio.io_serviced_recursive.total")
	m.data.SetDescription("Number of IOs (bio) issued to the disk by the group and descendant groups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServicedRecursiveTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServicedRecursiveTotal) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServicedRecursiveTotal) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServicedRecursiveTotal(settings MetricSettings) metricContainerBlockioIoServicedRecursiveTotal {
	m := metricContainerBlockioIoServicedRecursiveTotal{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoServicedRecursiveWrite struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_serviced_recursive.write metric with initial data.
func (m *metricContainerBlockioIoServicedRecursiveWrite) init() {
	m.data.SetName("container.blockio.io_serviced_recursive.write")
	m.data.SetDescription("Number of IOs (bio) issued to the disk by the group and descendant groups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoServicedRecursiveWrite) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoServicedRecursiveWrite) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoServicedRecursiveWrite) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoServicedRecursiveWrite(settings MetricSettings) metricContainerBlockioIoServicedRecursiveWrite {
	m := metricContainerBlockioIoServicedRecursiveWrite{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoTimeRecursiveAsync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_time_recursive.async metric with initial data.
func (m *metricContainerBlockioIoTimeRecursiveAsync) init() {
	m.data.SetName("container.blockio.io_time_recursive.async")
	m.data.SetDescription("Disk time allocated to cgroup (and descendant cgroups) per device in milliseconds.")
	m.data.SetUnit("ms")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoTimeRecursiveAsync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoTimeRecursiveAsync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoTimeRecursiveAsync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoTimeRecursiveAsync(settings MetricSettings) metricContainerBlockioIoTimeRecursiveAsync {
	m := metricContainerBlockioIoTimeRecursiveAsync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoTimeRecursiveDiscard struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_time_recursive.discard metric with initial data.
func (m *metricContainerBlockioIoTimeRecursiveDiscard) init() {
	m.data.SetName("container.blockio.io_time_recursive.discard")
	m.data.SetDescription("Disk time allocated to cgroup (and descendant cgroups) per device in milliseconds.")
	m.data.SetUnit("ms")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoTimeRecursiveDiscard) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoTimeRecursiveDiscard) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoTimeRecursiveDiscard) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoTimeRecursiveDiscard(settings MetricSettings) metricContainerBlockioIoTimeRecursiveDiscard {
	m := metricContainerBlockioIoTimeRecursiveDiscard{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoTimeRecursiveRead struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_time_recursive.read metric with initial data.
func (m *metricContainerBlockioIoTimeRecursiveRead) init() {
	m.data.SetName("container.blockio.io_time_recursive.read")
	m.data.SetDescription("Disk time allocated to cgroup (and descendant cgroups) per device in milliseconds.")
	m.data.SetUnit("ms")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoTimeRecursiveRead) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoTimeRecursiveRead) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoTimeRecursiveRead) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoTimeRecursiveRead(settings MetricSettings) metricContainerBlockioIoTimeRecursiveRead {
	m := metricContainerBlockioIoTimeRecursiveRead{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoTimeRecursiveSync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_time_recursive.sync metric with initial data.
func (m *metricContainerBlockioIoTimeRecursiveSync) init() {
	m.data.SetName("container.blockio.io_time_recursive.sync")
	m.data.SetDescription("Disk time allocated to cgroup (and descendant cgroups) per device in milliseconds.")
	m.data.SetUnit("ms")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoTimeRecursiveSync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoTimeRecursiveSync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoTimeRecursiveSync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoTimeRecursiveSync(settings MetricSettings) metricContainerBlockioIoTimeRecursiveSync {
	m := metricContainerBlockioIoTimeRecursiveSync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoTimeRecursiveTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_time_recursive.total metric with initial data.
func (m *metricContainerBlockioIoTimeRecursiveTotal) init() {
	m.data.SetName("container.blockio.io_time_recursive.total")
	m.data.SetDescription("Disk time allocated to cgroup (and descendant cgroups) per device in milliseconds.")
	m.data.SetUnit("ms")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoTimeRecursiveTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoTimeRecursiveTotal) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoTimeRecursiveTotal) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoTimeRecursiveTotal(settings MetricSettings) metricContainerBlockioIoTimeRecursiveTotal {
	m := metricContainerBlockioIoTimeRecursiveTotal{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoTimeRecursiveWrite struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_time_recursive.write metric with initial data.
func (m *metricContainerBlockioIoTimeRecursiveWrite) init() {
	m.data.SetName("container.blockio.io_time_recursive.write")
	m.data.SetDescription("Disk time allocated to cgroup (and descendant cgroups) per device in milliseconds.")
	m.data.SetUnit("ms")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoTimeRecursiveWrite) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoTimeRecursiveWrite) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoTimeRecursiveWrite) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoTimeRecursiveWrite(settings MetricSettings) metricContainerBlockioIoTimeRecursiveWrite {
	m := metricContainerBlockioIoTimeRecursiveWrite{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoWaitTimeRecursiveAsync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_wait_time_recursive.async metric with initial data.
func (m *metricContainerBlockioIoWaitTimeRecursiveAsync) init() {
	m.data.SetName("container.blockio.io_wait_time_recursive.async")
	m.data.SetDescription("Total amount of time the IOs for this cgroup (and descendant cgroups) spent waiting in the scheduler queues for service.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoWaitTimeRecursiveAsync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoWaitTimeRecursiveAsync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoWaitTimeRecursiveAsync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoWaitTimeRecursiveAsync(settings MetricSettings) metricContainerBlockioIoWaitTimeRecursiveAsync {
	m := metricContainerBlockioIoWaitTimeRecursiveAsync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoWaitTimeRecursiveDiscard struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_wait_time_recursive.discard metric with initial data.
func (m *metricContainerBlockioIoWaitTimeRecursiveDiscard) init() {
	m.data.SetName("container.blockio.io_wait_time_recursive.discard")
	m.data.SetDescription("Total amount of time the IOs for this cgroup (and descendant cgroups) spent waiting in the scheduler queues for service.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoWaitTimeRecursiveDiscard) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoWaitTimeRecursiveDiscard) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoWaitTimeRecursiveDiscard) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoWaitTimeRecursiveDiscard(settings MetricSettings) metricContainerBlockioIoWaitTimeRecursiveDiscard {
	m := metricContainerBlockioIoWaitTimeRecursiveDiscard{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoWaitTimeRecursiveRead struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_wait_time_recursive.read metric with initial data.
func (m *metricContainerBlockioIoWaitTimeRecursiveRead) init() {
	m.data.SetName("container.blockio.io_wait_time_recursive.read")
	m.data.SetDescription("Total amount of time the IOs for this cgroup (and descendant cgroups) spent waiting in the scheduler queues for service.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoWaitTimeRecursiveRead) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoWaitTimeRecursiveRead) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoWaitTimeRecursiveRead) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoWaitTimeRecursiveRead(settings MetricSettings) metricContainerBlockioIoWaitTimeRecursiveRead {
	m := metricContainerBlockioIoWaitTimeRecursiveRead{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoWaitTimeRecursiveSync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_wait_time_recursive.sync metric with initial data.
func (m *metricContainerBlockioIoWaitTimeRecursiveSync) init() {
	m.data.SetName("container.blockio.io_wait_time_recursive.sync")
	m.data.SetDescription("Total amount of time the IOs for this cgroup (and descendant cgroups) spent waiting in the scheduler queues for service.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoWaitTimeRecursiveSync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoWaitTimeRecursiveSync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoWaitTimeRecursiveSync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoWaitTimeRecursiveSync(settings MetricSettings) metricContainerBlockioIoWaitTimeRecursiveSync {
	m := metricContainerBlockioIoWaitTimeRecursiveSync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoWaitTimeRecursiveTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_wait_time_recursive.total metric with initial data.
func (m *metricContainerBlockioIoWaitTimeRecursiveTotal) init() {
	m.data.SetName("container.blockio.io_wait_time_recursive.total")
	m.data.SetDescription("Total amount of time the IOs for this cgroup (and descendant cgroups) spent waiting in the scheduler queues for service.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoWaitTimeRecursiveTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoWaitTimeRecursiveTotal) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoWaitTimeRecursiveTotal) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoWaitTimeRecursiveTotal(settings MetricSettings) metricContainerBlockioIoWaitTimeRecursiveTotal {
	m := metricContainerBlockioIoWaitTimeRecursiveTotal{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioIoWaitTimeRecursiveWrite struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.io_wait_time_recursive.write metric with initial data.
func (m *metricContainerBlockioIoWaitTimeRecursiveWrite) init() {
	m.data.SetName("container.blockio.io_wait_time_recursive.write")
	m.data.SetDescription("Total amount of time the IOs for this cgroup (and descendant cgroups) spent waiting in the scheduler queues for service.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioIoWaitTimeRecursiveWrite) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioIoWaitTimeRecursiveWrite) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioIoWaitTimeRecursiveWrite) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioIoWaitTimeRecursiveWrite(settings MetricSettings) metricContainerBlockioIoWaitTimeRecursiveWrite {
	m := metricContainerBlockioIoWaitTimeRecursiveWrite{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioSectorsRecursiveAsync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.sectors_recursive.async metric with initial data.
func (m *metricContainerBlockioSectorsRecursiveAsync) init() {
	m.data.SetName("container.blockio.sectors_recursive.async")
	m.data.SetDescription("Number of sectors transferred to/from disk by the group and descendant groups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioSectorsRecursiveAsync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioSectorsRecursiveAsync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioSectorsRecursiveAsync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioSectorsRecursiveAsync(settings MetricSettings) metricContainerBlockioSectorsRecursiveAsync {
	m := metricContainerBlockioSectorsRecursiveAsync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioSectorsRecursiveDiscard struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.sectors_recursive.discard metric with initial data.
func (m *metricContainerBlockioSectorsRecursiveDiscard) init() {
	m.data.SetName("container.blockio.sectors_recursive.discard")
	m.data.SetDescription("Number of sectors transferred to/from disk by the group and descendant groups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioSectorsRecursiveDiscard) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioSectorsRecursiveDiscard) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioSectorsRecursiveDiscard) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioSectorsRecursiveDiscard(settings MetricSettings) metricContainerBlockioSectorsRecursiveDiscard {
	m := metricContainerBlockioSectorsRecursiveDiscard{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioSectorsRecursiveRead struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.sectors_recursive.read metric with initial data.
func (m *metricContainerBlockioSectorsRecursiveRead) init() {
	m.data.SetName("container.blockio.sectors_recursive.read")
	m.data.SetDescription("Number of sectors transferred to/from disk by the group and descendant groups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioSectorsRecursiveRead) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioSectorsRecursiveRead) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioSectorsRecursiveRead) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioSectorsRecursiveRead(settings MetricSettings) metricContainerBlockioSectorsRecursiveRead {
	m := metricContainerBlockioSectorsRecursiveRead{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioSectorsRecursiveSync struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.sectors_recursive.sync metric with initial data.
func (m *metricContainerBlockioSectorsRecursiveSync) init() {
	m.data.SetName("container.blockio.sectors_recursive.sync")
	m.data.SetDescription("Number of sectors transferred to/from disk by the group and descendant groups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioSectorsRecursiveSync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioSectorsRecursiveSync) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioSectorsRecursiveSync) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioSectorsRecursiveSync(settings MetricSettings) metricContainerBlockioSectorsRecursiveSync {
	m := metricContainerBlockioSectorsRecursiveSync{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioSectorsRecursiveTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.sectors_recursive.total metric with initial data.
func (m *metricContainerBlockioSectorsRecursiveTotal) init() {
	m.data.SetName("container.blockio.sectors_recursive.total")
	m.data.SetDescription("Number of sectors transferred to/from disk by the group and descendant groups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioSectorsRecursiveTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioSectorsRecursiveTotal) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioSectorsRecursiveTotal) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioSectorsRecursiveTotal(settings MetricSettings) metricContainerBlockioSectorsRecursiveTotal {
	m := metricContainerBlockioSectorsRecursiveTotal{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerBlockioSectorsRecursiveWrite struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.blockio.sectors_recursive.write metric with initial data.
func (m *metricContainerBlockioSectorsRecursiveWrite) init() {
	m.data.SetName("container.blockio.sectors_recursive.write")
	m.data.SetDescription("Number of sectors transferred to/from disk by the group and descendant groups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerBlockioSectorsRecursiveWrite) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("device_major", pcommon.NewValueString(deviceMajorAttributeValue))
	dp.Attributes().Insert("device_minor", pcommon.NewValueString(deviceMinorAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerBlockioSectorsRecursiveWrite) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerBlockioSectorsRecursiveWrite) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerBlockioSectorsRecursiveWrite(settings MetricSettings) metricContainerBlockioSectorsRecursiveWrite {
	m := metricContainerBlockioSectorsRecursiveWrite{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUPercent struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.percent metric with initial data.
func (m *metricContainerCPUPercent) init() {
	m.data.SetName("container.cpu.percent")
	m.data.SetDescription("Percent of CPU used by the container.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerCPUPercent) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUPercent) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUPercent) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUPercent(settings MetricSettings) metricContainerCPUPercent {
	m := metricContainerCPUPercent{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUThrottlingDataPeriods struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.throttling_data.periods metric with initial data.
func (m *metricContainerCPUThrottlingDataPeriods) init() {
	m.data.SetName("container.cpu.throttling_data.periods")
	m.data.SetDescription("Number of periods with throttling active.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
}

func (m *metricContainerCPUThrottlingDataPeriods) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUThrottlingDataPeriods) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUThrottlingDataPeriods) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUThrottlingDataPeriods(settings MetricSettings) metricContainerCPUThrottlingDataPeriods {
	m := metricContainerCPUThrottlingDataPeriods{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUThrottlingDataThrottledPeriods struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.throttling_data.throttled_periods metric with initial data.
func (m *metricContainerCPUThrottlingDataThrottledPeriods) init() {
	m.data.SetName("container.cpu.throttling_data.throttled_periods")
	m.data.SetDescription("Number of periods when the container hits its throttling limit.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
}

func (m *metricContainerCPUThrottlingDataThrottledPeriods) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUThrottlingDataThrottledPeriods) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUThrottlingDataThrottledPeriods) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUThrottlingDataThrottledPeriods(settings MetricSettings) metricContainerCPUThrottlingDataThrottledPeriods {
	m := metricContainerCPUThrottlingDataThrottledPeriods{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUThrottlingDataThrottledTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.throttling_data.throttled_time metric with initial data.
func (m *metricContainerCPUThrottlingDataThrottledTime) init() {
	m.data.SetName("container.cpu.throttling_data.throttled_time")
	m.data.SetDescription("Aggregate time the container was throttled.")
	m.data.SetUnit("ns")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
}

func (m *metricContainerCPUThrottlingDataThrottledTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUThrottlingDataThrottledTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUThrottlingDataThrottledTime) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUThrottlingDataThrottledTime(settings MetricSettings) metricContainerCPUThrottlingDataThrottledTime {
	m := metricContainerCPUThrottlingDataThrottledTime{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUUsageKernelmode struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.usage.kernelmode metric with initial data.
func (m *metricContainerCPUUsageKernelmode) init() {
	m.data.SetName("container.cpu.usage.kernelmode")
	m.data.SetDescription("Time spent by tasks of the cgroup in kernel mode (Linux).  Time spent by all container processes in kernel mode (Windows).")
	m.data.SetUnit("ns")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
}

func (m *metricContainerCPUUsageKernelmode) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUUsageKernelmode) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUUsageKernelmode) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUUsageKernelmode(settings MetricSettings) metricContainerCPUUsageKernelmode {
	m := metricContainerCPUUsageKernelmode{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUUsagePercpu struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.usage.percpu metric with initial data.
func (m *metricContainerCPUUsagePercpu) init() {
	m.data.SetName("container.cpu.usage.percpu")
	m.data.SetDescription("Per-core CPU usage by the container.")
	m.data.SetUnit("ns")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerCPUUsagePercpu) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, coreAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("core", pcommon.NewValueString(coreAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUUsagePercpu) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUUsagePercpu) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUUsagePercpu(settings MetricSettings) metricContainerCPUUsagePercpu {
	m := metricContainerCPUUsagePercpu{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUUsageSystem struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.usage.system metric with initial data.
func (m *metricContainerCPUUsageSystem) init() {
	m.data.SetName("container.cpu.usage.system")
	m.data.SetDescription("System CPU usage.")
	m.data.SetUnit("ns")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
}

func (m *metricContainerCPUUsageSystem) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUUsageSystem) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUUsageSystem) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUUsageSystem(settings MetricSettings) metricContainerCPUUsageSystem {
	m := metricContainerCPUUsageSystem{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUUsageTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.usage.total metric with initial data.
func (m *metricContainerCPUUsageTotal) init() {
	m.data.SetName("container.cpu.usage.total")
	m.data.SetDescription("Total CPU time consumed.")
	m.data.SetUnit("ns")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
}

func (m *metricContainerCPUUsageTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUUsageTotal) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUUsageTotal) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUUsageTotal(settings MetricSettings) metricContainerCPUUsageTotal {
	m := metricContainerCPUUsageTotal{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerCPUUsageUsermode struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.cpu.usage.usermode metric with initial data.
func (m *metricContainerCPUUsageUsermode) init() {
	m.data.SetName("container.cpu.usage.usermode")
	m.data.SetDescription("Time spent by tasks of the cgroup in user mode (Linux).  Time spent by all container processes in user mode (Windows).")
	m.data.SetUnit("ns")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
}

func (m *metricContainerCPUUsageUsermode) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerCPUUsageUsermode) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerCPUUsageUsermode) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerCPUUsageUsermode(settings MetricSettings) metricContainerCPUUsageUsermode {
	m := metricContainerCPUUsageUsermode{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryActiveAnon struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.active_anon metric with initial data.
func (m *metricContainerMemoryActiveAnon) init() {
	m.data.SetName("container.memory.active_anon")
	m.data.SetDescription("The amount of anonymous memory that has been identified as active by the kernel.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryActiveAnon) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryActiveAnon) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryActiveAnon) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryActiveAnon(settings MetricSettings) metricContainerMemoryActiveAnon {
	m := metricContainerMemoryActiveAnon{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryActiveFile struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.active_file metric with initial data.
func (m *metricContainerMemoryActiveFile) init() {
	m.data.SetName("container.memory.active_file")
	m.data.SetDescription("Cache memory that has been identified as active by the kernel.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryActiveFile) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryActiveFile) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryActiveFile) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryActiveFile(settings MetricSettings) metricContainerMemoryActiveFile {
	m := metricContainerMemoryActiveFile{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryCache struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.cache metric with initial data.
func (m *metricContainerMemoryCache) init() {
	m.data.SetName("container.memory.cache")
	m.data.SetDescription("The amount of memory used by the processes of this control group that can be associated precisely with a block on a block device.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryCache) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryCache) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryCache) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryCache(settings MetricSettings) metricContainerMemoryCache {
	m := metricContainerMemoryCache{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryDirty struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.dirty metric with initial data.
func (m *metricContainerMemoryDirty) init() {
	m.data.SetName("container.memory.dirty")
	m.data.SetDescription("Bytes that are waiting to get written back to the disk, from this cgroup.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryDirty) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryDirty) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryDirty) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryDirty(settings MetricSettings) metricContainerMemoryDirty {
	m := metricContainerMemoryDirty{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryHierarchicalMemoryLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.hierarchical_memory_limit metric with initial data.
func (m *metricContainerMemoryHierarchicalMemoryLimit) init() {
	m.data.SetName("container.memory.hierarchical_memory_limit")
	m.data.SetDescription("The maximum amount of physical memory that can be used by the processes of this control group.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryHierarchicalMemoryLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryHierarchicalMemoryLimit) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryHierarchicalMemoryLimit) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryHierarchicalMemoryLimit(settings MetricSettings) metricContainerMemoryHierarchicalMemoryLimit {
	m := metricContainerMemoryHierarchicalMemoryLimit{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryHierarchicalMemswLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.hierarchical_memsw_limit metric with initial data.
func (m *metricContainerMemoryHierarchicalMemswLimit) init() {
	m.data.SetName("container.memory.hierarchical_memsw_limit")
	m.data.SetDescription("The maximum amount of RAM + swap that can be used by the processes of this control group.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryHierarchicalMemswLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryHierarchicalMemswLimit) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryHierarchicalMemswLimit) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryHierarchicalMemswLimit(settings MetricSettings) metricContainerMemoryHierarchicalMemswLimit {
	m := metricContainerMemoryHierarchicalMemswLimit{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryInactiveAnon struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.inactive_anon metric with initial data.
func (m *metricContainerMemoryInactiveAnon) init() {
	m.data.SetName("container.memory.inactive_anon")
	m.data.SetDescription("The amount of anonymous memory that has been identified as inactive by the kernel.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryInactiveAnon) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryInactiveAnon) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryInactiveAnon) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryInactiveAnon(settings MetricSettings) metricContainerMemoryInactiveAnon {
	m := metricContainerMemoryInactiveAnon{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryInactiveFile struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.inactive_file metric with initial data.
func (m *metricContainerMemoryInactiveFile) init() {
	m.data.SetName("container.memory.inactive_file")
	m.data.SetDescription("Cache memory that has been identified as inactive by the kernel.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryInactiveFile) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryInactiveFile) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryInactiveFile) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryInactiveFile(settings MetricSettings) metricContainerMemoryInactiveFile {
	m := metricContainerMemoryInactiveFile{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryMappedFile struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.mapped_file metric with initial data.
func (m *metricContainerMemoryMappedFile) init() {
	m.data.SetName("container.memory.mapped_file")
	m.data.SetDescription("Indicates the amount of memory mapped by the processes in the control group.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryMappedFile) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryMappedFile) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryMappedFile) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryMappedFile(settings MetricSettings) metricContainerMemoryMappedFile {
	m := metricContainerMemoryMappedFile{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryPercent struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.percent metric with initial data.
func (m *metricContainerMemoryPercent) init() {
	m.data.SetName("container.memory.percent")
	m.data.SetDescription("Percentage of memory used.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryPercent) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryPercent) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryPercent) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryPercent(settings MetricSettings) metricContainerMemoryPercent {
	m := metricContainerMemoryPercent{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryPgfault struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.pgfault metric with initial data.
func (m *metricContainerMemoryPgfault) init() {
	m.data.SetName("container.memory.pgfault")
	m.data.SetDescription("Indicate the number of times that a process of the cgroup triggered a page fault.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
}

func (m *metricContainerMemoryPgfault) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryPgfault) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryPgfault) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryPgfault(settings MetricSettings) metricContainerMemoryPgfault {
	m := metricContainerMemoryPgfault{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryPgmajfault struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.pgmajfault metric with initial data.
func (m *metricContainerMemoryPgmajfault) init() {
	m.data.SetName("container.memory.pgmajfault")
	m.data.SetDescription("Indicate the number of times that a process of the cgroup triggered a major fault.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
}

func (m *metricContainerMemoryPgmajfault) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryPgmajfault) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryPgmajfault) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryPgmajfault(settings MetricSettings) metricContainerMemoryPgmajfault {
	m := metricContainerMemoryPgmajfault{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryPgpgin struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.pgpgin metric with initial data.
func (m *metricContainerMemoryPgpgin) init() {
	m.data.SetName("container.memory.pgpgin")
	m.data.SetDescription("Number of pages read from disk by the cgroup.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
}

func (m *metricContainerMemoryPgpgin) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryPgpgin) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryPgpgin) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryPgpgin(settings MetricSettings) metricContainerMemoryPgpgin {
	m := metricContainerMemoryPgpgin{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryPgpgout struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.pgpgout metric with initial data.
func (m *metricContainerMemoryPgpgout) init() {
	m.data.SetName("container.memory.pgpgout")
	m.data.SetDescription("Number of pages written to disk by the cgroup.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
}

func (m *metricContainerMemoryPgpgout) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryPgpgout) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryPgpgout) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryPgpgout(settings MetricSettings) metricContainerMemoryPgpgout {
	m := metricContainerMemoryPgpgout{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryRss struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.rss metric with initial data.
func (m *metricContainerMemoryRss) init() {
	m.data.SetName("container.memory.rss")
	m.data.SetDescription("The amount of memory that doesnt correspond to anything on disk: stacks, heaps, and anonymous memory maps.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryRss) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryRss) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryRss) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryRss(settings MetricSettings) metricContainerMemoryRss {
	m := metricContainerMemoryRss{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryRssHuge struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.rss_huge metric with initial data.
func (m *metricContainerMemoryRssHuge) init() {
	m.data.SetName("container.memory.rss_huge")
	m.data.SetDescription("Number of bytes of anonymous transparent hugepages in this cgroup.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryRssHuge) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryRssHuge) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryRssHuge) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryRssHuge(settings MetricSettings) metricContainerMemoryRssHuge {
	m := metricContainerMemoryRssHuge{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemorySwap struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.swap metric with initial data.
func (m *metricContainerMemorySwap) init() {
	m.data.SetName("container.memory.swap")
	m.data.SetDescription("The amount of swap currently used by the processes in this cgroup.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemorySwap) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemorySwap) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemorySwap) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemorySwap(settings MetricSettings) metricContainerMemorySwap {
	m := metricContainerMemorySwap{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalActiveAnon struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_active_anon metric with initial data.
func (m *metricContainerMemoryTotalActiveAnon) init() {
	m.data.SetName("container.memory.total_active_anon")
	m.data.SetDescription("The amount of anonymous memory that has been identified as active by the kernel. Includes descendant cgroups.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryTotalActiveAnon) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalActiveAnon) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalActiveAnon) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalActiveAnon(settings MetricSettings) metricContainerMemoryTotalActiveAnon {
	m := metricContainerMemoryTotalActiveAnon{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalActiveFile struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_active_file metric with initial data.
func (m *metricContainerMemoryTotalActiveFile) init() {
	m.data.SetName("container.memory.total_active_file")
	m.data.SetDescription("Cache memory that has been identified as active by the kernel. Includes descendant cgroups.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryTotalActiveFile) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalActiveFile) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalActiveFile) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalActiveFile(settings MetricSettings) metricContainerMemoryTotalActiveFile {
	m := metricContainerMemoryTotalActiveFile{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalCache struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_cache metric with initial data.
func (m *metricContainerMemoryTotalCache) init() {
	m.data.SetName("container.memory.total_cache")
	m.data.SetDescription("Total amount of memory used by the processes of this cgroup (and descendants) that can be associated with a block on a block device. Also accounts for memory used by tmpfs.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryTotalCache) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalCache) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalCache) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalCache(settings MetricSettings) metricContainerMemoryTotalCache {
	m := metricContainerMemoryTotalCache{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalDirty struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_dirty metric with initial data.
func (m *metricContainerMemoryTotalDirty) init() {
	m.data.SetName("container.memory.total_dirty")
	m.data.SetDescription("Bytes that are waiting to get written back to the disk, from this cgroup and descendants.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryTotalDirty) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalDirty) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalDirty) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalDirty(settings MetricSettings) metricContainerMemoryTotalDirty {
	m := metricContainerMemoryTotalDirty{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalInactiveAnon struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_inactive_anon metric with initial data.
func (m *metricContainerMemoryTotalInactiveAnon) init() {
	m.data.SetName("container.memory.total_inactive_anon")
	m.data.SetDescription("The amount of anonymous memory that has been identified as inactive by the kernel. Includes descendant cgroups.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryTotalInactiveAnon) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalInactiveAnon) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalInactiveAnon) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalInactiveAnon(settings MetricSettings) metricContainerMemoryTotalInactiveAnon {
	m := metricContainerMemoryTotalInactiveAnon{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalInactiveFile struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_inactive_file metric with initial data.
func (m *metricContainerMemoryTotalInactiveFile) init() {
	m.data.SetName("container.memory.total_inactive_file")
	m.data.SetDescription("Cache memory that has been identified as inactive by the kernel. Includes descendant cgroups.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryTotalInactiveFile) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalInactiveFile) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalInactiveFile) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalInactiveFile(settings MetricSettings) metricContainerMemoryTotalInactiveFile {
	m := metricContainerMemoryTotalInactiveFile{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalMappedFile struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_mapped_file metric with initial data.
func (m *metricContainerMemoryTotalMappedFile) init() {
	m.data.SetName("container.memory.total_mapped_file")
	m.data.SetDescription("Indicates the amount of memory mapped by the processes in the control group and descendant groups.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryTotalMappedFile) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalMappedFile) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalMappedFile) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalMappedFile(settings MetricSettings) metricContainerMemoryTotalMappedFile {
	m := metricContainerMemoryTotalMappedFile{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalPgfault struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_pgfault metric with initial data.
func (m *metricContainerMemoryTotalPgfault) init() {
	m.data.SetName("container.memory.total_pgfault")
	m.data.SetDescription("Indicate the number of times that a process of the cgroup (or descendant cgroups) triggered a page fault.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalPgfault) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalPgfault) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalPgfault) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalPgfault(settings MetricSettings) metricContainerMemoryTotalPgfault {
	m := metricContainerMemoryTotalPgfault{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalPgmajfault struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_pgmajfault metric with initial data.
func (m *metricContainerMemoryTotalPgmajfault) init() {
	m.data.SetName("container.memory.total_pgmajfault")
	m.data.SetDescription("Indicate the number of times that a process of the cgroup (or descendant cgroups) triggered a major fault.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalPgmajfault) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalPgmajfault) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalPgmajfault) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalPgmajfault(settings MetricSettings) metricContainerMemoryTotalPgmajfault {
	m := metricContainerMemoryTotalPgmajfault{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalPgpgin struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_pgpgin metric with initial data.
func (m *metricContainerMemoryTotalPgpgin) init() {
	m.data.SetName("container.memory.total_pgpgin")
	m.data.SetDescription("Number of pages read from disk by the cgroup and descendant groups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalPgpgin) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalPgpgin) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalPgpgin) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalPgpgin(settings MetricSettings) metricContainerMemoryTotalPgpgin {
	m := metricContainerMemoryTotalPgpgin{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalPgpgout struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_pgpgout metric with initial data.
func (m *metricContainerMemoryTotalPgpgout) init() {
	m.data.SetName("container.memory.total_pgpgout")
	m.data.SetDescription("Number of pages written to disk by the cgroup and descendant groups.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
}

func (m *metricContainerMemoryTotalPgpgout) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalPgpgout) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalPgpgout) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalPgpgout(settings MetricSettings) metricContainerMemoryTotalPgpgout {
	m := metricContainerMemoryTotalPgpgout{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalRss struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_rss metric with initial data.
func (m *metricContainerMemoryTotalRss) init() {
	m.data.SetName("container.memory.total_rss")
	m.data.SetDescription("The amount of memory that doesnt correspond to anything on disk: stacks, heaps, and anonymous memory maps. Includes descendant cgroups.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryTotalRss) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalRss) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalRss) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalRss(settings MetricSettings) metricContainerMemoryTotalRss {
	m := metricContainerMemoryTotalRss{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalRssHuge struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_rss_huge metric with initial data.
func (m *metricContainerMemoryTotalRssHuge) init() {
	m.data.SetName("container.memory.total_rss_huge")
	m.data.SetDescription("Number of bytes of anonymous transparent hugepages in this cgroup and descendant cgroups.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryTotalRssHuge) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalRssHuge) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalRssHuge) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalRssHuge(settings MetricSettings) metricContainerMemoryTotalRssHuge {
	m := metricContainerMemoryTotalRssHuge{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalSwap struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_swap metric with initial data.
func (m *metricContainerMemoryTotalSwap) init() {
	m.data.SetName("container.memory.total_swap")
	m.data.SetDescription("The amount of swap currently used by the processes in this cgroup and descendant groups.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryTotalSwap) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalSwap) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalSwap) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalSwap(settings MetricSettings) metricContainerMemoryTotalSwap {
	m := metricContainerMemoryTotalSwap{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalUnevictable struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_unevictable metric with initial data.
func (m *metricContainerMemoryTotalUnevictable) init() {
	m.data.SetName("container.memory.total_unevictable")
	m.data.SetDescription("The amount of memory that cannot be reclaimed. Includes descendant cgroups.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryTotalUnevictable) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalUnevictable) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalUnevictable) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalUnevictable(settings MetricSettings) metricContainerMemoryTotalUnevictable {
	m := metricContainerMemoryTotalUnevictable{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryTotalWriteback struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.total_writeback metric with initial data.
func (m *metricContainerMemoryTotalWriteback) init() {
	m.data.SetName("container.memory.total_writeback")
	m.data.SetDescription("Number of bytes of file/anon cache that are queued for syncing to disk in this cgroup and descendants.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryTotalWriteback) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryTotalWriteback) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryTotalWriteback) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryTotalWriteback(settings MetricSettings) metricContainerMemoryTotalWriteback {
	m := metricContainerMemoryTotalWriteback{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryUnevictable struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.unevictable metric with initial data.
func (m *metricContainerMemoryUnevictable) init() {
	m.data.SetName("container.memory.unevictable")
	m.data.SetDescription("The amount of memory that cannot be reclaimed.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryUnevictable) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryUnevictable) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryUnevictable) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryUnevictable(settings MetricSettings) metricContainerMemoryUnevictable {
	m := metricContainerMemoryUnevictable{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryUsageLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.usage.limit metric with initial data.
func (m *metricContainerMemoryUsageLimit) init() {
	m.data.SetName("container.memory.usage.limit")
	m.data.SetDescription("Memory limit of the container.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryUsageLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryUsageLimit) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryUsageLimit) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryUsageLimit(settings MetricSettings) metricContainerMemoryUsageLimit {
	m := metricContainerMemoryUsageLimit{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryUsageMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.usage.max metric with initial data.
func (m *metricContainerMemoryUsageMax) init() {
	m.data.SetName("container.memory.usage.max")
	m.data.SetDescription("Maximum memory usage.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryUsageMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryUsageMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryUsageMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryUsageMax(settings MetricSettings) metricContainerMemoryUsageMax {
	m := metricContainerMemoryUsageMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryUsageTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.usage.total metric with initial data.
func (m *metricContainerMemoryUsageTotal) init() {
	m.data.SetName("container.memory.usage.total")
	m.data.SetDescription("Memory usage of the container. This excludes the total cache.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryUsageTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryUsageTotal) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryUsageTotal) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryUsageTotal(settings MetricSettings) metricContainerMemoryUsageTotal {
	m := metricContainerMemoryUsageTotal{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerMemoryWriteback struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.memory.writeback metric with initial data.
func (m *metricContainerMemoryWriteback) init() {
	m.data.SetName("container.memory.writeback")
	m.data.SetDescription("Number of bytes of file/anon cache that are queued for syncing to disk in this cgroup.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeGauge)
}

func (m *metricContainerMemoryWriteback) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerMemoryWriteback) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerMemoryWriteback) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerMemoryWriteback(settings MetricSettings) metricContainerMemoryWriteback {
	m := metricContainerMemoryWriteback{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageRxBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.rx_bytes metric with initial data.
func (m *metricContainerNetworkIoUsageRxBytes) init() {
	m.data.SetName("container.network.io.usage.rx_bytes")
	m.data.SetDescription("Bytes received by the container.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageRxBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("interface", pcommon.NewValueString(interfaceAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageRxBytes) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageRxBytes) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageRxBytes(settings MetricSettings) metricContainerNetworkIoUsageRxBytes {
	m := metricContainerNetworkIoUsageRxBytes{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageRxDropped struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.rx_dropped metric with initial data.
func (m *metricContainerNetworkIoUsageRxDropped) init() {
	m.data.SetName("container.network.io.usage.rx_dropped")
	m.data.SetDescription("Incoming packets dropped.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageRxDropped) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("interface", pcommon.NewValueString(interfaceAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageRxDropped) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageRxDropped) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageRxDropped(settings MetricSettings) metricContainerNetworkIoUsageRxDropped {
	m := metricContainerNetworkIoUsageRxDropped{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageRxErrors struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.rx_errors metric with initial data.
func (m *metricContainerNetworkIoUsageRxErrors) init() {
	m.data.SetName("container.network.io.usage.rx_errors")
	m.data.SetDescription("Received errors.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageRxErrors) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("interface", pcommon.NewValueString(interfaceAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageRxErrors) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageRxErrors) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageRxErrors(settings MetricSettings) metricContainerNetworkIoUsageRxErrors {
	m := metricContainerNetworkIoUsageRxErrors{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageRxPackets struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.rx_packets metric with initial data.
func (m *metricContainerNetworkIoUsageRxPackets) init() {
	m.data.SetName("container.network.io.usage.rx_packets")
	m.data.SetDescription("Packets received.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageRxPackets) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("interface", pcommon.NewValueString(interfaceAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageRxPackets) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageRxPackets) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageRxPackets(settings MetricSettings) metricContainerNetworkIoUsageRxPackets {
	m := metricContainerNetworkIoUsageRxPackets{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageTxBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.tx_bytes metric with initial data.
func (m *metricContainerNetworkIoUsageTxBytes) init() {
	m.data.SetName("container.network.io.usage.tx_bytes")
	m.data.SetDescription("Bytes sent.")
	m.data.SetUnit("By")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageTxBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("interface", pcommon.NewValueString(interfaceAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageTxBytes) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageTxBytes) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageTxBytes(settings MetricSettings) metricContainerNetworkIoUsageTxBytes {
	m := metricContainerNetworkIoUsageTxBytes{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageTxDropped struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.tx_dropped metric with initial data.
func (m *metricContainerNetworkIoUsageTxDropped) init() {
	m.data.SetName("container.network.io.usage.tx_dropped")
	m.data.SetDescription("Outgoing packets dropped.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageTxDropped) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("interface", pcommon.NewValueString(interfaceAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageTxDropped) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageTxDropped) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageTxDropped(settings MetricSettings) metricContainerNetworkIoUsageTxDropped {
	m := metricContainerNetworkIoUsageTxDropped{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageTxErrors struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.tx_errors metric with initial data.
func (m *metricContainerNetworkIoUsageTxErrors) init() {
	m.data.SetName("container.network.io.usage.tx_errors")
	m.data.SetDescription("Sent errors.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageTxErrors) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("interface", pcommon.NewValueString(interfaceAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageTxErrors) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageTxErrors) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageTxErrors(settings MetricSettings) metricContainerNetworkIoUsageTxErrors {
	m := metricContainerNetworkIoUsageTxErrors{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricContainerNetworkIoUsageTxPackets struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills container.network.io.usage.tx_packets metric with initial data.
func (m *metricContainerNetworkIoUsageTxPackets) init() {
	m.data.SetName("container.network.io.usage.tx_packets")
	m.data.SetDescription("Packets sent.")
	m.data.SetUnit("1")
	m.data.SetDataType(pmetric.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricContainerNetworkIoUsageTxPackets) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert("interface", pcommon.NewValueString(interfaceAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricContainerNetworkIoUsageTxPackets) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricContainerNetworkIoUsageTxPackets) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricContainerNetworkIoUsageTxPackets(settings MetricSettings) metricContainerNetworkIoUsageTxPackets {
	m := metricContainerNetworkIoUsageTxPackets{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user settings.
type MetricsBuilder struct {
	startTime                                            pcommon.Timestamp   // start time that will be applied to all recorded data points.
	metricsCapacity                                      int                 // maximum observed number of metrics per resource.
	resourceCapacity                                     int                 // maximum observed number of resource attributes.
	metricsBuffer                                        pmetric.Metrics     // accumulates metrics data before emitting.
	buildInfo                                            component.BuildInfo // contains version information
	metricContainerBlockioIoMergedRecursiveAsync         metricContainerBlockioIoMergedRecursiveAsync
	metricContainerBlockioIoMergedRecursiveDiscard       metricContainerBlockioIoMergedRecursiveDiscard
	metricContainerBlockioIoMergedRecursiveRead          metricContainerBlockioIoMergedRecursiveRead
	metricContainerBlockioIoMergedRecursiveSync          metricContainerBlockioIoMergedRecursiveSync
	metricContainerBlockioIoMergedRecursiveTotal         metricContainerBlockioIoMergedRecursiveTotal
	metricContainerBlockioIoMergedRecursiveWrite         metricContainerBlockioIoMergedRecursiveWrite
	metricContainerBlockioIoQueuedRecursiveAsync         metricContainerBlockioIoQueuedRecursiveAsync
	metricContainerBlockioIoQueuedRecursiveDiscard       metricContainerBlockioIoQueuedRecursiveDiscard
	metricContainerBlockioIoQueuedRecursiveRead          metricContainerBlockioIoQueuedRecursiveRead
	metricContainerBlockioIoQueuedRecursiveSync          metricContainerBlockioIoQueuedRecursiveSync
	metricContainerBlockioIoQueuedRecursiveTotal         metricContainerBlockioIoQueuedRecursiveTotal
	metricContainerBlockioIoQueuedRecursiveWrite         metricContainerBlockioIoQueuedRecursiveWrite
	metricContainerBlockioIoServiceBytesRecursiveAsync   metricContainerBlockioIoServiceBytesRecursiveAsync
	metricContainerBlockioIoServiceBytesRecursiveDiscard metricContainerBlockioIoServiceBytesRecursiveDiscard
	metricContainerBlockioIoServiceBytesRecursiveRead    metricContainerBlockioIoServiceBytesRecursiveRead
	metricContainerBlockioIoServiceBytesRecursiveSync    metricContainerBlockioIoServiceBytesRecursiveSync
	metricContainerBlockioIoServiceBytesRecursiveTotal   metricContainerBlockioIoServiceBytesRecursiveTotal
	metricContainerBlockioIoServiceBytesRecursiveWrite   metricContainerBlockioIoServiceBytesRecursiveWrite
	metricContainerBlockioIoServiceTimeRecursiveAsync    metricContainerBlockioIoServiceTimeRecursiveAsync
	metricContainerBlockioIoServiceTimeRecursiveDiscard  metricContainerBlockioIoServiceTimeRecursiveDiscard
	metricContainerBlockioIoServiceTimeRecursiveRead     metricContainerBlockioIoServiceTimeRecursiveRead
	metricContainerBlockioIoServiceTimeRecursiveSync     metricContainerBlockioIoServiceTimeRecursiveSync
	metricContainerBlockioIoServiceTimeRecursiveTotal    metricContainerBlockioIoServiceTimeRecursiveTotal
	metricContainerBlockioIoServiceTimeRecursiveWrite    metricContainerBlockioIoServiceTimeRecursiveWrite
	metricContainerBlockioIoServicedRecursiveAsync       metricContainerBlockioIoServicedRecursiveAsync
	metricContainerBlockioIoServicedRecursiveDiscard     metricContainerBlockioIoServicedRecursiveDiscard
	metricContainerBlockioIoServicedRecursiveRead        metricContainerBlockioIoServicedRecursiveRead
	metricContainerBlockioIoServicedRecursiveSync        metricContainerBlockioIoServicedRecursiveSync
	metricContainerBlockioIoServicedRecursiveTotal       metricContainerBlockioIoServicedRecursiveTotal
	metricContainerBlockioIoServicedRecursiveWrite       metricContainerBlockioIoServicedRecursiveWrite
	metricContainerBlockioIoTimeRecursiveAsync           metricContainerBlockioIoTimeRecursiveAsync
	metricContainerBlockioIoTimeRecursiveDiscard         metricContainerBlockioIoTimeRecursiveDiscard
	metricContainerBlockioIoTimeRecursiveRead            metricContainerBlockioIoTimeRecursiveRead
	metricContainerBlockioIoTimeRecursiveSync            metricContainerBlockioIoTimeRecursiveSync
	metricContainerBlockioIoTimeRecursiveTotal           metricContainerBlockioIoTimeRecursiveTotal
	metricContainerBlockioIoTimeRecursiveWrite           metricContainerBlockioIoTimeRecursiveWrite
	metricContainerBlockioIoWaitTimeRecursiveAsync       metricContainerBlockioIoWaitTimeRecursiveAsync
	metricContainerBlockioIoWaitTimeRecursiveDiscard     metricContainerBlockioIoWaitTimeRecursiveDiscard
	metricContainerBlockioIoWaitTimeRecursiveRead        metricContainerBlockioIoWaitTimeRecursiveRead
	metricContainerBlockioIoWaitTimeRecursiveSync        metricContainerBlockioIoWaitTimeRecursiveSync
	metricContainerBlockioIoWaitTimeRecursiveTotal       metricContainerBlockioIoWaitTimeRecursiveTotal
	metricContainerBlockioIoWaitTimeRecursiveWrite       metricContainerBlockioIoWaitTimeRecursiveWrite
	metricContainerBlockioSectorsRecursiveAsync          metricContainerBlockioSectorsRecursiveAsync
	metricContainerBlockioSectorsRecursiveDiscard        metricContainerBlockioSectorsRecursiveDiscard
	metricContainerBlockioSectorsRecursiveRead           metricContainerBlockioSectorsRecursiveRead
	metricContainerBlockioSectorsRecursiveSync           metricContainerBlockioSectorsRecursiveSync
	metricContainerBlockioSectorsRecursiveTotal          metricContainerBlockioSectorsRecursiveTotal
	metricContainerBlockioSectorsRecursiveWrite          metricContainerBlockioSectorsRecursiveWrite
	metricContainerCPUPercent                            metricContainerCPUPercent
	metricContainerCPUThrottlingDataPeriods              metricContainerCPUThrottlingDataPeriods
	metricContainerCPUThrottlingDataThrottledPeriods     metricContainerCPUThrottlingDataThrottledPeriods
	metricContainerCPUThrottlingDataThrottledTime        metricContainerCPUThrottlingDataThrottledTime
	metricContainerCPUUsageKernelmode                    metricContainerCPUUsageKernelmode
	metricContainerCPUUsagePercpu                        metricContainerCPUUsagePercpu
	metricContainerCPUUsageSystem                        metricContainerCPUUsageSystem
	metricContainerCPUUsageTotal                         metricContainerCPUUsageTotal
	metricContainerCPUUsageUsermode                      metricContainerCPUUsageUsermode
	metricContainerMemoryActiveAnon                      metricContainerMemoryActiveAnon
	metricContainerMemoryActiveFile                      metricContainerMemoryActiveFile
	metricContainerMemoryCache                           metricContainerMemoryCache
	metricContainerMemoryDirty                           metricContainerMemoryDirty
	metricContainerMemoryHierarchicalMemoryLimit         metricContainerMemoryHierarchicalMemoryLimit
	metricContainerMemoryHierarchicalMemswLimit          metricContainerMemoryHierarchicalMemswLimit
	metricContainerMemoryInactiveAnon                    metricContainerMemoryInactiveAnon
	metricContainerMemoryInactiveFile                    metricContainerMemoryInactiveFile
	metricContainerMemoryMappedFile                      metricContainerMemoryMappedFile
	metricContainerMemoryPercent                         metricContainerMemoryPercent
	metricContainerMemoryPgfault                         metricContainerMemoryPgfault
	metricContainerMemoryPgmajfault                      metricContainerMemoryPgmajfault
	metricContainerMemoryPgpgin                          metricContainerMemoryPgpgin
	metricContainerMemoryPgpgout                         metricContainerMemoryPgpgout
	metricContainerMemoryRss                             metricContainerMemoryRss
	metricContainerMemoryRssHuge                         metricContainerMemoryRssHuge
	metricContainerMemorySwap                            metricContainerMemorySwap
	metricContainerMemoryTotalActiveAnon                 metricContainerMemoryTotalActiveAnon
	metricContainerMemoryTotalActiveFile                 metricContainerMemoryTotalActiveFile
	metricContainerMemoryTotalCache                      metricContainerMemoryTotalCache
	metricContainerMemoryTotalDirty                      metricContainerMemoryTotalDirty
	metricContainerMemoryTotalInactiveAnon               metricContainerMemoryTotalInactiveAnon
	metricContainerMemoryTotalInactiveFile               metricContainerMemoryTotalInactiveFile
	metricContainerMemoryTotalMappedFile                 metricContainerMemoryTotalMappedFile
	metricContainerMemoryTotalPgfault                    metricContainerMemoryTotalPgfault
	metricContainerMemoryTotalPgmajfault                 metricContainerMemoryTotalPgmajfault
	metricContainerMemoryTotalPgpgin                     metricContainerMemoryTotalPgpgin
	metricContainerMemoryTotalPgpgout                    metricContainerMemoryTotalPgpgout
	metricContainerMemoryTotalRss                        metricContainerMemoryTotalRss
	metricContainerMemoryTotalRssHuge                    metricContainerMemoryTotalRssHuge
	metricContainerMemoryTotalSwap                       metricContainerMemoryTotalSwap
	metricContainerMemoryTotalUnevictable                metricContainerMemoryTotalUnevictable
	metricContainerMemoryTotalWriteback                  metricContainerMemoryTotalWriteback
	metricContainerMemoryUnevictable                     metricContainerMemoryUnevictable
	metricContainerMemoryUsageLimit                      metricContainerMemoryUsageLimit
	metricContainerMemoryUsageMax                        metricContainerMemoryUsageMax
	metricContainerMemoryUsageTotal                      metricContainerMemoryUsageTotal
	metricContainerMemoryWriteback                       metricContainerMemoryWriteback
	metricContainerNetworkIoUsageRxBytes                 metricContainerNetworkIoUsageRxBytes
	metricContainerNetworkIoUsageRxDropped               metricContainerNetworkIoUsageRxDropped
	metricContainerNetworkIoUsageRxErrors                metricContainerNetworkIoUsageRxErrors
	metricContainerNetworkIoUsageRxPackets               metricContainerNetworkIoUsageRxPackets
	metricContainerNetworkIoUsageTxBytes                 metricContainerNetworkIoUsageTxBytes
	metricContainerNetworkIoUsageTxDropped               metricContainerNetworkIoUsageTxDropped
	metricContainerNetworkIoUsageTxErrors                metricContainerNetworkIoUsageTxErrors
	metricContainerNetworkIoUsageTxPackets               metricContainerNetworkIoUsageTxPackets
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(settings MetricsSettings, buildInfo component.BuildInfo, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		startTime:     pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer: pmetric.NewMetrics(),
		buildInfo:     buildInfo,
		metricContainerBlockioIoMergedRecursiveAsync:         newMetricContainerBlockioIoMergedRecursiveAsync(settings.ContainerBlockioIoMergedRecursiveAsync),
		metricContainerBlockioIoMergedRecursiveDiscard:       newMetricContainerBlockioIoMergedRecursiveDiscard(settings.ContainerBlockioIoMergedRecursiveDiscard),
		metricContainerBlockioIoMergedRecursiveRead:          newMetricContainerBlockioIoMergedRecursiveRead(settings.ContainerBlockioIoMergedRecursiveRead),
		metricContainerBlockioIoMergedRecursiveSync:          newMetricContainerBlockioIoMergedRecursiveSync(settings.ContainerBlockioIoMergedRecursiveSync),
		metricContainerBlockioIoMergedRecursiveTotal:         newMetricContainerBlockioIoMergedRecursiveTotal(settings.ContainerBlockioIoMergedRecursiveTotal),
		metricContainerBlockioIoMergedRecursiveWrite:         newMetricContainerBlockioIoMergedRecursiveWrite(settings.ContainerBlockioIoMergedRecursiveWrite),
		metricContainerBlockioIoQueuedRecursiveAsync:         newMetricContainerBlockioIoQueuedRecursiveAsync(settings.ContainerBlockioIoQueuedRecursiveAsync),
		metricContainerBlockioIoQueuedRecursiveDiscard:       newMetricContainerBlockioIoQueuedRecursiveDiscard(settings.ContainerBlockioIoQueuedRecursiveDiscard),
		metricContainerBlockioIoQueuedRecursiveRead:          newMetricContainerBlockioIoQueuedRecursiveRead(settings.ContainerBlockioIoQueuedRecursiveRead),
		metricContainerBlockioIoQueuedRecursiveSync:          newMetricContainerBlockioIoQueuedRecursiveSync(settings.ContainerBlockioIoQueuedRecursiveSync),
		metricContainerBlockioIoQueuedRecursiveTotal:         newMetricContainerBlockioIoQueuedRecursiveTotal(settings.ContainerBlockioIoQueuedRecursiveTotal),
		metricContainerBlockioIoQueuedRecursiveWrite:         newMetricContainerBlockioIoQueuedRecursiveWrite(settings.ContainerBlockioIoQueuedRecursiveWrite),
		metricContainerBlockioIoServiceBytesRecursiveAsync:   newMetricContainerBlockioIoServiceBytesRecursiveAsync(settings.ContainerBlockioIoServiceBytesRecursiveAsync),
		metricContainerBlockioIoServiceBytesRecursiveDiscard: newMetricContainerBlockioIoServiceBytesRecursiveDiscard(settings.ContainerBlockioIoServiceBytesRecursiveDiscard),
		metricContainerBlockioIoServiceBytesRecursiveRead:    newMetricContainerBlockioIoServiceBytesRecursiveRead(settings.ContainerBlockioIoServiceBytesRecursiveRead),
		metricContainerBlockioIoServiceBytesRecursiveSync:    newMetricContainerBlockioIoServiceBytesRecursiveSync(settings.ContainerBlockioIoServiceBytesRecursiveSync),
		metricContainerBlockioIoServiceBytesRecursiveTotal:   newMetricContainerBlockioIoServiceBytesRecursiveTotal(settings.ContainerBlockioIoServiceBytesRecursiveTotal),
		metricContainerBlockioIoServiceBytesRecursiveWrite:   newMetricContainerBlockioIoServiceBytesRecursiveWrite(settings.ContainerBlockioIoServiceBytesRecursiveWrite),
		metricContainerBlockioIoServiceTimeRecursiveAsync:    newMetricContainerBlockioIoServiceTimeRecursiveAsync(settings.ContainerBlockioIoServiceTimeRecursiveAsync),
		metricContainerBlockioIoServiceTimeRecursiveDiscard:  newMetricContainerBlockioIoServiceTimeRecursiveDiscard(settings.ContainerBlockioIoServiceTimeRecursiveDiscard),
		metricContainerBlockioIoServiceTimeRecursiveRead:     newMetricContainerBlockioIoServiceTimeRecursiveRead(settings.ContainerBlockioIoServiceTimeRecursiveRead),
		metricContainerBlockioIoServiceTimeRecursiveSync:     newMetricContainerBlockioIoServiceTimeRecursiveSync(settings.ContainerBlockioIoServiceTimeRecursiveSync),
		metricContainerBlockioIoServiceTimeRecursiveTotal:    newMetricContainerBlockioIoServiceTimeRecursiveTotal(settings.ContainerBlockioIoServiceTimeRecursiveTotal),
		metricContainerBlockioIoServiceTimeRecursiveWrite:    newMetricContainerBlockioIoServiceTimeRecursiveWrite(settings.ContainerBlockioIoServiceTimeRecursiveWrite),
		metricContainerBlockioIoServicedRecursiveAsync:       newMetricContainerBlockioIoServicedRecursiveAsync(settings.ContainerBlockioIoServicedRecursiveAsync),
		metricContainerBlockioIoServicedRecursiveDiscard:     newMetricContainerBlockioIoServicedRecursiveDiscard(settings.ContainerBlockioIoServicedRecursiveDiscard),
		metricContainerBlockioIoServicedRecursiveRead:        newMetricContainerBlockioIoServicedRecursiveRead(settings.ContainerBlockioIoServicedRecursiveRead),
		metricContainerBlockioIoServicedRecursiveSync:        newMetricContainerBlockioIoServicedRecursiveSync(settings.ContainerBlockioIoServicedRecursiveSync),
		metricContainerBlockioIoServicedRecursiveTotal:       newMetricContainerBlockioIoServicedRecursiveTotal(settings.ContainerBlockioIoServicedRecursiveTotal),
		metricContainerBlockioIoServicedRecursiveWrite:       newMetricContainerBlockioIoServicedRecursiveWrite(settings.ContainerBlockioIoServicedRecursiveWrite),
		metricContainerBlockioIoTimeRecursiveAsync:           newMetricContainerBlockioIoTimeRecursiveAsync(settings.ContainerBlockioIoTimeRecursiveAsync),
		metricContainerBlockioIoTimeRecursiveDiscard:         newMetricContainerBlockioIoTimeRecursiveDiscard(settings.ContainerBlockioIoTimeRecursiveDiscard),
		metricContainerBlockioIoTimeRecursiveRead:            newMetricContainerBlockioIoTimeRecursiveRead(settings.ContainerBlockioIoTimeRecursiveRead),
		metricContainerBlockioIoTimeRecursiveSync:            newMetricContainerBlockioIoTimeRecursiveSync(settings.ContainerBlockioIoTimeRecursiveSync),
		metricContainerBlockioIoTimeRecursiveTotal:           newMetricContainerBlockioIoTimeRecursiveTotal(settings.ContainerBlockioIoTimeRecursiveTotal),
		metricContainerBlockioIoTimeRecursiveWrite:           newMetricContainerBlockioIoTimeRecursiveWrite(settings.ContainerBlockioIoTimeRecursiveWrite),
		metricContainerBlockioIoWaitTimeRecursiveAsync:       newMetricContainerBlockioIoWaitTimeRecursiveAsync(settings.ContainerBlockioIoWaitTimeRecursiveAsync),
		metricContainerBlockioIoWaitTimeRecursiveDiscard:     newMetricContainerBlockioIoWaitTimeRecursiveDiscard(settings.ContainerBlockioIoWaitTimeRecursiveDiscard),
		metricContainerBlockioIoWaitTimeRecursiveRead:        newMetricContainerBlockioIoWaitTimeRecursiveRead(settings.ContainerBlockioIoWaitTimeRecursiveRead),
		metricContainerBlockioIoWaitTimeRecursiveSync:        newMetricContainerBlockioIoWaitTimeRecursiveSync(settings.ContainerBlockioIoWaitTimeRecursiveSync),
		metricContainerBlockioIoWaitTimeRecursiveTotal:       newMetricContainerBlockioIoWaitTimeRecursiveTotal(settings.ContainerBlockioIoWaitTimeRecursiveTotal),
		metricContainerBlockioIoWaitTimeRecursiveWrite:       newMetricContainerBlockioIoWaitTimeRecursiveWrite(settings.ContainerBlockioIoWaitTimeRecursiveWrite),
		metricContainerBlockioSectorsRecursiveAsync:          newMetricContainerBlockioSectorsRecursiveAsync(settings.ContainerBlockioSectorsRecursiveAsync),
		metricContainerBlockioSectorsRecursiveDiscard:        newMetricContainerBlockioSectorsRecursiveDiscard(settings.ContainerBlockioSectorsRecursiveDiscard),
		metricContainerBlockioSectorsRecursiveRead:           newMetricContainerBlockioSectorsRecursiveRead(settings.ContainerBlockioSectorsRecursiveRead),
		metricContainerBlockioSectorsRecursiveSync:           newMetricContainerBlockioSectorsRecursiveSync(settings.ContainerBlockioSectorsRecursiveSync),
		metricContainerBlockioSectorsRecursiveTotal:          newMetricContainerBlockioSectorsRecursiveTotal(settings.ContainerBlockioSectorsRecursiveTotal),
		metricContainerBlockioSectorsRecursiveWrite:          newMetricContainerBlockioSectorsRecursiveWrite(settings.ContainerBlockioSectorsRecursiveWrite),
		metricContainerCPUPercent:                            newMetricContainerCPUPercent(settings.ContainerCPUPercent),
		metricContainerCPUThrottlingDataPeriods:              newMetricContainerCPUThrottlingDataPeriods(settings.ContainerCPUThrottlingDataPeriods),
		metricContainerCPUThrottlingDataThrottledPeriods:     newMetricContainerCPUThrottlingDataThrottledPeriods(settings.ContainerCPUThrottlingDataThrottledPeriods),
		metricContainerCPUThrottlingDataThrottledTime:        newMetricContainerCPUThrottlingDataThrottledTime(settings.ContainerCPUThrottlingDataThrottledTime),
		metricContainerCPUUsageKernelmode:                    newMetricContainerCPUUsageKernelmode(settings.ContainerCPUUsageKernelmode),
		metricContainerCPUUsagePercpu:                        newMetricContainerCPUUsagePercpu(settings.ContainerCPUUsagePercpu),
		metricContainerCPUUsageSystem:                        newMetricContainerCPUUsageSystem(settings.ContainerCPUUsageSystem),
		metricContainerCPUUsageTotal:                         newMetricContainerCPUUsageTotal(settings.ContainerCPUUsageTotal),
		metricContainerCPUUsageUsermode:                      newMetricContainerCPUUsageUsermode(settings.ContainerCPUUsageUsermode),
		metricContainerMemoryActiveAnon:                      newMetricContainerMemoryActiveAnon(settings.ContainerMemoryActiveAnon),
		metricContainerMemoryActiveFile:                      newMetricContainerMemoryActiveFile(settings.ContainerMemoryActiveFile),
		metricContainerMemoryCache:                           newMetricContainerMemoryCache(settings.ContainerMemoryCache),
		metricContainerMemoryDirty:                           newMetricContainerMemoryDirty(settings.ContainerMemoryDirty),
		metricContainerMemoryHierarchicalMemoryLimit:         newMetricContainerMemoryHierarchicalMemoryLimit(settings.ContainerMemoryHierarchicalMemoryLimit),
		metricContainerMemoryHierarchicalMemswLimit:          newMetricContainerMemoryHierarchicalMemswLimit(settings.ContainerMemoryHierarchicalMemswLimit),
		metricContainerMemoryInactiveAnon:                    newMetricContainerMemoryInactiveAnon(settings.ContainerMemoryInactiveAnon),
		metricContainerMemoryInactiveFile:                    newMetricContainerMemoryInactiveFile(settings.ContainerMemoryInactiveFile),
		metricContainerMemoryMappedFile:                      newMetricContainerMemoryMappedFile(settings.ContainerMemoryMappedFile),
		metricContainerMemoryPercent:                         newMetricContainerMemoryPercent(settings.ContainerMemoryPercent),
		metricContainerMemoryPgfault:                         newMetricContainerMemoryPgfault(settings.ContainerMemoryPgfault),
		metricContainerMemoryPgmajfault:                      newMetricContainerMemoryPgmajfault(settings.ContainerMemoryPgmajfault),
		metricContainerMemoryPgpgin:                          newMetricContainerMemoryPgpgin(settings.ContainerMemoryPgpgin),
		metricContainerMemoryPgpgout:                         newMetricContainerMemoryPgpgout(settings.ContainerMemoryPgpgout),
		metricContainerMemoryRss:                             newMetricContainerMemoryRss(settings.ContainerMemoryRss),
		metricContainerMemoryRssHuge:                         newMetricContainerMemoryRssHuge(settings.ContainerMemoryRssHuge),
		metricContainerMemorySwap:                            newMetricContainerMemorySwap(settings.ContainerMemorySwap),
		metricContainerMemoryTotalActiveAnon:                 newMetricContainerMemoryTotalActiveAnon(settings.ContainerMemoryTotalActiveAnon),
		metricContainerMemoryTotalActiveFile:                 newMetricContainerMemoryTotalActiveFile(settings.ContainerMemoryTotalActiveFile),
		metricContainerMemoryTotalCache:                      newMetricContainerMemoryTotalCache(settings.ContainerMemoryTotalCache),
		metricContainerMemoryTotalDirty:                      newMetricContainerMemoryTotalDirty(settings.ContainerMemoryTotalDirty),
		metricContainerMemoryTotalInactiveAnon:               newMetricContainerMemoryTotalInactiveAnon(settings.ContainerMemoryTotalInactiveAnon),
		metricContainerMemoryTotalInactiveFile:               newMetricContainerMemoryTotalInactiveFile(settings.ContainerMemoryTotalInactiveFile),
		metricContainerMemoryTotalMappedFile:                 newMetricContainerMemoryTotalMappedFile(settings.ContainerMemoryTotalMappedFile),
		metricContainerMemoryTotalPgfault:                    newMetricContainerMemoryTotalPgfault(settings.ContainerMemoryTotalPgfault),
		metricContainerMemoryTotalPgmajfault:                 newMetricContainerMemoryTotalPgmajfault(settings.ContainerMemoryTotalPgmajfault),
		metricContainerMemoryTotalPgpgin:                     newMetricContainerMemoryTotalPgpgin(settings.ContainerMemoryTotalPgpgin),
		metricContainerMemoryTotalPgpgout:                    newMetricContainerMemoryTotalPgpgout(settings.ContainerMemoryTotalPgpgout),
		metricContainerMemoryTotalRss:                        newMetricContainerMemoryTotalRss(settings.ContainerMemoryTotalRss),
		metricContainerMemoryTotalRssHuge:                    newMetricContainerMemoryTotalRssHuge(settings.ContainerMemoryTotalRssHuge),
		metricContainerMemoryTotalSwap:                       newMetricContainerMemoryTotalSwap(settings.ContainerMemoryTotalSwap),
		metricContainerMemoryTotalUnevictable:                newMetricContainerMemoryTotalUnevictable(settings.ContainerMemoryTotalUnevictable),
		metricContainerMemoryTotalWriteback:                  newMetricContainerMemoryTotalWriteback(settings.ContainerMemoryTotalWriteback),
		metricContainerMemoryUnevictable:                     newMetricContainerMemoryUnevictable(settings.ContainerMemoryUnevictable),
		metricContainerMemoryUsageLimit:                      newMetricContainerMemoryUsageLimit(settings.ContainerMemoryUsageLimit),
		metricContainerMemoryUsageMax:                        newMetricContainerMemoryUsageMax(settings.ContainerMemoryUsageMax),
		metricContainerMemoryUsageTotal:                      newMetricContainerMemoryUsageTotal(settings.ContainerMemoryUsageTotal),
		metricContainerMemoryWriteback:                       newMetricContainerMemoryWriteback(settings.ContainerMemoryWriteback),
		metricContainerNetworkIoUsageRxBytes:                 newMetricContainerNetworkIoUsageRxBytes(settings.ContainerNetworkIoUsageRxBytes),
		metricContainerNetworkIoUsageRxDropped:               newMetricContainerNetworkIoUsageRxDropped(settings.ContainerNetworkIoUsageRxDropped),
		metricContainerNetworkIoUsageRxErrors:                newMetricContainerNetworkIoUsageRxErrors(settings.ContainerNetworkIoUsageRxErrors),
		metricContainerNetworkIoUsageRxPackets:               newMetricContainerNetworkIoUsageRxPackets(settings.ContainerNetworkIoUsageRxPackets),
		metricContainerNetworkIoUsageTxBytes:                 newMetricContainerNetworkIoUsageTxBytes(settings.ContainerNetworkIoUsageTxBytes),
		metricContainerNetworkIoUsageTxDropped:               newMetricContainerNetworkIoUsageTxDropped(settings.ContainerNetworkIoUsageTxDropped),
		metricContainerNetworkIoUsageTxErrors:                newMetricContainerNetworkIoUsageTxErrors(settings.ContainerNetworkIoUsageTxErrors),
		metricContainerNetworkIoUsageTxPackets:               newMetricContainerNetworkIoUsageTxPackets(settings.ContainerNetworkIoUsageTxPackets),
	}
	for _, op := range options {
		op(mb)
	}
	return mb
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
	if mb.resourceCapacity < rm.Resource().Attributes().Len() {
		mb.resourceCapacity = rm.Resource().Attributes().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption func(pmetric.ResourceMetrics)

// WithContainerHostname sets provided value as "container.hostname" attribute for current resource.
func WithContainerHostname(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().UpsertString("container.hostname", val)
	}
}

// WithContainerID sets provided value as "container.id" attribute for current resource.
func WithContainerID(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().UpsertString("container.id", val)
	}
}

// WithContainerImageName sets provided value as "container.image.name" attribute for current resource.
func WithContainerImageName(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().UpsertString("container.image.name", val)
	}
}

// WithContainerName sets provided value as "container.name" attribute for current resource.
func WithContainerName(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().UpsertString("container.name", val)
	}
}

// WithContainerRuntime sets provided value as "container.runtime" attribute for current resource.
func WithContainerRuntime(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().UpsertString("container.runtime", val)
	}
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).DataType() {
			case pmetric.MetricDataTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricDataTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	}
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(rmo ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	rm.SetSchemaUrl(conventions.SchemaURL)
	rm.Resource().Attributes().EnsureCapacity(mb.resourceCapacity)
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName("otelcol/dockerstatsreceiver")
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricContainerBlockioIoMergedRecursiveAsync.emit(ils.Metrics())
	mb.metricContainerBlockioIoMergedRecursiveDiscard.emit(ils.Metrics())
	mb.metricContainerBlockioIoMergedRecursiveRead.emit(ils.Metrics())
	mb.metricContainerBlockioIoMergedRecursiveSync.emit(ils.Metrics())
	mb.metricContainerBlockioIoMergedRecursiveTotal.emit(ils.Metrics())
	mb.metricContainerBlockioIoMergedRecursiveWrite.emit(ils.Metrics())
	mb.metricContainerBlockioIoQueuedRecursiveAsync.emit(ils.Metrics())
	mb.metricContainerBlockioIoQueuedRecursiveDiscard.emit(ils.Metrics())
	mb.metricContainerBlockioIoQueuedRecursiveRead.emit(ils.Metrics())
	mb.metricContainerBlockioIoQueuedRecursiveSync.emit(ils.Metrics())
	mb.metricContainerBlockioIoQueuedRecursiveTotal.emit(ils.Metrics())
	mb.metricContainerBlockioIoQueuedRecursiveWrite.emit(ils.Metrics())
	mb.metricContainerBlockioIoServiceBytesRecursiveAsync.emit(ils.Metrics())
	mb.metricContainerBlockioIoServiceBytesRecursiveDiscard.emit(ils.Metrics())
	mb.metricContainerBlockioIoServiceBytesRecursiveRead.emit(ils.Metrics())
	mb.metricContainerBlockioIoServiceBytesRecursiveSync.emit(ils.Metrics())
	mb.metricContainerBlockioIoServiceBytesRecursiveTotal.emit(ils.Metrics())
	mb.metricContainerBlockioIoServiceBytesRecursiveWrite.emit(ils.Metrics())
	mb.metricContainerBlockioIoServiceTimeRecursiveAsync.emit(ils.Metrics())
	mb.metricContainerBlockioIoServiceTimeRecursiveDiscard.emit(ils.Metrics())
	mb.metricContainerBlockioIoServiceTimeRecursiveRead.emit(ils.Metrics())
	mb.metricContainerBlockioIoServiceTimeRecursiveSync.emit(ils.Metrics())
	mb.metricContainerBlockioIoServiceTimeRecursiveTotal.emit(ils.Metrics())
	mb.metricContainerBlockioIoServiceTimeRecursiveWrite.emit(ils.Metrics())
	mb.metricContainerBlockioIoServicedRecursiveAsync.emit(ils.Metrics())
	mb.metricContainerBlockioIoServicedRecursiveDiscard.emit(ils.Metrics())
	mb.metricContainerBlockioIoServicedRecursiveRead.emit(ils.Metrics())
	mb.metricContainerBlockioIoServicedRecursiveSync.emit(ils.Metrics())
	mb.metricContainerBlockioIoServicedRecursiveTotal.emit(ils.Metrics())
	mb.metricContainerBlockioIoServicedRecursiveWrite.emit(ils.Metrics())
	mb.metricContainerBlockioIoTimeRecursiveAsync.emit(ils.Metrics())
	mb.metricContainerBlockioIoTimeRecursiveDiscard.emit(ils.Metrics())
	mb.metricContainerBlockioIoTimeRecursiveRead.emit(ils.Metrics())
	mb.metricContainerBlockioIoTimeRecursiveSync.emit(ils.Metrics())
	mb.metricContainerBlockioIoTimeRecursiveTotal.emit(ils.Metrics())
	mb.metricContainerBlockioIoTimeRecursiveWrite.emit(ils.Metrics())
	mb.metricContainerBlockioIoWaitTimeRecursiveAsync.emit(ils.Metrics())
	mb.metricContainerBlockioIoWaitTimeRecursiveDiscard.emit(ils.Metrics())
	mb.metricContainerBlockioIoWaitTimeRecursiveRead.emit(ils.Metrics())
	mb.metricContainerBlockioIoWaitTimeRecursiveSync.emit(ils.Metrics())
	mb.metricContainerBlockioIoWaitTimeRecursiveTotal.emit(ils.Metrics())
	mb.metricContainerBlockioIoWaitTimeRecursiveWrite.emit(ils.Metrics())
	mb.metricContainerBlockioSectorsRecursiveAsync.emit(ils.Metrics())
	mb.metricContainerBlockioSectorsRecursiveDiscard.emit(ils.Metrics())
	mb.metricContainerBlockioSectorsRecursiveRead.emit(ils.Metrics())
	mb.metricContainerBlockioSectorsRecursiveSync.emit(ils.Metrics())
	mb.metricContainerBlockioSectorsRecursiveTotal.emit(ils.Metrics())
	mb.metricContainerBlockioSectorsRecursiveWrite.emit(ils.Metrics())
	mb.metricContainerCPUPercent.emit(ils.Metrics())
	mb.metricContainerCPUThrottlingDataPeriods.emit(ils.Metrics())
	mb.metricContainerCPUThrottlingDataThrottledPeriods.emit(ils.Metrics())
	mb.metricContainerCPUThrottlingDataThrottledTime.emit(ils.Metrics())
	mb.metricContainerCPUUsageKernelmode.emit(ils.Metrics())
	mb.metricContainerCPUUsagePercpu.emit(ils.Metrics())
	mb.metricContainerCPUUsageSystem.emit(ils.Metrics())
	mb.metricContainerCPUUsageTotal.emit(ils.Metrics())
	mb.metricContainerCPUUsageUsermode.emit(ils.Metrics())
	mb.metricContainerMemoryActiveAnon.emit(ils.Metrics())
	mb.metricContainerMemoryActiveFile.emit(ils.Metrics())
	mb.metricContainerMemoryCache.emit(ils.Metrics())
	mb.metricContainerMemoryDirty.emit(ils.Metrics())
	mb.metricContainerMemoryHierarchicalMemoryLimit.emit(ils.Metrics())
	mb.metricContainerMemoryHierarchicalMemswLimit.emit(ils.Metrics())
	mb.metricContainerMemoryInactiveAnon.emit(ils.Metrics())
	mb.metricContainerMemoryInactiveFile.emit(ils.Metrics())
	mb.metricContainerMemoryMappedFile.emit(ils.Metrics())
	mb.metricContainerMemoryPercent.emit(ils.Metrics())
	mb.metricContainerMemoryPgfault.emit(ils.Metrics())
	mb.metricContainerMemoryPgmajfault.emit(ils.Metrics())
	mb.metricContainerMemoryPgpgin.emit(ils.Metrics())
	mb.metricContainerMemoryPgpgout.emit(ils.Metrics())
	mb.metricContainerMemoryRss.emit(ils.Metrics())
	mb.metricContainerMemoryRssHuge.emit(ils.Metrics())
	mb.metricContainerMemorySwap.emit(ils.Metrics())
	mb.metricContainerMemoryTotalActiveAnon.emit(ils.Metrics())
	mb.metricContainerMemoryTotalActiveFile.emit(ils.Metrics())
	mb.metricContainerMemoryTotalCache.emit(ils.Metrics())
	mb.metricContainerMemoryTotalDirty.emit(ils.Metrics())
	mb.metricContainerMemoryTotalInactiveAnon.emit(ils.Metrics())
	mb.metricContainerMemoryTotalInactiveFile.emit(ils.Metrics())
	mb.metricContainerMemoryTotalMappedFile.emit(ils.Metrics())
	mb.metricContainerMemoryTotalPgfault.emit(ils.Metrics())
	mb.metricContainerMemoryTotalPgmajfault.emit(ils.Metrics())
	mb.metricContainerMemoryTotalPgpgin.emit(ils.Metrics())
	mb.metricContainerMemoryTotalPgpgout.emit(ils.Metrics())
	mb.metricContainerMemoryTotalRss.emit(ils.Metrics())
	mb.metricContainerMemoryTotalRssHuge.emit(ils.Metrics())
	mb.metricContainerMemoryTotalSwap.emit(ils.Metrics())
	mb.metricContainerMemoryTotalUnevictable.emit(ils.Metrics())
	mb.metricContainerMemoryTotalWriteback.emit(ils.Metrics())
	mb.metricContainerMemoryUnevictable.emit(ils.Metrics())
	mb.metricContainerMemoryUsageLimit.emit(ils.Metrics())
	mb.metricContainerMemoryUsageMax.emit(ils.Metrics())
	mb.metricContainerMemoryUsageTotal.emit(ils.Metrics())
	mb.metricContainerMemoryWriteback.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageRxBytes.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageRxDropped.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageRxErrors.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageRxPackets.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageTxBytes.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageTxDropped.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageTxErrors.emit(ils.Metrics())
	mb.metricContainerNetworkIoUsageTxPackets.emit(ils.Metrics())
	for _, op := range rmo {
		op(rm)
	}
	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user settings, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(rmo ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(rmo...)
	metrics := pmetric.NewMetrics()
	mb.metricsBuffer.MoveTo(metrics)
	return metrics
}

// RecordContainerBlockioIoMergedRecursiveAsyncDataPoint adds a data point to container.blockio.io_merged_recursive.async metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoMergedRecursiveAsyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoMergedRecursiveAsync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoMergedRecursiveDiscardDataPoint adds a data point to container.blockio.io_merged_recursive.discard metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoMergedRecursiveDiscardDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoMergedRecursiveDiscard.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoMergedRecursiveReadDataPoint adds a data point to container.blockio.io_merged_recursive.read metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoMergedRecursiveReadDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoMergedRecursiveRead.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoMergedRecursiveSyncDataPoint adds a data point to container.blockio.io_merged_recursive.sync metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoMergedRecursiveSyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoMergedRecursiveSync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoMergedRecursiveTotalDataPoint adds a data point to container.blockio.io_merged_recursive.total metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoMergedRecursiveTotalDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoMergedRecursiveTotal.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoMergedRecursiveWriteDataPoint adds a data point to container.blockio.io_merged_recursive.write metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoMergedRecursiveWriteDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoMergedRecursiveWrite.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoQueuedRecursiveAsyncDataPoint adds a data point to container.blockio.io_queued_recursive.async metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoQueuedRecursiveAsyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoQueuedRecursiveAsync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoQueuedRecursiveDiscardDataPoint adds a data point to container.blockio.io_queued_recursive.discard metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoQueuedRecursiveDiscardDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoQueuedRecursiveDiscard.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoQueuedRecursiveReadDataPoint adds a data point to container.blockio.io_queued_recursive.read metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoQueuedRecursiveReadDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoQueuedRecursiveRead.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoQueuedRecursiveSyncDataPoint adds a data point to container.blockio.io_queued_recursive.sync metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoQueuedRecursiveSyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoQueuedRecursiveSync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoQueuedRecursiveTotalDataPoint adds a data point to container.blockio.io_queued_recursive.total metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoQueuedRecursiveTotalDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoQueuedRecursiveTotal.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoQueuedRecursiveWriteDataPoint adds a data point to container.blockio.io_queued_recursive.write metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoQueuedRecursiveWriteDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoQueuedRecursiveWrite.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServiceBytesRecursiveAsyncDataPoint adds a data point to container.blockio.io_service_bytes_recursive.async metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServiceBytesRecursiveAsyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServiceBytesRecursiveAsync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServiceBytesRecursiveDiscardDataPoint adds a data point to container.blockio.io_service_bytes_recursive.discard metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServiceBytesRecursiveDiscardDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServiceBytesRecursiveDiscard.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServiceBytesRecursiveReadDataPoint adds a data point to container.blockio.io_service_bytes_recursive.read metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServiceBytesRecursiveReadDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServiceBytesRecursiveRead.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServiceBytesRecursiveSyncDataPoint adds a data point to container.blockio.io_service_bytes_recursive.sync metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServiceBytesRecursiveSyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServiceBytesRecursiveSync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServiceBytesRecursiveTotalDataPoint adds a data point to container.blockio.io_service_bytes_recursive.total metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServiceBytesRecursiveTotalDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServiceBytesRecursiveTotal.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServiceBytesRecursiveWriteDataPoint adds a data point to container.blockio.io_service_bytes_recursive.write metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServiceBytesRecursiveWriteDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServiceBytesRecursiveWrite.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServiceTimeRecursiveAsyncDataPoint adds a data point to container.blockio.io_service_time_recursive.async metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServiceTimeRecursiveAsyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServiceTimeRecursiveAsync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServiceTimeRecursiveDiscardDataPoint adds a data point to container.blockio.io_service_time_recursive.discard metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServiceTimeRecursiveDiscardDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServiceTimeRecursiveDiscard.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServiceTimeRecursiveReadDataPoint adds a data point to container.blockio.io_service_time_recursive.read metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServiceTimeRecursiveReadDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServiceTimeRecursiveRead.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServiceTimeRecursiveSyncDataPoint adds a data point to container.blockio.io_service_time_recursive.sync metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServiceTimeRecursiveSyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServiceTimeRecursiveSync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServiceTimeRecursiveTotalDataPoint adds a data point to container.blockio.io_service_time_recursive.total metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServiceTimeRecursiveTotalDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServiceTimeRecursiveTotal.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServiceTimeRecursiveWriteDataPoint adds a data point to container.blockio.io_service_time_recursive.write metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServiceTimeRecursiveWriteDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServiceTimeRecursiveWrite.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServicedRecursiveAsyncDataPoint adds a data point to container.blockio.io_serviced_recursive.async metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServicedRecursiveAsyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServicedRecursiveAsync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServicedRecursiveDiscardDataPoint adds a data point to container.blockio.io_serviced_recursive.discard metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServicedRecursiveDiscardDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServicedRecursiveDiscard.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServicedRecursiveReadDataPoint adds a data point to container.blockio.io_serviced_recursive.read metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServicedRecursiveReadDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServicedRecursiveRead.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServicedRecursiveSyncDataPoint adds a data point to container.blockio.io_serviced_recursive.sync metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServicedRecursiveSyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServicedRecursiveSync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServicedRecursiveTotalDataPoint adds a data point to container.blockio.io_serviced_recursive.total metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServicedRecursiveTotalDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServicedRecursiveTotal.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoServicedRecursiveWriteDataPoint adds a data point to container.blockio.io_serviced_recursive.write metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoServicedRecursiveWriteDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoServicedRecursiveWrite.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoTimeRecursiveAsyncDataPoint adds a data point to container.blockio.io_time_recursive.async metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoTimeRecursiveAsyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoTimeRecursiveAsync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoTimeRecursiveDiscardDataPoint adds a data point to container.blockio.io_time_recursive.discard metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoTimeRecursiveDiscardDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoTimeRecursiveDiscard.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoTimeRecursiveReadDataPoint adds a data point to container.blockio.io_time_recursive.read metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoTimeRecursiveReadDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoTimeRecursiveRead.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoTimeRecursiveSyncDataPoint adds a data point to container.blockio.io_time_recursive.sync metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoTimeRecursiveSyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoTimeRecursiveSync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoTimeRecursiveTotalDataPoint adds a data point to container.blockio.io_time_recursive.total metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoTimeRecursiveTotalDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoTimeRecursiveTotal.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoTimeRecursiveWriteDataPoint adds a data point to container.blockio.io_time_recursive.write metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoTimeRecursiveWriteDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoTimeRecursiveWrite.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoWaitTimeRecursiveAsyncDataPoint adds a data point to container.blockio.io_wait_time_recursive.async metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoWaitTimeRecursiveAsyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoWaitTimeRecursiveAsync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoWaitTimeRecursiveDiscardDataPoint adds a data point to container.blockio.io_wait_time_recursive.discard metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoWaitTimeRecursiveDiscardDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoWaitTimeRecursiveDiscard.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoWaitTimeRecursiveReadDataPoint adds a data point to container.blockio.io_wait_time_recursive.read metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoWaitTimeRecursiveReadDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoWaitTimeRecursiveRead.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoWaitTimeRecursiveSyncDataPoint adds a data point to container.blockio.io_wait_time_recursive.sync metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoWaitTimeRecursiveSyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoWaitTimeRecursiveSync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoWaitTimeRecursiveTotalDataPoint adds a data point to container.blockio.io_wait_time_recursive.total metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoWaitTimeRecursiveTotalDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoWaitTimeRecursiveTotal.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioIoWaitTimeRecursiveWriteDataPoint adds a data point to container.blockio.io_wait_time_recursive.write metric.
func (mb *MetricsBuilder) RecordContainerBlockioIoWaitTimeRecursiveWriteDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioIoWaitTimeRecursiveWrite.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioSectorsRecursiveAsyncDataPoint adds a data point to container.blockio.sectors_recursive.async metric.
func (mb *MetricsBuilder) RecordContainerBlockioSectorsRecursiveAsyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioSectorsRecursiveAsync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioSectorsRecursiveDiscardDataPoint adds a data point to container.blockio.sectors_recursive.discard metric.
func (mb *MetricsBuilder) RecordContainerBlockioSectorsRecursiveDiscardDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioSectorsRecursiveDiscard.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioSectorsRecursiveReadDataPoint adds a data point to container.blockio.sectors_recursive.read metric.
func (mb *MetricsBuilder) RecordContainerBlockioSectorsRecursiveReadDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioSectorsRecursiveRead.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioSectorsRecursiveSyncDataPoint adds a data point to container.blockio.sectors_recursive.sync metric.
func (mb *MetricsBuilder) RecordContainerBlockioSectorsRecursiveSyncDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioSectorsRecursiveSync.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioSectorsRecursiveTotalDataPoint adds a data point to container.blockio.sectors_recursive.total metric.
func (mb *MetricsBuilder) RecordContainerBlockioSectorsRecursiveTotalDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioSectorsRecursiveTotal.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerBlockioSectorsRecursiveWriteDataPoint adds a data point to container.blockio.sectors_recursive.write metric.
func (mb *MetricsBuilder) RecordContainerBlockioSectorsRecursiveWriteDataPoint(ts pcommon.Timestamp, val int64, deviceMajorAttributeValue string, deviceMinorAttributeValue string) {
	mb.metricContainerBlockioSectorsRecursiveWrite.recordDataPoint(mb.startTime, ts, val, deviceMajorAttributeValue, deviceMinorAttributeValue)
}

// RecordContainerCPUPercentDataPoint adds a data point to container.cpu.percent metric.
func (mb *MetricsBuilder) RecordContainerCPUPercentDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricContainerCPUPercent.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerCPUThrottlingDataPeriodsDataPoint adds a data point to container.cpu.throttling_data.periods metric.
func (mb *MetricsBuilder) RecordContainerCPUThrottlingDataPeriodsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerCPUThrottlingDataPeriods.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerCPUThrottlingDataThrottledPeriodsDataPoint adds a data point to container.cpu.throttling_data.throttled_periods metric.
func (mb *MetricsBuilder) RecordContainerCPUThrottlingDataThrottledPeriodsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerCPUThrottlingDataThrottledPeriods.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerCPUThrottlingDataThrottledTimeDataPoint adds a data point to container.cpu.throttling_data.throttled_time metric.
func (mb *MetricsBuilder) RecordContainerCPUThrottlingDataThrottledTimeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerCPUThrottlingDataThrottledTime.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerCPUUsageKernelmodeDataPoint adds a data point to container.cpu.usage.kernelmode metric.
func (mb *MetricsBuilder) RecordContainerCPUUsageKernelmodeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerCPUUsageKernelmode.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerCPUUsagePercpuDataPoint adds a data point to container.cpu.usage.percpu metric.
func (mb *MetricsBuilder) RecordContainerCPUUsagePercpuDataPoint(ts pcommon.Timestamp, val int64, coreAttributeValue string) {
	mb.metricContainerCPUUsagePercpu.recordDataPoint(mb.startTime, ts, val, coreAttributeValue)
}

// RecordContainerCPUUsageSystemDataPoint adds a data point to container.cpu.usage.system metric.
func (mb *MetricsBuilder) RecordContainerCPUUsageSystemDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerCPUUsageSystem.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerCPUUsageTotalDataPoint adds a data point to container.cpu.usage.total metric.
func (mb *MetricsBuilder) RecordContainerCPUUsageTotalDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerCPUUsageTotal.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerCPUUsageUsermodeDataPoint adds a data point to container.cpu.usage.usermode metric.
func (mb *MetricsBuilder) RecordContainerCPUUsageUsermodeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerCPUUsageUsermode.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryActiveAnonDataPoint adds a data point to container.memory.active_anon metric.
func (mb *MetricsBuilder) RecordContainerMemoryActiveAnonDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryActiveAnon.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryActiveFileDataPoint adds a data point to container.memory.active_file metric.
func (mb *MetricsBuilder) RecordContainerMemoryActiveFileDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryActiveFile.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryCacheDataPoint adds a data point to container.memory.cache metric.
func (mb *MetricsBuilder) RecordContainerMemoryCacheDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryCache.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryDirtyDataPoint adds a data point to container.memory.dirty metric.
func (mb *MetricsBuilder) RecordContainerMemoryDirtyDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryDirty.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryHierarchicalMemoryLimitDataPoint adds a data point to container.memory.hierarchical_memory_limit metric.
func (mb *MetricsBuilder) RecordContainerMemoryHierarchicalMemoryLimitDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryHierarchicalMemoryLimit.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryHierarchicalMemswLimitDataPoint adds a data point to container.memory.hierarchical_memsw_limit metric.
func (mb *MetricsBuilder) RecordContainerMemoryHierarchicalMemswLimitDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryHierarchicalMemswLimit.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryInactiveAnonDataPoint adds a data point to container.memory.inactive_anon metric.
func (mb *MetricsBuilder) RecordContainerMemoryInactiveAnonDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryInactiveAnon.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryInactiveFileDataPoint adds a data point to container.memory.inactive_file metric.
func (mb *MetricsBuilder) RecordContainerMemoryInactiveFileDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryInactiveFile.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryMappedFileDataPoint adds a data point to container.memory.mapped_file metric.
func (mb *MetricsBuilder) RecordContainerMemoryMappedFileDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryMappedFile.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryPercentDataPoint adds a data point to container.memory.percent metric.
func (mb *MetricsBuilder) RecordContainerMemoryPercentDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricContainerMemoryPercent.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryPgfaultDataPoint adds a data point to container.memory.pgfault metric.
func (mb *MetricsBuilder) RecordContainerMemoryPgfaultDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryPgfault.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryPgmajfaultDataPoint adds a data point to container.memory.pgmajfault metric.
func (mb *MetricsBuilder) RecordContainerMemoryPgmajfaultDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryPgmajfault.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryPgpginDataPoint adds a data point to container.memory.pgpgin metric.
func (mb *MetricsBuilder) RecordContainerMemoryPgpginDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryPgpgin.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryPgpgoutDataPoint adds a data point to container.memory.pgpgout metric.
func (mb *MetricsBuilder) RecordContainerMemoryPgpgoutDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryPgpgout.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryRssDataPoint adds a data point to container.memory.rss metric.
func (mb *MetricsBuilder) RecordContainerMemoryRssDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryRss.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryRssHugeDataPoint adds a data point to container.memory.rss_huge metric.
func (mb *MetricsBuilder) RecordContainerMemoryRssHugeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryRssHuge.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemorySwapDataPoint adds a data point to container.memory.swap metric.
func (mb *MetricsBuilder) RecordContainerMemorySwapDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemorySwap.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalActiveAnonDataPoint adds a data point to container.memory.total_active_anon metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalActiveAnonDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalActiveAnon.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalActiveFileDataPoint adds a data point to container.memory.total_active_file metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalActiveFileDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalActiveFile.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalCacheDataPoint adds a data point to container.memory.total_cache metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalCacheDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalCache.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalDirtyDataPoint adds a data point to container.memory.total_dirty metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalDirtyDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalDirty.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalInactiveAnonDataPoint adds a data point to container.memory.total_inactive_anon metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalInactiveAnonDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalInactiveAnon.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalInactiveFileDataPoint adds a data point to container.memory.total_inactive_file metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalInactiveFileDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalInactiveFile.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalMappedFileDataPoint adds a data point to container.memory.total_mapped_file metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalMappedFileDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalMappedFile.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalPgfaultDataPoint adds a data point to container.memory.total_pgfault metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalPgfaultDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalPgfault.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalPgmajfaultDataPoint adds a data point to container.memory.total_pgmajfault metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalPgmajfaultDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalPgmajfault.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalPgpginDataPoint adds a data point to container.memory.total_pgpgin metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalPgpginDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalPgpgin.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalPgpgoutDataPoint adds a data point to container.memory.total_pgpgout metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalPgpgoutDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalPgpgout.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalRssDataPoint adds a data point to container.memory.total_rss metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalRssDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalRss.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalRssHugeDataPoint adds a data point to container.memory.total_rss_huge metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalRssHugeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalRssHuge.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalSwapDataPoint adds a data point to container.memory.total_swap metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalSwapDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalSwap.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalUnevictableDataPoint adds a data point to container.memory.total_unevictable metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalUnevictableDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalUnevictable.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryTotalWritebackDataPoint adds a data point to container.memory.total_writeback metric.
func (mb *MetricsBuilder) RecordContainerMemoryTotalWritebackDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryTotalWriteback.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryUnevictableDataPoint adds a data point to container.memory.unevictable metric.
func (mb *MetricsBuilder) RecordContainerMemoryUnevictableDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryUnevictable.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryUsageLimitDataPoint adds a data point to container.memory.usage.limit metric.
func (mb *MetricsBuilder) RecordContainerMemoryUsageLimitDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryUsageLimit.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryUsageMaxDataPoint adds a data point to container.memory.usage.max metric.
func (mb *MetricsBuilder) RecordContainerMemoryUsageMaxDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryUsageMax.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryUsageTotalDataPoint adds a data point to container.memory.usage.total metric.
func (mb *MetricsBuilder) RecordContainerMemoryUsageTotalDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryUsageTotal.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerMemoryWritebackDataPoint adds a data point to container.memory.writeback metric.
func (mb *MetricsBuilder) RecordContainerMemoryWritebackDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricContainerMemoryWriteback.recordDataPoint(mb.startTime, ts, val)
}

// RecordContainerNetworkIoUsageRxBytesDataPoint adds a data point to container.network.io.usage.rx_bytes metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageRxBytesDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageRxBytes.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// RecordContainerNetworkIoUsageRxDroppedDataPoint adds a data point to container.network.io.usage.rx_dropped metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageRxDroppedDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageRxDropped.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// RecordContainerNetworkIoUsageRxErrorsDataPoint adds a data point to container.network.io.usage.rx_errors metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageRxErrorsDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageRxErrors.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// RecordContainerNetworkIoUsageRxPacketsDataPoint adds a data point to container.network.io.usage.rx_packets metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageRxPacketsDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageRxPackets.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// RecordContainerNetworkIoUsageTxBytesDataPoint adds a data point to container.network.io.usage.tx_bytes metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageTxBytesDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageTxBytes.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// RecordContainerNetworkIoUsageTxDroppedDataPoint adds a data point to container.network.io.usage.tx_dropped metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageTxDroppedDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageTxDropped.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// RecordContainerNetworkIoUsageTxErrorsDataPoint adds a data point to container.network.io.usage.tx_errors metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageTxErrorsDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageTxErrors.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// RecordContainerNetworkIoUsageTxPacketsDataPoint adds a data point to container.network.io.usage.tx_packets metric.
func (mb *MetricsBuilder) RecordContainerNetworkIoUsageTxPacketsDataPoint(ts pcommon.Timestamp, val int64, interfaceAttributeValue string) {
	mb.metricContainerNetworkIoUsageTxPackets.recordDataPoint(mb.startTime, ts, val, interfaceAttributeValue)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...metricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(mb)
	}
}
