// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

// AttributeBindType specifies the a value bind_type attribute.
type AttributeBindType int

const (
	_ AttributeBindType = iota
	AttributeBindTypeServer
	AttributeBindTypeClient
)

// String returns the string representation of the AttributeBindType.
func (av AttributeBindType) String() string {
	switch av {
	case AttributeBindTypeServer:
		return "server"
	case AttributeBindTypeClient:
		return "client"
	}
	return ""
}

// MapAttributeBindType is a helper map of string to AttributeBindType attribute value.
var MapAttributeBindType = map[string]AttributeBindType{
	"server": AttributeBindTypeServer,
	"client": AttributeBindTypeClient,
}

// AttributeDirection specifies the a value direction attribute.
type AttributeDirection int

const (
	_ AttributeDirection = iota
	AttributeDirectionSent
	AttributeDirectionReceived
)

// String returns the string representation of the AttributeDirection.
func (av AttributeDirection) String() string {
	switch av {
	case AttributeDirectionSent:
		return "sent"
	case AttributeDirectionReceived:
		return "received"
	}
	return ""
}

// MapAttributeDirection is a helper map of string to AttributeDirection attribute value.
var MapAttributeDirection = map[string]AttributeDirection{
	"sent":     AttributeDirectionSent,
	"received": AttributeDirectionReceived,
}

// AttributeNetworkDataType specifies the a value network_data_type attribute.
type AttributeNetworkDataType int

const (
	_ AttributeNetworkDataType = iota
	AttributeNetworkDataTypeCompressed
	AttributeNetworkDataTypeUncompressed
)

// String returns the string representation of the AttributeNetworkDataType.
func (av AttributeNetworkDataType) String() string {
	switch av {
	case AttributeNetworkDataTypeCompressed:
		return "compressed"
	case AttributeNetworkDataTypeUncompressed:
		return "uncompressed"
	}
	return ""
}

// MapAttributeNetworkDataType is a helper map of string to AttributeNetworkDataType attribute value.
var MapAttributeNetworkDataType = map[string]AttributeNetworkDataType{
	"compressed":   AttributeNetworkDataTypeCompressed,
	"uncompressed": AttributeNetworkDataTypeUncompressed,
}

// AttributeOperationType specifies the a value operation_type attribute.
type AttributeOperationType int

const (
	_ AttributeOperationType = iota
	AttributeOperationTypeRead
	AttributeOperationTypeWrite
	AttributeOperationTypeSearch
)

// String returns the string representation of the AttributeOperationType.
func (av AttributeOperationType) String() string {
	switch av {
	case AttributeOperationTypeRead:
		return "read"
	case AttributeOperationTypeWrite:
		return "write"
	case AttributeOperationTypeSearch:
		return "search"
	}
	return ""
}

// MapAttributeOperationType is a helper map of string to AttributeOperationType attribute value.
var MapAttributeOperationType = map[string]AttributeOperationType{
	"read":   AttributeOperationTypeRead,
	"write":  AttributeOperationTypeWrite,
	"search": AttributeOperationTypeSearch,
}

// AttributeSuboperationType specifies the a value suboperation_type attribute.
type AttributeSuboperationType int

const (
	_ AttributeSuboperationType = iota
	AttributeSuboperationTypeSecurityDescriptorPropagationsEvent
	AttributeSuboperationTypeSearch
)

// String returns the string representation of the AttributeSuboperationType.
func (av AttributeSuboperationType) String() string {
	switch av {
	case AttributeSuboperationTypeSecurityDescriptorPropagationsEvent:
		return "security_descriptor_propagations_event"
	case AttributeSuboperationTypeSearch:
		return "search"
	}
	return ""
}

// MapAttributeSuboperationType is a helper map of string to AttributeSuboperationType attribute value.
var MapAttributeSuboperationType = map[string]AttributeSuboperationType{
	"security_descriptor_propagations_event": AttributeSuboperationTypeSecurityDescriptorPropagationsEvent,
	"search":                                 AttributeSuboperationTypeSearch,
}

// AttributeSyncResult specifies the a value sync_result attribute.
type AttributeSyncResult int

const (
	_ AttributeSyncResult = iota
	AttributeSyncResultSuccess
	AttributeSyncResultSchemaMismatch
	AttributeSyncResultOther
)

// String returns the string representation of the AttributeSyncResult.
func (av AttributeSyncResult) String() string {
	switch av {
	case AttributeSyncResultSuccess:
		return "success"
	case AttributeSyncResultSchemaMismatch:
		return "schema_mismatch"
	case AttributeSyncResultOther:
		return "other"
	}
	return ""
}

// MapAttributeSyncResult is a helper map of string to AttributeSyncResult attribute value.
var MapAttributeSyncResult = map[string]AttributeSyncResult{
	"success":         AttributeSyncResultSuccess,
	"schema_mismatch": AttributeSyncResultSchemaMismatch,
	"other":           AttributeSyncResultOther,
}

// AttributeValueType specifies the a value value_type attribute.
type AttributeValueType int

const (
	_ AttributeValueType = iota
	AttributeValueTypeDistingushedNames
	AttributeValueTypeOther
)

// String returns the string representation of the AttributeValueType.
func (av AttributeValueType) String() string {
	switch av {
	case AttributeValueTypeDistingushedNames:
		return "distingushed_names"
	case AttributeValueTypeOther:
		return "other"
	}
	return ""
}

// MapAttributeValueType is a helper map of string to AttributeValueType attribute value.
var MapAttributeValueType = map[string]AttributeValueType{
	"distingushed_names": AttributeValueTypeDistingushedNames,
	"other":              AttributeValueTypeOther,
}

type metricActiveDirectoryDsBindRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.bind.rate metric with initial data.
func (m *metricActiveDirectoryDsBindRate) init() {
	m.data.SetName("active_directory.ds.bind.rate")
	m.data.SetDescription("The number of binds per second serviced by this domain controller.")
	m.data.SetUnit("{binds}/s")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricActiveDirectoryDsBindRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, bindTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("type", bindTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsBindRate) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsBindRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsBindRate(cfg MetricConfig) metricActiveDirectoryDsBindRate {
	m := metricActiveDirectoryDsBindRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsLdapBindLastSuccessfulTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.ldap.bind.last_successful.time metric with initial data.
func (m *metricActiveDirectoryDsLdapBindLastSuccessfulTime) init() {
	m.data.SetName("active_directory.ds.ldap.bind.last_successful.time")
	m.data.SetDescription("The amount of time taken for the last successful LDAP bind.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
}

func (m *metricActiveDirectoryDsLdapBindLastSuccessfulTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsLdapBindLastSuccessfulTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsLdapBindLastSuccessfulTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsLdapBindLastSuccessfulTime(cfg MetricConfig) metricActiveDirectoryDsLdapBindLastSuccessfulTime {
	m := metricActiveDirectoryDsLdapBindLastSuccessfulTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsLdapBindRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.ldap.bind.rate metric with initial data.
func (m *metricActiveDirectoryDsLdapBindRate) init() {
	m.data.SetName("active_directory.ds.ldap.bind.rate")
	m.data.SetDescription("The number of successful LDAP binds per second.")
	m.data.SetUnit("{binds}/s")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricActiveDirectoryDsLdapBindRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsLdapBindRate) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsLdapBindRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsLdapBindRate(cfg MetricConfig) metricActiveDirectoryDsLdapBindRate {
	m := metricActiveDirectoryDsLdapBindRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsLdapClientSessionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.ldap.client.session.count metric with initial data.
func (m *metricActiveDirectoryDsLdapClientSessionCount) init() {
	m.data.SetName("active_directory.ds.ldap.client.session.count")
	m.data.SetDescription("The number of connected LDAP client sessions.")
	m.data.SetUnit("{sessions}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricActiveDirectoryDsLdapClientSessionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsLdapClientSessionCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsLdapClientSessionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsLdapClientSessionCount(cfg MetricConfig) metricActiveDirectoryDsLdapClientSessionCount {
	m := metricActiveDirectoryDsLdapClientSessionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsLdapSearchRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.ldap.search.rate metric with initial data.
func (m *metricActiveDirectoryDsLdapSearchRate) init() {
	m.data.SetName("active_directory.ds.ldap.search.rate")
	m.data.SetDescription("The number of LDAP searches per second.")
	m.data.SetUnit("{searches}/s")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricActiveDirectoryDsLdapSearchRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsLdapSearchRate) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsLdapSearchRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsLdapSearchRate(cfg MetricConfig) metricActiveDirectoryDsLdapSearchRate {
	m := metricActiveDirectoryDsLdapSearchRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsNameCacheHitRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.name_cache.hit_rate metric with initial data.
func (m *metricActiveDirectoryDsNameCacheHitRate) init() {
	m.data.SetName("active_directory.ds.name_cache.hit_rate")
	m.data.SetDescription("The percentage of directory object name component lookups that are satisfied by the Directory System Agent's name cache.")
	m.data.SetUnit("%")
	m.data.SetEmptyGauge()
}

func (m *metricActiveDirectoryDsNameCacheHitRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsNameCacheHitRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsNameCacheHitRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsNameCacheHitRate(cfg MetricConfig) metricActiveDirectoryDsNameCacheHitRate {
	m := metricActiveDirectoryDsNameCacheHitRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsNotificationQueued struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.notification.queued metric with initial data.
func (m *metricActiveDirectoryDsNotificationQueued) init() {
	m.data.SetName("active_directory.ds.notification.queued")
	m.data.SetDescription("The number of pending update notifications that have been queued to push to clients.")
	m.data.SetUnit("{notifications}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricActiveDirectoryDsNotificationQueued) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsNotificationQueued) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsNotificationQueued) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsNotificationQueued(cfg MetricConfig) metricActiveDirectoryDsNotificationQueued {
	m := metricActiveDirectoryDsNotificationQueued{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsOperationRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.operation.rate metric with initial data.
func (m *metricActiveDirectoryDsOperationRate) init() {
	m.data.SetName("active_directory.ds.operation.rate")
	m.data.SetDescription("The number of operations performed per second.")
	m.data.SetUnit("{operations}/s")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricActiveDirectoryDsOperationRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, operationTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("type", operationTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsOperationRate) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsOperationRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsOperationRate(cfg MetricConfig) metricActiveDirectoryDsOperationRate {
	m := metricActiveDirectoryDsOperationRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsReplicationNetworkIo struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.replication.network.io metric with initial data.
func (m *metricActiveDirectoryDsReplicationNetworkIo) init() {
	m.data.SetName("active_directory.ds.replication.network.io")
	m.data.SetDescription("The amount of network data transmitted by the Directory Replication Agent.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricActiveDirectoryDsReplicationNetworkIo) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string, networkDataTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
	dp.Attributes().PutStr("type", networkDataTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsReplicationNetworkIo) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsReplicationNetworkIo) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsReplicationNetworkIo(cfg MetricConfig) metricActiveDirectoryDsReplicationNetworkIo {
	m := metricActiveDirectoryDsReplicationNetworkIo{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsReplicationObjectRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.replication.object.rate metric with initial data.
func (m *metricActiveDirectoryDsReplicationObjectRate) init() {
	m.data.SetName("active_directory.ds.replication.object.rate")
	m.data.SetDescription("The number of objects transmitted by the Directory Replication Agent per second.")
	m.data.SetUnit("{objects}/s")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricActiveDirectoryDsReplicationObjectRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsReplicationObjectRate) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsReplicationObjectRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsReplicationObjectRate(cfg MetricConfig) metricActiveDirectoryDsReplicationObjectRate {
	m := metricActiveDirectoryDsReplicationObjectRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsReplicationOperationPending struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.replication.operation.pending metric with initial data.
func (m *metricActiveDirectoryDsReplicationOperationPending) init() {
	m.data.SetName("active_directory.ds.replication.operation.pending")
	m.data.SetDescription("The number of pending replication operations for the Directory Replication Agent.")
	m.data.SetUnit("{operations}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricActiveDirectoryDsReplicationOperationPending) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsReplicationOperationPending) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsReplicationOperationPending) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsReplicationOperationPending(cfg MetricConfig) metricActiveDirectoryDsReplicationOperationPending {
	m := metricActiveDirectoryDsReplicationOperationPending{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsReplicationPropertyRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.replication.property.rate metric with initial data.
func (m *metricActiveDirectoryDsReplicationPropertyRate) init() {
	m.data.SetName("active_directory.ds.replication.property.rate")
	m.data.SetDescription("The number of properties transmitted by the Directory Replication Agent per second.")
	m.data.SetUnit("{properties}/s")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricActiveDirectoryDsReplicationPropertyRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsReplicationPropertyRate) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsReplicationPropertyRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsReplicationPropertyRate(cfg MetricConfig) metricActiveDirectoryDsReplicationPropertyRate {
	m := metricActiveDirectoryDsReplicationPropertyRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsReplicationSyncObjectPending struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.replication.sync.object.pending metric with initial data.
func (m *metricActiveDirectoryDsReplicationSyncObjectPending) init() {
	m.data.SetName("active_directory.ds.replication.sync.object.pending")
	m.data.SetDescription("The number of objects remaining until the full sync completes for the Directory Replication Agent.")
	m.data.SetUnit("{objects}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricActiveDirectoryDsReplicationSyncObjectPending) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsReplicationSyncObjectPending) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsReplicationSyncObjectPending) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsReplicationSyncObjectPending(cfg MetricConfig) metricActiveDirectoryDsReplicationSyncObjectPending {
	m := metricActiveDirectoryDsReplicationSyncObjectPending{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsReplicationSyncRequestCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.replication.sync.request.count metric with initial data.
func (m *metricActiveDirectoryDsReplicationSyncRequestCount) init() {
	m.data.SetName("active_directory.ds.replication.sync.request.count")
	m.data.SetDescription("The number of sync requests made by the Directory Replication Agent.")
	m.data.SetUnit("{requests}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricActiveDirectoryDsReplicationSyncRequestCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, syncResultAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("result", syncResultAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsReplicationSyncRequestCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsReplicationSyncRequestCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsReplicationSyncRequestCount(cfg MetricConfig) metricActiveDirectoryDsReplicationSyncRequestCount {
	m := metricActiveDirectoryDsReplicationSyncRequestCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsReplicationValueRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.replication.value.rate metric with initial data.
func (m *metricActiveDirectoryDsReplicationValueRate) init() {
	m.data.SetName("active_directory.ds.replication.value.rate")
	m.data.SetDescription("The number of values transmitted by the Directory Replication Agent per second.")
	m.data.SetUnit("{values}/s")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricActiveDirectoryDsReplicationValueRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, directionAttributeValue string, valueTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
	dp.Attributes().PutStr("type", valueTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsReplicationValueRate) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsReplicationValueRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsReplicationValueRate(cfg MetricConfig) metricActiveDirectoryDsReplicationValueRate {
	m := metricActiveDirectoryDsReplicationValueRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsSecurityDescriptorPropagationsEventQueued struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.security_descriptor_propagations_event.queued metric with initial data.
func (m *metricActiveDirectoryDsSecurityDescriptorPropagationsEventQueued) init() {
	m.data.SetName("active_directory.ds.security_descriptor_propagations_event.queued")
	m.data.SetDescription("The number of security descriptor propagation events that are queued for processing.")
	m.data.SetUnit("{events}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricActiveDirectoryDsSecurityDescriptorPropagationsEventQueued) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsSecurityDescriptorPropagationsEventQueued) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsSecurityDescriptorPropagationsEventQueued) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsSecurityDescriptorPropagationsEventQueued(cfg MetricConfig) metricActiveDirectoryDsSecurityDescriptorPropagationsEventQueued {
	m := metricActiveDirectoryDsSecurityDescriptorPropagationsEventQueued{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsSuboperationRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.suboperation.rate metric with initial data.
func (m *metricActiveDirectoryDsSuboperationRate) init() {
	m.data.SetName("active_directory.ds.suboperation.rate")
	m.data.SetDescription("The rate of sub-operations performed.")
	m.data.SetUnit("{suboperations}/s")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricActiveDirectoryDsSuboperationRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, suboperationTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("type", suboperationTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsSuboperationRate) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsSuboperationRate) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsSuboperationRate(cfg MetricConfig) metricActiveDirectoryDsSuboperationRate {
	m := metricActiveDirectoryDsSuboperationRate{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricActiveDirectoryDsThreadCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills active_directory.ds.thread.count metric with initial data.
func (m *metricActiveDirectoryDsThreadCount) init() {
	m.data.SetName("active_directory.ds.thread.count")
	m.data.SetDescription("The number of threads in use by the directory service.")
	m.data.SetUnit("{threads}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricActiveDirectoryDsThreadCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricActiveDirectoryDsThreadCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricActiveDirectoryDsThreadCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricActiveDirectoryDsThreadCount(cfg MetricConfig) metricActiveDirectoryDsThreadCount {
	m := metricActiveDirectoryDsThreadCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config                                                           MetricsBuilderConfig // config of the metrics builder.
	startTime                                                        pcommon.Timestamp    // start time that will be applied to all recorded data points.
	metricsCapacity                                                  int                  // maximum observed number of metrics per resource.
	metricsBuffer                                                    pmetric.Metrics      // accumulates metrics data before emitting.
	buildInfo                                                        component.BuildInfo  // contains version information.
	metricActiveDirectoryDsBindRate                                  metricActiveDirectoryDsBindRate
	metricActiveDirectoryDsLdapBindLastSuccessfulTime                metricActiveDirectoryDsLdapBindLastSuccessfulTime
	metricActiveDirectoryDsLdapBindRate                              metricActiveDirectoryDsLdapBindRate
	metricActiveDirectoryDsLdapClientSessionCount                    metricActiveDirectoryDsLdapClientSessionCount
	metricActiveDirectoryDsLdapSearchRate                            metricActiveDirectoryDsLdapSearchRate
	metricActiveDirectoryDsNameCacheHitRate                          metricActiveDirectoryDsNameCacheHitRate
	metricActiveDirectoryDsNotificationQueued                        metricActiveDirectoryDsNotificationQueued
	metricActiveDirectoryDsOperationRate                             metricActiveDirectoryDsOperationRate
	metricActiveDirectoryDsReplicationNetworkIo                      metricActiveDirectoryDsReplicationNetworkIo
	metricActiveDirectoryDsReplicationObjectRate                     metricActiveDirectoryDsReplicationObjectRate
	metricActiveDirectoryDsReplicationOperationPending               metricActiveDirectoryDsReplicationOperationPending
	metricActiveDirectoryDsReplicationPropertyRate                   metricActiveDirectoryDsReplicationPropertyRate
	metricActiveDirectoryDsReplicationSyncObjectPending              metricActiveDirectoryDsReplicationSyncObjectPending
	metricActiveDirectoryDsReplicationSyncRequestCount               metricActiveDirectoryDsReplicationSyncRequestCount
	metricActiveDirectoryDsReplicationValueRate                      metricActiveDirectoryDsReplicationValueRate
	metricActiveDirectoryDsSecurityDescriptorPropagationsEventQueued metricActiveDirectoryDsSecurityDescriptorPropagationsEventQueued
	metricActiveDirectoryDsSuboperationRate                          metricActiveDirectoryDsSuboperationRate
	metricActiveDirectoryDsThreadCount                               metricActiveDirectoryDsThreadCount
}

// MetricBuilderOption applies changes to default metrics builder.
type MetricBuilderOption interface {
	apply(*MetricsBuilder)
}

type metricBuilderOptionFunc func(mb *MetricsBuilder)

func (mbof metricBuilderOptionFunc) apply(mb *MetricsBuilder) {
	mbof(mb)
}

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) MetricBuilderOption {
	return metricBuilderOptionFunc(func(mb *MetricsBuilder) {
		mb.startTime = startTime
	})
}

func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.Settings, options ...MetricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:                          mbc,
		startTime:                       pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:                   pmetric.NewMetrics(),
		buildInfo:                       settings.BuildInfo,
		metricActiveDirectoryDsBindRate: newMetricActiveDirectoryDsBindRate(mbc.Metrics.ActiveDirectoryDsBindRate),
		metricActiveDirectoryDsLdapBindLastSuccessfulTime:                newMetricActiveDirectoryDsLdapBindLastSuccessfulTime(mbc.Metrics.ActiveDirectoryDsLdapBindLastSuccessfulTime),
		metricActiveDirectoryDsLdapBindRate:                              newMetricActiveDirectoryDsLdapBindRate(mbc.Metrics.ActiveDirectoryDsLdapBindRate),
		metricActiveDirectoryDsLdapClientSessionCount:                    newMetricActiveDirectoryDsLdapClientSessionCount(mbc.Metrics.ActiveDirectoryDsLdapClientSessionCount),
		metricActiveDirectoryDsLdapSearchRate:                            newMetricActiveDirectoryDsLdapSearchRate(mbc.Metrics.ActiveDirectoryDsLdapSearchRate),
		metricActiveDirectoryDsNameCacheHitRate:                          newMetricActiveDirectoryDsNameCacheHitRate(mbc.Metrics.ActiveDirectoryDsNameCacheHitRate),
		metricActiveDirectoryDsNotificationQueued:                        newMetricActiveDirectoryDsNotificationQueued(mbc.Metrics.ActiveDirectoryDsNotificationQueued),
		metricActiveDirectoryDsOperationRate:                             newMetricActiveDirectoryDsOperationRate(mbc.Metrics.ActiveDirectoryDsOperationRate),
		metricActiveDirectoryDsReplicationNetworkIo:                      newMetricActiveDirectoryDsReplicationNetworkIo(mbc.Metrics.ActiveDirectoryDsReplicationNetworkIo),
		metricActiveDirectoryDsReplicationObjectRate:                     newMetricActiveDirectoryDsReplicationObjectRate(mbc.Metrics.ActiveDirectoryDsReplicationObjectRate),
		metricActiveDirectoryDsReplicationOperationPending:               newMetricActiveDirectoryDsReplicationOperationPending(mbc.Metrics.ActiveDirectoryDsReplicationOperationPending),
		metricActiveDirectoryDsReplicationPropertyRate:                   newMetricActiveDirectoryDsReplicationPropertyRate(mbc.Metrics.ActiveDirectoryDsReplicationPropertyRate),
		metricActiveDirectoryDsReplicationSyncObjectPending:              newMetricActiveDirectoryDsReplicationSyncObjectPending(mbc.Metrics.ActiveDirectoryDsReplicationSyncObjectPending),
		metricActiveDirectoryDsReplicationSyncRequestCount:               newMetricActiveDirectoryDsReplicationSyncRequestCount(mbc.Metrics.ActiveDirectoryDsReplicationSyncRequestCount),
		metricActiveDirectoryDsReplicationValueRate:                      newMetricActiveDirectoryDsReplicationValueRate(mbc.Metrics.ActiveDirectoryDsReplicationValueRate),
		metricActiveDirectoryDsSecurityDescriptorPropagationsEventQueued: newMetricActiveDirectoryDsSecurityDescriptorPropagationsEventQueued(mbc.Metrics.ActiveDirectoryDsSecurityDescriptorPropagationsEventQueued),
		metricActiveDirectoryDsSuboperationRate:                          newMetricActiveDirectoryDsSuboperationRate(mbc.Metrics.ActiveDirectoryDsSuboperationRate),
		metricActiveDirectoryDsThreadCount:                               newMetricActiveDirectoryDsThreadCount(mbc.Metrics.ActiveDirectoryDsThreadCount),
	}

	for _, op := range options {
		op.apply(mb)
	}
	return mb
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption interface {
	apply(pmetric.ResourceMetrics)
}

type resourceMetricsOptionFunc func(pmetric.ResourceMetrics)

func (rmof resourceMetricsOptionFunc) apply(rm pmetric.ResourceMetrics) {
	rmof(rm)
}

// WithResource sets the provided resource on the emitted ResourceMetrics.
// It's recommended to use ResourceBuilder to create the resource.
func WithResource(res pcommon.Resource) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		res.CopyTo(rm.Resource())
	})
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	})
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(options ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName("github.com/open-telemetry/opentelemetry-collector-contrib/receiver/activedirectorydsreceiver")
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricActiveDirectoryDsBindRate.emit(ils.Metrics())
	mb.metricActiveDirectoryDsLdapBindLastSuccessfulTime.emit(ils.Metrics())
	mb.metricActiveDirectoryDsLdapBindRate.emit(ils.Metrics())
	mb.metricActiveDirectoryDsLdapClientSessionCount.emit(ils.Metrics())
	mb.metricActiveDirectoryDsLdapSearchRate.emit(ils.Metrics())
	mb.metricActiveDirectoryDsNameCacheHitRate.emit(ils.Metrics())
	mb.metricActiveDirectoryDsNotificationQueued.emit(ils.Metrics())
	mb.metricActiveDirectoryDsOperationRate.emit(ils.Metrics())
	mb.metricActiveDirectoryDsReplicationNetworkIo.emit(ils.Metrics())
	mb.metricActiveDirectoryDsReplicationObjectRate.emit(ils.Metrics())
	mb.metricActiveDirectoryDsReplicationOperationPending.emit(ils.Metrics())
	mb.metricActiveDirectoryDsReplicationPropertyRate.emit(ils.Metrics())
	mb.metricActiveDirectoryDsReplicationSyncObjectPending.emit(ils.Metrics())
	mb.metricActiveDirectoryDsReplicationSyncRequestCount.emit(ils.Metrics())
	mb.metricActiveDirectoryDsReplicationValueRate.emit(ils.Metrics())
	mb.metricActiveDirectoryDsSecurityDescriptorPropagationsEventQueued.emit(ils.Metrics())
	mb.metricActiveDirectoryDsSuboperationRate.emit(ils.Metrics())
	mb.metricActiveDirectoryDsThreadCount.emit(ils.Metrics())

	for _, op := range options {
		op.apply(rm)
	}

	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(options ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(options...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordActiveDirectoryDsBindRateDataPoint adds a data point to active_directory.ds.bind.rate metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsBindRateDataPoint(ts pcommon.Timestamp, val float64, bindTypeAttributeValue AttributeBindType) {
	mb.metricActiveDirectoryDsBindRate.recordDataPoint(mb.startTime, ts, val, bindTypeAttributeValue.String())
}

// RecordActiveDirectoryDsLdapBindLastSuccessfulTimeDataPoint adds a data point to active_directory.ds.ldap.bind.last_successful.time metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsLdapBindLastSuccessfulTimeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricActiveDirectoryDsLdapBindLastSuccessfulTime.recordDataPoint(mb.startTime, ts, val)
}

// RecordActiveDirectoryDsLdapBindRateDataPoint adds a data point to active_directory.ds.ldap.bind.rate metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsLdapBindRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricActiveDirectoryDsLdapBindRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordActiveDirectoryDsLdapClientSessionCountDataPoint adds a data point to active_directory.ds.ldap.client.session.count metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsLdapClientSessionCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricActiveDirectoryDsLdapClientSessionCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordActiveDirectoryDsLdapSearchRateDataPoint adds a data point to active_directory.ds.ldap.search.rate metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsLdapSearchRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricActiveDirectoryDsLdapSearchRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordActiveDirectoryDsNameCacheHitRateDataPoint adds a data point to active_directory.ds.name_cache.hit_rate metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsNameCacheHitRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricActiveDirectoryDsNameCacheHitRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordActiveDirectoryDsNotificationQueuedDataPoint adds a data point to active_directory.ds.notification.queued metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsNotificationQueuedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricActiveDirectoryDsNotificationQueued.recordDataPoint(mb.startTime, ts, val)
}

// RecordActiveDirectoryDsOperationRateDataPoint adds a data point to active_directory.ds.operation.rate metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsOperationRateDataPoint(ts pcommon.Timestamp, val float64, operationTypeAttributeValue AttributeOperationType) {
	mb.metricActiveDirectoryDsOperationRate.recordDataPoint(mb.startTime, ts, val, operationTypeAttributeValue.String())
}

// RecordActiveDirectoryDsReplicationNetworkIoDataPoint adds a data point to active_directory.ds.replication.network.io metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsReplicationNetworkIoDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection, networkDataTypeAttributeValue AttributeNetworkDataType) {
	mb.metricActiveDirectoryDsReplicationNetworkIo.recordDataPoint(mb.startTime, ts, val, directionAttributeValue.String(), networkDataTypeAttributeValue.String())
}

// RecordActiveDirectoryDsReplicationObjectRateDataPoint adds a data point to active_directory.ds.replication.object.rate metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsReplicationObjectRateDataPoint(ts pcommon.Timestamp, val float64, directionAttributeValue AttributeDirection) {
	mb.metricActiveDirectoryDsReplicationObjectRate.recordDataPoint(mb.startTime, ts, val, directionAttributeValue.String())
}

// RecordActiveDirectoryDsReplicationOperationPendingDataPoint adds a data point to active_directory.ds.replication.operation.pending metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsReplicationOperationPendingDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricActiveDirectoryDsReplicationOperationPending.recordDataPoint(mb.startTime, ts, val)
}

// RecordActiveDirectoryDsReplicationPropertyRateDataPoint adds a data point to active_directory.ds.replication.property.rate metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsReplicationPropertyRateDataPoint(ts pcommon.Timestamp, val float64, directionAttributeValue AttributeDirection) {
	mb.metricActiveDirectoryDsReplicationPropertyRate.recordDataPoint(mb.startTime, ts, val, directionAttributeValue.String())
}

// RecordActiveDirectoryDsReplicationSyncObjectPendingDataPoint adds a data point to active_directory.ds.replication.sync.object.pending metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsReplicationSyncObjectPendingDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricActiveDirectoryDsReplicationSyncObjectPending.recordDataPoint(mb.startTime, ts, val)
}

// RecordActiveDirectoryDsReplicationSyncRequestCountDataPoint adds a data point to active_directory.ds.replication.sync.request.count metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsReplicationSyncRequestCountDataPoint(ts pcommon.Timestamp, val int64, syncResultAttributeValue AttributeSyncResult) {
	mb.metricActiveDirectoryDsReplicationSyncRequestCount.recordDataPoint(mb.startTime, ts, val, syncResultAttributeValue.String())
}

// RecordActiveDirectoryDsReplicationValueRateDataPoint adds a data point to active_directory.ds.replication.value.rate metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsReplicationValueRateDataPoint(ts pcommon.Timestamp, val float64, directionAttributeValue AttributeDirection, valueTypeAttributeValue AttributeValueType) {
	mb.metricActiveDirectoryDsReplicationValueRate.recordDataPoint(mb.startTime, ts, val, directionAttributeValue.String(), valueTypeAttributeValue.String())
}

// RecordActiveDirectoryDsSecurityDescriptorPropagationsEventQueuedDataPoint adds a data point to active_directory.ds.security_descriptor_propagations_event.queued metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsSecurityDescriptorPropagationsEventQueuedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricActiveDirectoryDsSecurityDescriptorPropagationsEventQueued.recordDataPoint(mb.startTime, ts, val)
}

// RecordActiveDirectoryDsSuboperationRateDataPoint adds a data point to active_directory.ds.suboperation.rate metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsSuboperationRateDataPoint(ts pcommon.Timestamp, val float64, suboperationTypeAttributeValue AttributeSuboperationType) {
	mb.metricActiveDirectoryDsSuboperationRate.recordDataPoint(mb.startTime, ts, val, suboperationTypeAttributeValue.String())
}

// RecordActiveDirectoryDsThreadCountDataPoint adds a data point to active_directory.ds.thread.count metric.
func (mb *MetricsBuilder) RecordActiveDirectoryDsThreadCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricActiveDirectoryDsThreadCount.recordDataPoint(mb.startTime, ts, val)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...MetricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op.apply(mb)
	}
}
