// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

// AttributeDirection specifies the a value direction attribute.
type AttributeDirection int

const (
	_ AttributeDirection = iota
	AttributeDirectionIn
	AttributeDirectionOut
)

// String returns the string representation of the AttributeDirection.
func (av AttributeDirection) String() string {
	switch av {
	case AttributeDirectionIn:
		return "in"
	case AttributeDirectionOut:
		return "out"
	}
	return ""
}

// MapAttributeDirection is a helper map of string to AttributeDirection attribute value.
var MapAttributeDirection = map[string]AttributeDirection{
	"in":  AttributeDirectionIn,
	"out": AttributeDirectionOut,
}

// AttributeExecutorTaskResult specifies the a value executor_task_result attribute.
type AttributeExecutorTaskResult int

const (
	_ AttributeExecutorTaskResult = iota
	AttributeExecutorTaskResultCompleted
	AttributeExecutorTaskResultFailed
)

// String returns the string representation of the AttributeExecutorTaskResult.
func (av AttributeExecutorTaskResult) String() string {
	switch av {
	case AttributeExecutorTaskResultCompleted:
		return "completed"
	case AttributeExecutorTaskResultFailed:
		return "failed"
	}
	return ""
}

// MapAttributeExecutorTaskResult is a helper map of string to AttributeExecutorTaskResult attribute value.
var MapAttributeExecutorTaskResult = map[string]AttributeExecutorTaskResult{
	"completed": AttributeExecutorTaskResultCompleted,
	"failed":    AttributeExecutorTaskResultFailed,
}

// AttributeGcType specifies the a value gc_type attribute.
type AttributeGcType int

const (
	_ AttributeGcType = iota
	AttributeGcTypeMajor
	AttributeGcTypeMinor
)

// String returns the string representation of the AttributeGcType.
func (av AttributeGcType) String() string {
	switch av {
	case AttributeGcTypeMajor:
		return "major"
	case AttributeGcTypeMinor:
		return "minor"
	}
	return ""
}

// MapAttributeGcType is a helper map of string to AttributeGcType attribute value.
var MapAttributeGcType = map[string]AttributeGcType{
	"major": AttributeGcTypeMajor,
	"minor": AttributeGcTypeMinor,
}

// AttributeJobStageResult specifies the a value job_stage_result attribute.
type AttributeJobStageResult int

const (
	_ AttributeJobStageResult = iota
	AttributeJobStageResultCompleted
	AttributeJobStageResultFailed
	AttributeJobStageResultSkipped
)

// String returns the string representation of the AttributeJobStageResult.
func (av AttributeJobStageResult) String() string {
	switch av {
	case AttributeJobStageResultCompleted:
		return "completed"
	case AttributeJobStageResultFailed:
		return "failed"
	case AttributeJobStageResultSkipped:
		return "skipped"
	}
	return ""
}

// MapAttributeJobStageResult is a helper map of string to AttributeJobStageResult attribute value.
var MapAttributeJobStageResult = map[string]AttributeJobStageResult{
	"completed": AttributeJobStageResultCompleted,
	"failed":    AttributeJobStageResultFailed,
	"skipped":   AttributeJobStageResultSkipped,
}

// AttributeJobTaskResult specifies the a value job_task_result attribute.
type AttributeJobTaskResult int

const (
	_ AttributeJobTaskResult = iota
	AttributeJobTaskResultCompleted
	AttributeJobTaskResultFailed
	AttributeJobTaskResultSkipped
)

// String returns the string representation of the AttributeJobTaskResult.
func (av AttributeJobTaskResult) String() string {
	switch av {
	case AttributeJobTaskResultCompleted:
		return "completed"
	case AttributeJobTaskResultFailed:
		return "failed"
	case AttributeJobTaskResultSkipped:
		return "skipped"
	}
	return ""
}

// MapAttributeJobTaskResult is a helper map of string to AttributeJobTaskResult attribute value.
var MapAttributeJobTaskResult = map[string]AttributeJobTaskResult{
	"completed": AttributeJobTaskResultCompleted,
	"failed":    AttributeJobTaskResultFailed,
	"skipped":   AttributeJobTaskResultSkipped,
}

// AttributeLocation specifies the a value location attribute.
type AttributeLocation int

const (
	_ AttributeLocation = iota
	AttributeLocationOnHeap
	AttributeLocationOffHeap
)

// String returns the string representation of the AttributeLocation.
func (av AttributeLocation) String() string {
	switch av {
	case AttributeLocationOnHeap:
		return "on_heap"
	case AttributeLocationOffHeap:
		return "off_heap"
	}
	return ""
}

// MapAttributeLocation is a helper map of string to AttributeLocation attribute value.
var MapAttributeLocation = map[string]AttributeLocation{
	"on_heap":  AttributeLocationOnHeap,
	"off_heap": AttributeLocationOffHeap,
}

// AttributePoolMemoryType specifies the a value pool_memory_type attribute.
type AttributePoolMemoryType int

const (
	_ AttributePoolMemoryType = iota
	AttributePoolMemoryTypeDirect
	AttributePoolMemoryTypeMapped
)

// String returns the string representation of the AttributePoolMemoryType.
func (av AttributePoolMemoryType) String() string {
	switch av {
	case AttributePoolMemoryTypeDirect:
		return "direct"
	case AttributePoolMemoryTypeMapped:
		return "mapped"
	}
	return ""
}

// MapAttributePoolMemoryType is a helper map of string to AttributePoolMemoryType attribute value.
var MapAttributePoolMemoryType = map[string]AttributePoolMemoryType{
	"direct": AttributePoolMemoryTypeDirect,
	"mapped": AttributePoolMemoryTypeMapped,
}

// AttributeSource specifies the a value source attribute.
type AttributeSource int

const (
	_ AttributeSource = iota
	AttributeSourceLocal
	AttributeSourceRemote
)

// String returns the string representation of the AttributeSource.
func (av AttributeSource) String() string {
	switch av {
	case AttributeSourceLocal:
		return "local"
	case AttributeSourceRemote:
		return "remote"
	}
	return ""
}

// MapAttributeSource is a helper map of string to AttributeSource attribute value.
var MapAttributeSource = map[string]AttributeSource{
	"local":  AttributeSourceLocal,
	"remote": AttributeSourceRemote,
}

// AttributeStageTaskResult specifies the a value stage_task_result attribute.
type AttributeStageTaskResult int

const (
	_ AttributeStageTaskResult = iota
	AttributeStageTaskResultCompleted
	AttributeStageTaskResultFailed
	AttributeStageTaskResultKilled
)

// String returns the string representation of the AttributeStageTaskResult.
func (av AttributeStageTaskResult) String() string {
	switch av {
	case AttributeStageTaskResultCompleted:
		return "completed"
	case AttributeStageTaskResultFailed:
		return "failed"
	case AttributeStageTaskResultKilled:
		return "killed"
	}
	return ""
}

// MapAttributeStageTaskResult is a helper map of string to AttributeStageTaskResult attribute value.
var MapAttributeStageTaskResult = map[string]AttributeStageTaskResult{
	"completed": AttributeStageTaskResultCompleted,
	"failed":    AttributeStageTaskResultFailed,
	"killed":    AttributeStageTaskResultKilled,
}

type metricSparkComponenntExecutorMemoryExecution struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.componennt.executor.memory.execution metric with initial data.
func (m *metricSparkComponenntExecutorMemoryExecution) init() {
	m.data.SetName("spark.componennt.executor.memory.execution")
	m.data.SetDescription("Amount of execution memory currently used by the driver.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkComponenntExecutorMemoryExecution) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkComponenntExecutorMemoryExecution) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkComponenntExecutorMemoryExecution) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkComponenntExecutorMemoryExecution(cfg MetricConfig) metricSparkComponenntExecutorMemoryExecution {
	m := metricSparkComponenntExecutorMemoryExecution{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverBlockManagerDiskUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.block_manager.disk.usage metric with initial data.
func (m *metricSparkDriverBlockManagerDiskUsage) init() {
	m.data.SetName("spark.driver.block_manager.disk.usage")
	m.data.SetDescription("Disk space used by the BlockManager.")
	m.data.SetUnit("mb")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverBlockManagerDiskUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverBlockManagerDiskUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverBlockManagerDiskUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverBlockManagerDiskUsage(cfg MetricConfig) metricSparkDriverBlockManagerDiskUsage {
	m := metricSparkDriverBlockManagerDiskUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverBlockManagerMemoryRemaining struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.block_manager.memory.remaining metric with initial data.
func (m *metricSparkDriverBlockManagerMemoryRemaining) init() {
	m.data.SetName("spark.driver.block_manager.memory.remaining")
	m.data.SetDescription("Memory remaining for the BlockManager.")
	m.data.SetUnit("mb")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverBlockManagerMemoryRemaining) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverBlockManagerMemoryRemaining) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverBlockManagerMemoryRemaining) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverBlockManagerMemoryRemaining(cfg MetricConfig) metricSparkDriverBlockManagerMemoryRemaining {
	m := metricSparkDriverBlockManagerMemoryRemaining{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverBlockManagerMemoryUsed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.block_manager.memory.used metric with initial data.
func (m *metricSparkDriverBlockManagerMemoryUsed) init() {
	m.data.SetName("spark.driver.block_manager.memory.used")
	m.data.SetDescription("Memory used by the BlockManager.")
	m.data.SetUnit("mb")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverBlockManagerMemoryUsed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverBlockManagerMemoryUsed) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverBlockManagerMemoryUsed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverBlockManagerMemoryUsed(cfg MetricConfig) metricSparkDriverBlockManagerMemoryUsed {
	m := metricSparkDriverBlockManagerMemoryUsed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorCompilationAverageTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.compilation.average_time metric with initial data.
func (m *metricSparkDriverCodeGeneratorCompilationAverageTime) init() {
	m.data.SetName("spark.driver.code_generator.compilation.average_time")
	m.data.SetDescription("Average time spent during CodeGenerator source code compilation operations.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
}

func (m *metricSparkDriverCodeGeneratorCompilationAverageTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorCompilationAverageTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorCompilationAverageTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorCompilationAverageTime(cfg MetricConfig) metricSparkDriverCodeGeneratorCompilationAverageTime {
	m := metricSparkDriverCodeGeneratorCompilationAverageTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorCompilationCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.compilation.count metric with initial data.
func (m *metricSparkDriverCodeGeneratorCompilationCount) init() {
	m.data.SetName("spark.driver.code_generator.compilation.count")
	m.data.SetDescription("Number of source code compilation operations performed by the CodeGenerator.")
	m.data.SetUnit("{ compilation }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverCodeGeneratorCompilationCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorCompilationCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorCompilationCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorCompilationCount(cfg MetricConfig) metricSparkDriverCodeGeneratorCompilationCount {
	m := metricSparkDriverCodeGeneratorCompilationCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorGeneratedClassAverageSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.generated_class.average_size metric with initial data.
func (m *metricSparkDriverCodeGeneratorGeneratedClassAverageSize) init() {
	m.data.SetName("spark.driver.code_generator.generated_class.average_size")
	m.data.SetDescription("Average class size of the classes generated by the CodeGenerator.")
	m.data.SetUnit("bytes")
	m.data.SetEmptyGauge()
}

func (m *metricSparkDriverCodeGeneratorGeneratedClassAverageSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorGeneratedClassAverageSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorGeneratedClassAverageSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorGeneratedClassAverageSize(cfg MetricConfig) metricSparkDriverCodeGeneratorGeneratedClassAverageSize {
	m := metricSparkDriverCodeGeneratorGeneratedClassAverageSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorGeneratedClassCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.generated_class.count metric with initial data.
func (m *metricSparkDriverCodeGeneratorGeneratedClassCount) init() {
	m.data.SetName("spark.driver.code_generator.generated_class.count")
	m.data.SetDescription("Number of classes generated by the CodeGenerator.")
	m.data.SetUnit("{ class }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverCodeGeneratorGeneratedClassCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorGeneratedClassCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorGeneratedClassCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorGeneratedClassCount(cfg MetricConfig) metricSparkDriverCodeGeneratorGeneratedClassCount {
	m := metricSparkDriverCodeGeneratorGeneratedClassCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorGeneratedMethodAverageSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.generated_method.average_size metric with initial data.
func (m *metricSparkDriverCodeGeneratorGeneratedMethodAverageSize) init() {
	m.data.SetName("spark.driver.code_generator.generated_method.average_size")
	m.data.SetDescription("Average method size of the classes generated by the CodeGenerator.")
	m.data.SetUnit("bytes")
	m.data.SetEmptyGauge()
}

func (m *metricSparkDriverCodeGeneratorGeneratedMethodAverageSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorGeneratedMethodAverageSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorGeneratedMethodAverageSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorGeneratedMethodAverageSize(cfg MetricConfig) metricSparkDriverCodeGeneratorGeneratedMethodAverageSize {
	m := metricSparkDriverCodeGeneratorGeneratedMethodAverageSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorGeneratedMethodCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.generated_method.count metric with initial data.
func (m *metricSparkDriverCodeGeneratorGeneratedMethodCount) init() {
	m.data.SetName("spark.driver.code_generator.generated_method.count")
	m.data.SetDescription("Number of methods generated by the CodeGenerator.")
	m.data.SetUnit("{ method }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverCodeGeneratorGeneratedMethodCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorGeneratedMethodCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorGeneratedMethodCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorGeneratedMethodCount(cfg MetricConfig) metricSparkDriverCodeGeneratorGeneratedMethodCount {
	m := metricSparkDriverCodeGeneratorGeneratedMethodCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorSourceCodeAverageSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.source_code.average_size metric with initial data.
func (m *metricSparkDriverCodeGeneratorSourceCodeAverageSize) init() {
	m.data.SetName("spark.driver.code_generator.source_code.average_size")
	m.data.SetDescription("Average size of the source code generated by a CodeGenerator code generation operation.")
	m.data.SetUnit("bytes")
	m.data.SetEmptyGauge()
}

func (m *metricSparkDriverCodeGeneratorSourceCodeAverageSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorSourceCodeAverageSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorSourceCodeAverageSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorSourceCodeAverageSize(cfg MetricConfig) metricSparkDriverCodeGeneratorSourceCodeAverageSize {
	m := metricSparkDriverCodeGeneratorSourceCodeAverageSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorSourceCodeOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.source_code.operations metric with initial data.
func (m *metricSparkDriverCodeGeneratorSourceCodeOperations) init() {
	m.data.SetName("spark.driver.code_generator.source_code.operations")
	m.data.SetDescription("Number of source code generation operations performed by the CodeGenerator.")
	m.data.SetUnit("{ operation }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverCodeGeneratorSourceCodeOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorSourceCodeOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorSourceCodeOperations) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorSourceCodeOperations(cfg MetricConfig) metricSparkDriverCodeGeneratorSourceCodeOperations {
	m := metricSparkDriverCodeGeneratorSourceCodeOperations{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverDagSchedulerJobsActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.dag_scheduler.jobs.active metric with initial data.
func (m *metricSparkDriverDagSchedulerJobsActive) init() {
	m.data.SetName("spark.driver.dag_scheduler.jobs.active")
	m.data.SetDescription("Number of active jobs currently being processed by the DAGScheduler.")
	m.data.SetUnit("{ job }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverDagSchedulerJobsActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverDagSchedulerJobsActive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverDagSchedulerJobsActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverDagSchedulerJobsActive(cfg MetricConfig) metricSparkDriverDagSchedulerJobsActive {
	m := metricSparkDriverDagSchedulerJobsActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverDagSchedulerJobsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.dag_scheduler.jobs.count metric with initial data.
func (m *metricSparkDriverDagSchedulerJobsCount) init() {
	m.data.SetName("spark.driver.dag_scheduler.jobs.count")
	m.data.SetDescription("Number of jobs that have been submitted to the DAGScheduler.")
	m.data.SetUnit("{ job }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverDagSchedulerJobsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverDagSchedulerJobsCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverDagSchedulerJobsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverDagSchedulerJobsCount(cfg MetricConfig) metricSparkDriverDagSchedulerJobsCount {
	m := metricSparkDriverDagSchedulerJobsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverDagSchedulerStages struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.dag_scheduler.stages metric with initial data.
func (m *metricSparkDriverDagSchedulerStages) init() {
	m.data.SetName("spark.driver.dag_scheduler.stages")
	m.data.SetDescription("Number of stages the DAGScheduler is either running or needs to run.")
	m.data.SetUnit("{ stage }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverDagSchedulerStages) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, schedulerWaitingAttributeValue bool, schedulerRunningAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutBool("scheduler_waiting", schedulerWaitingAttributeValue)
	dp.Attributes().PutBool("scheduler_running", schedulerRunningAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverDagSchedulerStages) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverDagSchedulerStages) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverDagSchedulerStages(cfg MetricConfig) metricSparkDriverDagSchedulerStages {
	m := metricSparkDriverDagSchedulerStages{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverDagSchedulerStagesFailed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.dag_scheduler.stages.failed metric with initial data.
func (m *metricSparkDriverDagSchedulerStagesFailed) init() {
	m.data.SetName("spark.driver.dag_scheduler.stages.failed")
	m.data.SetDescription("Number of failed stages run by the DAGScheduler.")
	m.data.SetUnit("{ stage }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverDagSchedulerStagesFailed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverDagSchedulerStagesFailed) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverDagSchedulerStagesFailed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverDagSchedulerStagesFailed(cfg MetricConfig) metricSparkDriverDagSchedulerStagesFailed {
	m := metricSparkDriverDagSchedulerStagesFailed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverExecutorGcOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.executor.gc.operations metric with initial data.
func (m *metricSparkDriverExecutorGcOperations) init() {
	m.data.SetName("spark.driver.executor.gc.operations")
	m.data.SetDescription("Number of garbage collection operations performed by the driver.")
	m.data.SetUnit("{ gc_operation }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverExecutorGcOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, gcTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("gc_type", gcTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverExecutorGcOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverExecutorGcOperations) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverExecutorGcOperations(cfg MetricConfig) metricSparkDriverExecutorGcOperations {
	m := metricSparkDriverExecutorGcOperations{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverExecutorGcTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.executor.gc.time metric with initial data.
func (m *metricSparkDriverExecutorGcTime) init() {
	m.data.SetName("spark.driver.executor.gc.time")
	m.data.SetDescription("Total elapsed time during garbage collection operations performed by the driver.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverExecutorGcTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, gcTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("gc_type", gcTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverExecutorGcTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverExecutorGcTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverExecutorGcTime(cfg MetricConfig) metricSparkDriverExecutorGcTime {
	m := metricSparkDriverExecutorGcTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverExecutorJvmMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.executor.jvm_memory metric with initial data.
func (m *metricSparkDriverExecutorJvmMemory) init() {
	m.data.SetName("spark.driver.executor.jvm_memory")
	m.data.SetDescription("Amount of memory used by the driver's JVM.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverExecutorJvmMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverExecutorJvmMemory) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverExecutorJvmMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverExecutorJvmMemory(cfg MetricConfig) metricSparkDriverExecutorJvmMemory {
	m := metricSparkDriverExecutorJvmMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverExecutorMemoryPool struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.executor.memory.pool metric with initial data.
func (m *metricSparkDriverExecutorMemoryPool) init() {
	m.data.SetName("spark.driver.executor.memory.pool")
	m.data.SetDescription("Amount of pool memory currently used by the driver.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverExecutorMemoryPool) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, poolMemoryTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("pool_memory_type", poolMemoryTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverExecutorMemoryPool) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverExecutorMemoryPool) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverExecutorMemoryPool(cfg MetricConfig) metricSparkDriverExecutorMemoryPool {
	m := metricSparkDriverExecutorMemoryPool{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverExecutorMemoryStorage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.executor.memory.storage metric with initial data.
func (m *metricSparkDriverExecutorMemoryStorage) init() {
	m.data.SetName("spark.driver.executor.memory.storage")
	m.data.SetDescription("Amount of storage memory currently used by the driver.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverExecutorMemoryStorage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverExecutorMemoryStorage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverExecutorMemoryStorage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverExecutorMemoryStorage(cfg MetricConfig) metricSparkDriverExecutorMemoryStorage {
	m := metricSparkDriverExecutorMemoryStorage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverHiveExternalCatalogFileCacheHits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.hive_external_catalog.file_cache_hits metric with initial data.
func (m *metricSparkDriverHiveExternalCatalogFileCacheHits) init() {
	m.data.SetName("spark.driver.hive_external_catalog.file_cache_hits")
	m.data.SetDescription("Number of file cache hits on the HiveExternalCatalog.")
	m.data.SetUnit("{ hit }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverHiveExternalCatalogFileCacheHits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverHiveExternalCatalogFileCacheHits) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverHiveExternalCatalogFileCacheHits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverHiveExternalCatalogFileCacheHits(cfg MetricConfig) metricSparkDriverHiveExternalCatalogFileCacheHits {
	m := metricSparkDriverHiveExternalCatalogFileCacheHits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverHiveExternalCatalogFilesDiscovered struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.hive_external_catalog.files_discovered metric with initial data.
func (m *metricSparkDriverHiveExternalCatalogFilesDiscovered) init() {
	m.data.SetName("spark.driver.hive_external_catalog.files_discovered")
	m.data.SetDescription("Number of files discovered while listing the partitions of a table in the Hive metastore")
	m.data.SetUnit("{ file }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverHiveExternalCatalogFilesDiscovered) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverHiveExternalCatalogFilesDiscovered) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverHiveExternalCatalogFilesDiscovered) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverHiveExternalCatalogFilesDiscovered(cfg MetricConfig) metricSparkDriverHiveExternalCatalogFilesDiscovered {
	m := metricSparkDriverHiveExternalCatalogFilesDiscovered{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverHiveExternalCatalogHiveClientCalls struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.hive_external_catalog.hive_client_calls metric with initial data.
func (m *metricSparkDriverHiveExternalCatalogHiveClientCalls) init() {
	m.data.SetName("spark.driver.hive_external_catalog.hive_client_calls")
	m.data.SetDescription("Number of calls to the underlying Hive Metastore client made by the Spark application.")
	m.data.SetUnit("{ call }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverHiveExternalCatalogHiveClientCalls) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverHiveExternalCatalogHiveClientCalls) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverHiveExternalCatalogHiveClientCalls) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverHiveExternalCatalogHiveClientCalls(cfg MetricConfig) metricSparkDriverHiveExternalCatalogHiveClientCalls {
	m := metricSparkDriverHiveExternalCatalogHiveClientCalls{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverHiveExternalCatalogParallelListingJobs struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.hive_external_catalog.parallel_listing_jobs metric with initial data.
func (m *metricSparkDriverHiveExternalCatalogParallelListingJobs) init() {
	m.data.SetName("spark.driver.hive_external_catalog.parallel_listing_jobs")
	m.data.SetDescription("Number of parallel listing jobs initiated by the HiveExternalCatalog when listing partitions of a table.")
	m.data.SetUnit("{ listing_job }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverHiveExternalCatalogParallelListingJobs) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverHiveExternalCatalogParallelListingJobs) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverHiveExternalCatalogParallelListingJobs) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverHiveExternalCatalogParallelListingJobs(cfg MetricConfig) metricSparkDriverHiveExternalCatalogParallelListingJobs {
	m := metricSparkDriverHiveExternalCatalogParallelListingJobs{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverHiveExternalCatalogPartitionsFetched struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.hive_external_catalog.partitions_fetched metric with initial data.
func (m *metricSparkDriverHiveExternalCatalogPartitionsFetched) init() {
	m.data.SetName("spark.driver.hive_external_catalog.partitions_fetched")
	m.data.SetDescription("Table partitions fetched by the HiveExternalCatalog.")
	m.data.SetUnit("{ partition }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverHiveExternalCatalogPartitionsFetched) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverHiveExternalCatalogPartitionsFetched) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverHiveExternalCatalogPartitionsFetched) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverHiveExternalCatalogPartitionsFetched(cfg MetricConfig) metricSparkDriverHiveExternalCatalogPartitionsFetched {
	m := metricSparkDriverHiveExternalCatalogPartitionsFetched{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverJvmCPUTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.jvm_cpu_time metric with initial data.
func (m *metricSparkDriverJvmCPUTime) init() {
	m.data.SetName("spark.driver.jvm_cpu_time")
	m.data.SetDescription("Current CPU time taken by the Spark driver.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverJvmCPUTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverJvmCPUTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverJvmCPUTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverJvmCPUTime(cfg MetricConfig) metricSparkDriverJvmCPUTime {
	m := metricSparkDriverJvmCPUTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverLiveListenerBusEventsDropped struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.live_listener_bus.events_dropped metric with initial data.
func (m *metricSparkDriverLiveListenerBusEventsDropped) init() {
	m.data.SetName("spark.driver.live_listener_bus.events_dropped")
	m.data.SetDescription("Number of events that have been dropped by the LiveListenerBus.")
	m.data.SetUnit("{ event }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverLiveListenerBusEventsDropped) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverLiveListenerBusEventsDropped) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverLiveListenerBusEventsDropped) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverLiveListenerBusEventsDropped(cfg MetricConfig) metricSparkDriverLiveListenerBusEventsDropped {
	m := metricSparkDriverLiveListenerBusEventsDropped{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverLiveListenerBusEventsPosted struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.live_listener_bus.events_posted metric with initial data.
func (m *metricSparkDriverLiveListenerBusEventsPosted) init() {
	m.data.SetName("spark.driver.live_listener_bus.events_posted")
	m.data.SetDescription("Number of events that have been posted on the LiveListenerBus.")
	m.data.SetUnit("{ event }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverLiveListenerBusEventsPosted) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverLiveListenerBusEventsPosted) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverLiveListenerBusEventsPosted) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverLiveListenerBusEventsPosted(cfg MetricConfig) metricSparkDriverLiveListenerBusEventsPosted {
	m := metricSparkDriverLiveListenerBusEventsPosted{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverLiveListenerBusProcessingTimeAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.live_listener_bus.processing_time.average metric with initial data.
func (m *metricSparkDriverLiveListenerBusProcessingTimeAverage) init() {
	m.data.SetName("spark.driver.live_listener_bus.processing_time.average")
	m.data.SetDescription("Average time taken for the LiveListenerBus to process an event posted to it.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
}

func (m *metricSparkDriverLiveListenerBusProcessingTimeAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverLiveListenerBusProcessingTimeAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverLiveListenerBusProcessingTimeAverage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverLiveListenerBusProcessingTimeAverage(cfg MetricConfig) metricSparkDriverLiveListenerBusProcessingTimeAverage {
	m := metricSparkDriverLiveListenerBusProcessingTimeAverage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverLiveListenerBusQueueSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.live_listener_bus.queue_size metric with initial data.
func (m *metricSparkDriverLiveListenerBusQueueSize) init() {
	m.data.SetName("spark.driver.live_listener_bus.queue_size")
	m.data.SetDescription("Number of events currently waiting to be processed by the LiveListenerBus.")
	m.data.SetUnit("{ event }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverLiveListenerBusQueueSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverLiveListenerBusQueueSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverLiveListenerBusQueueSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverLiveListenerBusQueueSize(cfg MetricConfig) metricSparkDriverLiveListenerBusQueueSize {
	m := metricSparkDriverLiveListenerBusQueueSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorDiskUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.disk.usage metric with initial data.
func (m *metricSparkExecutorDiskUsage) init() {
	m.data.SetName("spark.executor.disk.usage")
	m.data.SetDescription("Disk space used by this executor for RDD storage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorDiskUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorDiskUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorDiskUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorDiskUsage(cfg MetricConfig) metricSparkExecutorDiskUsage {
	m := metricSparkExecutorDiskUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorGcTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.gc_time metric with initial data.
func (m *metricSparkExecutorGcTime) init() {
	m.data.SetName("spark.executor.gc_time")
	m.data.SetDescription("Elapsed time the JVM spent in garbage collection in this executor.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorGcTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorGcTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorGcTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorGcTime(cfg MetricConfig) metricSparkExecutorGcTime {
	m := metricSparkExecutorGcTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorInputSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.input_size metric with initial data.
func (m *metricSparkExecutorInputSize) init() {
	m.data.SetName("spark.executor.input_size")
	m.data.SetDescription("Amount of data input for this executor.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorInputSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorInputSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorInputSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorInputSize(cfg MetricConfig) metricSparkExecutorInputSize {
	m := metricSparkExecutorInputSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorMemoryUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.memory.usage metric with initial data.
func (m *metricSparkExecutorMemoryUsage) init() {
	m.data.SetName("spark.executor.memory.usage")
	m.data.SetDescription("Storage memory used by this executor.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorMemoryUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorMemoryUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorMemoryUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorMemoryUsage(cfg MetricConfig) metricSparkExecutorMemoryUsage {
	m := metricSparkExecutorMemoryUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorShuffleIoSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.shuffle.io.size metric with initial data.
func (m *metricSparkExecutorShuffleIoSize) init() {
	m.data.SetName("spark.executor.shuffle.io.size")
	m.data.SetDescription("Amount of data written and read during shuffle operations for this executor.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorShuffleIoSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorShuffleIoSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorShuffleIoSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorShuffleIoSize(cfg MetricConfig) metricSparkExecutorShuffleIoSize {
	m := metricSparkExecutorShuffleIoSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorStorageMemoryTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.storage_memory.total metric with initial data.
func (m *metricSparkExecutorStorageMemoryTotal) init() {
	m.data.SetName("spark.executor.storage_memory.total")
	m.data.SetDescription("Total memory that can be used for storage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorStorageMemoryTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorStorageMemoryTotal) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorStorageMemoryTotal) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorStorageMemoryTotal(cfg MetricConfig) metricSparkExecutorStorageMemoryTotal {
	m := metricSparkExecutorStorageMemoryTotal{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorStorageMemoryUsed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.storage_memory.used metric with initial data.
func (m *metricSparkExecutorStorageMemoryUsed) init() {
	m.data.SetName("spark.executor.storage_memory.used")
	m.data.SetDescription("Amount of memory currently used for storage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorStorageMemoryUsed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorStorageMemoryUsed) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorStorageMemoryUsed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorStorageMemoryUsed(cfg MetricConfig) metricSparkExecutorStorageMemoryUsed {
	m := metricSparkExecutorStorageMemoryUsed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorTasksActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.tasks.active metric with initial data.
func (m *metricSparkExecutorTasksActive) init() {
	m.data.SetName("spark.executor.tasks.active")
	m.data.SetDescription("Number of tasks currently running in this executor.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorTasksActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorTasksActive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorTasksActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorTasksActive(cfg MetricConfig) metricSparkExecutorTasksActive {
	m := metricSparkExecutorTasksActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorTasksMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.tasks.max metric with initial data.
func (m *metricSparkExecutorTasksMax) init() {
	m.data.SetName("spark.executor.tasks.max")
	m.data.SetDescription("Maximum number of tasks that can run concurrently in this executor.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorTasksMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorTasksMax) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorTasksMax) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorTasksMax(cfg MetricConfig) metricSparkExecutorTasksMax {
	m := metricSparkExecutorTasksMax{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorTasksResults struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.tasks.results metric with initial data.
func (m *metricSparkExecutorTasksResults) init() {
	m.data.SetName("spark.executor.tasks.results")
	m.data.SetDescription("Number of tasks with a specific result in this executor.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorTasksResults) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, executorTaskResultAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("executor_task_result", executorTaskResultAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorTasksResults) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorTasksResults) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorTasksResults(cfg MetricConfig) metricSparkExecutorTasksResults {
	m := metricSparkExecutorTasksResults{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.time metric with initial data.
func (m *metricSparkExecutorTime) init() {
	m.data.SetName("spark.executor.time")
	m.data.SetDescription("Elapsed time the JVM spent executing tasks in this executor.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorTime(cfg MetricConfig) metricSparkExecutorTime {
	m := metricSparkExecutorTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkJobStagesActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.job.stages.active metric with initial data.
func (m *metricSparkJobStagesActive) init() {
	m.data.SetName("spark.job.stages.active")
	m.data.SetDescription("Number of active stages in this job.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkJobStagesActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkJobStagesActive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkJobStagesActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkJobStagesActive(cfg MetricConfig) metricSparkJobStagesActive {
	m := metricSparkJobStagesActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkJobStagesResults struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.job.stages.results metric with initial data.
func (m *metricSparkJobStagesResults) init() {
	m.data.SetName("spark.job.stages.results")
	m.data.SetDescription("Number of stages with a specific result in this job.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkJobStagesResults) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, jobStageResultAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("job_stage_result", jobStageResultAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkJobStagesResults) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkJobStagesResults) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkJobStagesResults(cfg MetricConfig) metricSparkJobStagesResults {
	m := metricSparkJobStagesResults{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkJobTasksActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.job.tasks.active metric with initial data.
func (m *metricSparkJobTasksActive) init() {
	m.data.SetName("spark.job.tasks.active")
	m.data.SetDescription("Number of active tasks in this job.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkJobTasksActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkJobTasksActive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkJobTasksActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkJobTasksActive(cfg MetricConfig) metricSparkJobTasksActive {
	m := metricSparkJobTasksActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkJobTasksResults struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.job.tasks.results metric with initial data.
func (m *metricSparkJobTasksResults) init() {
	m.data.SetName("spark.job.tasks.results")
	m.data.SetDescription("Number of tasks with a specific result in this job.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkJobTasksResults) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, jobTaskResultAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("job_task_result", jobTaskResultAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkJobTasksResults) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkJobTasksResults) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkJobTasksResults(cfg MetricConfig) metricSparkJobTasksResults {
	m := metricSparkJobTasksResults{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageDiskSpilled struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.disk.spilled metric with initial data.
func (m *metricSparkStageDiskSpilled) init() {
	m.data.SetName("spark.stage.disk.spilled")
	m.data.SetDescription("The amount of disk space used for storing portions of overly large data chunks that couldnt fit in memory in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageDiskSpilled) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageDiskSpilled) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageDiskSpilled) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageDiskSpilled(cfg MetricConfig) metricSparkStageDiskSpilled {
	m := metricSparkStageDiskSpilled{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageExecutorCPUTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.executor.cpu_time metric with initial data.
func (m *metricSparkStageExecutorCPUTime) init() {
	m.data.SetName("spark.stage.executor.cpu_time")
	m.data.SetDescription("CPU time spent by the executor in this stage.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageExecutorCPUTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageExecutorCPUTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageExecutorCPUTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageExecutorCPUTime(cfg MetricConfig) metricSparkStageExecutorCPUTime {
	m := metricSparkStageExecutorCPUTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageExecutorRunTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.executor.run_time metric with initial data.
func (m *metricSparkStageExecutorRunTime) init() {
	m.data.SetName("spark.stage.executor.run_time")
	m.data.SetDescription("Amount of time spent by the executor in this stage.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageExecutorRunTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageExecutorRunTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageExecutorRunTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageExecutorRunTime(cfg MetricConfig) metricSparkStageExecutorRunTime {
	m := metricSparkStageExecutorRunTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageIoRecords struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.io.records metric with initial data.
func (m *metricSparkStageIoRecords) init() {
	m.data.SetName("spark.stage.io.records")
	m.data.SetDescription("Number of records written and read in this stage.")
	m.data.SetUnit("{ record }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageIoRecords) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageIoRecords) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageIoRecords) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageIoRecords(cfg MetricConfig) metricSparkStageIoRecords {
	m := metricSparkStageIoRecords{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageIoSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.io.size metric with initial data.
func (m *metricSparkStageIoSize) init() {
	m.data.SetName("spark.stage.io.size")
	m.data.SetDescription("Amount of data written and read at this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageIoSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageIoSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageIoSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageIoSize(cfg MetricConfig) metricSparkStageIoSize {
	m := metricSparkStageIoSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageJvmGcTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.jvm_gc_time metric with initial data.
func (m *metricSparkStageJvmGcTime) init() {
	m.data.SetName("spark.stage.jvm_gc_time")
	m.data.SetDescription("The amount of time the JVM spent on garbage collection in this stage.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageJvmGcTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageJvmGcTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageJvmGcTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageJvmGcTime(cfg MetricConfig) metricSparkStageJvmGcTime {
	m := metricSparkStageJvmGcTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageMemoryPeak struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.memory.peak metric with initial data.
func (m *metricSparkStageMemoryPeak) init() {
	m.data.SetName("spark.stage.memory.peak")
	m.data.SetDescription("Peak memory used by internal data structures created during shuffles, aggregations and joins in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageMemoryPeak) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageMemoryPeak) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageMemoryPeak) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageMemoryPeak(cfg MetricConfig) metricSparkStageMemoryPeak {
	m := metricSparkStageMemoryPeak{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageMemorySpilled struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.memory.spilled metric with initial data.
func (m *metricSparkStageMemorySpilled) init() {
	m.data.SetName("spark.stage.memory.spilled")
	m.data.SetDescription("The amount of memory moved to disk due to size constraints (spilled) in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageMemorySpilled) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageMemorySpilled) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageMemorySpilled) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageMemorySpilled(cfg MetricConfig) metricSparkStageMemorySpilled {
	m := metricSparkStageMemorySpilled{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleBlocksFetched struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.blocks_fetched metric with initial data.
func (m *metricSparkStageShuffleBlocksFetched) init() {
	m.data.SetName("spark.stage.shuffle.blocks_fetched")
	m.data.SetDescription("Number of blocks fetched in shuffle operations in this stage.")
	m.data.SetUnit("{ block }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageShuffleBlocksFetched) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, sourceAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
	dp.Attributes().PutStr("source", sourceAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleBlocksFetched) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleBlocksFetched) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleBlocksFetched(cfg MetricConfig) metricSparkStageShuffleBlocksFetched {
	m := metricSparkStageShuffleBlocksFetched{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleFetchWaitTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.fetch_wait_time metric with initial data.
func (m *metricSparkStageShuffleFetchWaitTime) init() {
	m.data.SetName("spark.stage.shuffle.fetch_wait_time")
	m.data.SetDescription("Time spent in this stage waiting for remote shuffle blocks.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageShuffleFetchWaitTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleFetchWaitTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleFetchWaitTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleFetchWaitTime(cfg MetricConfig) metricSparkStageShuffleFetchWaitTime {
	m := metricSparkStageShuffleFetchWaitTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleIoDisk struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.io.disk metric with initial data.
func (m *metricSparkStageShuffleIoDisk) init() {
	m.data.SetName("spark.stage.shuffle.io.disk")
	m.data.SetDescription("Amount of data read to disk in shuffle operations (sometimes required for large blocks, as opposed to the default behavior of reading into memory).")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageShuffleIoDisk) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleIoDisk) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleIoDisk) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleIoDisk(cfg MetricConfig) metricSparkStageShuffleIoDisk {
	m := metricSparkStageShuffleIoDisk{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleIoRecords struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.io.records metric with initial data.
func (m *metricSparkStageShuffleIoRecords) init() {
	m.data.SetName("spark.stage.shuffle.io.records")
	m.data.SetDescription("Number of records written or read in shuffle operations in this stage.")
	m.data.SetUnit("{ record }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageShuffleIoRecords) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleIoRecords) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleIoRecords) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleIoRecords(cfg MetricConfig) metricSparkStageShuffleIoRecords {
	m := metricSparkStageShuffleIoRecords{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleIoSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.io.size metric with initial data.
func (m *metricSparkStageShuffleIoSize) init() {
	m.data.SetName("spark.stage.shuffle.io.size")
	m.data.SetDescription("Amount of data written or read in shuffle operations in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageShuffleIoSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, sourceAttributeValue string, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
	dp.Attributes().PutStr("source", sourceAttributeValue)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleIoSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleIoSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleIoSize(cfg MetricConfig) metricSparkStageShuffleIoSize {
	m := metricSparkStageShuffleIoSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleWriteTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.write_time metric with initial data.
func (m *metricSparkStageShuffleWriteTime) init() {
	m.data.SetName("spark.stage.shuffle.write_time")
	m.data.SetDescription("Time spent blocking on writes to disk or buffer cache in this stage.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageShuffleWriteTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleWriteTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleWriteTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleWriteTime(cfg MetricConfig) metricSparkStageShuffleWriteTime {
	m := metricSparkStageShuffleWriteTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageTaskActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.task.active metric with initial data.
func (m *metricSparkStageTaskActive) init() {
	m.data.SetName("spark.stage.task.active")
	m.data.SetDescription("Number of active tasks in this stage.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageTaskActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageTaskActive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageTaskActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageTaskActive(cfg MetricConfig) metricSparkStageTaskActive {
	m := metricSparkStageTaskActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageTaskResultSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.task.result_size metric with initial data.
func (m *metricSparkStageTaskResultSize) init() {
	m.data.SetName("spark.stage.task.result_size")
	m.data.SetDescription("The amount of data transmitted back to the driver by all the tasks in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageTaskResultSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageTaskResultSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageTaskResultSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageTaskResultSize(cfg MetricConfig) metricSparkStageTaskResultSize {
	m := metricSparkStageTaskResultSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageTaskResults struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.task.results metric with initial data.
func (m *metricSparkStageTaskResults) init() {
	m.data.SetName("spark.stage.task.results")
	m.data.SetDescription("Number of tasks with a specific result in this stage.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageTaskResults) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, stageTaskResultAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
	dp.Attributes().PutStr("stage_task_result", stageTaskResultAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageTaskResults) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageTaskResults) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageTaskResults(cfg MetricConfig) metricSparkStageTaskResults {
	m := metricSparkStageTaskResults{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	startTime                                                pcommon.Timestamp   // start time that will be applied to all recorded data points.
	metricsCapacity                                          int                 // maximum observed number of metrics per resource.
	resourceCapacity                                         int                 // maximum observed number of resource attributes.
	metricsBuffer                                            pmetric.Metrics     // accumulates metrics data before emitting.
	buildInfo                                                component.BuildInfo // contains version information
	resourceAttributesConfig                                 ResourceAttributesConfig
	metricSparkComponenntExecutorMemoryExecution             metricSparkComponenntExecutorMemoryExecution
	metricSparkDriverBlockManagerDiskUsage                   metricSparkDriverBlockManagerDiskUsage
	metricSparkDriverBlockManagerMemoryRemaining             metricSparkDriverBlockManagerMemoryRemaining
	metricSparkDriverBlockManagerMemoryUsed                  metricSparkDriverBlockManagerMemoryUsed
	metricSparkDriverCodeGeneratorCompilationAverageTime     metricSparkDriverCodeGeneratorCompilationAverageTime
	metricSparkDriverCodeGeneratorCompilationCount           metricSparkDriverCodeGeneratorCompilationCount
	metricSparkDriverCodeGeneratorGeneratedClassAverageSize  metricSparkDriverCodeGeneratorGeneratedClassAverageSize
	metricSparkDriverCodeGeneratorGeneratedClassCount        metricSparkDriverCodeGeneratorGeneratedClassCount
	metricSparkDriverCodeGeneratorGeneratedMethodAverageSize metricSparkDriverCodeGeneratorGeneratedMethodAverageSize
	metricSparkDriverCodeGeneratorGeneratedMethodCount       metricSparkDriverCodeGeneratorGeneratedMethodCount
	metricSparkDriverCodeGeneratorSourceCodeAverageSize      metricSparkDriverCodeGeneratorSourceCodeAverageSize
	metricSparkDriverCodeGeneratorSourceCodeOperations       metricSparkDriverCodeGeneratorSourceCodeOperations
	metricSparkDriverDagSchedulerJobsActive                  metricSparkDriverDagSchedulerJobsActive
	metricSparkDriverDagSchedulerJobsCount                   metricSparkDriverDagSchedulerJobsCount
	metricSparkDriverDagSchedulerStages                      metricSparkDriverDagSchedulerStages
	metricSparkDriverDagSchedulerStagesFailed                metricSparkDriverDagSchedulerStagesFailed
	metricSparkDriverExecutorGcOperations                    metricSparkDriverExecutorGcOperations
	metricSparkDriverExecutorGcTime                          metricSparkDriverExecutorGcTime
	metricSparkDriverExecutorJvmMemory                       metricSparkDriverExecutorJvmMemory
	metricSparkDriverExecutorMemoryPool                      metricSparkDriverExecutorMemoryPool
	metricSparkDriverExecutorMemoryStorage                   metricSparkDriverExecutorMemoryStorage
	metricSparkDriverHiveExternalCatalogFileCacheHits        metricSparkDriverHiveExternalCatalogFileCacheHits
	metricSparkDriverHiveExternalCatalogFilesDiscovered      metricSparkDriverHiveExternalCatalogFilesDiscovered
	metricSparkDriverHiveExternalCatalogHiveClientCalls      metricSparkDriverHiveExternalCatalogHiveClientCalls
	metricSparkDriverHiveExternalCatalogParallelListingJobs  metricSparkDriverHiveExternalCatalogParallelListingJobs
	metricSparkDriverHiveExternalCatalogPartitionsFetched    metricSparkDriverHiveExternalCatalogPartitionsFetched
	metricSparkDriverJvmCPUTime                              metricSparkDriverJvmCPUTime
	metricSparkDriverLiveListenerBusEventsDropped            metricSparkDriverLiveListenerBusEventsDropped
	metricSparkDriverLiveListenerBusEventsPosted             metricSparkDriverLiveListenerBusEventsPosted
	metricSparkDriverLiveListenerBusProcessingTimeAverage    metricSparkDriverLiveListenerBusProcessingTimeAverage
	metricSparkDriverLiveListenerBusQueueSize                metricSparkDriverLiveListenerBusQueueSize
	metricSparkExecutorDiskUsage                             metricSparkExecutorDiskUsage
	metricSparkExecutorGcTime                                metricSparkExecutorGcTime
	metricSparkExecutorInputSize                             metricSparkExecutorInputSize
	metricSparkExecutorMemoryUsage                           metricSparkExecutorMemoryUsage
	metricSparkExecutorShuffleIoSize                         metricSparkExecutorShuffleIoSize
	metricSparkExecutorStorageMemoryTotal                    metricSparkExecutorStorageMemoryTotal
	metricSparkExecutorStorageMemoryUsed                     metricSparkExecutorStorageMemoryUsed
	metricSparkExecutorTasksActive                           metricSparkExecutorTasksActive
	metricSparkExecutorTasksMax                              metricSparkExecutorTasksMax
	metricSparkExecutorTasksResults                          metricSparkExecutorTasksResults
	metricSparkExecutorTime                                  metricSparkExecutorTime
	metricSparkJobStagesActive                               metricSparkJobStagesActive
	metricSparkJobStagesResults                              metricSparkJobStagesResults
	metricSparkJobTasksActive                                metricSparkJobTasksActive
	metricSparkJobTasksResults                               metricSparkJobTasksResults
	metricSparkStageDiskSpilled                              metricSparkStageDiskSpilled
	metricSparkStageExecutorCPUTime                          metricSparkStageExecutorCPUTime
	metricSparkStageExecutorRunTime                          metricSparkStageExecutorRunTime
	metricSparkStageIoRecords                                metricSparkStageIoRecords
	metricSparkStageIoSize                                   metricSparkStageIoSize
	metricSparkStageJvmGcTime                                metricSparkStageJvmGcTime
	metricSparkStageMemoryPeak                               metricSparkStageMemoryPeak
	metricSparkStageMemorySpilled                            metricSparkStageMemorySpilled
	metricSparkStageShuffleBlocksFetched                     metricSparkStageShuffleBlocksFetched
	metricSparkStageShuffleFetchWaitTime                     metricSparkStageShuffleFetchWaitTime
	metricSparkStageShuffleIoDisk                            metricSparkStageShuffleIoDisk
	metricSparkStageShuffleIoRecords                         metricSparkStageShuffleIoRecords
	metricSparkStageShuffleIoSize                            metricSparkStageShuffleIoSize
	metricSparkStageShuffleWriteTime                         metricSparkStageShuffleWriteTime
	metricSparkStageTaskActive                               metricSparkStageTaskActive
	metricSparkStageTaskResultSize                           metricSparkStageTaskResultSize
	metricSparkStageTaskResults                              metricSparkStageTaskResults
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.CreateSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		startTime:                pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:            pmetric.NewMetrics(),
		buildInfo:                settings.BuildInfo,
		resourceAttributesConfig: mbc.ResourceAttributes,
		metricSparkComponenntExecutorMemoryExecution:             newMetricSparkComponenntExecutorMemoryExecution(mbc.Metrics.SparkComponenntExecutorMemoryExecution),
		metricSparkDriverBlockManagerDiskUsage:                   newMetricSparkDriverBlockManagerDiskUsage(mbc.Metrics.SparkDriverBlockManagerDiskUsage),
		metricSparkDriverBlockManagerMemoryRemaining:             newMetricSparkDriverBlockManagerMemoryRemaining(mbc.Metrics.SparkDriverBlockManagerMemoryRemaining),
		metricSparkDriverBlockManagerMemoryUsed:                  newMetricSparkDriverBlockManagerMemoryUsed(mbc.Metrics.SparkDriverBlockManagerMemoryUsed),
		metricSparkDriverCodeGeneratorCompilationAverageTime:     newMetricSparkDriverCodeGeneratorCompilationAverageTime(mbc.Metrics.SparkDriverCodeGeneratorCompilationAverageTime),
		metricSparkDriverCodeGeneratorCompilationCount:           newMetricSparkDriverCodeGeneratorCompilationCount(mbc.Metrics.SparkDriverCodeGeneratorCompilationCount),
		metricSparkDriverCodeGeneratorGeneratedClassAverageSize:  newMetricSparkDriverCodeGeneratorGeneratedClassAverageSize(mbc.Metrics.SparkDriverCodeGeneratorGeneratedClassAverageSize),
		metricSparkDriverCodeGeneratorGeneratedClassCount:        newMetricSparkDriverCodeGeneratorGeneratedClassCount(mbc.Metrics.SparkDriverCodeGeneratorGeneratedClassCount),
		metricSparkDriverCodeGeneratorGeneratedMethodAverageSize: newMetricSparkDriverCodeGeneratorGeneratedMethodAverageSize(mbc.Metrics.SparkDriverCodeGeneratorGeneratedMethodAverageSize),
		metricSparkDriverCodeGeneratorGeneratedMethodCount:       newMetricSparkDriverCodeGeneratorGeneratedMethodCount(mbc.Metrics.SparkDriverCodeGeneratorGeneratedMethodCount),
		metricSparkDriverCodeGeneratorSourceCodeAverageSize:      newMetricSparkDriverCodeGeneratorSourceCodeAverageSize(mbc.Metrics.SparkDriverCodeGeneratorSourceCodeAverageSize),
		metricSparkDriverCodeGeneratorSourceCodeOperations:       newMetricSparkDriverCodeGeneratorSourceCodeOperations(mbc.Metrics.SparkDriverCodeGeneratorSourceCodeOperations),
		metricSparkDriverDagSchedulerJobsActive:                  newMetricSparkDriverDagSchedulerJobsActive(mbc.Metrics.SparkDriverDagSchedulerJobsActive),
		metricSparkDriverDagSchedulerJobsCount:                   newMetricSparkDriverDagSchedulerJobsCount(mbc.Metrics.SparkDriverDagSchedulerJobsCount),
		metricSparkDriverDagSchedulerStages:                      newMetricSparkDriverDagSchedulerStages(mbc.Metrics.SparkDriverDagSchedulerStages),
		metricSparkDriverDagSchedulerStagesFailed:                newMetricSparkDriverDagSchedulerStagesFailed(mbc.Metrics.SparkDriverDagSchedulerStagesFailed),
		metricSparkDriverExecutorGcOperations:                    newMetricSparkDriverExecutorGcOperations(mbc.Metrics.SparkDriverExecutorGcOperations),
		metricSparkDriverExecutorGcTime:                          newMetricSparkDriverExecutorGcTime(mbc.Metrics.SparkDriverExecutorGcTime),
		metricSparkDriverExecutorJvmMemory:                       newMetricSparkDriverExecutorJvmMemory(mbc.Metrics.SparkDriverExecutorJvmMemory),
		metricSparkDriverExecutorMemoryPool:                      newMetricSparkDriverExecutorMemoryPool(mbc.Metrics.SparkDriverExecutorMemoryPool),
		metricSparkDriverExecutorMemoryStorage:                   newMetricSparkDriverExecutorMemoryStorage(mbc.Metrics.SparkDriverExecutorMemoryStorage),
		metricSparkDriverHiveExternalCatalogFileCacheHits:        newMetricSparkDriverHiveExternalCatalogFileCacheHits(mbc.Metrics.SparkDriverHiveExternalCatalogFileCacheHits),
		metricSparkDriverHiveExternalCatalogFilesDiscovered:      newMetricSparkDriverHiveExternalCatalogFilesDiscovered(mbc.Metrics.SparkDriverHiveExternalCatalogFilesDiscovered),
		metricSparkDriverHiveExternalCatalogHiveClientCalls:      newMetricSparkDriverHiveExternalCatalogHiveClientCalls(mbc.Metrics.SparkDriverHiveExternalCatalogHiveClientCalls),
		metricSparkDriverHiveExternalCatalogParallelListingJobs:  newMetricSparkDriverHiveExternalCatalogParallelListingJobs(mbc.Metrics.SparkDriverHiveExternalCatalogParallelListingJobs),
		metricSparkDriverHiveExternalCatalogPartitionsFetched:    newMetricSparkDriverHiveExternalCatalogPartitionsFetched(mbc.Metrics.SparkDriverHiveExternalCatalogPartitionsFetched),
		metricSparkDriverJvmCPUTime:                              newMetricSparkDriverJvmCPUTime(mbc.Metrics.SparkDriverJvmCPUTime),
		metricSparkDriverLiveListenerBusEventsDropped:            newMetricSparkDriverLiveListenerBusEventsDropped(mbc.Metrics.SparkDriverLiveListenerBusEventsDropped),
		metricSparkDriverLiveListenerBusEventsPosted:             newMetricSparkDriverLiveListenerBusEventsPosted(mbc.Metrics.SparkDriverLiveListenerBusEventsPosted),
		metricSparkDriverLiveListenerBusProcessingTimeAverage:    newMetricSparkDriverLiveListenerBusProcessingTimeAverage(mbc.Metrics.SparkDriverLiveListenerBusProcessingTimeAverage),
		metricSparkDriverLiveListenerBusQueueSize:                newMetricSparkDriverLiveListenerBusQueueSize(mbc.Metrics.SparkDriverLiveListenerBusQueueSize),
		metricSparkExecutorDiskUsage:                             newMetricSparkExecutorDiskUsage(mbc.Metrics.SparkExecutorDiskUsage),
		metricSparkExecutorGcTime:                                newMetricSparkExecutorGcTime(mbc.Metrics.SparkExecutorGcTime),
		metricSparkExecutorInputSize:                             newMetricSparkExecutorInputSize(mbc.Metrics.SparkExecutorInputSize),
		metricSparkExecutorMemoryUsage:                           newMetricSparkExecutorMemoryUsage(mbc.Metrics.SparkExecutorMemoryUsage),
		metricSparkExecutorShuffleIoSize:                         newMetricSparkExecutorShuffleIoSize(mbc.Metrics.SparkExecutorShuffleIoSize),
		metricSparkExecutorStorageMemoryTotal:                    newMetricSparkExecutorStorageMemoryTotal(mbc.Metrics.SparkExecutorStorageMemoryTotal),
		metricSparkExecutorStorageMemoryUsed:                     newMetricSparkExecutorStorageMemoryUsed(mbc.Metrics.SparkExecutorStorageMemoryUsed),
		metricSparkExecutorTasksActive:                           newMetricSparkExecutorTasksActive(mbc.Metrics.SparkExecutorTasksActive),
		metricSparkExecutorTasksMax:                              newMetricSparkExecutorTasksMax(mbc.Metrics.SparkExecutorTasksMax),
		metricSparkExecutorTasksResults:                          newMetricSparkExecutorTasksResults(mbc.Metrics.SparkExecutorTasksResults),
		metricSparkExecutorTime:                                  newMetricSparkExecutorTime(mbc.Metrics.SparkExecutorTime),
		metricSparkJobStagesActive:                               newMetricSparkJobStagesActive(mbc.Metrics.SparkJobStagesActive),
		metricSparkJobStagesResults:                              newMetricSparkJobStagesResults(mbc.Metrics.SparkJobStagesResults),
		metricSparkJobTasksActive:                                newMetricSparkJobTasksActive(mbc.Metrics.SparkJobTasksActive),
		metricSparkJobTasksResults:                               newMetricSparkJobTasksResults(mbc.Metrics.SparkJobTasksResults),
		metricSparkStageDiskSpilled:                              newMetricSparkStageDiskSpilled(mbc.Metrics.SparkStageDiskSpilled),
		metricSparkStageExecutorCPUTime:                          newMetricSparkStageExecutorCPUTime(mbc.Metrics.SparkStageExecutorCPUTime),
		metricSparkStageExecutorRunTime:                          newMetricSparkStageExecutorRunTime(mbc.Metrics.SparkStageExecutorRunTime),
		metricSparkStageIoRecords:                                newMetricSparkStageIoRecords(mbc.Metrics.SparkStageIoRecords),
		metricSparkStageIoSize:                                   newMetricSparkStageIoSize(mbc.Metrics.SparkStageIoSize),
		metricSparkStageJvmGcTime:                                newMetricSparkStageJvmGcTime(mbc.Metrics.SparkStageJvmGcTime),
		metricSparkStageMemoryPeak:                               newMetricSparkStageMemoryPeak(mbc.Metrics.SparkStageMemoryPeak),
		metricSparkStageMemorySpilled:                            newMetricSparkStageMemorySpilled(mbc.Metrics.SparkStageMemorySpilled),
		metricSparkStageShuffleBlocksFetched:                     newMetricSparkStageShuffleBlocksFetched(mbc.Metrics.SparkStageShuffleBlocksFetched),
		metricSparkStageShuffleFetchWaitTime:                     newMetricSparkStageShuffleFetchWaitTime(mbc.Metrics.SparkStageShuffleFetchWaitTime),
		metricSparkStageShuffleIoDisk:                            newMetricSparkStageShuffleIoDisk(mbc.Metrics.SparkStageShuffleIoDisk),
		metricSparkStageShuffleIoRecords:                         newMetricSparkStageShuffleIoRecords(mbc.Metrics.SparkStageShuffleIoRecords),
		metricSparkStageShuffleIoSize:                            newMetricSparkStageShuffleIoSize(mbc.Metrics.SparkStageShuffleIoSize),
		metricSparkStageShuffleWriteTime:                         newMetricSparkStageShuffleWriteTime(mbc.Metrics.SparkStageShuffleWriteTime),
		metricSparkStageTaskActive:                               newMetricSparkStageTaskActive(mbc.Metrics.SparkStageTaskActive),
		metricSparkStageTaskResultSize:                           newMetricSparkStageTaskResultSize(mbc.Metrics.SparkStageTaskResultSize),
		metricSparkStageTaskResults:                              newMetricSparkStageTaskResults(mbc.Metrics.SparkStageTaskResults),
	}
	for _, op := range options {
		op(mb)
	}
	return mb
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
	if mb.resourceCapacity < rm.Resource().Attributes().Len() {
		mb.resourceCapacity = rm.Resource().Attributes().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption func(ResourceAttributesConfig, pmetric.ResourceMetrics)

// WithSparkApplicationID sets provided value as "spark.application.id" attribute for current resource.
func WithSparkApplicationID(val string) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SparkApplicationID.Enabled {
			rm.Resource().Attributes().PutStr("spark.application.id", val)
		}
	}
}

// WithSparkApplicationName sets provided value as "spark.application.name" attribute for current resource.
func WithSparkApplicationName(val string) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SparkApplicationName.Enabled {
			rm.Resource().Attributes().PutStr("spark.application.name", val)
		}
	}
}

// WithSparkExecutorID sets provided value as "spark.executor.id" attribute for current resource.
func WithSparkExecutorID(val string) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SparkExecutorID.Enabled {
			rm.Resource().Attributes().PutStr("spark.executor.id", val)
		}
	}
}

// WithSparkJobID sets provided value as "spark.job.id" attribute for current resource.
func WithSparkJobID(val int64) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SparkJobID.Enabled {
			rm.Resource().Attributes().PutInt("spark.job.id", val)
		}
	}
}

// WithSparkStageID sets provided value as "spark.stage.id" attribute for current resource.
func WithSparkStageID(val int64) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SparkStageID.Enabled {
			rm.Resource().Attributes().PutInt("spark.stage.id", val)
		}
	}
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return func(_ ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	}
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(rmo ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	rm.Resource().Attributes().EnsureCapacity(mb.resourceCapacity)
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName("otelcol/apachesparkreceiver")
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricSparkComponenntExecutorMemoryExecution.emit(ils.Metrics())
	mb.metricSparkDriverBlockManagerDiskUsage.emit(ils.Metrics())
	mb.metricSparkDriverBlockManagerMemoryRemaining.emit(ils.Metrics())
	mb.metricSparkDriverBlockManagerMemoryUsed.emit(ils.Metrics())
	mb.metricSparkDriverCodeGeneratorCompilationAverageTime.emit(ils.Metrics())
	mb.metricSparkDriverCodeGeneratorCompilationCount.emit(ils.Metrics())
	mb.metricSparkDriverCodeGeneratorGeneratedClassAverageSize.emit(ils.Metrics())
	mb.metricSparkDriverCodeGeneratorGeneratedClassCount.emit(ils.Metrics())
	mb.metricSparkDriverCodeGeneratorGeneratedMethodAverageSize.emit(ils.Metrics())
	mb.metricSparkDriverCodeGeneratorGeneratedMethodCount.emit(ils.Metrics())
	mb.metricSparkDriverCodeGeneratorSourceCodeAverageSize.emit(ils.Metrics())
	mb.metricSparkDriverCodeGeneratorSourceCodeOperations.emit(ils.Metrics())
	mb.metricSparkDriverDagSchedulerJobsActive.emit(ils.Metrics())
	mb.metricSparkDriverDagSchedulerJobsCount.emit(ils.Metrics())
	mb.metricSparkDriverDagSchedulerStages.emit(ils.Metrics())
	mb.metricSparkDriverDagSchedulerStagesFailed.emit(ils.Metrics())
	mb.metricSparkDriverExecutorGcOperations.emit(ils.Metrics())
	mb.metricSparkDriverExecutorGcTime.emit(ils.Metrics())
	mb.metricSparkDriverExecutorJvmMemory.emit(ils.Metrics())
	mb.metricSparkDriverExecutorMemoryPool.emit(ils.Metrics())
	mb.metricSparkDriverExecutorMemoryStorage.emit(ils.Metrics())
	mb.metricSparkDriverHiveExternalCatalogFileCacheHits.emit(ils.Metrics())
	mb.metricSparkDriverHiveExternalCatalogFilesDiscovered.emit(ils.Metrics())
	mb.metricSparkDriverHiveExternalCatalogHiveClientCalls.emit(ils.Metrics())
	mb.metricSparkDriverHiveExternalCatalogParallelListingJobs.emit(ils.Metrics())
	mb.metricSparkDriverHiveExternalCatalogPartitionsFetched.emit(ils.Metrics())
	mb.metricSparkDriverJvmCPUTime.emit(ils.Metrics())
	mb.metricSparkDriverLiveListenerBusEventsDropped.emit(ils.Metrics())
	mb.metricSparkDriverLiveListenerBusEventsPosted.emit(ils.Metrics())
	mb.metricSparkDriverLiveListenerBusProcessingTimeAverage.emit(ils.Metrics())
	mb.metricSparkDriverLiveListenerBusQueueSize.emit(ils.Metrics())
	mb.metricSparkExecutorDiskUsage.emit(ils.Metrics())
	mb.metricSparkExecutorGcTime.emit(ils.Metrics())
	mb.metricSparkExecutorInputSize.emit(ils.Metrics())
	mb.metricSparkExecutorMemoryUsage.emit(ils.Metrics())
	mb.metricSparkExecutorShuffleIoSize.emit(ils.Metrics())
	mb.metricSparkExecutorStorageMemoryTotal.emit(ils.Metrics())
	mb.metricSparkExecutorStorageMemoryUsed.emit(ils.Metrics())
	mb.metricSparkExecutorTasksActive.emit(ils.Metrics())
	mb.metricSparkExecutorTasksMax.emit(ils.Metrics())
	mb.metricSparkExecutorTasksResults.emit(ils.Metrics())
	mb.metricSparkExecutorTime.emit(ils.Metrics())
	mb.metricSparkJobStagesActive.emit(ils.Metrics())
	mb.metricSparkJobStagesResults.emit(ils.Metrics())
	mb.metricSparkJobTasksActive.emit(ils.Metrics())
	mb.metricSparkJobTasksResults.emit(ils.Metrics())
	mb.metricSparkStageDiskSpilled.emit(ils.Metrics())
	mb.metricSparkStageExecutorCPUTime.emit(ils.Metrics())
	mb.metricSparkStageExecutorRunTime.emit(ils.Metrics())
	mb.metricSparkStageIoRecords.emit(ils.Metrics())
	mb.metricSparkStageIoSize.emit(ils.Metrics())
	mb.metricSparkStageJvmGcTime.emit(ils.Metrics())
	mb.metricSparkStageMemoryPeak.emit(ils.Metrics())
	mb.metricSparkStageMemorySpilled.emit(ils.Metrics())
	mb.metricSparkStageShuffleBlocksFetched.emit(ils.Metrics())
	mb.metricSparkStageShuffleFetchWaitTime.emit(ils.Metrics())
	mb.metricSparkStageShuffleIoDisk.emit(ils.Metrics())
	mb.metricSparkStageShuffleIoRecords.emit(ils.Metrics())
	mb.metricSparkStageShuffleIoSize.emit(ils.Metrics())
	mb.metricSparkStageShuffleWriteTime.emit(ils.Metrics())
	mb.metricSparkStageTaskActive.emit(ils.Metrics())
	mb.metricSparkStageTaskResultSize.emit(ils.Metrics())
	mb.metricSparkStageTaskResults.emit(ils.Metrics())

	for _, op := range rmo {
		op(mb.resourceAttributesConfig, rm)
	}
	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(rmo ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(rmo...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordSparkComponenntExecutorMemoryExecutionDataPoint adds a data point to spark.componennt.executor.memory.execution metric.
func (mb *MetricsBuilder) RecordSparkComponenntExecutorMemoryExecutionDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	mb.metricSparkComponenntExecutorMemoryExecution.recordDataPoint(mb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkDriverBlockManagerDiskUsageDataPoint adds a data point to spark.driver.block_manager.disk.usage metric.
func (mb *MetricsBuilder) RecordSparkDriverBlockManagerDiskUsageDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverBlockManagerDiskUsage.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverBlockManagerMemoryRemainingDataPoint adds a data point to spark.driver.block_manager.memory.remaining metric.
func (mb *MetricsBuilder) RecordSparkDriverBlockManagerMemoryRemainingDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	mb.metricSparkDriverBlockManagerMemoryRemaining.recordDataPoint(mb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkDriverBlockManagerMemoryUsedDataPoint adds a data point to spark.driver.block_manager.memory.used metric.
func (mb *MetricsBuilder) RecordSparkDriverBlockManagerMemoryUsedDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	mb.metricSparkDriverBlockManagerMemoryUsed.recordDataPoint(mb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkDriverCodeGeneratorCompilationAverageTimeDataPoint adds a data point to spark.driver.code_generator.compilation.average_time metric.
func (mb *MetricsBuilder) RecordSparkDriverCodeGeneratorCompilationAverageTimeDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSparkDriverCodeGeneratorCompilationAverageTime.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverCodeGeneratorCompilationCountDataPoint adds a data point to spark.driver.code_generator.compilation.count metric.
func (mb *MetricsBuilder) RecordSparkDriverCodeGeneratorCompilationCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverCodeGeneratorCompilationCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverCodeGeneratorGeneratedClassAverageSizeDataPoint adds a data point to spark.driver.code_generator.generated_class.average_size metric.
func (mb *MetricsBuilder) RecordSparkDriverCodeGeneratorGeneratedClassAverageSizeDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSparkDriverCodeGeneratorGeneratedClassAverageSize.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverCodeGeneratorGeneratedClassCountDataPoint adds a data point to spark.driver.code_generator.generated_class.count metric.
func (mb *MetricsBuilder) RecordSparkDriverCodeGeneratorGeneratedClassCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverCodeGeneratorGeneratedClassCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverCodeGeneratorGeneratedMethodAverageSizeDataPoint adds a data point to spark.driver.code_generator.generated_method.average_size metric.
func (mb *MetricsBuilder) RecordSparkDriverCodeGeneratorGeneratedMethodAverageSizeDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSparkDriverCodeGeneratorGeneratedMethodAverageSize.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverCodeGeneratorGeneratedMethodCountDataPoint adds a data point to spark.driver.code_generator.generated_method.count metric.
func (mb *MetricsBuilder) RecordSparkDriverCodeGeneratorGeneratedMethodCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverCodeGeneratorGeneratedMethodCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverCodeGeneratorSourceCodeAverageSizeDataPoint adds a data point to spark.driver.code_generator.source_code.average_size metric.
func (mb *MetricsBuilder) RecordSparkDriverCodeGeneratorSourceCodeAverageSizeDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSparkDriverCodeGeneratorSourceCodeAverageSize.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverCodeGeneratorSourceCodeOperationsDataPoint adds a data point to spark.driver.code_generator.source_code.operations metric.
func (mb *MetricsBuilder) RecordSparkDriverCodeGeneratorSourceCodeOperationsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverCodeGeneratorSourceCodeOperations.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverDagSchedulerJobsActiveDataPoint adds a data point to spark.driver.dag_scheduler.jobs.active metric.
func (mb *MetricsBuilder) RecordSparkDriverDagSchedulerJobsActiveDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverDagSchedulerJobsActive.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverDagSchedulerJobsCountDataPoint adds a data point to spark.driver.dag_scheduler.jobs.count metric.
func (mb *MetricsBuilder) RecordSparkDriverDagSchedulerJobsCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverDagSchedulerJobsCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverDagSchedulerStagesDataPoint adds a data point to spark.driver.dag_scheduler.stages metric.
func (mb *MetricsBuilder) RecordSparkDriverDagSchedulerStagesDataPoint(ts pcommon.Timestamp, val int64, schedulerWaitingAttributeValue bool, schedulerRunningAttributeValue bool) {
	mb.metricSparkDriverDagSchedulerStages.recordDataPoint(mb.startTime, ts, val, schedulerWaitingAttributeValue, schedulerRunningAttributeValue)
}

// RecordSparkDriverDagSchedulerStagesFailedDataPoint adds a data point to spark.driver.dag_scheduler.stages.failed metric.
func (mb *MetricsBuilder) RecordSparkDriverDagSchedulerStagesFailedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverDagSchedulerStagesFailed.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverExecutorGcOperationsDataPoint adds a data point to spark.driver.executor.gc.operations metric.
func (mb *MetricsBuilder) RecordSparkDriverExecutorGcOperationsDataPoint(ts pcommon.Timestamp, val int64, gcTypeAttributeValue AttributeGcType) {
	mb.metricSparkDriverExecutorGcOperations.recordDataPoint(mb.startTime, ts, val, gcTypeAttributeValue.String())
}

// RecordSparkDriverExecutorGcTimeDataPoint adds a data point to spark.driver.executor.gc.time metric.
func (mb *MetricsBuilder) RecordSparkDriverExecutorGcTimeDataPoint(ts pcommon.Timestamp, val int64, gcTypeAttributeValue AttributeGcType) {
	mb.metricSparkDriverExecutorGcTime.recordDataPoint(mb.startTime, ts, val, gcTypeAttributeValue.String())
}

// RecordSparkDriverExecutorJvmMemoryDataPoint adds a data point to spark.driver.executor.jvm_memory metric.
func (mb *MetricsBuilder) RecordSparkDriverExecutorJvmMemoryDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	mb.metricSparkDriverExecutorJvmMemory.recordDataPoint(mb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkDriverExecutorMemoryPoolDataPoint adds a data point to spark.driver.executor.memory.pool metric.
func (mb *MetricsBuilder) RecordSparkDriverExecutorMemoryPoolDataPoint(ts pcommon.Timestamp, val int64, poolMemoryTypeAttributeValue AttributePoolMemoryType) {
	mb.metricSparkDriverExecutorMemoryPool.recordDataPoint(mb.startTime, ts, val, poolMemoryTypeAttributeValue.String())
}

// RecordSparkDriverExecutorMemoryStorageDataPoint adds a data point to spark.driver.executor.memory.storage metric.
func (mb *MetricsBuilder) RecordSparkDriverExecutorMemoryStorageDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	mb.metricSparkDriverExecutorMemoryStorage.recordDataPoint(mb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkDriverHiveExternalCatalogFileCacheHitsDataPoint adds a data point to spark.driver.hive_external_catalog.file_cache_hits metric.
func (mb *MetricsBuilder) RecordSparkDriverHiveExternalCatalogFileCacheHitsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverHiveExternalCatalogFileCacheHits.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverHiveExternalCatalogFilesDiscoveredDataPoint adds a data point to spark.driver.hive_external_catalog.files_discovered metric.
func (mb *MetricsBuilder) RecordSparkDriverHiveExternalCatalogFilesDiscoveredDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverHiveExternalCatalogFilesDiscovered.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverHiveExternalCatalogHiveClientCallsDataPoint adds a data point to spark.driver.hive_external_catalog.hive_client_calls metric.
func (mb *MetricsBuilder) RecordSparkDriverHiveExternalCatalogHiveClientCallsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverHiveExternalCatalogHiveClientCalls.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverHiveExternalCatalogParallelListingJobsDataPoint adds a data point to spark.driver.hive_external_catalog.parallel_listing_jobs metric.
func (mb *MetricsBuilder) RecordSparkDriverHiveExternalCatalogParallelListingJobsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverHiveExternalCatalogParallelListingJobs.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverHiveExternalCatalogPartitionsFetchedDataPoint adds a data point to spark.driver.hive_external_catalog.partitions_fetched metric.
func (mb *MetricsBuilder) RecordSparkDriverHiveExternalCatalogPartitionsFetchedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverHiveExternalCatalogPartitionsFetched.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverJvmCPUTimeDataPoint adds a data point to spark.driver.jvm_cpu_time metric.
func (mb *MetricsBuilder) RecordSparkDriverJvmCPUTimeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverJvmCPUTime.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverLiveListenerBusEventsDroppedDataPoint adds a data point to spark.driver.live_listener_bus.events_dropped metric.
func (mb *MetricsBuilder) RecordSparkDriverLiveListenerBusEventsDroppedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverLiveListenerBusEventsDropped.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverLiveListenerBusEventsPostedDataPoint adds a data point to spark.driver.live_listener_bus.events_posted metric.
func (mb *MetricsBuilder) RecordSparkDriverLiveListenerBusEventsPostedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverLiveListenerBusEventsPosted.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverLiveListenerBusProcessingTimeAverageDataPoint adds a data point to spark.driver.live_listener_bus.processing_time.average metric.
func (mb *MetricsBuilder) RecordSparkDriverLiveListenerBusProcessingTimeAverageDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSparkDriverLiveListenerBusProcessingTimeAverage.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDriverLiveListenerBusQueueSizeDataPoint adds a data point to spark.driver.live_listener_bus.queue_size metric.
func (mb *MetricsBuilder) RecordSparkDriverLiveListenerBusQueueSizeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDriverLiveListenerBusQueueSize.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkExecutorDiskUsageDataPoint adds a data point to spark.executor.disk.usage metric.
func (mb *MetricsBuilder) RecordSparkExecutorDiskUsageDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkExecutorDiskUsage.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkExecutorGcTimeDataPoint adds a data point to spark.executor.gc_time metric.
func (mb *MetricsBuilder) RecordSparkExecutorGcTimeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkExecutorGcTime.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkExecutorInputSizeDataPoint adds a data point to spark.executor.input_size metric.
func (mb *MetricsBuilder) RecordSparkExecutorInputSizeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkExecutorInputSize.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkExecutorMemoryUsageDataPoint adds a data point to spark.executor.memory.usage metric.
func (mb *MetricsBuilder) RecordSparkExecutorMemoryUsageDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkExecutorMemoryUsage.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkExecutorShuffleIoSizeDataPoint adds a data point to spark.executor.shuffle.io.size metric.
func (mb *MetricsBuilder) RecordSparkExecutorShuffleIoSizeDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	mb.metricSparkExecutorShuffleIoSize.recordDataPoint(mb.startTime, ts, val, directionAttributeValue.String())
}

// RecordSparkExecutorStorageMemoryTotalDataPoint adds a data point to spark.executor.storage_memory.total metric.
func (mb *MetricsBuilder) RecordSparkExecutorStorageMemoryTotalDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	mb.metricSparkExecutorStorageMemoryTotal.recordDataPoint(mb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkExecutorStorageMemoryUsedDataPoint adds a data point to spark.executor.storage_memory.used metric.
func (mb *MetricsBuilder) RecordSparkExecutorStorageMemoryUsedDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	mb.metricSparkExecutorStorageMemoryUsed.recordDataPoint(mb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkExecutorTasksActiveDataPoint adds a data point to spark.executor.tasks.active metric.
func (mb *MetricsBuilder) RecordSparkExecutorTasksActiveDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkExecutorTasksActive.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkExecutorTasksMaxDataPoint adds a data point to spark.executor.tasks.max metric.
func (mb *MetricsBuilder) RecordSparkExecutorTasksMaxDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkExecutorTasksMax.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkExecutorTasksResultsDataPoint adds a data point to spark.executor.tasks.results metric.
func (mb *MetricsBuilder) RecordSparkExecutorTasksResultsDataPoint(ts pcommon.Timestamp, val int64, executorTaskResultAttributeValue AttributeExecutorTaskResult) {
	mb.metricSparkExecutorTasksResults.recordDataPoint(mb.startTime, ts, val, executorTaskResultAttributeValue.String())
}

// RecordSparkExecutorTimeDataPoint adds a data point to spark.executor.time metric.
func (mb *MetricsBuilder) RecordSparkExecutorTimeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkExecutorTime.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkJobStagesActiveDataPoint adds a data point to spark.job.stages.active metric.
func (mb *MetricsBuilder) RecordSparkJobStagesActiveDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkJobStagesActive.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkJobStagesResultsDataPoint adds a data point to spark.job.stages.results metric.
func (mb *MetricsBuilder) RecordSparkJobStagesResultsDataPoint(ts pcommon.Timestamp, val int64, jobStageResultAttributeValue AttributeJobStageResult) {
	mb.metricSparkJobStagesResults.recordDataPoint(mb.startTime, ts, val, jobStageResultAttributeValue.String())
}

// RecordSparkJobTasksActiveDataPoint adds a data point to spark.job.tasks.active metric.
func (mb *MetricsBuilder) RecordSparkJobTasksActiveDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkJobTasksActive.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkJobTasksResultsDataPoint adds a data point to spark.job.tasks.results metric.
func (mb *MetricsBuilder) RecordSparkJobTasksResultsDataPoint(ts pcommon.Timestamp, val int64, jobTaskResultAttributeValue AttributeJobTaskResult) {
	mb.metricSparkJobTasksResults.recordDataPoint(mb.startTime, ts, val, jobTaskResultAttributeValue.String())
}

// RecordSparkStageDiskSpilledDataPoint adds a data point to spark.stage.disk.spilled metric.
func (mb *MetricsBuilder) RecordSparkStageDiskSpilledDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageDiskSpilled.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageExecutorCPUTimeDataPoint adds a data point to spark.stage.executor.cpu_time metric.
func (mb *MetricsBuilder) RecordSparkStageExecutorCPUTimeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageExecutorCPUTime.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageExecutorRunTimeDataPoint adds a data point to spark.stage.executor.run_time metric.
func (mb *MetricsBuilder) RecordSparkStageExecutorRunTimeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageExecutorRunTime.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageIoRecordsDataPoint adds a data point to spark.stage.io.records metric.
func (mb *MetricsBuilder) RecordSparkStageIoRecordsDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, directionAttributeValue AttributeDirection) {
	mb.metricSparkStageIoRecords.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue, directionAttributeValue.String())
}

// RecordSparkStageIoSizeDataPoint adds a data point to spark.stage.io.size metric.
func (mb *MetricsBuilder) RecordSparkStageIoSizeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, directionAttributeValue AttributeDirection) {
	mb.metricSparkStageIoSize.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue, directionAttributeValue.String())
}

// RecordSparkStageJvmGcTimeDataPoint adds a data point to spark.stage.jvm_gc_time metric.
func (mb *MetricsBuilder) RecordSparkStageJvmGcTimeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageJvmGcTime.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageMemoryPeakDataPoint adds a data point to spark.stage.memory.peak metric.
func (mb *MetricsBuilder) RecordSparkStageMemoryPeakDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageMemoryPeak.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageMemorySpilledDataPoint adds a data point to spark.stage.memory.spilled metric.
func (mb *MetricsBuilder) RecordSparkStageMemorySpilledDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageMemorySpilled.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageShuffleBlocksFetchedDataPoint adds a data point to spark.stage.shuffle.blocks_fetched metric.
func (mb *MetricsBuilder) RecordSparkStageShuffleBlocksFetchedDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, sourceAttributeValue AttributeSource) {
	mb.metricSparkStageShuffleBlocksFetched.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue, sourceAttributeValue.String())
}

// RecordSparkStageShuffleFetchWaitTimeDataPoint adds a data point to spark.stage.shuffle.fetch_wait_time metric.
func (mb *MetricsBuilder) RecordSparkStageShuffleFetchWaitTimeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageShuffleFetchWaitTime.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageShuffleIoDiskDataPoint adds a data point to spark.stage.shuffle.io.disk metric.
func (mb *MetricsBuilder) RecordSparkStageShuffleIoDiskDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageShuffleIoDisk.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageShuffleIoRecordsDataPoint adds a data point to spark.stage.shuffle.io.records metric.
func (mb *MetricsBuilder) RecordSparkStageShuffleIoRecordsDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, directionAttributeValue AttributeDirection) {
	mb.metricSparkStageShuffleIoRecords.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue, directionAttributeValue.String())
}

// RecordSparkStageShuffleIoSizeDataPoint adds a data point to spark.stage.shuffle.io.size metric.
func (mb *MetricsBuilder) RecordSparkStageShuffleIoSizeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, sourceAttributeValue AttributeSource, directionAttributeValue AttributeDirection) {
	mb.metricSparkStageShuffleIoSize.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue, sourceAttributeValue.String(), directionAttributeValue.String())
}

// RecordSparkStageShuffleWriteTimeDataPoint adds a data point to spark.stage.shuffle.write_time metric.
func (mb *MetricsBuilder) RecordSparkStageShuffleWriteTimeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageShuffleWriteTime.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageTaskActiveDataPoint adds a data point to spark.stage.task.active metric.
func (mb *MetricsBuilder) RecordSparkStageTaskActiveDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageTaskActive.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageTaskResultSizeDataPoint adds a data point to spark.stage.task.result_size metric.
func (mb *MetricsBuilder) RecordSparkStageTaskResultSizeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageTaskResultSize.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageTaskResultsDataPoint adds a data point to spark.stage.task.results metric.
func (mb *MetricsBuilder) RecordSparkStageTaskResultsDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, stageTaskResultAttributeValue AttributeStageTaskResult) {
	mb.metricSparkStageTaskResults.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue, stageTaskResultAttributeValue.String())
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...metricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(mb)
	}
}
