// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/filter"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

var MetricsInfo = metricsInfo{
	OracledbBufferCacheHitRatio: metricInfo{
		Name: "oracledb.buffer_cache_hit_ratio",
	},
	OracledbConsistentGets: metricInfo{
		Name: "oracledb.consistent_gets",
	},
	OracledbCPUTime: metricInfo{
		Name: "oracledb.cpu_time",
	},
	OracledbDbBlockGets: metricInfo{
		Name: "oracledb.db_block_gets",
	},
	OracledbDdlStatementsParallelized: metricInfo{
		Name: "oracledb.ddl_statements_parallelized",
	},
	OracledbDmlLocksLimit: metricInfo{
		Name: "oracledb.dml_locks_limit",
	},
	OracledbDmlLocksUsage: metricInfo{
		Name: "oracledb.dml_locks_usage",
	},
	OracledbDmlStatementsParallelized: metricInfo{
		Name: "oracledb.dml_statements_parallelized",
	},
	OracledbEnqueueDeadlocks: metricInfo{
		Name: "oracledb.enqueue_deadlocks",
	},
	OracledbEnqueueLocksLimit: metricInfo{
		Name: "oracledb.enqueue_locks_limit",
	},
	OracledbEnqueueLocksUsage: metricInfo{
		Name: "oracledb.enqueue_locks_usage",
	},
	OracledbEnqueueResourcesLimit: metricInfo{
		Name: "oracledb.enqueue_resources_limit",
	},
	OracledbEnqueueResourcesUsage: metricInfo{
		Name: "oracledb.enqueue_resources_usage",
	},
	OracledbExchangeDeadlocks: metricInfo{
		Name: "oracledb.exchange_deadlocks",
	},
	OracledbExecutions: metricInfo{
		Name: "oracledb.executions",
	},
	OracledbHardParses: metricInfo{
		Name: "oracledb.hard_parses",
	},
	OracledbLibraryCacheHitRatio: metricInfo{
		Name: "oracledb.library_cache_hit_ratio",
	},
	OracledbLogicalReads: metricInfo{
		Name: "oracledb.logical_reads",
	},
	OracledbLogons: metricInfo{
		Name: "oracledb.logons",
	},
	OracledbParallelOperationsDowngraded1To25Pct: metricInfo{
		Name: "oracledb.parallel_operations_downgraded_1_to_25_pct",
	},
	OracledbParallelOperationsDowngraded25To50Pct: metricInfo{
		Name: "oracledb.parallel_operations_downgraded_25_to_50_pct",
	},
	OracledbParallelOperationsDowngraded50To75Pct: metricInfo{
		Name: "oracledb.parallel_operations_downgraded_50_to_75_pct",
	},
	OracledbParallelOperationsDowngraded75To99Pct: metricInfo{
		Name: "oracledb.parallel_operations_downgraded_75_to_99_pct",
	},
	OracledbParallelOperationsDowngradedToSerial: metricInfo{
		Name: "oracledb.parallel_operations_downgraded_to_serial",
	},
	OracledbParallelOperationsNotDowngraded: metricInfo{
		Name: "oracledb.parallel_operations_not_downgraded",
	},
	OracledbParseCalls: metricInfo{
		Name: "oracledb.parse_calls",
	},
	OracledbPgaAllocatedMemory: metricInfo{
		Name: "oracledb.pga_allocated_memory",
	},
	OracledbPgaFreeableMemory: metricInfo{
		Name: "oracledb.pga_freeable_memory",
	},
	OracledbPgaMaximumMemory: metricInfo{
		Name: "oracledb.pga_maximum_memory",
	},
	OracledbPgaMemory: metricInfo{
		Name: "oracledb.pga_memory",
	},
	OracledbPgaUsedMemory: metricInfo{
		Name: "oracledb.pga_used_memory",
	},
	OracledbPhysicalReadBytes: metricInfo{
		Name: "oracledb.physical_read_bytes",
	},
	OracledbPhysicalReadIoRequests: metricInfo{
		Name: "oracledb.physical_read_io_requests",
	},
	OracledbPhysicalReads: metricInfo{
		Name: "oracledb.physical_reads",
	},
	OracledbPhysicalReadsDirect: metricInfo{
		Name: "oracledb.physical_reads_direct",
	},
	OracledbPhysicalWriteBytes: metricInfo{
		Name: "oracledb.physical_write_bytes",
	},
	OracledbPhysicalWriteIoRequests: metricInfo{
		Name: "oracledb.physical_write_io_requests",
	},
	OracledbPhysicalWrites: metricInfo{
		Name: "oracledb.physical_writes",
	},
	OracledbPhysicalWritesDirect: metricInfo{
		Name: "oracledb.physical_writes_direct",
	},
	OracledbProcessesLimit: metricInfo{
		Name: "oracledb.processes_limit",
	},
	OracledbProcessesUsage: metricInfo{
		Name: "oracledb.processes_usage",
	},
	OracledbQueriesParallelized: metricInfo{
		Name: "oracledb.queries_parallelized",
	},
	OracledbRedoSize: metricInfo{
		Name: "oracledb.redo_size",
	},
	OracledbRowCacheHitRatio: metricInfo{
		Name: "oracledb.row_cache_hit_ratio",
	},
	OracledbSessions: metricInfo{
		Name: "oracledb.sessions",
	},
	OracledbSessionsLimit: metricInfo{
		Name: "oracledb.sessions_limit",
	},
	OracledbSgaFixedSize: metricInfo{
		Name: "oracledb.sga_fixed_size",
	},
	OracledbSharedPoolFree: metricInfo{
		Name: "oracledb.shared_pool_free",
	},
	OracledbTablespaceOffline: metricInfo{
		Name: "oracledb.tablespace_offline",
	},
	OracledbTablespaceSizeLimit: metricInfo{
		Name: "oracledb.tablespace_size_limit",
	},
	OracledbTablespaceSizeUsage: metricInfo{
		Name: "oracledb.tablespace_size_usage",
	},
	OracledbTablespaceUsagePercentage: metricInfo{
		Name: "oracledb.tablespace_usage_percentage",
	},
	OracledbTransactionsLimit: metricInfo{
		Name: "oracledb.transactions_limit",
	},
	OracledbTransactionsUsage: metricInfo{
		Name: "oracledb.transactions_usage",
	},
	OracledbUserCommits: metricInfo{
		Name: "oracledb.user_commits",
	},
	OracledbUserRollbacks: metricInfo{
		Name: "oracledb.user_rollbacks",
	},
	OracledbWaitEvents: metricInfo{
		Name: "oracledb.wait_events",
	},
	OracledbWaitTime: metricInfo{
		Name: "oracledb.wait_time",
	},
}

type metricsInfo struct {
	OracledbBufferCacheHitRatio                   metricInfo
	OracledbConsistentGets                        metricInfo
	OracledbCPUTime                               metricInfo
	OracledbDbBlockGets                           metricInfo
	OracledbDdlStatementsParallelized             metricInfo
	OracledbDmlLocksLimit                         metricInfo
	OracledbDmlLocksUsage                         metricInfo
	OracledbDmlStatementsParallelized             metricInfo
	OracledbEnqueueDeadlocks                      metricInfo
	OracledbEnqueueLocksLimit                     metricInfo
	OracledbEnqueueLocksUsage                     metricInfo
	OracledbEnqueueResourcesLimit                 metricInfo
	OracledbEnqueueResourcesUsage                 metricInfo
	OracledbExchangeDeadlocks                     metricInfo
	OracledbExecutions                            metricInfo
	OracledbHardParses                            metricInfo
	OracledbLibraryCacheHitRatio                  metricInfo
	OracledbLogicalReads                          metricInfo
	OracledbLogons                                metricInfo
	OracledbParallelOperationsDowngraded1To25Pct  metricInfo
	OracledbParallelOperationsDowngraded25To50Pct metricInfo
	OracledbParallelOperationsDowngraded50To75Pct metricInfo
	OracledbParallelOperationsDowngraded75To99Pct metricInfo
	OracledbParallelOperationsDowngradedToSerial  metricInfo
	OracledbParallelOperationsNotDowngraded       metricInfo
	OracledbParseCalls                            metricInfo
	OracledbPgaAllocatedMemory                    metricInfo
	OracledbPgaFreeableMemory                     metricInfo
	OracledbPgaMaximumMemory                      metricInfo
	OracledbPgaMemory                             metricInfo
	OracledbPgaUsedMemory                         metricInfo
	OracledbPhysicalReadBytes                     metricInfo
	OracledbPhysicalReadIoRequests                metricInfo
	OracledbPhysicalReads                         metricInfo
	OracledbPhysicalReadsDirect                   metricInfo
	OracledbPhysicalWriteBytes                    metricInfo
	OracledbPhysicalWriteIoRequests               metricInfo
	OracledbPhysicalWrites                        metricInfo
	OracledbPhysicalWritesDirect                  metricInfo
	OracledbProcessesLimit                        metricInfo
	OracledbProcessesUsage                        metricInfo
	OracledbQueriesParallelized                   metricInfo
	OracledbRedoSize                              metricInfo
	OracledbRowCacheHitRatio                      metricInfo
	OracledbSessions                              metricInfo
	OracledbSessionsLimit                         metricInfo
	OracledbSgaFixedSize                          metricInfo
	OracledbSharedPoolFree                        metricInfo
	OracledbTablespaceOffline                     metricInfo
	OracledbTablespaceSizeLimit                   metricInfo
	OracledbTablespaceSizeUsage                   metricInfo
	OracledbTablespaceUsagePercentage             metricInfo
	OracledbTransactionsLimit                     metricInfo
	OracledbTransactionsUsage                     metricInfo
	OracledbUserCommits                           metricInfo
	OracledbUserRollbacks                         metricInfo
	OracledbWaitEvents                            metricInfo
	OracledbWaitTime                              metricInfo
}

type metricInfo struct {
	Name string
}

type metricOracledbBufferCacheHitRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.buffer_cache_hit_ratio metric with initial data.
func (m *metricOracledbBufferCacheHitRatio) init() {
	m.data.SetName("oracledb.buffer_cache_hit_ratio")
	m.data.SetDescription("Buffer cache hit ratio")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbBufferCacheHitRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbBufferCacheHitRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbBufferCacheHitRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbBufferCacheHitRatio(cfg MetricConfig) metricOracledbBufferCacheHitRatio {
	m := metricOracledbBufferCacheHitRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbConsistentGets struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.consistent_gets metric with initial data.
func (m *metricOracledbConsistentGets) init() {
	m.data.SetName("oracledb.consistent_gets")
	m.data.SetDescription("Consistent read gets")
	m.data.SetUnit("{gets}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbConsistentGets) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbConsistentGets) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbConsistentGets) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbConsistentGets(cfg MetricConfig) metricOracledbConsistentGets {
	m := metricOracledbConsistentGets{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbCPUTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.cpu_time metric with initial data.
func (m *metricOracledbCPUTime) init() {
	m.data.SetName("oracledb.cpu_time")
	m.data.SetDescription("Cumulative CPU time, in seconds")
	m.data.SetUnit("s")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbCPUTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbCPUTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbCPUTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbCPUTime(cfg MetricConfig) metricOracledbCPUTime {
	m := metricOracledbCPUTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbDbBlockGets struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.db_block_gets metric with initial data.
func (m *metricOracledbDbBlockGets) init() {
	m.data.SetName("oracledb.db_block_gets")
	m.data.SetDescription("Database block gets")
	m.data.SetUnit("{gets}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbDbBlockGets) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbDbBlockGets) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbDbBlockGets) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbDbBlockGets(cfg MetricConfig) metricOracledbDbBlockGets {
	m := metricOracledbDbBlockGets{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbDdlStatementsParallelized struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.ddl_statements_parallelized metric with initial data.
func (m *metricOracledbDdlStatementsParallelized) init() {
	m.data.SetName("oracledb.ddl_statements_parallelized")
	m.data.SetDescription("Number of DDL statements executed in parallel")
	m.data.SetUnit("{statements}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbDdlStatementsParallelized) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbDdlStatementsParallelized) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbDdlStatementsParallelized) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbDdlStatementsParallelized(cfg MetricConfig) metricOracledbDdlStatementsParallelized {
	m := metricOracledbDdlStatementsParallelized{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbDmlLocksLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.dml_locks_limit metric with initial data.
func (m *metricOracledbDmlLocksLimit) init() {
	m.data.SetName("oracledb.dml_locks_limit")
	m.data.SetDescription("Maximum limit of active DML locks, -1 if unlimited")
	m.data.SetUnit("{locks}")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbDmlLocksLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbDmlLocksLimit) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbDmlLocksLimit) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbDmlLocksLimit(cfg MetricConfig) metricOracledbDmlLocksLimit {
	m := metricOracledbDmlLocksLimit{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbDmlLocksUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.dml_locks_usage metric with initial data.
func (m *metricOracledbDmlLocksUsage) init() {
	m.data.SetName("oracledb.dml_locks_usage")
	m.data.SetDescription("Current count of active DML (Data Manipulation Language) locks")
	m.data.SetUnit("{locks}")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbDmlLocksUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbDmlLocksUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbDmlLocksUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbDmlLocksUsage(cfg MetricConfig) metricOracledbDmlLocksUsage {
	m := metricOracledbDmlLocksUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbDmlStatementsParallelized struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.dml_statements_parallelized metric with initial data.
func (m *metricOracledbDmlStatementsParallelized) init() {
	m.data.SetName("oracledb.dml_statements_parallelized")
	m.data.SetDescription("Number of DML statements executed in parallel")
	m.data.SetUnit("{statements}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbDmlStatementsParallelized) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbDmlStatementsParallelized) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbDmlStatementsParallelized) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbDmlStatementsParallelized(cfg MetricConfig) metricOracledbDmlStatementsParallelized {
	m := metricOracledbDmlStatementsParallelized{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbEnqueueDeadlocks struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.enqueue_deadlocks metric with initial data.
func (m *metricOracledbEnqueueDeadlocks) init() {
	m.data.SetName("oracledb.enqueue_deadlocks")
	m.data.SetDescription("Total number of deadlocks between table or row locks in different sessions")
	m.data.SetUnit("{deadlocks}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbEnqueueDeadlocks) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbEnqueueDeadlocks) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbEnqueueDeadlocks) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbEnqueueDeadlocks(cfg MetricConfig) metricOracledbEnqueueDeadlocks {
	m := metricOracledbEnqueueDeadlocks{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbEnqueueLocksLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.enqueue_locks_limit metric with initial data.
func (m *metricOracledbEnqueueLocksLimit) init() {
	m.data.SetName("oracledb.enqueue_locks_limit")
	m.data.SetDescription("Maximum limit of active enqueue locks, -1 if unlimited")
	m.data.SetUnit("{locks}")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbEnqueueLocksLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbEnqueueLocksLimit) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbEnqueueLocksLimit) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbEnqueueLocksLimit(cfg MetricConfig) metricOracledbEnqueueLocksLimit {
	m := metricOracledbEnqueueLocksLimit{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbEnqueueLocksUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.enqueue_locks_usage metric with initial data.
func (m *metricOracledbEnqueueLocksUsage) init() {
	m.data.SetName("oracledb.enqueue_locks_usage")
	m.data.SetDescription("Current count of active enqueue locks")
	m.data.SetUnit("{locks}")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbEnqueueLocksUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbEnqueueLocksUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbEnqueueLocksUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbEnqueueLocksUsage(cfg MetricConfig) metricOracledbEnqueueLocksUsage {
	m := metricOracledbEnqueueLocksUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbEnqueueResourcesLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.enqueue_resources_limit metric with initial data.
func (m *metricOracledbEnqueueResourcesLimit) init() {
	m.data.SetName("oracledb.enqueue_resources_limit")
	m.data.SetDescription("Maximum limit of active enqueue resources, -1 if unlimited")
	m.data.SetUnit("{resources}")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbEnqueueResourcesLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbEnqueueResourcesLimit) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbEnqueueResourcesLimit) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbEnqueueResourcesLimit(cfg MetricConfig) metricOracledbEnqueueResourcesLimit {
	m := metricOracledbEnqueueResourcesLimit{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbEnqueueResourcesUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.enqueue_resources_usage metric with initial data.
func (m *metricOracledbEnqueueResourcesUsage) init() {
	m.data.SetName("oracledb.enqueue_resources_usage")
	m.data.SetDescription("Current count of active enqueue resources")
	m.data.SetUnit("{resources}")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbEnqueueResourcesUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbEnqueueResourcesUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbEnqueueResourcesUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbEnqueueResourcesUsage(cfg MetricConfig) metricOracledbEnqueueResourcesUsage {
	m := metricOracledbEnqueueResourcesUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbExchangeDeadlocks struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.exchange_deadlocks metric with initial data.
func (m *metricOracledbExchangeDeadlocks) init() {
	m.data.SetName("oracledb.exchange_deadlocks")
	m.data.SetDescription("Number of times that a process detected a potential deadlock when exchanging buffers")
	m.data.SetUnit("{deadlocks}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbExchangeDeadlocks) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbExchangeDeadlocks) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbExchangeDeadlocks) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbExchangeDeadlocks(cfg MetricConfig) metricOracledbExchangeDeadlocks {
	m := metricOracledbExchangeDeadlocks{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbExecutions struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.executions metric with initial data.
func (m *metricOracledbExecutions) init() {
	m.data.SetName("oracledb.executions")
	m.data.SetDescription("Total number of calls (user and recursive) that executed SQL statements")
	m.data.SetUnit("{executions}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbExecutions) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbExecutions) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbExecutions) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbExecutions(cfg MetricConfig) metricOracledbExecutions {
	m := metricOracledbExecutions{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbHardParses struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.hard_parses metric with initial data.
func (m *metricOracledbHardParses) init() {
	m.data.SetName("oracledb.hard_parses")
	m.data.SetDescription("Number of hard parses")
	m.data.SetUnit("{parses}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbHardParses) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbHardParses) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbHardParses) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbHardParses(cfg MetricConfig) metricOracledbHardParses {
	m := metricOracledbHardParses{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbLibraryCacheHitRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.library_cache_hit_ratio metric with initial data.
func (m *metricOracledbLibraryCacheHitRatio) init() {
	m.data.SetName("oracledb.library_cache_hit_ratio")
	m.data.SetDescription("Library cache hit ratio")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbLibraryCacheHitRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbLibraryCacheHitRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbLibraryCacheHitRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbLibraryCacheHitRatio(cfg MetricConfig) metricOracledbLibraryCacheHitRatio {
	m := metricOracledbLibraryCacheHitRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbLogicalReads struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.logical_reads metric with initial data.
func (m *metricOracledbLogicalReads) init() {
	m.data.SetName("oracledb.logical_reads")
	m.data.SetDescription("Session logical reads")
	m.data.SetUnit("{reads}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbLogicalReads) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbLogicalReads) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbLogicalReads) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbLogicalReads(cfg MetricConfig) metricOracledbLogicalReads {
	m := metricOracledbLogicalReads{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbLogons struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.logons metric with initial data.
func (m *metricOracledbLogons) init() {
	m.data.SetName("oracledb.logons")
	m.data.SetDescription("Number of logon operations")
	m.data.SetUnit("{operations}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbLogons) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbLogons) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbLogons) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbLogons(cfg MetricConfig) metricOracledbLogons {
	m := metricOracledbLogons{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbParallelOperationsDowngraded1To25Pct struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.parallel_operations_downgraded_1_to_25_pct metric with initial data.
func (m *metricOracledbParallelOperationsDowngraded1To25Pct) init() {
	m.data.SetName("oracledb.parallel_operations_downgraded_1_to_25_pct")
	m.data.SetDescription("Number of times parallel execution was requested and the degree of parallelism was reduced down to 1-25% because of insufficient parallel execution servers")
	m.data.SetUnit("{executions}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbParallelOperationsDowngraded1To25Pct) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbParallelOperationsDowngraded1To25Pct) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbParallelOperationsDowngraded1To25Pct) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbParallelOperationsDowngraded1To25Pct(cfg MetricConfig) metricOracledbParallelOperationsDowngraded1To25Pct {
	m := metricOracledbParallelOperationsDowngraded1To25Pct{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbParallelOperationsDowngraded25To50Pct struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.parallel_operations_downgraded_25_to_50_pct metric with initial data.
func (m *metricOracledbParallelOperationsDowngraded25To50Pct) init() {
	m.data.SetName("oracledb.parallel_operations_downgraded_25_to_50_pct")
	m.data.SetDescription("Number of times parallel execution was requested and the degree of parallelism was reduced down to 25-50% because of insufficient parallel execution servers")
	m.data.SetUnit("{executions}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbParallelOperationsDowngraded25To50Pct) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbParallelOperationsDowngraded25To50Pct) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbParallelOperationsDowngraded25To50Pct) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbParallelOperationsDowngraded25To50Pct(cfg MetricConfig) metricOracledbParallelOperationsDowngraded25To50Pct {
	m := metricOracledbParallelOperationsDowngraded25To50Pct{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbParallelOperationsDowngraded50To75Pct struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.parallel_operations_downgraded_50_to_75_pct metric with initial data.
func (m *metricOracledbParallelOperationsDowngraded50To75Pct) init() {
	m.data.SetName("oracledb.parallel_operations_downgraded_50_to_75_pct")
	m.data.SetDescription("Number of times parallel execution was requested and the degree of parallelism was reduced down to 50-75% because of insufficient parallel execution servers")
	m.data.SetUnit("{executions}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbParallelOperationsDowngraded50To75Pct) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbParallelOperationsDowngraded50To75Pct) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbParallelOperationsDowngraded50To75Pct) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbParallelOperationsDowngraded50To75Pct(cfg MetricConfig) metricOracledbParallelOperationsDowngraded50To75Pct {
	m := metricOracledbParallelOperationsDowngraded50To75Pct{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbParallelOperationsDowngraded75To99Pct struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.parallel_operations_downgraded_75_to_99_pct metric with initial data.
func (m *metricOracledbParallelOperationsDowngraded75To99Pct) init() {
	m.data.SetName("oracledb.parallel_operations_downgraded_75_to_99_pct")
	m.data.SetDescription("Number of times parallel execution was requested and the degree of parallelism was reduced down to 75-99% because of insufficient parallel execution servers")
	m.data.SetUnit("{executions}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbParallelOperationsDowngraded75To99Pct) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbParallelOperationsDowngraded75To99Pct) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbParallelOperationsDowngraded75To99Pct) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbParallelOperationsDowngraded75To99Pct(cfg MetricConfig) metricOracledbParallelOperationsDowngraded75To99Pct {
	m := metricOracledbParallelOperationsDowngraded75To99Pct{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbParallelOperationsDowngradedToSerial struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.parallel_operations_downgraded_to_serial metric with initial data.
func (m *metricOracledbParallelOperationsDowngradedToSerial) init() {
	m.data.SetName("oracledb.parallel_operations_downgraded_to_serial")
	m.data.SetDescription("Number of times parallel execution was requested but execution was serial because of insufficient parallel execution servers")
	m.data.SetUnit("{executions}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbParallelOperationsDowngradedToSerial) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbParallelOperationsDowngradedToSerial) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbParallelOperationsDowngradedToSerial) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbParallelOperationsDowngradedToSerial(cfg MetricConfig) metricOracledbParallelOperationsDowngradedToSerial {
	m := metricOracledbParallelOperationsDowngradedToSerial{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbParallelOperationsNotDowngraded struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.parallel_operations_not_downgraded metric with initial data.
func (m *metricOracledbParallelOperationsNotDowngraded) init() {
	m.data.SetName("oracledb.parallel_operations_not_downgraded")
	m.data.SetDescription("Number of times parallel execution was executed at the requested degree of parallelism")
	m.data.SetUnit("{executions}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbParallelOperationsNotDowngraded) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbParallelOperationsNotDowngraded) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbParallelOperationsNotDowngraded) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbParallelOperationsNotDowngraded(cfg MetricConfig) metricOracledbParallelOperationsNotDowngraded {
	m := metricOracledbParallelOperationsNotDowngraded{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbParseCalls struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.parse_calls metric with initial data.
func (m *metricOracledbParseCalls) init() {
	m.data.SetName("oracledb.parse_calls")
	m.data.SetDescription("Total number of parse calls")
	m.data.SetUnit("{calls}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbParseCalls) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbParseCalls) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbParseCalls) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbParseCalls(cfg MetricConfig) metricOracledbParseCalls {
	m := metricOracledbParseCalls{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbPgaAllocatedMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.pga_allocated_memory metric with initial data.
func (m *metricOracledbPgaAllocatedMemory) init() {
	m.data.SetName("oracledb.pga_allocated_memory")
	m.data.SetDescription("PGA memory allocated by process")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbPgaAllocatedMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbPgaAllocatedMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbPgaAllocatedMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbPgaAllocatedMemory(cfg MetricConfig) metricOracledbPgaAllocatedMemory {
	m := metricOracledbPgaAllocatedMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbPgaFreeableMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.pga_freeable_memory metric with initial data.
func (m *metricOracledbPgaFreeableMemory) init() {
	m.data.SetName("oracledb.pga_freeable_memory")
	m.data.SetDescription("PGA freeable memory")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbPgaFreeableMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbPgaFreeableMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbPgaFreeableMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbPgaFreeableMemory(cfg MetricConfig) metricOracledbPgaFreeableMemory {
	m := metricOracledbPgaFreeableMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbPgaMaximumMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.pga_maximum_memory metric with initial data.
func (m *metricOracledbPgaMaximumMemory) init() {
	m.data.SetName("oracledb.pga_maximum_memory")
	m.data.SetDescription("Maximum PGA memory ever allocated")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbPgaMaximumMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbPgaMaximumMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbPgaMaximumMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbPgaMaximumMemory(cfg MetricConfig) metricOracledbPgaMaximumMemory {
	m := metricOracledbPgaMaximumMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbPgaMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.pga_memory metric with initial data.
func (m *metricOracledbPgaMemory) init() {
	m.data.SetName("oracledb.pga_memory")
	m.data.SetDescription("Program Global Area memory usage")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbPgaMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbPgaMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbPgaMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbPgaMemory(cfg MetricConfig) metricOracledbPgaMemory {
	m := metricOracledbPgaMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbPgaUsedMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.pga_used_memory metric with initial data.
func (m *metricOracledbPgaUsedMemory) init() {
	m.data.SetName("oracledb.pga_used_memory")
	m.data.SetDescription("PGA memory used by process")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbPgaUsedMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbPgaUsedMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbPgaUsedMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbPgaUsedMemory(cfg MetricConfig) metricOracledbPgaUsedMemory {
	m := metricOracledbPgaUsedMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbPhysicalReadBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.physical_read_bytes metric with initial data.
func (m *metricOracledbPhysicalReadBytes) init() {
	m.data.SetName("oracledb.physical_read_bytes")
	m.data.SetDescription("Physical read bytes")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbPhysicalReadBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbPhysicalReadBytes) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbPhysicalReadBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbPhysicalReadBytes(cfg MetricConfig) metricOracledbPhysicalReadBytes {
	m := metricOracledbPhysicalReadBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbPhysicalReadIoRequests struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.physical_read_io_requests metric with initial data.
func (m *metricOracledbPhysicalReadIoRequests) init() {
	m.data.SetName("oracledb.physical_read_io_requests")
	m.data.SetDescription("Number of read requests for application activity")
	m.data.SetUnit("{requests}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbPhysicalReadIoRequests) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbPhysicalReadIoRequests) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbPhysicalReadIoRequests) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbPhysicalReadIoRequests(cfg MetricConfig) metricOracledbPhysicalReadIoRequests {
	m := metricOracledbPhysicalReadIoRequests{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbPhysicalReads struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.physical_reads metric with initial data.
func (m *metricOracledbPhysicalReads) init() {
	m.data.SetName("oracledb.physical_reads")
	m.data.SetDescription("Physical disk reads")
	m.data.SetUnit("{reads}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbPhysicalReads) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbPhysicalReads) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbPhysicalReads) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbPhysicalReads(cfg MetricConfig) metricOracledbPhysicalReads {
	m := metricOracledbPhysicalReads{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbPhysicalReadsDirect struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.physical_reads_direct metric with initial data.
func (m *metricOracledbPhysicalReadsDirect) init() {
	m.data.SetName("oracledb.physical_reads_direct")
	m.data.SetDescription("Physical reads direct")
	m.data.SetUnit("{reads}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbPhysicalReadsDirect) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbPhysicalReadsDirect) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbPhysicalReadsDirect) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbPhysicalReadsDirect(cfg MetricConfig) metricOracledbPhysicalReadsDirect {
	m := metricOracledbPhysicalReadsDirect{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbPhysicalWriteBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.physical_write_bytes metric with initial data.
func (m *metricOracledbPhysicalWriteBytes) init() {
	m.data.SetName("oracledb.physical_write_bytes")
	m.data.SetDescription("Physical write bytes")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbPhysicalWriteBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbPhysicalWriteBytes) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbPhysicalWriteBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbPhysicalWriteBytes(cfg MetricConfig) metricOracledbPhysicalWriteBytes {
	m := metricOracledbPhysicalWriteBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbPhysicalWriteIoRequests struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.physical_write_io_requests metric with initial data.
func (m *metricOracledbPhysicalWriteIoRequests) init() {
	m.data.SetName("oracledb.physical_write_io_requests")
	m.data.SetDescription("Number of write requests for application activity")
	m.data.SetUnit("{requests}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbPhysicalWriteIoRequests) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbPhysicalWriteIoRequests) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbPhysicalWriteIoRequests) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbPhysicalWriteIoRequests(cfg MetricConfig) metricOracledbPhysicalWriteIoRequests {
	m := metricOracledbPhysicalWriteIoRequests{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbPhysicalWrites struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.physical_writes metric with initial data.
func (m *metricOracledbPhysicalWrites) init() {
	m.data.SetName("oracledb.physical_writes")
	m.data.SetDescription("Physical disk writes")
	m.data.SetUnit("{writes}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbPhysicalWrites) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbPhysicalWrites) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbPhysicalWrites) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbPhysicalWrites(cfg MetricConfig) metricOracledbPhysicalWrites {
	m := metricOracledbPhysicalWrites{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbPhysicalWritesDirect struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.physical_writes_direct metric with initial data.
func (m *metricOracledbPhysicalWritesDirect) init() {
	m.data.SetName("oracledb.physical_writes_direct")
	m.data.SetDescription("Physical writes direct")
	m.data.SetUnit("{writes}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbPhysicalWritesDirect) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbPhysicalWritesDirect) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbPhysicalWritesDirect) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbPhysicalWritesDirect(cfg MetricConfig) metricOracledbPhysicalWritesDirect {
	m := metricOracledbPhysicalWritesDirect{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbProcessesLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.processes_limit metric with initial data.
func (m *metricOracledbProcessesLimit) init() {
	m.data.SetName("oracledb.processes_limit")
	m.data.SetDescription("Maximum limit of active processes, -1 if unlimited")
	m.data.SetUnit("{processes}")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbProcessesLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbProcessesLimit) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbProcessesLimit) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbProcessesLimit(cfg MetricConfig) metricOracledbProcessesLimit {
	m := metricOracledbProcessesLimit{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbProcessesUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.processes_usage metric with initial data.
func (m *metricOracledbProcessesUsage) init() {
	m.data.SetName("oracledb.processes_usage")
	m.data.SetDescription("Current count of active processes")
	m.data.SetUnit("{processes}")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbProcessesUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbProcessesUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbProcessesUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbProcessesUsage(cfg MetricConfig) metricOracledbProcessesUsage {
	m := metricOracledbProcessesUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbQueriesParallelized struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.queries_parallelized metric with initial data.
func (m *metricOracledbQueriesParallelized) init() {
	m.data.SetName("oracledb.queries_parallelized")
	m.data.SetDescription("Number of queries executed in parallel")
	m.data.SetUnit("{queries}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbQueriesParallelized) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbQueriesParallelized) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbQueriesParallelized) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbQueriesParallelized(cfg MetricConfig) metricOracledbQueriesParallelized {
	m := metricOracledbQueriesParallelized{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbRedoSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.redo_size metric with initial data.
func (m *metricOracledbRedoSize) init() {
	m.data.SetName("oracledb.redo_size")
	m.data.SetDescription("Redo log size")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbRedoSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbRedoSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbRedoSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbRedoSize(cfg MetricConfig) metricOracledbRedoSize {
	m := metricOracledbRedoSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbRowCacheHitRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.row_cache_hit_ratio metric with initial data.
func (m *metricOracledbRowCacheHitRatio) init() {
	m.data.SetName("oracledb.row_cache_hit_ratio")
	m.data.SetDescription("Row cache hit ratio")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbRowCacheHitRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbRowCacheHitRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbRowCacheHitRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbRowCacheHitRatio(cfg MetricConfig) metricOracledbRowCacheHitRatio {
	m := metricOracledbRowCacheHitRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbSessions struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.sessions metric with initial data.
func (m *metricOracledbSessions) init() {
	m.data.SetName("oracledb.sessions")
	m.data.SetDescription("Active sessions by type and status")
	m.data.SetUnit("{sessions}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricOracledbSessions) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, sessionStatusAttributeValue string, sessionTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("session_status", sessionStatusAttributeValue)
	dp.Attributes().PutStr("session_type", sessionTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbSessions) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbSessions) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbSessions(cfg MetricConfig) metricOracledbSessions {
	m := metricOracledbSessions{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbSessionsLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.sessions_limit metric with initial data.
func (m *metricOracledbSessionsLimit) init() {
	m.data.SetName("oracledb.sessions_limit")
	m.data.SetDescription("Maximum limit of active sessions, -1 if unlimited")
	m.data.SetUnit("{sessions}")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbSessionsLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbSessionsLimit) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbSessionsLimit) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbSessionsLimit(cfg MetricConfig) metricOracledbSessionsLimit {
	m := metricOracledbSessionsLimit{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbSgaFixedSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.sga_fixed_size metric with initial data.
func (m *metricOracledbSgaFixedSize) init() {
	m.data.SetName("oracledb.sga_fixed_size")
	m.data.SetDescription("SGA fixed size in bytes")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbSgaFixedSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbSgaFixedSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbSgaFixedSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbSgaFixedSize(cfg MetricConfig) metricOracledbSgaFixedSize {
	m := metricOracledbSgaFixedSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbSharedPoolFree struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.shared_pool_free metric with initial data.
func (m *metricOracledbSharedPoolFree) init() {
	m.data.SetName("oracledb.shared_pool_free")
	m.data.SetDescription("Shared pool free memory percentage")
	m.data.SetUnit("%")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbSharedPoolFree) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbSharedPoolFree) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbSharedPoolFree) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbSharedPoolFree(cfg MetricConfig) metricOracledbSharedPoolFree {
	m := metricOracledbSharedPoolFree{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbTablespaceOffline struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.tablespace_offline metric with initial data.
func (m *metricOracledbTablespaceOffline) init() {
	m.data.SetName("oracledb.tablespace_offline")
	m.data.SetDescription("Tablespace offline status (1 if offline, 0 if online)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricOracledbTablespaceOffline) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("tablespace_name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbTablespaceOffline) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbTablespaceOffline) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbTablespaceOffline(cfg MetricConfig) metricOracledbTablespaceOffline {
	m := metricOracledbTablespaceOffline{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbTablespaceSizeLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.tablespace_size_limit metric with initial data.
func (m *metricOracledbTablespaceSizeLimit) init() {
	m.data.SetName("oracledb.tablespace_size_limit")
	m.data.SetDescription("Tablespace size limit in bytes")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricOracledbTablespaceSizeLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("tablespace_name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbTablespaceSizeLimit) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbTablespaceSizeLimit) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbTablespaceSizeLimit(cfg MetricConfig) metricOracledbTablespaceSizeLimit {
	m := metricOracledbTablespaceSizeLimit{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbTablespaceSizeUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.tablespace_size_usage metric with initial data.
func (m *metricOracledbTablespaceSizeUsage) init() {
	m.data.SetName("oracledb.tablespace_size_usage")
	m.data.SetDescription("Tablespace usage in bytes")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricOracledbTablespaceSizeUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("tablespace_name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbTablespaceSizeUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbTablespaceSizeUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbTablespaceSizeUsage(cfg MetricConfig) metricOracledbTablespaceSizeUsage {
	m := metricOracledbTablespaceSizeUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbTablespaceUsagePercentage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.tablespace_usage_percentage metric with initial data.
func (m *metricOracledbTablespaceUsagePercentage) init() {
	m.data.SetName("oracledb.tablespace_usage_percentage")
	m.data.SetDescription("Tablespace usage percentage")
	m.data.SetUnit("%")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricOracledbTablespaceUsagePercentage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("tablespace_name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbTablespaceUsagePercentage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbTablespaceUsagePercentage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbTablespaceUsagePercentage(cfg MetricConfig) metricOracledbTablespaceUsagePercentage {
	m := metricOracledbTablespaceUsagePercentage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbTransactionsLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.transactions_limit metric with initial data.
func (m *metricOracledbTransactionsLimit) init() {
	m.data.SetName("oracledb.transactions_limit")
	m.data.SetDescription("Maximum limit of active transactions, -1 if unlimited")
	m.data.SetUnit("{transactions}")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbTransactionsLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbTransactionsLimit) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbTransactionsLimit) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbTransactionsLimit(cfg MetricConfig) metricOracledbTransactionsLimit {
	m := metricOracledbTransactionsLimit{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbTransactionsUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.transactions_usage metric with initial data.
func (m *metricOracledbTransactionsUsage) init() {
	m.data.SetName("oracledb.transactions_usage")
	m.data.SetDescription("Current count of active transactions")
	m.data.SetUnit("{transactions}")
	m.data.SetEmptyGauge()
}

func (m *metricOracledbTransactionsUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbTransactionsUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbTransactionsUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbTransactionsUsage(cfg MetricConfig) metricOracledbTransactionsUsage {
	m := metricOracledbTransactionsUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbUserCommits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.user_commits metric with initial data.
func (m *metricOracledbUserCommits) init() {
	m.data.SetName("oracledb.user_commits")
	m.data.SetDescription("User transaction commits")
	m.data.SetUnit("{commits}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbUserCommits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbUserCommits) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbUserCommits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbUserCommits(cfg MetricConfig) metricOracledbUserCommits {
	m := metricOracledbUserCommits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbUserRollbacks struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.user_rollbacks metric with initial data.
func (m *metricOracledbUserRollbacks) init() {
	m.data.SetName("oracledb.user_rollbacks")
	m.data.SetDescription("User transaction rollbacks")
	m.data.SetUnit("{rollbacks}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbUserRollbacks) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbUserRollbacks) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbUserRollbacks) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbUserRollbacks(cfg MetricConfig) metricOracledbUserRollbacks {
	m := metricOracledbUserRollbacks{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbWaitEvents struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.wait_events metric with initial data.
func (m *metricOracledbWaitEvents) init() {
	m.data.SetName("oracledb.wait_events")
	m.data.SetDescription("Database wait events by type")
	m.data.SetUnit("{events}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbWaitEvents) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbWaitEvents) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbWaitEvents) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbWaitEvents(cfg MetricConfig) metricOracledbWaitEvents {
	m := metricOracledbWaitEvents{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricOracledbWaitTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills oracledb.wait_time metric with initial data.
func (m *metricOracledbWaitTime) init() {
	m.data.SetName("oracledb.wait_time")
	m.data.SetDescription("Total time waited for events")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricOracledbWaitTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricOracledbWaitTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricOracledbWaitTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricOracledbWaitTime(cfg MetricConfig) metricOracledbWaitTime {
	m := metricOracledbWaitTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config                                              MetricsBuilderConfig // config of the metrics builder.
	startTime                                           pcommon.Timestamp    // start time that will be applied to all recorded data points.
	metricsCapacity                                     int                  // maximum observed number of metrics per resource.
	metricsBuffer                                       pmetric.Metrics      // accumulates metrics data before emitting.
	buildInfo                                           component.BuildInfo  // contains version information.
	resourceAttributeIncludeFilter                      map[string]filter.Filter
	resourceAttributeExcludeFilter                      map[string]filter.Filter
	metricOracledbBufferCacheHitRatio                   metricOracledbBufferCacheHitRatio
	metricOracledbConsistentGets                        metricOracledbConsistentGets
	metricOracledbCPUTime                               metricOracledbCPUTime
	metricOracledbDbBlockGets                           metricOracledbDbBlockGets
	metricOracledbDdlStatementsParallelized             metricOracledbDdlStatementsParallelized
	metricOracledbDmlLocksLimit                         metricOracledbDmlLocksLimit
	metricOracledbDmlLocksUsage                         metricOracledbDmlLocksUsage
	metricOracledbDmlStatementsParallelized             metricOracledbDmlStatementsParallelized
	metricOracledbEnqueueDeadlocks                      metricOracledbEnqueueDeadlocks
	metricOracledbEnqueueLocksLimit                     metricOracledbEnqueueLocksLimit
	metricOracledbEnqueueLocksUsage                     metricOracledbEnqueueLocksUsage
	metricOracledbEnqueueResourcesLimit                 metricOracledbEnqueueResourcesLimit
	metricOracledbEnqueueResourcesUsage                 metricOracledbEnqueueResourcesUsage
	metricOracledbExchangeDeadlocks                     metricOracledbExchangeDeadlocks
	metricOracledbExecutions                            metricOracledbExecutions
	metricOracledbHardParses                            metricOracledbHardParses
	metricOracledbLibraryCacheHitRatio                  metricOracledbLibraryCacheHitRatio
	metricOracledbLogicalReads                          metricOracledbLogicalReads
	metricOracledbLogons                                metricOracledbLogons
	metricOracledbParallelOperationsDowngraded1To25Pct  metricOracledbParallelOperationsDowngraded1To25Pct
	metricOracledbParallelOperationsDowngraded25To50Pct metricOracledbParallelOperationsDowngraded25To50Pct
	metricOracledbParallelOperationsDowngraded50To75Pct metricOracledbParallelOperationsDowngraded50To75Pct
	metricOracledbParallelOperationsDowngraded75To99Pct metricOracledbParallelOperationsDowngraded75To99Pct
	metricOracledbParallelOperationsDowngradedToSerial  metricOracledbParallelOperationsDowngradedToSerial
	metricOracledbParallelOperationsNotDowngraded       metricOracledbParallelOperationsNotDowngraded
	metricOracledbParseCalls                            metricOracledbParseCalls
	metricOracledbPgaAllocatedMemory                    metricOracledbPgaAllocatedMemory
	metricOracledbPgaFreeableMemory                     metricOracledbPgaFreeableMemory
	metricOracledbPgaMaximumMemory                      metricOracledbPgaMaximumMemory
	metricOracledbPgaMemory                             metricOracledbPgaMemory
	metricOracledbPgaUsedMemory                         metricOracledbPgaUsedMemory
	metricOracledbPhysicalReadBytes                     metricOracledbPhysicalReadBytes
	metricOracledbPhysicalReadIoRequests                metricOracledbPhysicalReadIoRequests
	metricOracledbPhysicalReads                         metricOracledbPhysicalReads
	metricOracledbPhysicalReadsDirect                   metricOracledbPhysicalReadsDirect
	metricOracledbPhysicalWriteBytes                    metricOracledbPhysicalWriteBytes
	metricOracledbPhysicalWriteIoRequests               metricOracledbPhysicalWriteIoRequests
	metricOracledbPhysicalWrites                        metricOracledbPhysicalWrites
	metricOracledbPhysicalWritesDirect                  metricOracledbPhysicalWritesDirect
	metricOracledbProcessesLimit                        metricOracledbProcessesLimit
	metricOracledbProcessesUsage                        metricOracledbProcessesUsage
	metricOracledbQueriesParallelized                   metricOracledbQueriesParallelized
	metricOracledbRedoSize                              metricOracledbRedoSize
	metricOracledbRowCacheHitRatio                      metricOracledbRowCacheHitRatio
	metricOracledbSessions                              metricOracledbSessions
	metricOracledbSessionsLimit                         metricOracledbSessionsLimit
	metricOracledbSgaFixedSize                          metricOracledbSgaFixedSize
	metricOracledbSharedPoolFree                        metricOracledbSharedPoolFree
	metricOracledbTablespaceOffline                     metricOracledbTablespaceOffline
	metricOracledbTablespaceSizeLimit                   metricOracledbTablespaceSizeLimit
	metricOracledbTablespaceSizeUsage                   metricOracledbTablespaceSizeUsage
	metricOracledbTablespaceUsagePercentage             metricOracledbTablespaceUsagePercentage
	metricOracledbTransactionsLimit                     metricOracledbTransactionsLimit
	metricOracledbTransactionsUsage                     metricOracledbTransactionsUsage
	metricOracledbUserCommits                           metricOracledbUserCommits
	metricOracledbUserRollbacks                         metricOracledbUserRollbacks
	metricOracledbWaitEvents                            metricOracledbWaitEvents
	metricOracledbWaitTime                              metricOracledbWaitTime
}

// MetricBuilderOption applies changes to default metrics builder.
type MetricBuilderOption interface {
	apply(*MetricsBuilder)
}

type metricBuilderOptionFunc func(mb *MetricsBuilder)

func (mbof metricBuilderOptionFunc) apply(mb *MetricsBuilder) {
	mbof(mb)
}

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) MetricBuilderOption {
	return metricBuilderOptionFunc(func(mb *MetricsBuilder) {
		mb.startTime = startTime
	})
}
func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.Settings, options ...MetricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:                                              mbc,
		startTime:                                           pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:                                       pmetric.NewMetrics(),
		buildInfo:                                           settings.BuildInfo,
		metricOracledbBufferCacheHitRatio:                   newMetricOracledbBufferCacheHitRatio(mbc.Metrics.OracledbBufferCacheHitRatio),
		metricOracledbConsistentGets:                        newMetricOracledbConsistentGets(mbc.Metrics.OracledbConsistentGets),
		metricOracledbCPUTime:                               newMetricOracledbCPUTime(mbc.Metrics.OracledbCPUTime),
		metricOracledbDbBlockGets:                           newMetricOracledbDbBlockGets(mbc.Metrics.OracledbDbBlockGets),
		metricOracledbDdlStatementsParallelized:             newMetricOracledbDdlStatementsParallelized(mbc.Metrics.OracledbDdlStatementsParallelized),
		metricOracledbDmlLocksLimit:                         newMetricOracledbDmlLocksLimit(mbc.Metrics.OracledbDmlLocksLimit),
		metricOracledbDmlLocksUsage:                         newMetricOracledbDmlLocksUsage(mbc.Metrics.OracledbDmlLocksUsage),
		metricOracledbDmlStatementsParallelized:             newMetricOracledbDmlStatementsParallelized(mbc.Metrics.OracledbDmlStatementsParallelized),
		metricOracledbEnqueueDeadlocks:                      newMetricOracledbEnqueueDeadlocks(mbc.Metrics.OracledbEnqueueDeadlocks),
		metricOracledbEnqueueLocksLimit:                     newMetricOracledbEnqueueLocksLimit(mbc.Metrics.OracledbEnqueueLocksLimit),
		metricOracledbEnqueueLocksUsage:                     newMetricOracledbEnqueueLocksUsage(mbc.Metrics.OracledbEnqueueLocksUsage),
		metricOracledbEnqueueResourcesLimit:                 newMetricOracledbEnqueueResourcesLimit(mbc.Metrics.OracledbEnqueueResourcesLimit),
		metricOracledbEnqueueResourcesUsage:                 newMetricOracledbEnqueueResourcesUsage(mbc.Metrics.OracledbEnqueueResourcesUsage),
		metricOracledbExchangeDeadlocks:                     newMetricOracledbExchangeDeadlocks(mbc.Metrics.OracledbExchangeDeadlocks),
		metricOracledbExecutions:                            newMetricOracledbExecutions(mbc.Metrics.OracledbExecutions),
		metricOracledbHardParses:                            newMetricOracledbHardParses(mbc.Metrics.OracledbHardParses),
		metricOracledbLibraryCacheHitRatio:                  newMetricOracledbLibraryCacheHitRatio(mbc.Metrics.OracledbLibraryCacheHitRatio),
		metricOracledbLogicalReads:                          newMetricOracledbLogicalReads(mbc.Metrics.OracledbLogicalReads),
		metricOracledbLogons:                                newMetricOracledbLogons(mbc.Metrics.OracledbLogons),
		metricOracledbParallelOperationsDowngraded1To25Pct:  newMetricOracledbParallelOperationsDowngraded1To25Pct(mbc.Metrics.OracledbParallelOperationsDowngraded1To25Pct),
		metricOracledbParallelOperationsDowngraded25To50Pct: newMetricOracledbParallelOperationsDowngraded25To50Pct(mbc.Metrics.OracledbParallelOperationsDowngraded25To50Pct),
		metricOracledbParallelOperationsDowngraded50To75Pct: newMetricOracledbParallelOperationsDowngraded50To75Pct(mbc.Metrics.OracledbParallelOperationsDowngraded50To75Pct),
		metricOracledbParallelOperationsDowngraded75To99Pct: newMetricOracledbParallelOperationsDowngraded75To99Pct(mbc.Metrics.OracledbParallelOperationsDowngraded75To99Pct),
		metricOracledbParallelOperationsDowngradedToSerial:  newMetricOracledbParallelOperationsDowngradedToSerial(mbc.Metrics.OracledbParallelOperationsDowngradedToSerial),
		metricOracledbParallelOperationsNotDowngraded:       newMetricOracledbParallelOperationsNotDowngraded(mbc.Metrics.OracledbParallelOperationsNotDowngraded),
		metricOracledbParseCalls:                            newMetricOracledbParseCalls(mbc.Metrics.OracledbParseCalls),
		metricOracledbPgaAllocatedMemory:                    newMetricOracledbPgaAllocatedMemory(mbc.Metrics.OracledbPgaAllocatedMemory),
		metricOracledbPgaFreeableMemory:                     newMetricOracledbPgaFreeableMemory(mbc.Metrics.OracledbPgaFreeableMemory),
		metricOracledbPgaMaximumMemory:                      newMetricOracledbPgaMaximumMemory(mbc.Metrics.OracledbPgaMaximumMemory),
		metricOracledbPgaMemory:                             newMetricOracledbPgaMemory(mbc.Metrics.OracledbPgaMemory),
		metricOracledbPgaUsedMemory:                         newMetricOracledbPgaUsedMemory(mbc.Metrics.OracledbPgaUsedMemory),
		metricOracledbPhysicalReadBytes:                     newMetricOracledbPhysicalReadBytes(mbc.Metrics.OracledbPhysicalReadBytes),
		metricOracledbPhysicalReadIoRequests:                newMetricOracledbPhysicalReadIoRequests(mbc.Metrics.OracledbPhysicalReadIoRequests),
		metricOracledbPhysicalReads:                         newMetricOracledbPhysicalReads(mbc.Metrics.OracledbPhysicalReads),
		metricOracledbPhysicalReadsDirect:                   newMetricOracledbPhysicalReadsDirect(mbc.Metrics.OracledbPhysicalReadsDirect),
		metricOracledbPhysicalWriteBytes:                    newMetricOracledbPhysicalWriteBytes(mbc.Metrics.OracledbPhysicalWriteBytes),
		metricOracledbPhysicalWriteIoRequests:               newMetricOracledbPhysicalWriteIoRequests(mbc.Metrics.OracledbPhysicalWriteIoRequests),
		metricOracledbPhysicalWrites:                        newMetricOracledbPhysicalWrites(mbc.Metrics.OracledbPhysicalWrites),
		metricOracledbPhysicalWritesDirect:                  newMetricOracledbPhysicalWritesDirect(mbc.Metrics.OracledbPhysicalWritesDirect),
		metricOracledbProcessesLimit:                        newMetricOracledbProcessesLimit(mbc.Metrics.OracledbProcessesLimit),
		metricOracledbProcessesUsage:                        newMetricOracledbProcessesUsage(mbc.Metrics.OracledbProcessesUsage),
		metricOracledbQueriesParallelized:                   newMetricOracledbQueriesParallelized(mbc.Metrics.OracledbQueriesParallelized),
		metricOracledbRedoSize:                              newMetricOracledbRedoSize(mbc.Metrics.OracledbRedoSize),
		metricOracledbRowCacheHitRatio:                      newMetricOracledbRowCacheHitRatio(mbc.Metrics.OracledbRowCacheHitRatio),
		metricOracledbSessions:                              newMetricOracledbSessions(mbc.Metrics.OracledbSessions),
		metricOracledbSessionsLimit:                         newMetricOracledbSessionsLimit(mbc.Metrics.OracledbSessionsLimit),
		metricOracledbSgaFixedSize:                          newMetricOracledbSgaFixedSize(mbc.Metrics.OracledbSgaFixedSize),
		metricOracledbSharedPoolFree:                        newMetricOracledbSharedPoolFree(mbc.Metrics.OracledbSharedPoolFree),
		metricOracledbTablespaceOffline:                     newMetricOracledbTablespaceOffline(mbc.Metrics.OracledbTablespaceOffline),
		metricOracledbTablespaceSizeLimit:                   newMetricOracledbTablespaceSizeLimit(mbc.Metrics.OracledbTablespaceSizeLimit),
		metricOracledbTablespaceSizeUsage:                   newMetricOracledbTablespaceSizeUsage(mbc.Metrics.OracledbTablespaceSizeUsage),
		metricOracledbTablespaceUsagePercentage:             newMetricOracledbTablespaceUsagePercentage(mbc.Metrics.OracledbTablespaceUsagePercentage),
		metricOracledbTransactionsLimit:                     newMetricOracledbTransactionsLimit(mbc.Metrics.OracledbTransactionsLimit),
		metricOracledbTransactionsUsage:                     newMetricOracledbTransactionsUsage(mbc.Metrics.OracledbTransactionsUsage),
		metricOracledbUserCommits:                           newMetricOracledbUserCommits(mbc.Metrics.OracledbUserCommits),
		metricOracledbUserRollbacks:                         newMetricOracledbUserRollbacks(mbc.Metrics.OracledbUserRollbacks),
		metricOracledbWaitEvents:                            newMetricOracledbWaitEvents(mbc.Metrics.OracledbWaitEvents),
		metricOracledbWaitTime:                              newMetricOracledbWaitTime(mbc.Metrics.OracledbWaitTime),
		resourceAttributeIncludeFilter:                      make(map[string]filter.Filter),
		resourceAttributeExcludeFilter:                      make(map[string]filter.Filter),
	}
	if mbc.ResourceAttributes.HostName.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["host.name"] = filter.CreateFilter(mbc.ResourceAttributes.HostName.MetricsInclude)
	}
	if mbc.ResourceAttributes.HostName.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["host.name"] = filter.CreateFilter(mbc.ResourceAttributes.HostName.MetricsExclude)
	}
	if mbc.ResourceAttributes.OracledbDatabaseSid.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["oracledb.database.sid"] = filter.CreateFilter(mbc.ResourceAttributes.OracledbDatabaseSid.MetricsInclude)
	}
	if mbc.ResourceAttributes.OracledbDatabaseSid.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["oracledb.database.sid"] = filter.CreateFilter(mbc.ResourceAttributes.OracledbDatabaseSid.MetricsExclude)
	}
	if mbc.ResourceAttributes.OracledbInstanceName.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["oracledb.instance.name"] = filter.CreateFilter(mbc.ResourceAttributes.OracledbInstanceName.MetricsInclude)
	}
	if mbc.ResourceAttributes.OracledbInstanceName.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["oracledb.instance.name"] = filter.CreateFilter(mbc.ResourceAttributes.OracledbInstanceName.MetricsExclude)
	}
	if mbc.ResourceAttributes.OracledbLogFileName.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["oracledb.log.file.name"] = filter.CreateFilter(mbc.ResourceAttributes.OracledbLogFileName.MetricsInclude)
	}
	if mbc.ResourceAttributes.OracledbLogFileName.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["oracledb.log.file.name"] = filter.CreateFilter(mbc.ResourceAttributes.OracledbLogFileName.MetricsExclude)
	}
	if mbc.ResourceAttributes.OracledbLogFilePath.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["oracledb.log.file.path"] = filter.CreateFilter(mbc.ResourceAttributes.OracledbLogFilePath.MetricsInclude)
	}
	if mbc.ResourceAttributes.OracledbLogFilePath.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["oracledb.log.file.path"] = filter.CreateFilter(mbc.ResourceAttributes.OracledbLogFilePath.MetricsExclude)
	}
	if mbc.ResourceAttributes.OracledbLogSource.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["oracledb.log.source"] = filter.CreateFilter(mbc.ResourceAttributes.OracledbLogSource.MetricsInclude)
	}
	if mbc.ResourceAttributes.OracledbLogSource.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["oracledb.log.source"] = filter.CreateFilter(mbc.ResourceAttributes.OracledbLogSource.MetricsExclude)
	}

	for _, op := range options {
		op.apply(mb)
	}
	return mb
}

// NewResourceBuilder returns a new resource builder that should be used to build a resource associated with for the emitted metrics.
func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	return NewResourceBuilder(mb.config.ResourceAttributes)
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption interface {
	apply(pmetric.ResourceMetrics)
}

type resourceMetricsOptionFunc func(pmetric.ResourceMetrics)

func (rmof resourceMetricsOptionFunc) apply(rm pmetric.ResourceMetrics) {
	rmof(rm)
}

// WithResource sets the provided resource on the emitted ResourceMetrics.
// It's recommended to use ResourceBuilder to create the resource.
func WithResource(res pcommon.Resource) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		res.CopyTo(rm.Resource())
	})
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	})
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(options ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName(ScopeName)
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricOracledbBufferCacheHitRatio.emit(ils.Metrics())
	mb.metricOracledbConsistentGets.emit(ils.Metrics())
	mb.metricOracledbCPUTime.emit(ils.Metrics())
	mb.metricOracledbDbBlockGets.emit(ils.Metrics())
	mb.metricOracledbDdlStatementsParallelized.emit(ils.Metrics())
	mb.metricOracledbDmlLocksLimit.emit(ils.Metrics())
	mb.metricOracledbDmlLocksUsage.emit(ils.Metrics())
	mb.metricOracledbDmlStatementsParallelized.emit(ils.Metrics())
	mb.metricOracledbEnqueueDeadlocks.emit(ils.Metrics())
	mb.metricOracledbEnqueueLocksLimit.emit(ils.Metrics())
	mb.metricOracledbEnqueueLocksUsage.emit(ils.Metrics())
	mb.metricOracledbEnqueueResourcesLimit.emit(ils.Metrics())
	mb.metricOracledbEnqueueResourcesUsage.emit(ils.Metrics())
	mb.metricOracledbExchangeDeadlocks.emit(ils.Metrics())
	mb.metricOracledbExecutions.emit(ils.Metrics())
	mb.metricOracledbHardParses.emit(ils.Metrics())
	mb.metricOracledbLibraryCacheHitRatio.emit(ils.Metrics())
	mb.metricOracledbLogicalReads.emit(ils.Metrics())
	mb.metricOracledbLogons.emit(ils.Metrics())
	mb.metricOracledbParallelOperationsDowngraded1To25Pct.emit(ils.Metrics())
	mb.metricOracledbParallelOperationsDowngraded25To50Pct.emit(ils.Metrics())
	mb.metricOracledbParallelOperationsDowngraded50To75Pct.emit(ils.Metrics())
	mb.metricOracledbParallelOperationsDowngraded75To99Pct.emit(ils.Metrics())
	mb.metricOracledbParallelOperationsDowngradedToSerial.emit(ils.Metrics())
	mb.metricOracledbParallelOperationsNotDowngraded.emit(ils.Metrics())
	mb.metricOracledbParseCalls.emit(ils.Metrics())
	mb.metricOracledbPgaAllocatedMemory.emit(ils.Metrics())
	mb.metricOracledbPgaFreeableMemory.emit(ils.Metrics())
	mb.metricOracledbPgaMaximumMemory.emit(ils.Metrics())
	mb.metricOracledbPgaMemory.emit(ils.Metrics())
	mb.metricOracledbPgaUsedMemory.emit(ils.Metrics())
	mb.metricOracledbPhysicalReadBytes.emit(ils.Metrics())
	mb.metricOracledbPhysicalReadIoRequests.emit(ils.Metrics())
	mb.metricOracledbPhysicalReads.emit(ils.Metrics())
	mb.metricOracledbPhysicalReadsDirect.emit(ils.Metrics())
	mb.metricOracledbPhysicalWriteBytes.emit(ils.Metrics())
	mb.metricOracledbPhysicalWriteIoRequests.emit(ils.Metrics())
	mb.metricOracledbPhysicalWrites.emit(ils.Metrics())
	mb.metricOracledbPhysicalWritesDirect.emit(ils.Metrics())
	mb.metricOracledbProcessesLimit.emit(ils.Metrics())
	mb.metricOracledbProcessesUsage.emit(ils.Metrics())
	mb.metricOracledbQueriesParallelized.emit(ils.Metrics())
	mb.metricOracledbRedoSize.emit(ils.Metrics())
	mb.metricOracledbRowCacheHitRatio.emit(ils.Metrics())
	mb.metricOracledbSessions.emit(ils.Metrics())
	mb.metricOracledbSessionsLimit.emit(ils.Metrics())
	mb.metricOracledbSgaFixedSize.emit(ils.Metrics())
	mb.metricOracledbSharedPoolFree.emit(ils.Metrics())
	mb.metricOracledbTablespaceOffline.emit(ils.Metrics())
	mb.metricOracledbTablespaceSizeLimit.emit(ils.Metrics())
	mb.metricOracledbTablespaceSizeUsage.emit(ils.Metrics())
	mb.metricOracledbTablespaceUsagePercentage.emit(ils.Metrics())
	mb.metricOracledbTransactionsLimit.emit(ils.Metrics())
	mb.metricOracledbTransactionsUsage.emit(ils.Metrics())
	mb.metricOracledbUserCommits.emit(ils.Metrics())
	mb.metricOracledbUserRollbacks.emit(ils.Metrics())
	mb.metricOracledbWaitEvents.emit(ils.Metrics())
	mb.metricOracledbWaitTime.emit(ils.Metrics())

	for _, op := range options {
		op.apply(rm)
	}
	for attr, filter := range mb.resourceAttributeIncludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && !filter.Matches(val.AsString()) {
			return
		}
	}
	for attr, filter := range mb.resourceAttributeExcludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && filter.Matches(val.AsString()) {
			return
		}
	}

	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(options ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(options...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordOracledbBufferCacheHitRatioDataPoint adds a data point to oracledb.buffer_cache_hit_ratio metric.
func (mb *MetricsBuilder) RecordOracledbBufferCacheHitRatioDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricOracledbBufferCacheHitRatio.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbConsistentGetsDataPoint adds a data point to oracledb.consistent_gets metric.
func (mb *MetricsBuilder) RecordOracledbConsistentGetsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbConsistentGets.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbCPUTimeDataPoint adds a data point to oracledb.cpu_time metric.
func (mb *MetricsBuilder) RecordOracledbCPUTimeDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricOracledbCPUTime.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbDbBlockGetsDataPoint adds a data point to oracledb.db_block_gets metric.
func (mb *MetricsBuilder) RecordOracledbDbBlockGetsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbDbBlockGets.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbDdlStatementsParallelizedDataPoint adds a data point to oracledb.ddl_statements_parallelized metric.
func (mb *MetricsBuilder) RecordOracledbDdlStatementsParallelizedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbDdlStatementsParallelized.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbDmlLocksLimitDataPoint adds a data point to oracledb.dml_locks_limit metric.
func (mb *MetricsBuilder) RecordOracledbDmlLocksLimitDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbDmlLocksLimit.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbDmlLocksUsageDataPoint adds a data point to oracledb.dml_locks_usage metric.
func (mb *MetricsBuilder) RecordOracledbDmlLocksUsageDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbDmlLocksUsage.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbDmlStatementsParallelizedDataPoint adds a data point to oracledb.dml_statements_parallelized metric.
func (mb *MetricsBuilder) RecordOracledbDmlStatementsParallelizedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbDmlStatementsParallelized.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbEnqueueDeadlocksDataPoint adds a data point to oracledb.enqueue_deadlocks metric.
func (mb *MetricsBuilder) RecordOracledbEnqueueDeadlocksDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbEnqueueDeadlocks.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbEnqueueLocksLimitDataPoint adds a data point to oracledb.enqueue_locks_limit metric.
func (mb *MetricsBuilder) RecordOracledbEnqueueLocksLimitDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbEnqueueLocksLimit.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbEnqueueLocksUsageDataPoint adds a data point to oracledb.enqueue_locks_usage metric.
func (mb *MetricsBuilder) RecordOracledbEnqueueLocksUsageDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbEnqueueLocksUsage.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbEnqueueResourcesLimitDataPoint adds a data point to oracledb.enqueue_resources_limit metric.
func (mb *MetricsBuilder) RecordOracledbEnqueueResourcesLimitDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbEnqueueResourcesLimit.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbEnqueueResourcesUsageDataPoint adds a data point to oracledb.enqueue_resources_usage metric.
func (mb *MetricsBuilder) RecordOracledbEnqueueResourcesUsageDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbEnqueueResourcesUsage.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbExchangeDeadlocksDataPoint adds a data point to oracledb.exchange_deadlocks metric.
func (mb *MetricsBuilder) RecordOracledbExchangeDeadlocksDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbExchangeDeadlocks.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbExecutionsDataPoint adds a data point to oracledb.executions metric.
func (mb *MetricsBuilder) RecordOracledbExecutionsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbExecutions.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbHardParsesDataPoint adds a data point to oracledb.hard_parses metric.
func (mb *MetricsBuilder) RecordOracledbHardParsesDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbHardParses.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbLibraryCacheHitRatioDataPoint adds a data point to oracledb.library_cache_hit_ratio metric.
func (mb *MetricsBuilder) RecordOracledbLibraryCacheHitRatioDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricOracledbLibraryCacheHitRatio.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbLogicalReadsDataPoint adds a data point to oracledb.logical_reads metric.
func (mb *MetricsBuilder) RecordOracledbLogicalReadsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbLogicalReads.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbLogonsDataPoint adds a data point to oracledb.logons metric.
func (mb *MetricsBuilder) RecordOracledbLogonsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbLogons.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbParallelOperationsDowngraded1To25PctDataPoint adds a data point to oracledb.parallel_operations_downgraded_1_to_25_pct metric.
func (mb *MetricsBuilder) RecordOracledbParallelOperationsDowngraded1To25PctDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbParallelOperationsDowngraded1To25Pct.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbParallelOperationsDowngraded25To50PctDataPoint adds a data point to oracledb.parallel_operations_downgraded_25_to_50_pct metric.
func (mb *MetricsBuilder) RecordOracledbParallelOperationsDowngraded25To50PctDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbParallelOperationsDowngraded25To50Pct.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbParallelOperationsDowngraded50To75PctDataPoint adds a data point to oracledb.parallel_operations_downgraded_50_to_75_pct metric.
func (mb *MetricsBuilder) RecordOracledbParallelOperationsDowngraded50To75PctDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbParallelOperationsDowngraded50To75Pct.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbParallelOperationsDowngraded75To99PctDataPoint adds a data point to oracledb.parallel_operations_downgraded_75_to_99_pct metric.
func (mb *MetricsBuilder) RecordOracledbParallelOperationsDowngraded75To99PctDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbParallelOperationsDowngraded75To99Pct.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbParallelOperationsDowngradedToSerialDataPoint adds a data point to oracledb.parallel_operations_downgraded_to_serial metric.
func (mb *MetricsBuilder) RecordOracledbParallelOperationsDowngradedToSerialDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbParallelOperationsDowngradedToSerial.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbParallelOperationsNotDowngradedDataPoint adds a data point to oracledb.parallel_operations_not_downgraded metric.
func (mb *MetricsBuilder) RecordOracledbParallelOperationsNotDowngradedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbParallelOperationsNotDowngraded.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbParseCallsDataPoint adds a data point to oracledb.parse_calls metric.
func (mb *MetricsBuilder) RecordOracledbParseCallsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbParseCalls.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbPgaAllocatedMemoryDataPoint adds a data point to oracledb.pga_allocated_memory metric.
func (mb *MetricsBuilder) RecordOracledbPgaAllocatedMemoryDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbPgaAllocatedMemory.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbPgaFreeableMemoryDataPoint adds a data point to oracledb.pga_freeable_memory metric.
func (mb *MetricsBuilder) RecordOracledbPgaFreeableMemoryDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbPgaFreeableMemory.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbPgaMaximumMemoryDataPoint adds a data point to oracledb.pga_maximum_memory metric.
func (mb *MetricsBuilder) RecordOracledbPgaMaximumMemoryDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbPgaMaximumMemory.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbPgaMemoryDataPoint adds a data point to oracledb.pga_memory metric.
func (mb *MetricsBuilder) RecordOracledbPgaMemoryDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbPgaMemory.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbPgaUsedMemoryDataPoint adds a data point to oracledb.pga_used_memory metric.
func (mb *MetricsBuilder) RecordOracledbPgaUsedMemoryDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbPgaUsedMemory.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbPhysicalReadBytesDataPoint adds a data point to oracledb.physical_read_bytes metric.
func (mb *MetricsBuilder) RecordOracledbPhysicalReadBytesDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbPhysicalReadBytes.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbPhysicalReadIoRequestsDataPoint adds a data point to oracledb.physical_read_io_requests metric.
func (mb *MetricsBuilder) RecordOracledbPhysicalReadIoRequestsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbPhysicalReadIoRequests.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbPhysicalReadsDataPoint adds a data point to oracledb.physical_reads metric.
func (mb *MetricsBuilder) RecordOracledbPhysicalReadsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbPhysicalReads.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbPhysicalReadsDirectDataPoint adds a data point to oracledb.physical_reads_direct metric.
func (mb *MetricsBuilder) RecordOracledbPhysicalReadsDirectDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbPhysicalReadsDirect.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbPhysicalWriteBytesDataPoint adds a data point to oracledb.physical_write_bytes metric.
func (mb *MetricsBuilder) RecordOracledbPhysicalWriteBytesDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbPhysicalWriteBytes.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbPhysicalWriteIoRequestsDataPoint adds a data point to oracledb.physical_write_io_requests metric.
func (mb *MetricsBuilder) RecordOracledbPhysicalWriteIoRequestsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbPhysicalWriteIoRequests.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbPhysicalWritesDataPoint adds a data point to oracledb.physical_writes metric.
func (mb *MetricsBuilder) RecordOracledbPhysicalWritesDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbPhysicalWrites.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbPhysicalWritesDirectDataPoint adds a data point to oracledb.physical_writes_direct metric.
func (mb *MetricsBuilder) RecordOracledbPhysicalWritesDirectDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbPhysicalWritesDirect.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbProcessesLimitDataPoint adds a data point to oracledb.processes_limit metric.
func (mb *MetricsBuilder) RecordOracledbProcessesLimitDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbProcessesLimit.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbProcessesUsageDataPoint adds a data point to oracledb.processes_usage metric.
func (mb *MetricsBuilder) RecordOracledbProcessesUsageDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbProcessesUsage.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbQueriesParallelizedDataPoint adds a data point to oracledb.queries_parallelized metric.
func (mb *MetricsBuilder) RecordOracledbQueriesParallelizedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbQueriesParallelized.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbRedoSizeDataPoint adds a data point to oracledb.redo_size metric.
func (mb *MetricsBuilder) RecordOracledbRedoSizeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbRedoSize.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbRowCacheHitRatioDataPoint adds a data point to oracledb.row_cache_hit_ratio metric.
func (mb *MetricsBuilder) RecordOracledbRowCacheHitRatioDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricOracledbRowCacheHitRatio.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbSessionsDataPoint adds a data point to oracledb.sessions metric.
func (mb *MetricsBuilder) RecordOracledbSessionsDataPoint(ts pcommon.Timestamp, val int64, sessionStatusAttributeValue string, sessionTypeAttributeValue string) {
	mb.metricOracledbSessions.recordDataPoint(mb.startTime, ts, val, sessionStatusAttributeValue, sessionTypeAttributeValue)
}

// RecordOracledbSessionsLimitDataPoint adds a data point to oracledb.sessions_limit metric.
func (mb *MetricsBuilder) RecordOracledbSessionsLimitDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbSessionsLimit.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbSgaFixedSizeDataPoint adds a data point to oracledb.sga_fixed_size metric.
func (mb *MetricsBuilder) RecordOracledbSgaFixedSizeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbSgaFixedSize.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbSharedPoolFreeDataPoint adds a data point to oracledb.shared_pool_free metric.
func (mb *MetricsBuilder) RecordOracledbSharedPoolFreeDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricOracledbSharedPoolFree.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbTablespaceOfflineDataPoint adds a data point to oracledb.tablespace_offline metric.
func (mb *MetricsBuilder) RecordOracledbTablespaceOfflineDataPoint(ts pcommon.Timestamp, val int64, tablespaceNameAttributeValue string) {
	mb.metricOracledbTablespaceOffline.recordDataPoint(mb.startTime, ts, val, tablespaceNameAttributeValue)
}

// RecordOracledbTablespaceSizeLimitDataPoint adds a data point to oracledb.tablespace_size_limit metric.
func (mb *MetricsBuilder) RecordOracledbTablespaceSizeLimitDataPoint(ts pcommon.Timestamp, val int64, tablespaceNameAttributeValue string) {
	mb.metricOracledbTablespaceSizeLimit.recordDataPoint(mb.startTime, ts, val, tablespaceNameAttributeValue)
}

// RecordOracledbTablespaceSizeUsageDataPoint adds a data point to oracledb.tablespace_size_usage metric.
func (mb *MetricsBuilder) RecordOracledbTablespaceSizeUsageDataPoint(ts pcommon.Timestamp, val int64, tablespaceNameAttributeValue string) {
	mb.metricOracledbTablespaceSizeUsage.recordDataPoint(mb.startTime, ts, val, tablespaceNameAttributeValue)
}

// RecordOracledbTablespaceUsagePercentageDataPoint adds a data point to oracledb.tablespace_usage_percentage metric.
func (mb *MetricsBuilder) RecordOracledbTablespaceUsagePercentageDataPoint(ts pcommon.Timestamp, val float64, tablespaceNameAttributeValue string) {
	mb.metricOracledbTablespaceUsagePercentage.recordDataPoint(mb.startTime, ts, val, tablespaceNameAttributeValue)
}

// RecordOracledbTransactionsLimitDataPoint adds a data point to oracledb.transactions_limit metric.
func (mb *MetricsBuilder) RecordOracledbTransactionsLimitDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbTransactionsLimit.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbTransactionsUsageDataPoint adds a data point to oracledb.transactions_usage metric.
func (mb *MetricsBuilder) RecordOracledbTransactionsUsageDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbTransactionsUsage.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbUserCommitsDataPoint adds a data point to oracledb.user_commits metric.
func (mb *MetricsBuilder) RecordOracledbUserCommitsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbUserCommits.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbUserRollbacksDataPoint adds a data point to oracledb.user_rollbacks metric.
func (mb *MetricsBuilder) RecordOracledbUserRollbacksDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbUserRollbacks.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbWaitEventsDataPoint adds a data point to oracledb.wait_events metric.
func (mb *MetricsBuilder) RecordOracledbWaitEventsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricOracledbWaitEvents.recordDataPoint(mb.startTime, ts, val)
}

// RecordOracledbWaitTimeDataPoint adds a data point to oracledb.wait_time metric.
func (mb *MetricsBuilder) RecordOracledbWaitTimeDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricOracledbWaitTime.recordDataPoint(mb.startTime, ts, val)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...MetricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op.apply(mb)
	}
}
