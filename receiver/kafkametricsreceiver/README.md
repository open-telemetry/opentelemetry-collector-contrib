# Kafka Metrics Receiver

<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [beta]: metrics   |
| Distributions | [contrib], [splunk], [sumo] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aopen%20label%3Areceiver%2Fkafkametrics%20&label=open&color=orange&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aopen+is%3Aissue+label%3Areceiver%2Fkafkametrics) [![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aclosed%20label%3Areceiver%2Fkafkametrics%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aclosed+is%3Aissue+label%3Areceiver%2Fkafkametrics) |
| [Code Owners](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/CONTRIBUTING.md#becoming-a-code-owner)    | [@dmitryax](https://www.github.com/dmitryax) |

[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta
[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib
[splunk]: https://github.com/signalfx/splunk-otel-collector
[sumo]: https://github.com/SumoLogic/sumologic-otel-collector
<!-- end autogenerated section -->

Kafka metrics receiver collects kafka metrics (brokers, topics, partitions, consumer groups) from kafka server,
converting into otlp.

## Getting Started

Required settings (no defaults):

- `protocol_version`: Kafka protocol version
- `scrapers`: any combination of the following scrapers can be enabled.
    - `topics`
    - `consumers`
    - `brokers`
    
Metrics collected by the associated scraper are listed [here](metadata.yaml)

Optional Settings (with defaults):

- `brokers` (default = localhost:9092): the list of brokers to read from.
- `resolve_canonical_bootstrap_servers_only` (default = false): whether to resolve then reverse-lookup broker IPs during startup.
- `topic_match` (default = ^[^_].*$): regex pattern of topics to filter on metrics collection. The default filter excludes internal topics (starting with `_`).
- `group_match` (default = .*): regex pattern of consumer groups to filter on for metrics.
- `client_id` (default = otel-metrics-receiver): consumer client id
- `collection_interval` (default = 1m): frequency of metric collection/scraping.
- `initial_delay` (default = `1s`): defines how long this receiver waits before starting.
- `auth` (default none)
    - `plain_text`
        - `username`: The username to use.
        - `password`: The password to use
    - `tls`
        - `ca_file`: path to the CA cert. For a client this verifies the server certificate. Should only be used
          if `insecure` is set to true.
        - `cert_file`: path to the TLS cert to use for TLS required connections. Should only be used if `insecure` is
          set to true.
        - `key_file`: path to the TLS key to use for TLS required connections. Should only be used if `insecure` is set
          to true.
        - `insecure` (default = false): Disable verifying the server's certificate chain and host
          name (`InsecureSkipVerify` in the tls config)
        - `server_name_override`: ServerName indicates the name of the server requested by the client in order to
          support virtual hosting.
    - `kerberos`
        - `service_name`: Kerberos service name
        - `realm`: Kerberos realm
        - `use_keytab`:  Use of keytab instead of password, if this is true, keytab file will be used instead of
          password
        - `username`: The Kerberos username used for authenticate with KDC
        - `password`: The Kerberos password used for authenticate with KDC
        - `config_file`: Path to Kerberos configuration. i.e /etc/krb5.conf
        - `keytab_file`: Path to keytab file. i.e /etc/security/kafka.keytab

## Examples:

1) Basic configuration with all scrapers:

```yaml
receivers:
  kafkametrics:
    protocol_version: 2.0.0
    scrapers:
      - brokers
      - topics
      - consumers
```

2) Configuration with more optional settings:

For this example:
- collection interval is 5 secs.

```yaml
receivers:
  kafkametrics:
    brokers: 10.10.10.10:9092
    protocol_version: 2.0.0
    scrapers:
      - brokers
      - topics
      - consumers
    auth:
      tls:
        ca_file: ca.pem
        cert_file: cert.pem
        key_file: key.pem
    collection_interval: 5s
```
