// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/confmap"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
)

// MetricSettings provides common settings for a particular metric.
type MetricSettings struct {
	Enabled bool `mapstructure:"enabled"`

	enabledProvidedByUser bool
}

// IsEnabledProvidedByUser returns true if `enabled` option is explicitly set in user settings to any value.
func (ms *MetricSettings) IsEnabledProvidedByUser() bool {
	return ms.enabledProvidedByUser
}

func (ms *MetricSettings) Unmarshal(parser *confmap.Conf) error {
	if parser == nil {
		return nil
	}
	err := parser.Unmarshal(ms, confmap.WithErrorUnused())
	if err != nil {
		return err
	}
	ms.enabledProvidedByUser = parser.IsSet("enabled")
	return nil
}

// MetricsSettings provides settings for mongoatlasreceiver metrics.
type MetricsSettings struct {
	MongodbatlasDbCounts                                  MetricSettings `mapstructure:"mongodbatlas.db.counts"`
	MongodbatlasDbSize                                    MetricSettings `mapstructure:"mongodbatlas.db.size"`
	MongodbatlasDiskPartitionIopsAverage                  MetricSettings `mapstructure:"mongodbatlas.disk.partition.iops.average"`
	MongodbatlasDiskPartitionIopsMax                      MetricSettings `mapstructure:"mongodbatlas.disk.partition.iops.max"`
	MongodbatlasDiskPartitionLatencyAverage               MetricSettings `mapstructure:"mongodbatlas.disk.partition.latency.average"`
	MongodbatlasDiskPartitionLatencyMax                   MetricSettings `mapstructure:"mongodbatlas.disk.partition.latency.max"`
	MongodbatlasDiskPartitionSpaceAverage                 MetricSettings `mapstructure:"mongodbatlas.disk.partition.space.average"`
	MongodbatlasDiskPartitionSpaceMax                     MetricSettings `mapstructure:"mongodbatlas.disk.partition.space.max"`
	MongodbatlasDiskPartitionUsageAverage                 MetricSettings `mapstructure:"mongodbatlas.disk.partition.usage.average"`
	MongodbatlasDiskPartitionUsageMax                     MetricSettings `mapstructure:"mongodbatlas.disk.partition.usage.max"`
	MongodbatlasDiskPartitionUtilizationAverage           MetricSettings `mapstructure:"mongodbatlas.disk.partition.utilization.average"`
	MongodbatlasDiskPartitionUtilizationMax               MetricSettings `mapstructure:"mongodbatlas.disk.partition.utilization.max"`
	MongodbatlasProcessAsserts                            MetricSettings `mapstructure:"mongodbatlas.process.asserts"`
	MongodbatlasProcessBackgroundFlush                    MetricSettings `mapstructure:"mongodbatlas.process.background_flush"`
	MongodbatlasProcessCacheIo                            MetricSettings `mapstructure:"mongodbatlas.process.cache.io"`
	MongodbatlasProcessCacheSize                          MetricSettings `mapstructure:"mongodbatlas.process.cache.size"`
	MongodbatlasProcessConnections                        MetricSettings `mapstructure:"mongodbatlas.process.connections"`
	MongodbatlasProcessCPUChildrenNormalizedUsageAverage  MetricSettings `mapstructure:"mongodbatlas.process.cpu.children.normalized.usage.average"`
	MongodbatlasProcessCPUChildrenNormalizedUsageMax      MetricSettings `mapstructure:"mongodbatlas.process.cpu.children.normalized.usage.max"`
	MongodbatlasProcessCPUChildrenUsageAverage            MetricSettings `mapstructure:"mongodbatlas.process.cpu.children.usage.average"`
	MongodbatlasProcessCPUChildrenUsageMax                MetricSettings `mapstructure:"mongodbatlas.process.cpu.children.usage.max"`
	MongodbatlasProcessCPUNormalizedUsageAverage          MetricSettings `mapstructure:"mongodbatlas.process.cpu.normalized.usage.average"`
	MongodbatlasProcessCPUNormalizedUsageMax              MetricSettings `mapstructure:"mongodbatlas.process.cpu.normalized.usage.max"`
	MongodbatlasProcessCPUUsageAverage                    MetricSettings `mapstructure:"mongodbatlas.process.cpu.usage.average"`
	MongodbatlasProcessCPUUsageMax                        MetricSettings `mapstructure:"mongodbatlas.process.cpu.usage.max"`
	MongodbatlasProcessCursors                            MetricSettings `mapstructure:"mongodbatlas.process.cursors"`
	MongodbatlasProcessDbDocumentRate                     MetricSettings `mapstructure:"mongodbatlas.process.db.document.rate"`
	MongodbatlasProcessDbOperationsRate                   MetricSettings `mapstructure:"mongodbatlas.process.db.operations.rate"`
	MongodbatlasProcessDbOperationsTime                   MetricSettings `mapstructure:"mongodbatlas.process.db.operations.time"`
	MongodbatlasProcessDbQueryExecutorScanned             MetricSettings `mapstructure:"mongodbatlas.process.db.query_executor.scanned"`
	MongodbatlasProcessDbQueryTargetingScannedPerReturned MetricSettings `mapstructure:"mongodbatlas.process.db.query_targeting.scanned_per_returned"`
	MongodbatlasProcessDbStorage                          MetricSettings `mapstructure:"mongodbatlas.process.db.storage"`
	MongodbatlasProcessFtsCPUUsage                        MetricSettings `mapstructure:"mongodbatlas.process.fts.cpu.usage"`
	MongodbatlasProcessGlobalLock                         MetricSettings `mapstructure:"mongodbatlas.process.global_lock"`
	MongodbatlasProcessIndexBtreeMissRatio                MetricSettings `mapstructure:"mongodbatlas.process.index.btree_miss_ratio"`
	MongodbatlasProcessIndexCounters                      MetricSettings `mapstructure:"mongodbatlas.process.index.counters"`
	MongodbatlasProcessJournalingCommits                  MetricSettings `mapstructure:"mongodbatlas.process.journaling.commits"`
	MongodbatlasProcessJournalingDataFiles                MetricSettings `mapstructure:"mongodbatlas.process.journaling.data_files"`
	MongodbatlasProcessJournalingWritten                  MetricSettings `mapstructure:"mongodbatlas.process.journaling.written"`
	MongodbatlasProcessMemoryUsage                        MetricSettings `mapstructure:"mongodbatlas.process.memory.usage"`
	MongodbatlasProcessNetworkIo                          MetricSettings `mapstructure:"mongodbatlas.process.network.io"`
	MongodbatlasProcessNetworkRequests                    MetricSettings `mapstructure:"mongodbatlas.process.network.requests"`
	MongodbatlasProcessOplogRate                          MetricSettings `mapstructure:"mongodbatlas.process.oplog.rate"`
	MongodbatlasProcessOplogTime                          MetricSettings `mapstructure:"mongodbatlas.process.oplog.time"`
	MongodbatlasProcessPageFaults                         MetricSettings `mapstructure:"mongodbatlas.process.page_faults"`
	MongodbatlasProcessRestarts                           MetricSettings `mapstructure:"mongodbatlas.process.restarts"`
	MongodbatlasProcessTickets                            MetricSettings `mapstructure:"mongodbatlas.process.tickets"`
	MongodbatlasSystemCPUNormalizedUsageAverage           MetricSettings `mapstructure:"mongodbatlas.system.cpu.normalized.usage.average"`
	MongodbatlasSystemCPUNormalizedUsageMax               MetricSettings `mapstructure:"mongodbatlas.system.cpu.normalized.usage.max"`
	MongodbatlasSystemCPUUsageAverage                     MetricSettings `mapstructure:"mongodbatlas.system.cpu.usage.average"`
	MongodbatlasSystemCPUUsageMax                         MetricSettings `mapstructure:"mongodbatlas.system.cpu.usage.max"`
	MongodbatlasSystemFtsCPUNormalizedUsage               MetricSettings `mapstructure:"mongodbatlas.system.fts.cpu.normalized.usage"`
	MongodbatlasSystemFtsCPUUsage                         MetricSettings `mapstructure:"mongodbatlas.system.fts.cpu.usage"`
	MongodbatlasSystemFtsDiskUsed                         MetricSettings `mapstructure:"mongodbatlas.system.fts.disk.used"`
	MongodbatlasSystemFtsMemoryUsage                      MetricSettings `mapstructure:"mongodbatlas.system.fts.memory.usage"`
	MongodbatlasSystemMemoryUsageAverage                  MetricSettings `mapstructure:"mongodbatlas.system.memory.usage.average"`
	MongodbatlasSystemMemoryUsageMax                      MetricSettings `mapstructure:"mongodbatlas.system.memory.usage.max"`
	MongodbatlasSystemNetworkIoAverage                    MetricSettings `mapstructure:"mongodbatlas.system.network.io.average"`
	MongodbatlasSystemNetworkIoMax                        MetricSettings `mapstructure:"mongodbatlas.system.network.io.max"`
	MongodbatlasSystemPagingIoAverage                     MetricSettings `mapstructure:"mongodbatlas.system.paging.io.average"`
	MongodbatlasSystemPagingIoMax                         MetricSettings `mapstructure:"mongodbatlas.system.paging.io.max"`
	MongodbatlasSystemPagingUsageAverage                  MetricSettings `mapstructure:"mongodbatlas.system.paging.usage.average"`
	MongodbatlasSystemPagingUsageMax                      MetricSettings `mapstructure:"mongodbatlas.system.paging.usage.max"`
}

func DefaultMetricsSettings() MetricsSettings {
	return MetricsSettings{
		MongodbatlasDbCounts: MetricSettings{
			Enabled: true,
		},
		MongodbatlasDbSize: MetricSettings{
			Enabled: true,
		},
		MongodbatlasDiskPartitionIopsAverage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasDiskPartitionIopsMax: MetricSettings{
			Enabled: true,
		},
		MongodbatlasDiskPartitionLatencyAverage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasDiskPartitionLatencyMax: MetricSettings{
			Enabled: true,
		},
		MongodbatlasDiskPartitionSpaceAverage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasDiskPartitionSpaceMax: MetricSettings{
			Enabled: true,
		},
		MongodbatlasDiskPartitionUsageAverage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasDiskPartitionUsageMax: MetricSettings{
			Enabled: true,
		},
		MongodbatlasDiskPartitionUtilizationAverage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasDiskPartitionUtilizationMax: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessAsserts: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessBackgroundFlush: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessCacheIo: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessCacheSize: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessConnections: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessCPUChildrenNormalizedUsageAverage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessCPUChildrenNormalizedUsageMax: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessCPUChildrenUsageAverage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessCPUChildrenUsageMax: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessCPUNormalizedUsageAverage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessCPUNormalizedUsageMax: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessCPUUsageAverage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessCPUUsageMax: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessCursors: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessDbDocumentRate: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessDbOperationsRate: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessDbOperationsTime: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessDbQueryExecutorScanned: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessDbQueryTargetingScannedPerReturned: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessDbStorage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessFtsCPUUsage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessGlobalLock: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessIndexBtreeMissRatio: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessIndexCounters: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessJournalingCommits: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessJournalingDataFiles: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessJournalingWritten: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessMemoryUsage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessNetworkIo: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessNetworkRequests: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessOplogRate: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessOplogTime: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessPageFaults: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessRestarts: MetricSettings{
			Enabled: true,
		},
		MongodbatlasProcessTickets: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemCPUNormalizedUsageAverage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemCPUNormalizedUsageMax: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemCPUUsageAverage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemCPUUsageMax: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemFtsCPUNormalizedUsage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemFtsCPUUsage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemFtsDiskUsed: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemFtsMemoryUsage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemMemoryUsageAverage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemMemoryUsageMax: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemNetworkIoAverage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemNetworkIoMax: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemPagingIoAverage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemPagingIoMax: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemPagingUsageAverage: MetricSettings{
			Enabled: true,
		},
		MongodbatlasSystemPagingUsageMax: MetricSettings{
			Enabled: true,
		},
	}
}

// AttributeAssertType specifies the a value assert_type attribute.
type AttributeAssertType int

const (
	_ AttributeAssertType = iota
	AttributeAssertTypeRegular
	AttributeAssertTypeWarning
	AttributeAssertTypeMsg
	AttributeAssertTypeUser
)

// String returns the string representation of the AttributeAssertType.
func (av AttributeAssertType) String() string {
	switch av {
	case AttributeAssertTypeRegular:
		return "regular"
	case AttributeAssertTypeWarning:
		return "warning"
	case AttributeAssertTypeMsg:
		return "msg"
	case AttributeAssertTypeUser:
		return "user"
	}
	return ""
}

// MapAttributeAssertType is a helper map of string to AttributeAssertType attribute value.
var MapAttributeAssertType = map[string]AttributeAssertType{
	"regular": AttributeAssertTypeRegular,
	"warning": AttributeAssertTypeWarning,
	"msg":     AttributeAssertTypeMsg,
	"user":    AttributeAssertTypeUser,
}

// AttributeBtreeCounterType specifies the a value btree_counter_type attribute.
type AttributeBtreeCounterType int

const (
	_ AttributeBtreeCounterType = iota
	AttributeBtreeCounterTypeAccesses
	AttributeBtreeCounterTypeHits
	AttributeBtreeCounterTypeMisses
)

// String returns the string representation of the AttributeBtreeCounterType.
func (av AttributeBtreeCounterType) String() string {
	switch av {
	case AttributeBtreeCounterTypeAccesses:
		return "accesses"
	case AttributeBtreeCounterTypeHits:
		return "hits"
	case AttributeBtreeCounterTypeMisses:
		return "misses"
	}
	return ""
}

// MapAttributeBtreeCounterType is a helper map of string to AttributeBtreeCounterType attribute value.
var MapAttributeBtreeCounterType = map[string]AttributeBtreeCounterType{
	"accesses": AttributeBtreeCounterTypeAccesses,
	"hits":     AttributeBtreeCounterTypeHits,
	"misses":   AttributeBtreeCounterTypeMisses,
}

// AttributeCacheDirection specifies the a value cache_direction attribute.
type AttributeCacheDirection int

const (
	_ AttributeCacheDirection = iota
	AttributeCacheDirectionReadInto
	AttributeCacheDirectionWrittenFrom
)

// String returns the string representation of the AttributeCacheDirection.
func (av AttributeCacheDirection) String() string {
	switch av {
	case AttributeCacheDirectionReadInto:
		return "read_into"
	case AttributeCacheDirectionWrittenFrom:
		return "written_from"
	}
	return ""
}

// MapAttributeCacheDirection is a helper map of string to AttributeCacheDirection attribute value.
var MapAttributeCacheDirection = map[string]AttributeCacheDirection{
	"read_into":    AttributeCacheDirectionReadInto,
	"written_from": AttributeCacheDirectionWrittenFrom,
}

// AttributeCacheStatus specifies the a value cache_status attribute.
type AttributeCacheStatus int

const (
	_ AttributeCacheStatus = iota
	AttributeCacheStatusDirty
	AttributeCacheStatusUsed
)

// String returns the string representation of the AttributeCacheStatus.
func (av AttributeCacheStatus) String() string {
	switch av {
	case AttributeCacheStatusDirty:
		return "dirty"
	case AttributeCacheStatusUsed:
		return "used"
	}
	return ""
}

// MapAttributeCacheStatus is a helper map of string to AttributeCacheStatus attribute value.
var MapAttributeCacheStatus = map[string]AttributeCacheStatus{
	"dirty": AttributeCacheStatusDirty,
	"used":  AttributeCacheStatusUsed,
}

// AttributeClusterRole specifies the a value cluster_role attribute.
type AttributeClusterRole int

const (
	_ AttributeClusterRole = iota
	AttributeClusterRolePrimary
	AttributeClusterRoleReplica
)

// String returns the string representation of the AttributeClusterRole.
func (av AttributeClusterRole) String() string {
	switch av {
	case AttributeClusterRolePrimary:
		return "primary"
	case AttributeClusterRoleReplica:
		return "replica"
	}
	return ""
}

// MapAttributeClusterRole is a helper map of string to AttributeClusterRole attribute value.
var MapAttributeClusterRole = map[string]AttributeClusterRole{
	"primary": AttributeClusterRolePrimary,
	"replica": AttributeClusterRoleReplica,
}

// AttributeCPUState specifies the a value cpu_state attribute.
type AttributeCPUState int

const (
	_ AttributeCPUState = iota
	AttributeCPUStateKernel
	AttributeCPUStateUser
	AttributeCPUStateNice
	AttributeCPUStateIowait
	AttributeCPUStateIrq
	AttributeCPUStateSoftirq
	AttributeCPUStateGuest
	AttributeCPUStateSteal
)

// String returns the string representation of the AttributeCPUState.
func (av AttributeCPUState) String() string {
	switch av {
	case AttributeCPUStateKernel:
		return "kernel"
	case AttributeCPUStateUser:
		return "user"
	case AttributeCPUStateNice:
		return "nice"
	case AttributeCPUStateIowait:
		return "iowait"
	case AttributeCPUStateIrq:
		return "irq"
	case AttributeCPUStateSoftirq:
		return "softirq"
	case AttributeCPUStateGuest:
		return "guest"
	case AttributeCPUStateSteal:
		return "steal"
	}
	return ""
}

// MapAttributeCPUState is a helper map of string to AttributeCPUState attribute value.
var MapAttributeCPUState = map[string]AttributeCPUState{
	"kernel":  AttributeCPUStateKernel,
	"user":    AttributeCPUStateUser,
	"nice":    AttributeCPUStateNice,
	"iowait":  AttributeCPUStateIowait,
	"irq":     AttributeCPUStateIrq,
	"softirq": AttributeCPUStateSoftirq,
	"guest":   AttributeCPUStateGuest,
	"steal":   AttributeCPUStateSteal,
}

// AttributeCursorState specifies the a value cursor_state attribute.
type AttributeCursorState int

const (
	_ AttributeCursorState = iota
	AttributeCursorStateTimedOut
	AttributeCursorStateOpen
)

// String returns the string representation of the AttributeCursorState.
func (av AttributeCursorState) String() string {
	switch av {
	case AttributeCursorStateTimedOut:
		return "timed_out"
	case AttributeCursorStateOpen:
		return "open"
	}
	return ""
}

// MapAttributeCursorState is a helper map of string to AttributeCursorState attribute value.
var MapAttributeCursorState = map[string]AttributeCursorState{
	"timed_out": AttributeCursorStateTimedOut,
	"open":      AttributeCursorStateOpen,
}

// AttributeDirection specifies the a value direction attribute.
type AttributeDirection int

const (
	_ AttributeDirection = iota
	AttributeDirectionReceive
	AttributeDirectionTransmit
)

// String returns the string representation of the AttributeDirection.
func (av AttributeDirection) String() string {
	switch av {
	case AttributeDirectionReceive:
		return "receive"
	case AttributeDirectionTransmit:
		return "transmit"
	}
	return ""
}

// MapAttributeDirection is a helper map of string to AttributeDirection attribute value.
var MapAttributeDirection = map[string]AttributeDirection{
	"receive":  AttributeDirectionReceive,
	"transmit": AttributeDirectionTransmit,
}

// AttributeDiskDirection specifies the a value disk_direction attribute.
type AttributeDiskDirection int

const (
	_ AttributeDiskDirection = iota
	AttributeDiskDirectionRead
	AttributeDiskDirectionWrite
	AttributeDiskDirectionTotal
)

// String returns the string representation of the AttributeDiskDirection.
func (av AttributeDiskDirection) String() string {
	switch av {
	case AttributeDiskDirectionRead:
		return "read"
	case AttributeDiskDirectionWrite:
		return "write"
	case AttributeDiskDirectionTotal:
		return "total"
	}
	return ""
}

// MapAttributeDiskDirection is a helper map of string to AttributeDiskDirection attribute value.
var MapAttributeDiskDirection = map[string]AttributeDiskDirection{
	"read":  AttributeDiskDirectionRead,
	"write": AttributeDiskDirectionWrite,
	"total": AttributeDiskDirectionTotal,
}

// AttributeDiskStatus specifies the a value disk_status attribute.
type AttributeDiskStatus int

const (
	_ AttributeDiskStatus = iota
	AttributeDiskStatusFree
	AttributeDiskStatusUsed
)

// String returns the string representation of the AttributeDiskStatus.
func (av AttributeDiskStatus) String() string {
	switch av {
	case AttributeDiskStatusFree:
		return "free"
	case AttributeDiskStatusUsed:
		return "used"
	}
	return ""
}

// MapAttributeDiskStatus is a helper map of string to AttributeDiskStatus attribute value.
var MapAttributeDiskStatus = map[string]AttributeDiskStatus{
	"free": AttributeDiskStatusFree,
	"used": AttributeDiskStatusUsed,
}

// AttributeDocumentStatus specifies the a value document_status attribute.
type AttributeDocumentStatus int

const (
	_ AttributeDocumentStatus = iota
	AttributeDocumentStatusReturned
	AttributeDocumentStatusInserted
	AttributeDocumentStatusUpdated
	AttributeDocumentStatusDeleted
)

// String returns the string representation of the AttributeDocumentStatus.
func (av AttributeDocumentStatus) String() string {
	switch av {
	case AttributeDocumentStatusReturned:
		return "returned"
	case AttributeDocumentStatusInserted:
		return "inserted"
	case AttributeDocumentStatusUpdated:
		return "updated"
	case AttributeDocumentStatusDeleted:
		return "deleted"
	}
	return ""
}

// MapAttributeDocumentStatus is a helper map of string to AttributeDocumentStatus attribute value.
var MapAttributeDocumentStatus = map[string]AttributeDocumentStatus{
	"returned": AttributeDocumentStatusReturned,
	"inserted": AttributeDocumentStatusInserted,
	"updated":  AttributeDocumentStatusUpdated,
	"deleted":  AttributeDocumentStatusDeleted,
}

// AttributeExecutionType specifies the a value execution_type attribute.
type AttributeExecutionType int

const (
	_ AttributeExecutionType = iota
	AttributeExecutionTypeReads
	AttributeExecutionTypeWrites
	AttributeExecutionTypeCommands
)

// String returns the string representation of the AttributeExecutionType.
func (av AttributeExecutionType) String() string {
	switch av {
	case AttributeExecutionTypeReads:
		return "reads"
	case AttributeExecutionTypeWrites:
		return "writes"
	case AttributeExecutionTypeCommands:
		return "commands"
	}
	return ""
}

// MapAttributeExecutionType is a helper map of string to AttributeExecutionType attribute value.
var MapAttributeExecutionType = map[string]AttributeExecutionType{
	"reads":    AttributeExecutionTypeReads,
	"writes":   AttributeExecutionTypeWrites,
	"commands": AttributeExecutionTypeCommands,
}

// AttributeGlobalLockState specifies the a value global_lock_state attribute.
type AttributeGlobalLockState int

const (
	_ AttributeGlobalLockState = iota
	AttributeGlobalLockStateCurrentQueueTotal
	AttributeGlobalLockStateCurrentQueueReaders
	AttributeGlobalLockStateCurrentQueueWriters
)

// String returns the string representation of the AttributeGlobalLockState.
func (av AttributeGlobalLockState) String() string {
	switch av {
	case AttributeGlobalLockStateCurrentQueueTotal:
		return "current_queue_total"
	case AttributeGlobalLockStateCurrentQueueReaders:
		return "current_queue_readers"
	case AttributeGlobalLockStateCurrentQueueWriters:
		return "current_queue_writers"
	}
	return ""
}

// MapAttributeGlobalLockState is a helper map of string to AttributeGlobalLockState attribute value.
var MapAttributeGlobalLockState = map[string]AttributeGlobalLockState{
	"current_queue_total":   AttributeGlobalLockStateCurrentQueueTotal,
	"current_queue_readers": AttributeGlobalLockStateCurrentQueueReaders,
	"current_queue_writers": AttributeGlobalLockStateCurrentQueueWriters,
}

// AttributeMemoryIssueType specifies the a value memory_issue_type attribute.
type AttributeMemoryIssueType int

const (
	_ AttributeMemoryIssueType = iota
	AttributeMemoryIssueTypeExtraInfo
	AttributeMemoryIssueTypeGlobalAccessesNotInMemory
	AttributeMemoryIssueTypeExceptionsThrown
)

// String returns the string representation of the AttributeMemoryIssueType.
func (av AttributeMemoryIssueType) String() string {
	switch av {
	case AttributeMemoryIssueTypeExtraInfo:
		return "extra_info"
	case AttributeMemoryIssueTypeGlobalAccessesNotInMemory:
		return "global_accesses_not_in_memory"
	case AttributeMemoryIssueTypeExceptionsThrown:
		return "exceptions_thrown"
	}
	return ""
}

// MapAttributeMemoryIssueType is a helper map of string to AttributeMemoryIssueType attribute value.
var MapAttributeMemoryIssueType = map[string]AttributeMemoryIssueType{
	"extra_info":                    AttributeMemoryIssueTypeExtraInfo,
	"global_accesses_not_in_memory": AttributeMemoryIssueTypeGlobalAccessesNotInMemory,
	"exceptions_thrown":             AttributeMemoryIssueTypeExceptionsThrown,
}

// AttributeMemoryState specifies the a value memory_state attribute.
type AttributeMemoryState int

const (
	_ AttributeMemoryState = iota
	AttributeMemoryStateResident
	AttributeMemoryStateVirtual
	AttributeMemoryStateMapped
	AttributeMemoryStateComputed
	AttributeMemoryStateShared
	AttributeMemoryStateFree
	AttributeMemoryStateUsed
)

// String returns the string representation of the AttributeMemoryState.
func (av AttributeMemoryState) String() string {
	switch av {
	case AttributeMemoryStateResident:
		return "resident"
	case AttributeMemoryStateVirtual:
		return "virtual"
	case AttributeMemoryStateMapped:
		return "mapped"
	case AttributeMemoryStateComputed:
		return "computed"
	case AttributeMemoryStateShared:
		return "shared"
	case AttributeMemoryStateFree:
		return "free"
	case AttributeMemoryStateUsed:
		return "used"
	}
	return ""
}

// MapAttributeMemoryState is a helper map of string to AttributeMemoryState attribute value.
var MapAttributeMemoryState = map[string]AttributeMemoryState{
	"resident": AttributeMemoryStateResident,
	"virtual":  AttributeMemoryStateVirtual,
	"mapped":   AttributeMemoryStateMapped,
	"computed": AttributeMemoryStateComputed,
	"shared":   AttributeMemoryStateShared,
	"free":     AttributeMemoryStateFree,
	"used":     AttributeMemoryStateUsed,
}

// AttributeMemoryStatus specifies the a value memory_status attribute.
type AttributeMemoryStatus int

const (
	_ AttributeMemoryStatus = iota
	AttributeMemoryStatusAvailable
	AttributeMemoryStatusBuffers
	AttributeMemoryStatusCached
	AttributeMemoryStatusFree
	AttributeMemoryStatusShared
	AttributeMemoryStatusUsed
)

// String returns the string representation of the AttributeMemoryStatus.
func (av AttributeMemoryStatus) String() string {
	switch av {
	case AttributeMemoryStatusAvailable:
		return "available"
	case AttributeMemoryStatusBuffers:
		return "buffers"
	case AttributeMemoryStatusCached:
		return "cached"
	case AttributeMemoryStatusFree:
		return "free"
	case AttributeMemoryStatusShared:
		return "shared"
	case AttributeMemoryStatusUsed:
		return "used"
	}
	return ""
}

// MapAttributeMemoryStatus is a helper map of string to AttributeMemoryStatus attribute value.
var MapAttributeMemoryStatus = map[string]AttributeMemoryStatus{
	"available": AttributeMemoryStatusAvailable,
	"buffers":   AttributeMemoryStatusBuffers,
	"cached":    AttributeMemoryStatusCached,
	"free":      AttributeMemoryStatusFree,
	"shared":    AttributeMemoryStatusShared,
	"used":      AttributeMemoryStatusUsed,
}

// AttributeObjectType specifies the a value object_type attribute.
type AttributeObjectType int

const (
	_ AttributeObjectType = iota
	AttributeObjectTypeCollection
	AttributeObjectTypeIndex
	AttributeObjectTypeExtent
	AttributeObjectTypeObject
	AttributeObjectTypeView
	AttributeObjectTypeStorage
	AttributeObjectTypeData
)

// String returns the string representation of the AttributeObjectType.
func (av AttributeObjectType) String() string {
	switch av {
	case AttributeObjectTypeCollection:
		return "collection"
	case AttributeObjectTypeIndex:
		return "index"
	case AttributeObjectTypeExtent:
		return "extent"
	case AttributeObjectTypeObject:
		return "object"
	case AttributeObjectTypeView:
		return "view"
	case AttributeObjectTypeStorage:
		return "storage"
	case AttributeObjectTypeData:
		return "data"
	}
	return ""
}

// MapAttributeObjectType is a helper map of string to AttributeObjectType attribute value.
var MapAttributeObjectType = map[string]AttributeObjectType{
	"collection": AttributeObjectTypeCollection,
	"index":      AttributeObjectTypeIndex,
	"extent":     AttributeObjectTypeExtent,
	"object":     AttributeObjectTypeObject,
	"view":       AttributeObjectTypeView,
	"storage":    AttributeObjectTypeStorage,
	"data":       AttributeObjectTypeData,
}

// AttributeOperation specifies the a value operation attribute.
type AttributeOperation int

const (
	_ AttributeOperation = iota
	AttributeOperationCmd
	AttributeOperationQuery
	AttributeOperationUpdate
	AttributeOperationDelete
	AttributeOperationGetmore
	AttributeOperationInsert
	AttributeOperationScanAndOrder
)

// String returns the string representation of the AttributeOperation.
func (av AttributeOperation) String() string {
	switch av {
	case AttributeOperationCmd:
		return "cmd"
	case AttributeOperationQuery:
		return "query"
	case AttributeOperationUpdate:
		return "update"
	case AttributeOperationDelete:
		return "delete"
	case AttributeOperationGetmore:
		return "getmore"
	case AttributeOperationInsert:
		return "insert"
	case AttributeOperationScanAndOrder:
		return "scan_and_order"
	}
	return ""
}

// MapAttributeOperation is a helper map of string to AttributeOperation attribute value.
var MapAttributeOperation = map[string]AttributeOperation{
	"cmd":            AttributeOperationCmd,
	"query":          AttributeOperationQuery,
	"update":         AttributeOperationUpdate,
	"delete":         AttributeOperationDelete,
	"getmore":        AttributeOperationGetmore,
	"insert":         AttributeOperationInsert,
	"scan_and_order": AttributeOperationScanAndOrder,
}

// AttributeOplogType specifies the a value oplog_type attribute.
type AttributeOplogType int

const (
	_ AttributeOplogType = iota
	AttributeOplogTypeSlaveLagMasterTime
	AttributeOplogTypeMasterTime
	AttributeOplogTypeMasterLagTimeDiff
)

// String returns the string representation of the AttributeOplogType.
func (av AttributeOplogType) String() string {
	switch av {
	case AttributeOplogTypeSlaveLagMasterTime:
		return "slave_lag_master_time"
	case AttributeOplogTypeMasterTime:
		return "master_time"
	case AttributeOplogTypeMasterLagTimeDiff:
		return "master_lag_time_diff"
	}
	return ""
}

// MapAttributeOplogType is a helper map of string to AttributeOplogType attribute value.
var MapAttributeOplogType = map[string]AttributeOplogType{
	"slave_lag_master_time": AttributeOplogTypeSlaveLagMasterTime,
	"master_time":           AttributeOplogTypeMasterTime,
	"master_lag_time_diff":  AttributeOplogTypeMasterLagTimeDiff,
}

// AttributeScannedType specifies the a value scanned_type attribute.
type AttributeScannedType int

const (
	_ AttributeScannedType = iota
	AttributeScannedTypeIndexItems
	AttributeScannedTypeObjects
)

// String returns the string representation of the AttributeScannedType.
func (av AttributeScannedType) String() string {
	switch av {
	case AttributeScannedTypeIndexItems:
		return "index_items"
	case AttributeScannedTypeObjects:
		return "objects"
	}
	return ""
}

// MapAttributeScannedType is a helper map of string to AttributeScannedType attribute value.
var MapAttributeScannedType = map[string]AttributeScannedType{
	"index_items": AttributeScannedTypeIndexItems,
	"objects":     AttributeScannedTypeObjects,
}

// AttributeStorageStatus specifies the a value storage_status attribute.
type AttributeStorageStatus int

const (
	_ AttributeStorageStatus = iota
	AttributeStorageStatusTotal
	AttributeStorageStatusDataSize
	AttributeStorageStatusIndexSize
	AttributeStorageStatusDataSizeWoSystem
)

// String returns the string representation of the AttributeStorageStatus.
func (av AttributeStorageStatus) String() string {
	switch av {
	case AttributeStorageStatusTotal:
		return "total"
	case AttributeStorageStatusDataSize:
		return "data_size"
	case AttributeStorageStatusIndexSize:
		return "index_size"
	case AttributeStorageStatusDataSizeWoSystem:
		return "data_size_wo_system"
	}
	return ""
}

// MapAttributeStorageStatus is a helper map of string to AttributeStorageStatus attribute value.
var MapAttributeStorageStatus = map[string]AttributeStorageStatus{
	"total":               AttributeStorageStatusTotal,
	"data_size":           AttributeStorageStatusDataSize,
	"index_size":          AttributeStorageStatusIndexSize,
	"data_size_wo_system": AttributeStorageStatusDataSizeWoSystem,
}

// AttributeTicketType specifies the a value ticket_type attribute.
type AttributeTicketType int

const (
	_ AttributeTicketType = iota
	AttributeTicketTypeAvailableReads
	AttributeTicketTypeAvailableWrites
)

// String returns the string representation of the AttributeTicketType.
func (av AttributeTicketType) String() string {
	switch av {
	case AttributeTicketTypeAvailableReads:
		return "available_reads"
	case AttributeTicketTypeAvailableWrites:
		return "available_writes"
	}
	return ""
}

// MapAttributeTicketType is a helper map of string to AttributeTicketType attribute value.
var MapAttributeTicketType = map[string]AttributeTicketType{
	"available_reads":  AttributeTicketTypeAvailableReads,
	"available_writes": AttributeTicketTypeAvailableWrites,
}

type metricMongodbatlasDbCounts struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.db.counts metric with initial data.
func (m *metricMongodbatlasDbCounts) init() {
	m.data.SetName("mongodbatlas.db.counts")
	m.data.SetDescription("Database feature size")
	m.data.SetUnit("{objects}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasDbCounts) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, objectTypeAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("object_type", objectTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasDbCounts) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasDbCounts) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasDbCounts(settings MetricSettings) metricMongodbatlasDbCounts {
	m := metricMongodbatlasDbCounts{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasDbSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.db.size metric with initial data.
func (m *metricMongodbatlasDbSize) init() {
	m.data.SetName("mongodbatlas.db.size")
	m.data.SetDescription("Database feature size")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasDbSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, objectTypeAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("object_type", objectTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasDbSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasDbSize) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasDbSize(settings MetricSettings) metricMongodbatlasDbSize {
	m := metricMongodbatlasDbSize{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasDiskPartitionIopsAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.disk.partition.iops.average metric with initial data.
func (m *metricMongodbatlasDiskPartitionIopsAverage) init() {
	m.data.SetName("mongodbatlas.disk.partition.iops.average")
	m.data.SetDescription("Disk partition iops")
	m.data.SetUnit("{ops}/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasDiskPartitionIopsAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, diskDirectionAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("disk_direction", diskDirectionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasDiskPartitionIopsAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasDiskPartitionIopsAverage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasDiskPartitionIopsAverage(settings MetricSettings) metricMongodbatlasDiskPartitionIopsAverage {
	m := metricMongodbatlasDiskPartitionIopsAverage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasDiskPartitionIopsMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.disk.partition.iops.max metric with initial data.
func (m *metricMongodbatlasDiskPartitionIopsMax) init() {
	m.data.SetName("mongodbatlas.disk.partition.iops.max")
	m.data.SetDescription("Disk partition iops")
	m.data.SetUnit("{ops}/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasDiskPartitionIopsMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, diskDirectionAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("disk_direction", diskDirectionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasDiskPartitionIopsMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasDiskPartitionIopsMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasDiskPartitionIopsMax(settings MetricSettings) metricMongodbatlasDiskPartitionIopsMax {
	m := metricMongodbatlasDiskPartitionIopsMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasDiskPartitionLatencyAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.disk.partition.latency.average metric with initial data.
func (m *metricMongodbatlasDiskPartitionLatencyAverage) init() {
	m.data.SetName("mongodbatlas.disk.partition.latency.average")
	m.data.SetDescription("Disk partition latency")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasDiskPartitionLatencyAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, diskDirectionAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("disk_direction", diskDirectionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasDiskPartitionLatencyAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasDiskPartitionLatencyAverage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasDiskPartitionLatencyAverage(settings MetricSettings) metricMongodbatlasDiskPartitionLatencyAverage {
	m := metricMongodbatlasDiskPartitionLatencyAverage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasDiskPartitionLatencyMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.disk.partition.latency.max metric with initial data.
func (m *metricMongodbatlasDiskPartitionLatencyMax) init() {
	m.data.SetName("mongodbatlas.disk.partition.latency.max")
	m.data.SetDescription("Disk partition latency")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasDiskPartitionLatencyMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, diskDirectionAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("disk_direction", diskDirectionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasDiskPartitionLatencyMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasDiskPartitionLatencyMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasDiskPartitionLatencyMax(settings MetricSettings) metricMongodbatlasDiskPartitionLatencyMax {
	m := metricMongodbatlasDiskPartitionLatencyMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasDiskPartitionSpaceAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.disk.partition.space.average metric with initial data.
func (m *metricMongodbatlasDiskPartitionSpaceAverage) init() {
	m.data.SetName("mongodbatlas.disk.partition.space.average")
	m.data.SetDescription("Disk partition space")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasDiskPartitionSpaceAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, diskStatusAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("disk_status", diskStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasDiskPartitionSpaceAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasDiskPartitionSpaceAverage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasDiskPartitionSpaceAverage(settings MetricSettings) metricMongodbatlasDiskPartitionSpaceAverage {
	m := metricMongodbatlasDiskPartitionSpaceAverage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasDiskPartitionSpaceMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.disk.partition.space.max metric with initial data.
func (m *metricMongodbatlasDiskPartitionSpaceMax) init() {
	m.data.SetName("mongodbatlas.disk.partition.space.max")
	m.data.SetDescription("Disk partition space")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasDiskPartitionSpaceMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, diskStatusAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("disk_status", diskStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasDiskPartitionSpaceMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasDiskPartitionSpaceMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasDiskPartitionSpaceMax(settings MetricSettings) metricMongodbatlasDiskPartitionSpaceMax {
	m := metricMongodbatlasDiskPartitionSpaceMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasDiskPartitionUsageAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.disk.partition.usage.average metric with initial data.
func (m *metricMongodbatlasDiskPartitionUsageAverage) init() {
	m.data.SetName("mongodbatlas.disk.partition.usage.average")
	m.data.SetDescription("Disk partition usage (%)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasDiskPartitionUsageAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, diskStatusAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("disk_status", diskStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasDiskPartitionUsageAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasDiskPartitionUsageAverage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasDiskPartitionUsageAverage(settings MetricSettings) metricMongodbatlasDiskPartitionUsageAverage {
	m := metricMongodbatlasDiskPartitionUsageAverage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasDiskPartitionUsageMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.disk.partition.usage.max metric with initial data.
func (m *metricMongodbatlasDiskPartitionUsageMax) init() {
	m.data.SetName("mongodbatlas.disk.partition.usage.max")
	m.data.SetDescription("Disk partition usage (%)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasDiskPartitionUsageMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, diskStatusAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("disk_status", diskStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasDiskPartitionUsageMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasDiskPartitionUsageMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasDiskPartitionUsageMax(settings MetricSettings) metricMongodbatlasDiskPartitionUsageMax {
	m := metricMongodbatlasDiskPartitionUsageMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasDiskPartitionUtilizationAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.disk.partition.utilization.average metric with initial data.
func (m *metricMongodbatlasDiskPartitionUtilizationAverage) init() {
	m.data.SetName("mongodbatlas.disk.partition.utilization.average")
	m.data.SetDescription("Disk partition utilization (%)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasDiskPartitionUtilizationAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, diskStatusAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("disk_status", diskStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasDiskPartitionUtilizationAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasDiskPartitionUtilizationAverage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasDiskPartitionUtilizationAverage(settings MetricSettings) metricMongodbatlasDiskPartitionUtilizationAverage {
	m := metricMongodbatlasDiskPartitionUtilizationAverage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasDiskPartitionUtilizationMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.disk.partition.utilization.max metric with initial data.
func (m *metricMongodbatlasDiskPartitionUtilizationMax) init() {
	m.data.SetName("mongodbatlas.disk.partition.utilization.max")
	m.data.SetDescription("Disk partition utilization (%)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasDiskPartitionUtilizationMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, diskStatusAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("disk_status", diskStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasDiskPartitionUtilizationMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasDiskPartitionUtilizationMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasDiskPartitionUtilizationMax(settings MetricSettings) metricMongodbatlasDiskPartitionUtilizationMax {
	m := metricMongodbatlasDiskPartitionUtilizationMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessAsserts struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.asserts metric with initial data.
func (m *metricMongodbatlasProcessAsserts) init() {
	m.data.SetName("mongodbatlas.process.asserts")
	m.data.SetDescription("Number of assertions per second")
	m.data.SetUnit("{assertions}/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessAsserts) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, assertTypeAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("assert_type", assertTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessAsserts) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessAsserts) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessAsserts(settings MetricSettings) metricMongodbatlasProcessAsserts {
	m := metricMongodbatlasProcessAsserts{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessBackgroundFlush struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.background_flush metric with initial data.
func (m *metricMongodbatlasProcessBackgroundFlush) init() {
	m.data.SetName("mongodbatlas.process.background_flush")
	m.data.SetDescription("Amount of data flushed in the background")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
}

func (m *metricMongodbatlasProcessBackgroundFlush) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessBackgroundFlush) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessBackgroundFlush) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessBackgroundFlush(settings MetricSettings) metricMongodbatlasProcessBackgroundFlush {
	m := metricMongodbatlasProcessBackgroundFlush{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessCacheIo struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.cache.io metric with initial data.
func (m *metricMongodbatlasProcessCacheIo) init() {
	m.data.SetName("mongodbatlas.process.cache.io")
	m.data.SetDescription("Cache throughput (per second)")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessCacheIo) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cacheDirectionAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cache_direction", cacheDirectionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessCacheIo) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessCacheIo) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessCacheIo(settings MetricSettings) metricMongodbatlasProcessCacheIo {
	m := metricMongodbatlasProcessCacheIo{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessCacheSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.cache.size metric with initial data.
func (m *metricMongodbatlasProcessCacheSize) init() {
	m.data.SetName("mongodbatlas.process.cache.size")
	m.data.SetDescription("Cache sizes")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessCacheSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cacheStatusAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cache_status", cacheStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessCacheSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessCacheSize) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessCacheSize(settings MetricSettings) metricMongodbatlasProcessCacheSize {
	m := metricMongodbatlasProcessCacheSize{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessConnections struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.connections metric with initial data.
func (m *metricMongodbatlasProcessConnections) init() {
	m.data.SetName("mongodbatlas.process.connections")
	m.data.SetDescription("Number of current connections")
	m.data.SetUnit("{connections}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricMongodbatlasProcessConnections) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessConnections) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessConnections) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessConnections(settings MetricSettings) metricMongodbatlasProcessConnections {
	m := metricMongodbatlasProcessConnections{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessCPUChildrenNormalizedUsageAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.cpu.children.normalized.usage.average metric with initial data.
func (m *metricMongodbatlasProcessCPUChildrenNormalizedUsageAverage) init() {
	m.data.SetName("mongodbatlas.process.cpu.children.normalized.usage.average")
	m.data.SetDescription("CPU Usage for child processes, normalized to pct")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessCPUChildrenNormalizedUsageAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cpu_state", cpuStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessCPUChildrenNormalizedUsageAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessCPUChildrenNormalizedUsageAverage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessCPUChildrenNormalizedUsageAverage(settings MetricSettings) metricMongodbatlasProcessCPUChildrenNormalizedUsageAverage {
	m := metricMongodbatlasProcessCPUChildrenNormalizedUsageAverage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessCPUChildrenNormalizedUsageMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.cpu.children.normalized.usage.max metric with initial data.
func (m *metricMongodbatlasProcessCPUChildrenNormalizedUsageMax) init() {
	m.data.SetName("mongodbatlas.process.cpu.children.normalized.usage.max")
	m.data.SetDescription("CPU Usage for child processes, normalized to pct")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessCPUChildrenNormalizedUsageMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cpu_state", cpuStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessCPUChildrenNormalizedUsageMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessCPUChildrenNormalizedUsageMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessCPUChildrenNormalizedUsageMax(settings MetricSettings) metricMongodbatlasProcessCPUChildrenNormalizedUsageMax {
	m := metricMongodbatlasProcessCPUChildrenNormalizedUsageMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessCPUChildrenUsageAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.cpu.children.usage.average metric with initial data.
func (m *metricMongodbatlasProcessCPUChildrenUsageAverage) init() {
	m.data.SetName("mongodbatlas.process.cpu.children.usage.average")
	m.data.SetDescription("CPU Usage for child processes (%)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessCPUChildrenUsageAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cpu_state", cpuStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessCPUChildrenUsageAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessCPUChildrenUsageAverage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessCPUChildrenUsageAverage(settings MetricSettings) metricMongodbatlasProcessCPUChildrenUsageAverage {
	m := metricMongodbatlasProcessCPUChildrenUsageAverage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessCPUChildrenUsageMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.cpu.children.usage.max metric with initial data.
func (m *metricMongodbatlasProcessCPUChildrenUsageMax) init() {
	m.data.SetName("mongodbatlas.process.cpu.children.usage.max")
	m.data.SetDescription("CPU Usage for child processes (%)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessCPUChildrenUsageMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cpu_state", cpuStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessCPUChildrenUsageMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessCPUChildrenUsageMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessCPUChildrenUsageMax(settings MetricSettings) metricMongodbatlasProcessCPUChildrenUsageMax {
	m := metricMongodbatlasProcessCPUChildrenUsageMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessCPUNormalizedUsageAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.cpu.normalized.usage.average metric with initial data.
func (m *metricMongodbatlasProcessCPUNormalizedUsageAverage) init() {
	m.data.SetName("mongodbatlas.process.cpu.normalized.usage.average")
	m.data.SetDescription("CPU Usage, normalized to pct")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessCPUNormalizedUsageAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cpu_state", cpuStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessCPUNormalizedUsageAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessCPUNormalizedUsageAverage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessCPUNormalizedUsageAverage(settings MetricSettings) metricMongodbatlasProcessCPUNormalizedUsageAverage {
	m := metricMongodbatlasProcessCPUNormalizedUsageAverage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessCPUNormalizedUsageMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.cpu.normalized.usage.max metric with initial data.
func (m *metricMongodbatlasProcessCPUNormalizedUsageMax) init() {
	m.data.SetName("mongodbatlas.process.cpu.normalized.usage.max")
	m.data.SetDescription("CPU Usage, normalized to pct")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessCPUNormalizedUsageMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cpu_state", cpuStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessCPUNormalizedUsageMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessCPUNormalizedUsageMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessCPUNormalizedUsageMax(settings MetricSettings) metricMongodbatlasProcessCPUNormalizedUsageMax {
	m := metricMongodbatlasProcessCPUNormalizedUsageMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessCPUUsageAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.cpu.usage.average metric with initial data.
func (m *metricMongodbatlasProcessCPUUsageAverage) init() {
	m.data.SetName("mongodbatlas.process.cpu.usage.average")
	m.data.SetDescription("CPU Usage (%)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessCPUUsageAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cpu_state", cpuStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessCPUUsageAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessCPUUsageAverage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessCPUUsageAverage(settings MetricSettings) metricMongodbatlasProcessCPUUsageAverage {
	m := metricMongodbatlasProcessCPUUsageAverage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessCPUUsageMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.cpu.usage.max metric with initial data.
func (m *metricMongodbatlasProcessCPUUsageMax) init() {
	m.data.SetName("mongodbatlas.process.cpu.usage.max")
	m.data.SetDescription("CPU Usage (%)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessCPUUsageMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cpu_state", cpuStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessCPUUsageMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessCPUUsageMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessCPUUsageMax(settings MetricSettings) metricMongodbatlasProcessCPUUsageMax {
	m := metricMongodbatlasProcessCPUUsageMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessCursors struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.cursors metric with initial data.
func (m *metricMongodbatlasProcessCursors) init() {
	m.data.SetName("mongodbatlas.process.cursors")
	m.data.SetDescription("Number of cursors")
	m.data.SetUnit("{cursors}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessCursors) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cursorStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cursor_state", cursorStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessCursors) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessCursors) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessCursors(settings MetricSettings) metricMongodbatlasProcessCursors {
	m := metricMongodbatlasProcessCursors{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessDbDocumentRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.db.document.rate metric with initial data.
func (m *metricMongodbatlasProcessDbDocumentRate) init() {
	m.data.SetName("mongodbatlas.process.db.document.rate")
	m.data.SetDescription("Document access rates")
	m.data.SetUnit("{documents}/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessDbDocumentRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, documentStatusAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("document_status", documentStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessDbDocumentRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessDbDocumentRate) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessDbDocumentRate(settings MetricSettings) metricMongodbatlasProcessDbDocumentRate {
	m := metricMongodbatlasProcessDbDocumentRate{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessDbOperationsRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.db.operations.rate metric with initial data.
func (m *metricMongodbatlasProcessDbOperationsRate) init() {
	m.data.SetName("mongodbatlas.process.db.operations.rate")
	m.data.SetDescription("DB Operation Rates")
	m.data.SetUnit("{operations}/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessDbOperationsRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, operationAttributeValue string, clusterRoleAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("operation", operationAttributeValue)
	dp.Attributes().PutStr("cluster_role", clusterRoleAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessDbOperationsRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessDbOperationsRate) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessDbOperationsRate(settings MetricSettings) metricMongodbatlasProcessDbOperationsRate {
	m := metricMongodbatlasProcessDbOperationsRate{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessDbOperationsTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.db.operations.time metric with initial data.
func (m *metricMongodbatlasProcessDbOperationsTime) init() {
	m.data.SetName("mongodbatlas.process.db.operations.time")
	m.data.SetDescription("DB Operation Times")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessDbOperationsTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, executionTypeAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("execution_type", executionTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessDbOperationsTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessDbOperationsTime) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessDbOperationsTime(settings MetricSettings) metricMongodbatlasProcessDbOperationsTime {
	m := metricMongodbatlasProcessDbOperationsTime{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessDbQueryExecutorScanned struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.db.query_executor.scanned metric with initial data.
func (m *metricMongodbatlasProcessDbQueryExecutorScanned) init() {
	m.data.SetName("mongodbatlas.process.db.query_executor.scanned")
	m.data.SetDescription("Scanned objects")
	m.data.SetUnit("{objects}/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessDbQueryExecutorScanned) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, scannedTypeAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("scanned_type", scannedTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessDbQueryExecutorScanned) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessDbQueryExecutorScanned) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessDbQueryExecutorScanned(settings MetricSettings) metricMongodbatlasProcessDbQueryExecutorScanned {
	m := metricMongodbatlasProcessDbQueryExecutorScanned{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessDbQueryTargetingScannedPerReturned struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.db.query_targeting.scanned_per_returned metric with initial data.
func (m *metricMongodbatlasProcessDbQueryTargetingScannedPerReturned) init() {
	m.data.SetName("mongodbatlas.process.db.query_targeting.scanned_per_returned")
	m.data.SetDescription("Scanned objects per returned")
	m.data.SetUnit("{scanned}/{returned}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessDbQueryTargetingScannedPerReturned) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, scannedTypeAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("scanned_type", scannedTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessDbQueryTargetingScannedPerReturned) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessDbQueryTargetingScannedPerReturned) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessDbQueryTargetingScannedPerReturned(settings MetricSettings) metricMongodbatlasProcessDbQueryTargetingScannedPerReturned {
	m := metricMongodbatlasProcessDbQueryTargetingScannedPerReturned{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessDbStorage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.db.storage metric with initial data.
func (m *metricMongodbatlasProcessDbStorage) init() {
	m.data.SetName("mongodbatlas.process.db.storage")
	m.data.SetDescription("Storage used by the database")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessDbStorage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, storageStatusAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("storage_status", storageStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessDbStorage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessDbStorage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessDbStorage(settings MetricSettings) metricMongodbatlasProcessDbStorage {
	m := metricMongodbatlasProcessDbStorage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessFtsCPUUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.fts.cpu.usage metric with initial data.
func (m *metricMongodbatlasProcessFtsCPUUsage) init() {
	m.data.SetName("mongodbatlas.process.fts.cpu.usage")
	m.data.SetDescription("Full text search CPU (%)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessFtsCPUUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cpu_state", cpuStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessFtsCPUUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessFtsCPUUsage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessFtsCPUUsage(settings MetricSettings) metricMongodbatlasProcessFtsCPUUsage {
	m := metricMongodbatlasProcessFtsCPUUsage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessGlobalLock struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.global_lock metric with initial data.
func (m *metricMongodbatlasProcessGlobalLock) init() {
	m.data.SetName("mongodbatlas.process.global_lock")
	m.data.SetDescription("Number and status of locks")
	m.data.SetUnit("{locks}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessGlobalLock) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, globalLockStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("global_lock_state", globalLockStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessGlobalLock) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessGlobalLock) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessGlobalLock(settings MetricSettings) metricMongodbatlasProcessGlobalLock {
	m := metricMongodbatlasProcessGlobalLock{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessIndexBtreeMissRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.index.btree_miss_ratio metric with initial data.
func (m *metricMongodbatlasProcessIndexBtreeMissRatio) init() {
	m.data.SetName("mongodbatlas.process.index.btree_miss_ratio")
	m.data.SetDescription("Index miss ratio (%)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
}

func (m *metricMongodbatlasProcessIndexBtreeMissRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessIndexBtreeMissRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessIndexBtreeMissRatio) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessIndexBtreeMissRatio(settings MetricSettings) metricMongodbatlasProcessIndexBtreeMissRatio {
	m := metricMongodbatlasProcessIndexBtreeMissRatio{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessIndexCounters struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.index.counters metric with initial data.
func (m *metricMongodbatlasProcessIndexCounters) init() {
	m.data.SetName("mongodbatlas.process.index.counters")
	m.data.SetDescription("Indexes")
	m.data.SetUnit("{indexes}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessIndexCounters) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, btreeCounterTypeAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("btree_counter_type", btreeCounterTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessIndexCounters) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessIndexCounters) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessIndexCounters(settings MetricSettings) metricMongodbatlasProcessIndexCounters {
	m := metricMongodbatlasProcessIndexCounters{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessJournalingCommits struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.journaling.commits metric with initial data.
func (m *metricMongodbatlasProcessJournalingCommits) init() {
	m.data.SetName("mongodbatlas.process.journaling.commits")
	m.data.SetDescription("Journaling commits")
	m.data.SetUnit("{commits}")
	m.data.SetEmptyGauge()
}

func (m *metricMongodbatlasProcessJournalingCommits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessJournalingCommits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessJournalingCommits) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessJournalingCommits(settings MetricSettings) metricMongodbatlasProcessJournalingCommits {
	m := metricMongodbatlasProcessJournalingCommits{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessJournalingDataFiles struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.journaling.data_files metric with initial data.
func (m *metricMongodbatlasProcessJournalingDataFiles) init() {
	m.data.SetName("mongodbatlas.process.journaling.data_files")
	m.data.SetDescription("Data file sizes")
	m.data.SetUnit("MiBy")
	m.data.SetEmptyGauge()
}

func (m *metricMongodbatlasProcessJournalingDataFiles) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessJournalingDataFiles) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessJournalingDataFiles) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessJournalingDataFiles(settings MetricSettings) metricMongodbatlasProcessJournalingDataFiles {
	m := metricMongodbatlasProcessJournalingDataFiles{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessJournalingWritten struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.journaling.written metric with initial data.
func (m *metricMongodbatlasProcessJournalingWritten) init() {
	m.data.SetName("mongodbatlas.process.journaling.written")
	m.data.SetDescription("Journals written")
	m.data.SetUnit("MiBy")
	m.data.SetEmptyGauge()
}

func (m *metricMongodbatlasProcessJournalingWritten) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessJournalingWritten) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessJournalingWritten) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessJournalingWritten(settings MetricSettings) metricMongodbatlasProcessJournalingWritten {
	m := metricMongodbatlasProcessJournalingWritten{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessMemoryUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.memory.usage metric with initial data.
func (m *metricMongodbatlasProcessMemoryUsage) init() {
	m.data.SetName("mongodbatlas.process.memory.usage")
	m.data.SetDescription("Memory Usage")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessMemoryUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, memoryStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("memory_state", memoryStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessMemoryUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessMemoryUsage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessMemoryUsage(settings MetricSettings) metricMongodbatlasProcessMemoryUsage {
	m := metricMongodbatlasProcessMemoryUsage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessNetworkIo struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.network.io metric with initial data.
func (m *metricMongodbatlasProcessNetworkIo) init() {
	m.data.SetName("mongodbatlas.process.network.io")
	m.data.SetDescription("Network IO")
	m.data.SetUnit("By/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessNetworkIo) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, directionAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessNetworkIo) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessNetworkIo) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessNetworkIo(settings MetricSettings) metricMongodbatlasProcessNetworkIo {
	m := metricMongodbatlasProcessNetworkIo{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessNetworkRequests struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.network.requests metric with initial data.
func (m *metricMongodbatlasProcessNetworkRequests) init() {
	m.data.SetName("mongodbatlas.process.network.requests")
	m.data.SetDescription("Network requests")
	m.data.SetUnit("{requests}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricMongodbatlasProcessNetworkRequests) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessNetworkRequests) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessNetworkRequests) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessNetworkRequests(settings MetricSettings) metricMongodbatlasProcessNetworkRequests {
	m := metricMongodbatlasProcessNetworkRequests{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessOplogRate struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.oplog.rate metric with initial data.
func (m *metricMongodbatlasProcessOplogRate) init() {
	m.data.SetName("mongodbatlas.process.oplog.rate")
	m.data.SetDescription("Execution rate by operation")
	m.data.SetUnit("GiBy/h")
	m.data.SetEmptyGauge()
}

func (m *metricMongodbatlasProcessOplogRate) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessOplogRate) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessOplogRate) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessOplogRate(settings MetricSettings) metricMongodbatlasProcessOplogRate {
	m := metricMongodbatlasProcessOplogRate{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessOplogTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.oplog.time metric with initial data.
func (m *metricMongodbatlasProcessOplogTime) init() {
	m.data.SetName("mongodbatlas.process.oplog.time")
	m.data.SetDescription("Execution time by operation")
	m.data.SetUnit("s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessOplogTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, oplogTypeAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("oplog_type", oplogTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessOplogTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessOplogTime) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessOplogTime(settings MetricSettings) metricMongodbatlasProcessOplogTime {
	m := metricMongodbatlasProcessOplogTime{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessPageFaults struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.page_faults metric with initial data.
func (m *metricMongodbatlasProcessPageFaults) init() {
	m.data.SetName("mongodbatlas.process.page_faults")
	m.data.SetDescription("Page faults")
	m.data.SetUnit("{faults}/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessPageFaults) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, memoryIssueTypeAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("memory_issue_type", memoryIssueTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessPageFaults) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessPageFaults) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessPageFaults(settings MetricSettings) metricMongodbatlasProcessPageFaults {
	m := metricMongodbatlasProcessPageFaults{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessRestarts struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.restarts metric with initial data.
func (m *metricMongodbatlasProcessRestarts) init() {
	m.data.SetName("mongodbatlas.process.restarts")
	m.data.SetDescription("Restarts in last hour")
	m.data.SetUnit("{restarts}/h")
	m.data.SetEmptyGauge()
}

func (m *metricMongodbatlasProcessRestarts) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessRestarts) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessRestarts) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessRestarts(settings MetricSettings) metricMongodbatlasProcessRestarts {
	m := metricMongodbatlasProcessRestarts{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasProcessTickets struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.process.tickets metric with initial data.
func (m *metricMongodbatlasProcessTickets) init() {
	m.data.SetName("mongodbatlas.process.tickets")
	m.data.SetDescription("Tickets")
	m.data.SetUnit("{tickets}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasProcessTickets) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, ticketTypeAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("ticket_type", ticketTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasProcessTickets) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasProcessTickets) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasProcessTickets(settings MetricSettings) metricMongodbatlasProcessTickets {
	m := metricMongodbatlasProcessTickets{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemCPUNormalizedUsageAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.cpu.normalized.usage.average metric with initial data.
func (m *metricMongodbatlasSystemCPUNormalizedUsageAverage) init() {
	m.data.SetName("mongodbatlas.system.cpu.normalized.usage.average")
	m.data.SetDescription("System CPU Normalized to pct")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasSystemCPUNormalizedUsageAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cpu_state", cpuStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemCPUNormalizedUsageAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemCPUNormalizedUsageAverage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemCPUNormalizedUsageAverage(settings MetricSettings) metricMongodbatlasSystemCPUNormalizedUsageAverage {
	m := metricMongodbatlasSystemCPUNormalizedUsageAverage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemCPUNormalizedUsageMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.cpu.normalized.usage.max metric with initial data.
func (m *metricMongodbatlasSystemCPUNormalizedUsageMax) init() {
	m.data.SetName("mongodbatlas.system.cpu.normalized.usage.max")
	m.data.SetDescription("System CPU Normalized to pct")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasSystemCPUNormalizedUsageMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cpu_state", cpuStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemCPUNormalizedUsageMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemCPUNormalizedUsageMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemCPUNormalizedUsageMax(settings MetricSettings) metricMongodbatlasSystemCPUNormalizedUsageMax {
	m := metricMongodbatlasSystemCPUNormalizedUsageMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemCPUUsageAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.cpu.usage.average metric with initial data.
func (m *metricMongodbatlasSystemCPUUsageAverage) init() {
	m.data.SetName("mongodbatlas.system.cpu.usage.average")
	m.data.SetDescription("System CPU Usage (%)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasSystemCPUUsageAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cpu_state", cpuStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemCPUUsageAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemCPUUsageAverage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemCPUUsageAverage(settings MetricSettings) metricMongodbatlasSystemCPUUsageAverage {
	m := metricMongodbatlasSystemCPUUsageAverage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemCPUUsageMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.cpu.usage.max metric with initial data.
func (m *metricMongodbatlasSystemCPUUsageMax) init() {
	m.data.SetName("mongodbatlas.system.cpu.usage.max")
	m.data.SetDescription("System CPU Usage (%)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasSystemCPUUsageMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cpu_state", cpuStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemCPUUsageMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemCPUUsageMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemCPUUsageMax(settings MetricSettings) metricMongodbatlasSystemCPUUsageMax {
	m := metricMongodbatlasSystemCPUUsageMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemFtsCPUNormalizedUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.fts.cpu.normalized.usage metric with initial data.
func (m *metricMongodbatlasSystemFtsCPUNormalizedUsage) init() {
	m.data.SetName("mongodbatlas.system.fts.cpu.normalized.usage")
	m.data.SetDescription("Full text search disk usage (%)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasSystemFtsCPUNormalizedUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cpu_state", cpuStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemFtsCPUNormalizedUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemFtsCPUNormalizedUsage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemFtsCPUNormalizedUsage(settings MetricSettings) metricMongodbatlasSystemFtsCPUNormalizedUsage {
	m := metricMongodbatlasSystemFtsCPUNormalizedUsage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemFtsCPUUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.fts.cpu.usage metric with initial data.
func (m *metricMongodbatlasSystemFtsCPUUsage) init() {
	m.data.SetName("mongodbatlas.system.fts.cpu.usage")
	m.data.SetDescription("Full-text search (%)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasSystemFtsCPUUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cpu_state", cpuStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemFtsCPUUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemFtsCPUUsage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemFtsCPUUsage(settings MetricSettings) metricMongodbatlasSystemFtsCPUUsage {
	m := metricMongodbatlasSystemFtsCPUUsage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemFtsDiskUsed struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.fts.disk.used metric with initial data.
func (m *metricMongodbatlasSystemFtsDiskUsed) init() {
	m.data.SetName("mongodbatlas.system.fts.disk.used")
	m.data.SetDescription("Full text search disk usage")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricMongodbatlasSystemFtsDiskUsed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemFtsDiskUsed) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemFtsDiskUsed) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemFtsDiskUsed(settings MetricSettings) metricMongodbatlasSystemFtsDiskUsed {
	m := metricMongodbatlasSystemFtsDiskUsed{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemFtsMemoryUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.fts.memory.usage metric with initial data.
func (m *metricMongodbatlasSystemFtsMemoryUsage) init() {
	m.data.SetName("mongodbatlas.system.fts.memory.usage")
	m.data.SetDescription("Full-text search")
	m.data.SetUnit("MiBy")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasSystemFtsMemoryUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, memoryStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("memory_state", memoryStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemFtsMemoryUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemFtsMemoryUsage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemFtsMemoryUsage(settings MetricSettings) metricMongodbatlasSystemFtsMemoryUsage {
	m := metricMongodbatlasSystemFtsMemoryUsage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemMemoryUsageAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.memory.usage.average metric with initial data.
func (m *metricMongodbatlasSystemMemoryUsageAverage) init() {
	m.data.SetName("mongodbatlas.system.memory.usage.average")
	m.data.SetDescription("System Memory Usage")
	m.data.SetUnit("KiBy")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasSystemMemoryUsageAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, memoryStatusAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("memory_status", memoryStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemMemoryUsageAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemMemoryUsageAverage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemMemoryUsageAverage(settings MetricSettings) metricMongodbatlasSystemMemoryUsageAverage {
	m := metricMongodbatlasSystemMemoryUsageAverage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemMemoryUsageMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.memory.usage.max metric with initial data.
func (m *metricMongodbatlasSystemMemoryUsageMax) init() {
	m.data.SetName("mongodbatlas.system.memory.usage.max")
	m.data.SetDescription("System Memory Usage")
	m.data.SetUnit("KiBy")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasSystemMemoryUsageMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, memoryStatusAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("memory_status", memoryStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemMemoryUsageMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemMemoryUsageMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemMemoryUsageMax(settings MetricSettings) metricMongodbatlasSystemMemoryUsageMax {
	m := metricMongodbatlasSystemMemoryUsageMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemNetworkIoAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.network.io.average metric with initial data.
func (m *metricMongodbatlasSystemNetworkIoAverage) init() {
	m.data.SetName("mongodbatlas.system.network.io.average")
	m.data.SetDescription("System Network IO")
	m.data.SetUnit("By/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasSystemNetworkIoAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, directionAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemNetworkIoAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemNetworkIoAverage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemNetworkIoAverage(settings MetricSettings) metricMongodbatlasSystemNetworkIoAverage {
	m := metricMongodbatlasSystemNetworkIoAverage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemNetworkIoMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.network.io.max metric with initial data.
func (m *metricMongodbatlasSystemNetworkIoMax) init() {
	m.data.SetName("mongodbatlas.system.network.io.max")
	m.data.SetDescription("System Network IO")
	m.data.SetUnit("By/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasSystemNetworkIoMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, directionAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemNetworkIoMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemNetworkIoMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemNetworkIoMax(settings MetricSettings) metricMongodbatlasSystemNetworkIoMax {
	m := metricMongodbatlasSystemNetworkIoMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemPagingIoAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.paging.io.average metric with initial data.
func (m *metricMongodbatlasSystemPagingIoAverage) init() {
	m.data.SetName("mongodbatlas.system.paging.io.average")
	m.data.SetDescription("Swap IO")
	m.data.SetUnit("{pages}/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasSystemPagingIoAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, directionAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemPagingIoAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemPagingIoAverage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemPagingIoAverage(settings MetricSettings) metricMongodbatlasSystemPagingIoAverage {
	m := metricMongodbatlasSystemPagingIoAverage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemPagingIoMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.paging.io.max metric with initial data.
func (m *metricMongodbatlasSystemPagingIoMax) init() {
	m.data.SetName("mongodbatlas.system.paging.io.max")
	m.data.SetDescription("Swap IO")
	m.data.SetUnit("{pages}/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasSystemPagingIoMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, directionAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemPagingIoMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemPagingIoMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemPagingIoMax(settings MetricSettings) metricMongodbatlasSystemPagingIoMax {
	m := metricMongodbatlasSystemPagingIoMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemPagingUsageAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.paging.usage.average metric with initial data.
func (m *metricMongodbatlasSystemPagingUsageAverage) init() {
	m.data.SetName("mongodbatlas.system.paging.usage.average")
	m.data.SetDescription("Swap usage")
	m.data.SetUnit("KiBy")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasSystemPagingUsageAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, memoryStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("memory_state", memoryStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemPagingUsageAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemPagingUsageAverage) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemPagingUsageAverage(settings MetricSettings) metricMongodbatlasSystemPagingUsageAverage {
	m := metricMongodbatlasSystemPagingUsageAverage{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMongodbatlasSystemPagingUsageMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mongodbatlas.system.paging.usage.max metric with initial data.
func (m *metricMongodbatlasSystemPagingUsageMax) init() {
	m.data.SetName("mongodbatlas.system.paging.usage.max")
	m.data.SetDescription("Swap usage")
	m.data.SetUnit("KiBy")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMongodbatlasSystemPagingUsageMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, memoryStateAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("memory_state", memoryStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMongodbatlasSystemPagingUsageMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMongodbatlasSystemPagingUsageMax) emit(metrics pmetric.MetricSlice) {
	if m.settings.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMongodbatlasSystemPagingUsageMax(settings MetricSettings) metricMongodbatlasSystemPagingUsageMax {
	m := metricMongodbatlasSystemPagingUsageMax{settings: settings}
	if settings.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user settings.
type MetricsBuilder struct {
	startTime                                                   pcommon.Timestamp   // start time that will be applied to all recorded data points.
	metricsCapacity                                             int                 // maximum observed number of metrics per resource.
	resourceCapacity                                            int                 // maximum observed number of resource attributes.
	metricsBuffer                                               pmetric.Metrics     // accumulates metrics data before emitting.
	buildInfo                                                   component.BuildInfo // contains version information
	metricMongodbatlasDbCounts                                  metricMongodbatlasDbCounts
	metricMongodbatlasDbSize                                    metricMongodbatlasDbSize
	metricMongodbatlasDiskPartitionIopsAverage                  metricMongodbatlasDiskPartitionIopsAverage
	metricMongodbatlasDiskPartitionIopsMax                      metricMongodbatlasDiskPartitionIopsMax
	metricMongodbatlasDiskPartitionLatencyAverage               metricMongodbatlasDiskPartitionLatencyAverage
	metricMongodbatlasDiskPartitionLatencyMax                   metricMongodbatlasDiskPartitionLatencyMax
	metricMongodbatlasDiskPartitionSpaceAverage                 metricMongodbatlasDiskPartitionSpaceAverage
	metricMongodbatlasDiskPartitionSpaceMax                     metricMongodbatlasDiskPartitionSpaceMax
	metricMongodbatlasDiskPartitionUsageAverage                 metricMongodbatlasDiskPartitionUsageAverage
	metricMongodbatlasDiskPartitionUsageMax                     metricMongodbatlasDiskPartitionUsageMax
	metricMongodbatlasDiskPartitionUtilizationAverage           metricMongodbatlasDiskPartitionUtilizationAverage
	metricMongodbatlasDiskPartitionUtilizationMax               metricMongodbatlasDiskPartitionUtilizationMax
	metricMongodbatlasProcessAsserts                            metricMongodbatlasProcessAsserts
	metricMongodbatlasProcessBackgroundFlush                    metricMongodbatlasProcessBackgroundFlush
	metricMongodbatlasProcessCacheIo                            metricMongodbatlasProcessCacheIo
	metricMongodbatlasProcessCacheSize                          metricMongodbatlasProcessCacheSize
	metricMongodbatlasProcessConnections                        metricMongodbatlasProcessConnections
	metricMongodbatlasProcessCPUChildrenNormalizedUsageAverage  metricMongodbatlasProcessCPUChildrenNormalizedUsageAverage
	metricMongodbatlasProcessCPUChildrenNormalizedUsageMax      metricMongodbatlasProcessCPUChildrenNormalizedUsageMax
	metricMongodbatlasProcessCPUChildrenUsageAverage            metricMongodbatlasProcessCPUChildrenUsageAverage
	metricMongodbatlasProcessCPUChildrenUsageMax                metricMongodbatlasProcessCPUChildrenUsageMax
	metricMongodbatlasProcessCPUNormalizedUsageAverage          metricMongodbatlasProcessCPUNormalizedUsageAverage
	metricMongodbatlasProcessCPUNormalizedUsageMax              metricMongodbatlasProcessCPUNormalizedUsageMax
	metricMongodbatlasProcessCPUUsageAverage                    metricMongodbatlasProcessCPUUsageAverage
	metricMongodbatlasProcessCPUUsageMax                        metricMongodbatlasProcessCPUUsageMax
	metricMongodbatlasProcessCursors                            metricMongodbatlasProcessCursors
	metricMongodbatlasProcessDbDocumentRate                     metricMongodbatlasProcessDbDocumentRate
	metricMongodbatlasProcessDbOperationsRate                   metricMongodbatlasProcessDbOperationsRate
	metricMongodbatlasProcessDbOperationsTime                   metricMongodbatlasProcessDbOperationsTime
	metricMongodbatlasProcessDbQueryExecutorScanned             metricMongodbatlasProcessDbQueryExecutorScanned
	metricMongodbatlasProcessDbQueryTargetingScannedPerReturned metricMongodbatlasProcessDbQueryTargetingScannedPerReturned
	metricMongodbatlasProcessDbStorage                          metricMongodbatlasProcessDbStorage
	metricMongodbatlasProcessFtsCPUUsage                        metricMongodbatlasProcessFtsCPUUsage
	metricMongodbatlasProcessGlobalLock                         metricMongodbatlasProcessGlobalLock
	metricMongodbatlasProcessIndexBtreeMissRatio                metricMongodbatlasProcessIndexBtreeMissRatio
	metricMongodbatlasProcessIndexCounters                      metricMongodbatlasProcessIndexCounters
	metricMongodbatlasProcessJournalingCommits                  metricMongodbatlasProcessJournalingCommits
	metricMongodbatlasProcessJournalingDataFiles                metricMongodbatlasProcessJournalingDataFiles
	metricMongodbatlasProcessJournalingWritten                  metricMongodbatlasProcessJournalingWritten
	metricMongodbatlasProcessMemoryUsage                        metricMongodbatlasProcessMemoryUsage
	metricMongodbatlasProcessNetworkIo                          metricMongodbatlasProcessNetworkIo
	metricMongodbatlasProcessNetworkRequests                    metricMongodbatlasProcessNetworkRequests
	metricMongodbatlasProcessOplogRate                          metricMongodbatlasProcessOplogRate
	metricMongodbatlasProcessOplogTime                          metricMongodbatlasProcessOplogTime
	metricMongodbatlasProcessPageFaults                         metricMongodbatlasProcessPageFaults
	metricMongodbatlasProcessRestarts                           metricMongodbatlasProcessRestarts
	metricMongodbatlasProcessTickets                            metricMongodbatlasProcessTickets
	metricMongodbatlasSystemCPUNormalizedUsageAverage           metricMongodbatlasSystemCPUNormalizedUsageAverage
	metricMongodbatlasSystemCPUNormalizedUsageMax               metricMongodbatlasSystemCPUNormalizedUsageMax
	metricMongodbatlasSystemCPUUsageAverage                     metricMongodbatlasSystemCPUUsageAverage
	metricMongodbatlasSystemCPUUsageMax                         metricMongodbatlasSystemCPUUsageMax
	metricMongodbatlasSystemFtsCPUNormalizedUsage               metricMongodbatlasSystemFtsCPUNormalizedUsage
	metricMongodbatlasSystemFtsCPUUsage                         metricMongodbatlasSystemFtsCPUUsage
	metricMongodbatlasSystemFtsDiskUsed                         metricMongodbatlasSystemFtsDiskUsed
	metricMongodbatlasSystemFtsMemoryUsage                      metricMongodbatlasSystemFtsMemoryUsage
	metricMongodbatlasSystemMemoryUsageAverage                  metricMongodbatlasSystemMemoryUsageAverage
	metricMongodbatlasSystemMemoryUsageMax                      metricMongodbatlasSystemMemoryUsageMax
	metricMongodbatlasSystemNetworkIoAverage                    metricMongodbatlasSystemNetworkIoAverage
	metricMongodbatlasSystemNetworkIoMax                        metricMongodbatlasSystemNetworkIoMax
	metricMongodbatlasSystemPagingIoAverage                     metricMongodbatlasSystemPagingIoAverage
	metricMongodbatlasSystemPagingIoMax                         metricMongodbatlasSystemPagingIoMax
	metricMongodbatlasSystemPagingUsageAverage                  metricMongodbatlasSystemPagingUsageAverage
	metricMongodbatlasSystemPagingUsageMax                      metricMongodbatlasSystemPagingUsageMax
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(settings MetricsSettings, buildInfo component.BuildInfo, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		startTime:                  pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:              pmetric.NewMetrics(),
		buildInfo:                  buildInfo,
		metricMongodbatlasDbCounts: newMetricMongodbatlasDbCounts(settings.MongodbatlasDbCounts),
		metricMongodbatlasDbSize:   newMetricMongodbatlasDbSize(settings.MongodbatlasDbSize),
		metricMongodbatlasDiskPartitionIopsAverage:                  newMetricMongodbatlasDiskPartitionIopsAverage(settings.MongodbatlasDiskPartitionIopsAverage),
		metricMongodbatlasDiskPartitionIopsMax:                      newMetricMongodbatlasDiskPartitionIopsMax(settings.MongodbatlasDiskPartitionIopsMax),
		metricMongodbatlasDiskPartitionLatencyAverage:               newMetricMongodbatlasDiskPartitionLatencyAverage(settings.MongodbatlasDiskPartitionLatencyAverage),
		metricMongodbatlasDiskPartitionLatencyMax:                   newMetricMongodbatlasDiskPartitionLatencyMax(settings.MongodbatlasDiskPartitionLatencyMax),
		metricMongodbatlasDiskPartitionSpaceAverage:                 newMetricMongodbatlasDiskPartitionSpaceAverage(settings.MongodbatlasDiskPartitionSpaceAverage),
		metricMongodbatlasDiskPartitionSpaceMax:                     newMetricMongodbatlasDiskPartitionSpaceMax(settings.MongodbatlasDiskPartitionSpaceMax),
		metricMongodbatlasDiskPartitionUsageAverage:                 newMetricMongodbatlasDiskPartitionUsageAverage(settings.MongodbatlasDiskPartitionUsageAverage),
		metricMongodbatlasDiskPartitionUsageMax:                     newMetricMongodbatlasDiskPartitionUsageMax(settings.MongodbatlasDiskPartitionUsageMax),
		metricMongodbatlasDiskPartitionUtilizationAverage:           newMetricMongodbatlasDiskPartitionUtilizationAverage(settings.MongodbatlasDiskPartitionUtilizationAverage),
		metricMongodbatlasDiskPartitionUtilizationMax:               newMetricMongodbatlasDiskPartitionUtilizationMax(settings.MongodbatlasDiskPartitionUtilizationMax),
		metricMongodbatlasProcessAsserts:                            newMetricMongodbatlasProcessAsserts(settings.MongodbatlasProcessAsserts),
		metricMongodbatlasProcessBackgroundFlush:                    newMetricMongodbatlasProcessBackgroundFlush(settings.MongodbatlasProcessBackgroundFlush),
		metricMongodbatlasProcessCacheIo:                            newMetricMongodbatlasProcessCacheIo(settings.MongodbatlasProcessCacheIo),
		metricMongodbatlasProcessCacheSize:                          newMetricMongodbatlasProcessCacheSize(settings.MongodbatlasProcessCacheSize),
		metricMongodbatlasProcessConnections:                        newMetricMongodbatlasProcessConnections(settings.MongodbatlasProcessConnections),
		metricMongodbatlasProcessCPUChildrenNormalizedUsageAverage:  newMetricMongodbatlasProcessCPUChildrenNormalizedUsageAverage(settings.MongodbatlasProcessCPUChildrenNormalizedUsageAverage),
		metricMongodbatlasProcessCPUChildrenNormalizedUsageMax:      newMetricMongodbatlasProcessCPUChildrenNormalizedUsageMax(settings.MongodbatlasProcessCPUChildrenNormalizedUsageMax),
		metricMongodbatlasProcessCPUChildrenUsageAverage:            newMetricMongodbatlasProcessCPUChildrenUsageAverage(settings.MongodbatlasProcessCPUChildrenUsageAverage),
		metricMongodbatlasProcessCPUChildrenUsageMax:                newMetricMongodbatlasProcessCPUChildrenUsageMax(settings.MongodbatlasProcessCPUChildrenUsageMax),
		metricMongodbatlasProcessCPUNormalizedUsageAverage:          newMetricMongodbatlasProcessCPUNormalizedUsageAverage(settings.MongodbatlasProcessCPUNormalizedUsageAverage),
		metricMongodbatlasProcessCPUNormalizedUsageMax:              newMetricMongodbatlasProcessCPUNormalizedUsageMax(settings.MongodbatlasProcessCPUNormalizedUsageMax),
		metricMongodbatlasProcessCPUUsageAverage:                    newMetricMongodbatlasProcessCPUUsageAverage(settings.MongodbatlasProcessCPUUsageAverage),
		metricMongodbatlasProcessCPUUsageMax:                        newMetricMongodbatlasProcessCPUUsageMax(settings.MongodbatlasProcessCPUUsageMax),
		metricMongodbatlasProcessCursors:                            newMetricMongodbatlasProcessCursors(settings.MongodbatlasProcessCursors),
		metricMongodbatlasProcessDbDocumentRate:                     newMetricMongodbatlasProcessDbDocumentRate(settings.MongodbatlasProcessDbDocumentRate),
		metricMongodbatlasProcessDbOperationsRate:                   newMetricMongodbatlasProcessDbOperationsRate(settings.MongodbatlasProcessDbOperationsRate),
		metricMongodbatlasProcessDbOperationsTime:                   newMetricMongodbatlasProcessDbOperationsTime(settings.MongodbatlasProcessDbOperationsTime),
		metricMongodbatlasProcessDbQueryExecutorScanned:             newMetricMongodbatlasProcessDbQueryExecutorScanned(settings.MongodbatlasProcessDbQueryExecutorScanned),
		metricMongodbatlasProcessDbQueryTargetingScannedPerReturned: newMetricMongodbatlasProcessDbQueryTargetingScannedPerReturned(settings.MongodbatlasProcessDbQueryTargetingScannedPerReturned),
		metricMongodbatlasProcessDbStorage:                          newMetricMongodbatlasProcessDbStorage(settings.MongodbatlasProcessDbStorage),
		metricMongodbatlasProcessFtsCPUUsage:                        newMetricMongodbatlasProcessFtsCPUUsage(settings.MongodbatlasProcessFtsCPUUsage),
		metricMongodbatlasProcessGlobalLock:                         newMetricMongodbatlasProcessGlobalLock(settings.MongodbatlasProcessGlobalLock),
		metricMongodbatlasProcessIndexBtreeMissRatio:                newMetricMongodbatlasProcessIndexBtreeMissRatio(settings.MongodbatlasProcessIndexBtreeMissRatio),
		metricMongodbatlasProcessIndexCounters:                      newMetricMongodbatlasProcessIndexCounters(settings.MongodbatlasProcessIndexCounters),
		metricMongodbatlasProcessJournalingCommits:                  newMetricMongodbatlasProcessJournalingCommits(settings.MongodbatlasProcessJournalingCommits),
		metricMongodbatlasProcessJournalingDataFiles:                newMetricMongodbatlasProcessJournalingDataFiles(settings.MongodbatlasProcessJournalingDataFiles),
		metricMongodbatlasProcessJournalingWritten:                  newMetricMongodbatlasProcessJournalingWritten(settings.MongodbatlasProcessJournalingWritten),
		metricMongodbatlasProcessMemoryUsage:                        newMetricMongodbatlasProcessMemoryUsage(settings.MongodbatlasProcessMemoryUsage),
		metricMongodbatlasProcessNetworkIo:                          newMetricMongodbatlasProcessNetworkIo(settings.MongodbatlasProcessNetworkIo),
		metricMongodbatlasProcessNetworkRequests:                    newMetricMongodbatlasProcessNetworkRequests(settings.MongodbatlasProcessNetworkRequests),
		metricMongodbatlasProcessOplogRate:                          newMetricMongodbatlasProcessOplogRate(settings.MongodbatlasProcessOplogRate),
		metricMongodbatlasProcessOplogTime:                          newMetricMongodbatlasProcessOplogTime(settings.MongodbatlasProcessOplogTime),
		metricMongodbatlasProcessPageFaults:                         newMetricMongodbatlasProcessPageFaults(settings.MongodbatlasProcessPageFaults),
		metricMongodbatlasProcessRestarts:                           newMetricMongodbatlasProcessRestarts(settings.MongodbatlasProcessRestarts),
		metricMongodbatlasProcessTickets:                            newMetricMongodbatlasProcessTickets(settings.MongodbatlasProcessTickets),
		metricMongodbatlasSystemCPUNormalizedUsageAverage:           newMetricMongodbatlasSystemCPUNormalizedUsageAverage(settings.MongodbatlasSystemCPUNormalizedUsageAverage),
		metricMongodbatlasSystemCPUNormalizedUsageMax:               newMetricMongodbatlasSystemCPUNormalizedUsageMax(settings.MongodbatlasSystemCPUNormalizedUsageMax),
		metricMongodbatlasSystemCPUUsageAverage:                     newMetricMongodbatlasSystemCPUUsageAverage(settings.MongodbatlasSystemCPUUsageAverage),
		metricMongodbatlasSystemCPUUsageMax:                         newMetricMongodbatlasSystemCPUUsageMax(settings.MongodbatlasSystemCPUUsageMax),
		metricMongodbatlasSystemFtsCPUNormalizedUsage:               newMetricMongodbatlasSystemFtsCPUNormalizedUsage(settings.MongodbatlasSystemFtsCPUNormalizedUsage),
		metricMongodbatlasSystemFtsCPUUsage:                         newMetricMongodbatlasSystemFtsCPUUsage(settings.MongodbatlasSystemFtsCPUUsage),
		metricMongodbatlasSystemFtsDiskUsed:                         newMetricMongodbatlasSystemFtsDiskUsed(settings.MongodbatlasSystemFtsDiskUsed),
		metricMongodbatlasSystemFtsMemoryUsage:                      newMetricMongodbatlasSystemFtsMemoryUsage(settings.MongodbatlasSystemFtsMemoryUsage),
		metricMongodbatlasSystemMemoryUsageAverage:                  newMetricMongodbatlasSystemMemoryUsageAverage(settings.MongodbatlasSystemMemoryUsageAverage),
		metricMongodbatlasSystemMemoryUsageMax:                      newMetricMongodbatlasSystemMemoryUsageMax(settings.MongodbatlasSystemMemoryUsageMax),
		metricMongodbatlasSystemNetworkIoAverage:                    newMetricMongodbatlasSystemNetworkIoAverage(settings.MongodbatlasSystemNetworkIoAverage),
		metricMongodbatlasSystemNetworkIoMax:                        newMetricMongodbatlasSystemNetworkIoMax(settings.MongodbatlasSystemNetworkIoMax),
		metricMongodbatlasSystemPagingIoAverage:                     newMetricMongodbatlasSystemPagingIoAverage(settings.MongodbatlasSystemPagingIoAverage),
		metricMongodbatlasSystemPagingIoMax:                         newMetricMongodbatlasSystemPagingIoMax(settings.MongodbatlasSystemPagingIoMax),
		metricMongodbatlasSystemPagingUsageAverage:                  newMetricMongodbatlasSystemPagingUsageAverage(settings.MongodbatlasSystemPagingUsageAverage),
		metricMongodbatlasSystemPagingUsageMax:                      newMetricMongodbatlasSystemPagingUsageMax(settings.MongodbatlasSystemPagingUsageMax),
	}
	for _, op := range options {
		op(mb)
	}
	return mb
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
	if mb.resourceCapacity < rm.Resource().Attributes().Len() {
		mb.resourceCapacity = rm.Resource().Attributes().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption func(pmetric.ResourceMetrics)

// WithMongodbAtlasDbName sets provided value as "mongodb_atlas.db.name" attribute for current resource.
func WithMongodbAtlasDbName(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().PutStr("mongodb_atlas.db.name", val)
	}
}

// WithMongodbAtlasDiskPartition sets provided value as "mongodb_atlas.disk.partition" attribute for current resource.
func WithMongodbAtlasDiskPartition(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().PutStr("mongodb_atlas.disk.partition", val)
	}
}

// WithMongodbAtlasHostName sets provided value as "mongodb_atlas.host.name" attribute for current resource.
func WithMongodbAtlasHostName(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().PutStr("mongodb_atlas.host.name", val)
	}
}

// WithMongodbAtlasOrgName sets provided value as "mongodb_atlas.org_name" attribute for current resource.
func WithMongodbAtlasOrgName(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().PutStr("mongodb_atlas.org_name", val)
	}
}

// WithMongodbAtlasProcessID sets provided value as "mongodb_atlas.process.id" attribute for current resource.
func WithMongodbAtlasProcessID(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().PutStr("mongodb_atlas.process.id", val)
	}
}

// WithMongodbAtlasProcessPort sets provided value as "mongodb_atlas.process.port" attribute for current resource.
func WithMongodbAtlasProcessPort(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().PutStr("mongodb_atlas.process.port", val)
	}
}

// WithMongodbAtlasProcessTypeName sets provided value as "mongodb_atlas.process.type_name" attribute for current resource.
func WithMongodbAtlasProcessTypeName(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().PutStr("mongodb_atlas.process.type_name", val)
	}
}

// WithMongodbAtlasProjectID sets provided value as "mongodb_atlas.project.id" attribute for current resource.
func WithMongodbAtlasProjectID(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().PutStr("mongodb_atlas.project.id", val)
	}
}

// WithMongodbAtlasProjectName sets provided value as "mongodb_atlas.project.name" attribute for current resource.
func WithMongodbAtlasProjectName(val string) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		rm.Resource().Attributes().PutStr("mongodb_atlas.project.name", val)
	}
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	}
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(rmo ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	rm.Resource().Attributes().EnsureCapacity(mb.resourceCapacity)
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName("otelcol/mongoatlasreceiver")
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricMongodbatlasDbCounts.emit(ils.Metrics())
	mb.metricMongodbatlasDbSize.emit(ils.Metrics())
	mb.metricMongodbatlasDiskPartitionIopsAverage.emit(ils.Metrics())
	mb.metricMongodbatlasDiskPartitionIopsMax.emit(ils.Metrics())
	mb.metricMongodbatlasDiskPartitionLatencyAverage.emit(ils.Metrics())
	mb.metricMongodbatlasDiskPartitionLatencyMax.emit(ils.Metrics())
	mb.metricMongodbatlasDiskPartitionSpaceAverage.emit(ils.Metrics())
	mb.metricMongodbatlasDiskPartitionSpaceMax.emit(ils.Metrics())
	mb.metricMongodbatlasDiskPartitionUsageAverage.emit(ils.Metrics())
	mb.metricMongodbatlasDiskPartitionUsageMax.emit(ils.Metrics())
	mb.metricMongodbatlasDiskPartitionUtilizationAverage.emit(ils.Metrics())
	mb.metricMongodbatlasDiskPartitionUtilizationMax.emit(ils.Metrics())
	mb.metricMongodbatlasProcessAsserts.emit(ils.Metrics())
	mb.metricMongodbatlasProcessBackgroundFlush.emit(ils.Metrics())
	mb.metricMongodbatlasProcessCacheIo.emit(ils.Metrics())
	mb.metricMongodbatlasProcessCacheSize.emit(ils.Metrics())
	mb.metricMongodbatlasProcessConnections.emit(ils.Metrics())
	mb.metricMongodbatlasProcessCPUChildrenNormalizedUsageAverage.emit(ils.Metrics())
	mb.metricMongodbatlasProcessCPUChildrenNormalizedUsageMax.emit(ils.Metrics())
	mb.metricMongodbatlasProcessCPUChildrenUsageAverage.emit(ils.Metrics())
	mb.metricMongodbatlasProcessCPUChildrenUsageMax.emit(ils.Metrics())
	mb.metricMongodbatlasProcessCPUNormalizedUsageAverage.emit(ils.Metrics())
	mb.metricMongodbatlasProcessCPUNormalizedUsageMax.emit(ils.Metrics())
	mb.metricMongodbatlasProcessCPUUsageAverage.emit(ils.Metrics())
	mb.metricMongodbatlasProcessCPUUsageMax.emit(ils.Metrics())
	mb.metricMongodbatlasProcessCursors.emit(ils.Metrics())
	mb.metricMongodbatlasProcessDbDocumentRate.emit(ils.Metrics())
	mb.metricMongodbatlasProcessDbOperationsRate.emit(ils.Metrics())
	mb.metricMongodbatlasProcessDbOperationsTime.emit(ils.Metrics())
	mb.metricMongodbatlasProcessDbQueryExecutorScanned.emit(ils.Metrics())
	mb.metricMongodbatlasProcessDbQueryTargetingScannedPerReturned.emit(ils.Metrics())
	mb.metricMongodbatlasProcessDbStorage.emit(ils.Metrics())
	mb.metricMongodbatlasProcessFtsCPUUsage.emit(ils.Metrics())
	mb.metricMongodbatlasProcessGlobalLock.emit(ils.Metrics())
	mb.metricMongodbatlasProcessIndexBtreeMissRatio.emit(ils.Metrics())
	mb.metricMongodbatlasProcessIndexCounters.emit(ils.Metrics())
	mb.metricMongodbatlasProcessJournalingCommits.emit(ils.Metrics())
	mb.metricMongodbatlasProcessJournalingDataFiles.emit(ils.Metrics())
	mb.metricMongodbatlasProcessJournalingWritten.emit(ils.Metrics())
	mb.metricMongodbatlasProcessMemoryUsage.emit(ils.Metrics())
	mb.metricMongodbatlasProcessNetworkIo.emit(ils.Metrics())
	mb.metricMongodbatlasProcessNetworkRequests.emit(ils.Metrics())
	mb.metricMongodbatlasProcessOplogRate.emit(ils.Metrics())
	mb.metricMongodbatlasProcessOplogTime.emit(ils.Metrics())
	mb.metricMongodbatlasProcessPageFaults.emit(ils.Metrics())
	mb.metricMongodbatlasProcessRestarts.emit(ils.Metrics())
	mb.metricMongodbatlasProcessTickets.emit(ils.Metrics())
	mb.metricMongodbatlasSystemCPUNormalizedUsageAverage.emit(ils.Metrics())
	mb.metricMongodbatlasSystemCPUNormalizedUsageMax.emit(ils.Metrics())
	mb.metricMongodbatlasSystemCPUUsageAverage.emit(ils.Metrics())
	mb.metricMongodbatlasSystemCPUUsageMax.emit(ils.Metrics())
	mb.metricMongodbatlasSystemFtsCPUNormalizedUsage.emit(ils.Metrics())
	mb.metricMongodbatlasSystemFtsCPUUsage.emit(ils.Metrics())
	mb.metricMongodbatlasSystemFtsDiskUsed.emit(ils.Metrics())
	mb.metricMongodbatlasSystemFtsMemoryUsage.emit(ils.Metrics())
	mb.metricMongodbatlasSystemMemoryUsageAverage.emit(ils.Metrics())
	mb.metricMongodbatlasSystemMemoryUsageMax.emit(ils.Metrics())
	mb.metricMongodbatlasSystemNetworkIoAverage.emit(ils.Metrics())
	mb.metricMongodbatlasSystemNetworkIoMax.emit(ils.Metrics())
	mb.metricMongodbatlasSystemPagingIoAverage.emit(ils.Metrics())
	mb.metricMongodbatlasSystemPagingIoMax.emit(ils.Metrics())
	mb.metricMongodbatlasSystemPagingUsageAverage.emit(ils.Metrics())
	mb.metricMongodbatlasSystemPagingUsageMax.emit(ils.Metrics())
	for _, op := range rmo {
		op(rm)
	}
	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user settings, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(rmo ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(rmo...)
	metrics := pmetric.NewMetrics()
	mb.metricsBuffer.MoveTo(metrics)
	return metrics
}

// RecordMongodbatlasDbCountsDataPoint adds a data point to mongodbatlas.db.counts metric.
func (mb *MetricsBuilder) RecordMongodbatlasDbCountsDataPoint(ts pcommon.Timestamp, val float64, objectTypeAttributeValue AttributeObjectType) {
	mb.metricMongodbatlasDbCounts.recordDataPoint(mb.startTime, ts, val, objectTypeAttributeValue.String())
}

// RecordMongodbatlasDbSizeDataPoint adds a data point to mongodbatlas.db.size metric.
func (mb *MetricsBuilder) RecordMongodbatlasDbSizeDataPoint(ts pcommon.Timestamp, val float64, objectTypeAttributeValue AttributeObjectType) {
	mb.metricMongodbatlasDbSize.recordDataPoint(mb.startTime, ts, val, objectTypeAttributeValue.String())
}

// RecordMongodbatlasDiskPartitionIopsAverageDataPoint adds a data point to mongodbatlas.disk.partition.iops.average metric.
func (mb *MetricsBuilder) RecordMongodbatlasDiskPartitionIopsAverageDataPoint(ts pcommon.Timestamp, val float64, diskDirectionAttributeValue AttributeDiskDirection) {
	mb.metricMongodbatlasDiskPartitionIopsAverage.recordDataPoint(mb.startTime, ts, val, diskDirectionAttributeValue.String())
}

// RecordMongodbatlasDiskPartitionIopsMaxDataPoint adds a data point to mongodbatlas.disk.partition.iops.max metric.
func (mb *MetricsBuilder) RecordMongodbatlasDiskPartitionIopsMaxDataPoint(ts pcommon.Timestamp, val float64, diskDirectionAttributeValue AttributeDiskDirection) {
	mb.metricMongodbatlasDiskPartitionIopsMax.recordDataPoint(mb.startTime, ts, val, diskDirectionAttributeValue.String())
}

// RecordMongodbatlasDiskPartitionLatencyAverageDataPoint adds a data point to mongodbatlas.disk.partition.latency.average metric.
func (mb *MetricsBuilder) RecordMongodbatlasDiskPartitionLatencyAverageDataPoint(ts pcommon.Timestamp, val float64, diskDirectionAttributeValue AttributeDiskDirection) {
	mb.metricMongodbatlasDiskPartitionLatencyAverage.recordDataPoint(mb.startTime, ts, val, diskDirectionAttributeValue.String())
}

// RecordMongodbatlasDiskPartitionLatencyMaxDataPoint adds a data point to mongodbatlas.disk.partition.latency.max metric.
func (mb *MetricsBuilder) RecordMongodbatlasDiskPartitionLatencyMaxDataPoint(ts pcommon.Timestamp, val float64, diskDirectionAttributeValue AttributeDiskDirection) {
	mb.metricMongodbatlasDiskPartitionLatencyMax.recordDataPoint(mb.startTime, ts, val, diskDirectionAttributeValue.String())
}

// RecordMongodbatlasDiskPartitionSpaceAverageDataPoint adds a data point to mongodbatlas.disk.partition.space.average metric.
func (mb *MetricsBuilder) RecordMongodbatlasDiskPartitionSpaceAverageDataPoint(ts pcommon.Timestamp, val float64, diskStatusAttributeValue AttributeDiskStatus) {
	mb.metricMongodbatlasDiskPartitionSpaceAverage.recordDataPoint(mb.startTime, ts, val, diskStatusAttributeValue.String())
}

// RecordMongodbatlasDiskPartitionSpaceMaxDataPoint adds a data point to mongodbatlas.disk.partition.space.max metric.
func (mb *MetricsBuilder) RecordMongodbatlasDiskPartitionSpaceMaxDataPoint(ts pcommon.Timestamp, val float64, diskStatusAttributeValue AttributeDiskStatus) {
	mb.metricMongodbatlasDiskPartitionSpaceMax.recordDataPoint(mb.startTime, ts, val, diskStatusAttributeValue.String())
}

// RecordMongodbatlasDiskPartitionUsageAverageDataPoint adds a data point to mongodbatlas.disk.partition.usage.average metric.
func (mb *MetricsBuilder) RecordMongodbatlasDiskPartitionUsageAverageDataPoint(ts pcommon.Timestamp, val float64, diskStatusAttributeValue AttributeDiskStatus) {
	mb.metricMongodbatlasDiskPartitionUsageAverage.recordDataPoint(mb.startTime, ts, val, diskStatusAttributeValue.String())
}

// RecordMongodbatlasDiskPartitionUsageMaxDataPoint adds a data point to mongodbatlas.disk.partition.usage.max metric.
func (mb *MetricsBuilder) RecordMongodbatlasDiskPartitionUsageMaxDataPoint(ts pcommon.Timestamp, val float64, diskStatusAttributeValue AttributeDiskStatus) {
	mb.metricMongodbatlasDiskPartitionUsageMax.recordDataPoint(mb.startTime, ts, val, diskStatusAttributeValue.String())
}

// RecordMongodbatlasDiskPartitionUtilizationAverageDataPoint adds a data point to mongodbatlas.disk.partition.utilization.average metric.
func (mb *MetricsBuilder) RecordMongodbatlasDiskPartitionUtilizationAverageDataPoint(ts pcommon.Timestamp, val float64, diskStatusAttributeValue AttributeDiskStatus) {
	mb.metricMongodbatlasDiskPartitionUtilizationAverage.recordDataPoint(mb.startTime, ts, val, diskStatusAttributeValue.String())
}

// RecordMongodbatlasDiskPartitionUtilizationMaxDataPoint adds a data point to mongodbatlas.disk.partition.utilization.max metric.
func (mb *MetricsBuilder) RecordMongodbatlasDiskPartitionUtilizationMaxDataPoint(ts pcommon.Timestamp, val float64, diskStatusAttributeValue AttributeDiskStatus) {
	mb.metricMongodbatlasDiskPartitionUtilizationMax.recordDataPoint(mb.startTime, ts, val, diskStatusAttributeValue.String())
}

// RecordMongodbatlasProcessAssertsDataPoint adds a data point to mongodbatlas.process.asserts metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessAssertsDataPoint(ts pcommon.Timestamp, val float64, assertTypeAttributeValue AttributeAssertType) {
	mb.metricMongodbatlasProcessAsserts.recordDataPoint(mb.startTime, ts, val, assertTypeAttributeValue.String())
}

// RecordMongodbatlasProcessBackgroundFlushDataPoint adds a data point to mongodbatlas.process.background_flush metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessBackgroundFlushDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricMongodbatlasProcessBackgroundFlush.recordDataPoint(mb.startTime, ts, val)
}

// RecordMongodbatlasProcessCacheIoDataPoint adds a data point to mongodbatlas.process.cache.io metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessCacheIoDataPoint(ts pcommon.Timestamp, val float64, cacheDirectionAttributeValue AttributeCacheDirection) {
	mb.metricMongodbatlasProcessCacheIo.recordDataPoint(mb.startTime, ts, val, cacheDirectionAttributeValue.String())
}

// RecordMongodbatlasProcessCacheSizeDataPoint adds a data point to mongodbatlas.process.cache.size metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessCacheSizeDataPoint(ts pcommon.Timestamp, val float64, cacheStatusAttributeValue AttributeCacheStatus) {
	mb.metricMongodbatlasProcessCacheSize.recordDataPoint(mb.startTime, ts, val, cacheStatusAttributeValue.String())
}

// RecordMongodbatlasProcessConnectionsDataPoint adds a data point to mongodbatlas.process.connections metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessConnectionsDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricMongodbatlasProcessConnections.recordDataPoint(mb.startTime, ts, val)
}

// RecordMongodbatlasProcessCPUChildrenNormalizedUsageAverageDataPoint adds a data point to mongodbatlas.process.cpu.children.normalized.usage.average metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessCPUChildrenNormalizedUsageAverageDataPoint(ts pcommon.Timestamp, val float64, cpuStateAttributeValue AttributeCPUState) {
	mb.metricMongodbatlasProcessCPUChildrenNormalizedUsageAverage.recordDataPoint(mb.startTime, ts, val, cpuStateAttributeValue.String())
}

// RecordMongodbatlasProcessCPUChildrenNormalizedUsageMaxDataPoint adds a data point to mongodbatlas.process.cpu.children.normalized.usage.max metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessCPUChildrenNormalizedUsageMaxDataPoint(ts pcommon.Timestamp, val float64, cpuStateAttributeValue AttributeCPUState) {
	mb.metricMongodbatlasProcessCPUChildrenNormalizedUsageMax.recordDataPoint(mb.startTime, ts, val, cpuStateAttributeValue.String())
}

// RecordMongodbatlasProcessCPUChildrenUsageAverageDataPoint adds a data point to mongodbatlas.process.cpu.children.usage.average metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessCPUChildrenUsageAverageDataPoint(ts pcommon.Timestamp, val float64, cpuStateAttributeValue AttributeCPUState) {
	mb.metricMongodbatlasProcessCPUChildrenUsageAverage.recordDataPoint(mb.startTime, ts, val, cpuStateAttributeValue.String())
}

// RecordMongodbatlasProcessCPUChildrenUsageMaxDataPoint adds a data point to mongodbatlas.process.cpu.children.usage.max metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessCPUChildrenUsageMaxDataPoint(ts pcommon.Timestamp, val float64, cpuStateAttributeValue AttributeCPUState) {
	mb.metricMongodbatlasProcessCPUChildrenUsageMax.recordDataPoint(mb.startTime, ts, val, cpuStateAttributeValue.String())
}

// RecordMongodbatlasProcessCPUNormalizedUsageAverageDataPoint adds a data point to mongodbatlas.process.cpu.normalized.usage.average metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessCPUNormalizedUsageAverageDataPoint(ts pcommon.Timestamp, val float64, cpuStateAttributeValue AttributeCPUState) {
	mb.metricMongodbatlasProcessCPUNormalizedUsageAverage.recordDataPoint(mb.startTime, ts, val, cpuStateAttributeValue.String())
}

// RecordMongodbatlasProcessCPUNormalizedUsageMaxDataPoint adds a data point to mongodbatlas.process.cpu.normalized.usage.max metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessCPUNormalizedUsageMaxDataPoint(ts pcommon.Timestamp, val float64, cpuStateAttributeValue AttributeCPUState) {
	mb.metricMongodbatlasProcessCPUNormalizedUsageMax.recordDataPoint(mb.startTime, ts, val, cpuStateAttributeValue.String())
}

// RecordMongodbatlasProcessCPUUsageAverageDataPoint adds a data point to mongodbatlas.process.cpu.usage.average metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessCPUUsageAverageDataPoint(ts pcommon.Timestamp, val float64, cpuStateAttributeValue AttributeCPUState) {
	mb.metricMongodbatlasProcessCPUUsageAverage.recordDataPoint(mb.startTime, ts, val, cpuStateAttributeValue.String())
}

// RecordMongodbatlasProcessCPUUsageMaxDataPoint adds a data point to mongodbatlas.process.cpu.usage.max metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessCPUUsageMaxDataPoint(ts pcommon.Timestamp, val float64, cpuStateAttributeValue AttributeCPUState) {
	mb.metricMongodbatlasProcessCPUUsageMax.recordDataPoint(mb.startTime, ts, val, cpuStateAttributeValue.String())
}

// RecordMongodbatlasProcessCursorsDataPoint adds a data point to mongodbatlas.process.cursors metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessCursorsDataPoint(ts pcommon.Timestamp, val float64, cursorStateAttributeValue AttributeCursorState) {
	mb.metricMongodbatlasProcessCursors.recordDataPoint(mb.startTime, ts, val, cursorStateAttributeValue.String())
}

// RecordMongodbatlasProcessDbDocumentRateDataPoint adds a data point to mongodbatlas.process.db.document.rate metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessDbDocumentRateDataPoint(ts pcommon.Timestamp, val float64, documentStatusAttributeValue AttributeDocumentStatus) {
	mb.metricMongodbatlasProcessDbDocumentRate.recordDataPoint(mb.startTime, ts, val, documentStatusAttributeValue.String())
}

// RecordMongodbatlasProcessDbOperationsRateDataPoint adds a data point to mongodbatlas.process.db.operations.rate metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessDbOperationsRateDataPoint(ts pcommon.Timestamp, val float64, operationAttributeValue AttributeOperation, clusterRoleAttributeValue AttributeClusterRole) {
	mb.metricMongodbatlasProcessDbOperationsRate.recordDataPoint(mb.startTime, ts, val, operationAttributeValue.String(), clusterRoleAttributeValue.String())
}

// RecordMongodbatlasProcessDbOperationsTimeDataPoint adds a data point to mongodbatlas.process.db.operations.time metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessDbOperationsTimeDataPoint(ts pcommon.Timestamp, val float64, executionTypeAttributeValue AttributeExecutionType) {
	mb.metricMongodbatlasProcessDbOperationsTime.recordDataPoint(mb.startTime, ts, val, executionTypeAttributeValue.String())
}

// RecordMongodbatlasProcessDbQueryExecutorScannedDataPoint adds a data point to mongodbatlas.process.db.query_executor.scanned metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessDbQueryExecutorScannedDataPoint(ts pcommon.Timestamp, val float64, scannedTypeAttributeValue AttributeScannedType) {
	mb.metricMongodbatlasProcessDbQueryExecutorScanned.recordDataPoint(mb.startTime, ts, val, scannedTypeAttributeValue.String())
}

// RecordMongodbatlasProcessDbQueryTargetingScannedPerReturnedDataPoint adds a data point to mongodbatlas.process.db.query_targeting.scanned_per_returned metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessDbQueryTargetingScannedPerReturnedDataPoint(ts pcommon.Timestamp, val float64, scannedTypeAttributeValue AttributeScannedType) {
	mb.metricMongodbatlasProcessDbQueryTargetingScannedPerReturned.recordDataPoint(mb.startTime, ts, val, scannedTypeAttributeValue.String())
}

// RecordMongodbatlasProcessDbStorageDataPoint adds a data point to mongodbatlas.process.db.storage metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessDbStorageDataPoint(ts pcommon.Timestamp, val float64, storageStatusAttributeValue AttributeStorageStatus) {
	mb.metricMongodbatlasProcessDbStorage.recordDataPoint(mb.startTime, ts, val, storageStatusAttributeValue.String())
}

// RecordMongodbatlasProcessFtsCPUUsageDataPoint adds a data point to mongodbatlas.process.fts.cpu.usage metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessFtsCPUUsageDataPoint(ts pcommon.Timestamp, val float64, cpuStateAttributeValue AttributeCPUState) {
	mb.metricMongodbatlasProcessFtsCPUUsage.recordDataPoint(mb.startTime, ts, val, cpuStateAttributeValue.String())
}

// RecordMongodbatlasProcessGlobalLockDataPoint adds a data point to mongodbatlas.process.global_lock metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessGlobalLockDataPoint(ts pcommon.Timestamp, val float64, globalLockStateAttributeValue AttributeGlobalLockState) {
	mb.metricMongodbatlasProcessGlobalLock.recordDataPoint(mb.startTime, ts, val, globalLockStateAttributeValue.String())
}

// RecordMongodbatlasProcessIndexBtreeMissRatioDataPoint adds a data point to mongodbatlas.process.index.btree_miss_ratio metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessIndexBtreeMissRatioDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricMongodbatlasProcessIndexBtreeMissRatio.recordDataPoint(mb.startTime, ts, val)
}

// RecordMongodbatlasProcessIndexCountersDataPoint adds a data point to mongodbatlas.process.index.counters metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessIndexCountersDataPoint(ts pcommon.Timestamp, val float64, btreeCounterTypeAttributeValue AttributeBtreeCounterType) {
	mb.metricMongodbatlasProcessIndexCounters.recordDataPoint(mb.startTime, ts, val, btreeCounterTypeAttributeValue.String())
}

// RecordMongodbatlasProcessJournalingCommitsDataPoint adds a data point to mongodbatlas.process.journaling.commits metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessJournalingCommitsDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricMongodbatlasProcessJournalingCommits.recordDataPoint(mb.startTime, ts, val)
}

// RecordMongodbatlasProcessJournalingDataFilesDataPoint adds a data point to mongodbatlas.process.journaling.data_files metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessJournalingDataFilesDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricMongodbatlasProcessJournalingDataFiles.recordDataPoint(mb.startTime, ts, val)
}

// RecordMongodbatlasProcessJournalingWrittenDataPoint adds a data point to mongodbatlas.process.journaling.written metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessJournalingWrittenDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricMongodbatlasProcessJournalingWritten.recordDataPoint(mb.startTime, ts, val)
}

// RecordMongodbatlasProcessMemoryUsageDataPoint adds a data point to mongodbatlas.process.memory.usage metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessMemoryUsageDataPoint(ts pcommon.Timestamp, val float64, memoryStateAttributeValue AttributeMemoryState) {
	mb.metricMongodbatlasProcessMemoryUsage.recordDataPoint(mb.startTime, ts, val, memoryStateAttributeValue.String())
}

// RecordMongodbatlasProcessNetworkIoDataPoint adds a data point to mongodbatlas.process.network.io metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessNetworkIoDataPoint(ts pcommon.Timestamp, val float64, directionAttributeValue AttributeDirection) {
	mb.metricMongodbatlasProcessNetworkIo.recordDataPoint(mb.startTime, ts, val, directionAttributeValue.String())
}

// RecordMongodbatlasProcessNetworkRequestsDataPoint adds a data point to mongodbatlas.process.network.requests metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessNetworkRequestsDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricMongodbatlasProcessNetworkRequests.recordDataPoint(mb.startTime, ts, val)
}

// RecordMongodbatlasProcessOplogRateDataPoint adds a data point to mongodbatlas.process.oplog.rate metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessOplogRateDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricMongodbatlasProcessOplogRate.recordDataPoint(mb.startTime, ts, val)
}

// RecordMongodbatlasProcessOplogTimeDataPoint adds a data point to mongodbatlas.process.oplog.time metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessOplogTimeDataPoint(ts pcommon.Timestamp, val float64, oplogTypeAttributeValue AttributeOplogType) {
	mb.metricMongodbatlasProcessOplogTime.recordDataPoint(mb.startTime, ts, val, oplogTypeAttributeValue.String())
}

// RecordMongodbatlasProcessPageFaultsDataPoint adds a data point to mongodbatlas.process.page_faults metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessPageFaultsDataPoint(ts pcommon.Timestamp, val float64, memoryIssueTypeAttributeValue AttributeMemoryIssueType) {
	mb.metricMongodbatlasProcessPageFaults.recordDataPoint(mb.startTime, ts, val, memoryIssueTypeAttributeValue.String())
}

// RecordMongodbatlasProcessRestartsDataPoint adds a data point to mongodbatlas.process.restarts metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessRestartsDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricMongodbatlasProcessRestarts.recordDataPoint(mb.startTime, ts, val)
}

// RecordMongodbatlasProcessTicketsDataPoint adds a data point to mongodbatlas.process.tickets metric.
func (mb *MetricsBuilder) RecordMongodbatlasProcessTicketsDataPoint(ts pcommon.Timestamp, val float64, ticketTypeAttributeValue AttributeTicketType) {
	mb.metricMongodbatlasProcessTickets.recordDataPoint(mb.startTime, ts, val, ticketTypeAttributeValue.String())
}

// RecordMongodbatlasSystemCPUNormalizedUsageAverageDataPoint adds a data point to mongodbatlas.system.cpu.normalized.usage.average metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemCPUNormalizedUsageAverageDataPoint(ts pcommon.Timestamp, val float64, cpuStateAttributeValue AttributeCPUState) {
	mb.metricMongodbatlasSystemCPUNormalizedUsageAverage.recordDataPoint(mb.startTime, ts, val, cpuStateAttributeValue.String())
}

// RecordMongodbatlasSystemCPUNormalizedUsageMaxDataPoint adds a data point to mongodbatlas.system.cpu.normalized.usage.max metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemCPUNormalizedUsageMaxDataPoint(ts pcommon.Timestamp, val float64, cpuStateAttributeValue AttributeCPUState) {
	mb.metricMongodbatlasSystemCPUNormalizedUsageMax.recordDataPoint(mb.startTime, ts, val, cpuStateAttributeValue.String())
}

// RecordMongodbatlasSystemCPUUsageAverageDataPoint adds a data point to mongodbatlas.system.cpu.usage.average metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemCPUUsageAverageDataPoint(ts pcommon.Timestamp, val float64, cpuStateAttributeValue AttributeCPUState) {
	mb.metricMongodbatlasSystemCPUUsageAverage.recordDataPoint(mb.startTime, ts, val, cpuStateAttributeValue.String())
}

// RecordMongodbatlasSystemCPUUsageMaxDataPoint adds a data point to mongodbatlas.system.cpu.usage.max metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemCPUUsageMaxDataPoint(ts pcommon.Timestamp, val float64, cpuStateAttributeValue AttributeCPUState) {
	mb.metricMongodbatlasSystemCPUUsageMax.recordDataPoint(mb.startTime, ts, val, cpuStateAttributeValue.String())
}

// RecordMongodbatlasSystemFtsCPUNormalizedUsageDataPoint adds a data point to mongodbatlas.system.fts.cpu.normalized.usage metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemFtsCPUNormalizedUsageDataPoint(ts pcommon.Timestamp, val float64, cpuStateAttributeValue AttributeCPUState) {
	mb.metricMongodbatlasSystemFtsCPUNormalizedUsage.recordDataPoint(mb.startTime, ts, val, cpuStateAttributeValue.String())
}

// RecordMongodbatlasSystemFtsCPUUsageDataPoint adds a data point to mongodbatlas.system.fts.cpu.usage metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemFtsCPUUsageDataPoint(ts pcommon.Timestamp, val float64, cpuStateAttributeValue AttributeCPUState) {
	mb.metricMongodbatlasSystemFtsCPUUsage.recordDataPoint(mb.startTime, ts, val, cpuStateAttributeValue.String())
}

// RecordMongodbatlasSystemFtsDiskUsedDataPoint adds a data point to mongodbatlas.system.fts.disk.used metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemFtsDiskUsedDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricMongodbatlasSystemFtsDiskUsed.recordDataPoint(mb.startTime, ts, val)
}

// RecordMongodbatlasSystemFtsMemoryUsageDataPoint adds a data point to mongodbatlas.system.fts.memory.usage metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemFtsMemoryUsageDataPoint(ts pcommon.Timestamp, val float64, memoryStateAttributeValue AttributeMemoryState) {
	mb.metricMongodbatlasSystemFtsMemoryUsage.recordDataPoint(mb.startTime, ts, val, memoryStateAttributeValue.String())
}

// RecordMongodbatlasSystemMemoryUsageAverageDataPoint adds a data point to mongodbatlas.system.memory.usage.average metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemMemoryUsageAverageDataPoint(ts pcommon.Timestamp, val float64, memoryStatusAttributeValue AttributeMemoryStatus) {
	mb.metricMongodbatlasSystemMemoryUsageAverage.recordDataPoint(mb.startTime, ts, val, memoryStatusAttributeValue.String())
}

// RecordMongodbatlasSystemMemoryUsageMaxDataPoint adds a data point to mongodbatlas.system.memory.usage.max metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemMemoryUsageMaxDataPoint(ts pcommon.Timestamp, val float64, memoryStatusAttributeValue AttributeMemoryStatus) {
	mb.metricMongodbatlasSystemMemoryUsageMax.recordDataPoint(mb.startTime, ts, val, memoryStatusAttributeValue.String())
}

// RecordMongodbatlasSystemNetworkIoAverageDataPoint adds a data point to mongodbatlas.system.network.io.average metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemNetworkIoAverageDataPoint(ts pcommon.Timestamp, val float64, directionAttributeValue AttributeDirection) {
	mb.metricMongodbatlasSystemNetworkIoAverage.recordDataPoint(mb.startTime, ts, val, directionAttributeValue.String())
}

// RecordMongodbatlasSystemNetworkIoMaxDataPoint adds a data point to mongodbatlas.system.network.io.max metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemNetworkIoMaxDataPoint(ts pcommon.Timestamp, val float64, directionAttributeValue AttributeDirection) {
	mb.metricMongodbatlasSystemNetworkIoMax.recordDataPoint(mb.startTime, ts, val, directionAttributeValue.String())
}

// RecordMongodbatlasSystemPagingIoAverageDataPoint adds a data point to mongodbatlas.system.paging.io.average metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemPagingIoAverageDataPoint(ts pcommon.Timestamp, val float64, directionAttributeValue AttributeDirection) {
	mb.metricMongodbatlasSystemPagingIoAverage.recordDataPoint(mb.startTime, ts, val, directionAttributeValue.String())
}

// RecordMongodbatlasSystemPagingIoMaxDataPoint adds a data point to mongodbatlas.system.paging.io.max metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemPagingIoMaxDataPoint(ts pcommon.Timestamp, val float64, directionAttributeValue AttributeDirection) {
	mb.metricMongodbatlasSystemPagingIoMax.recordDataPoint(mb.startTime, ts, val, directionAttributeValue.String())
}

// RecordMongodbatlasSystemPagingUsageAverageDataPoint adds a data point to mongodbatlas.system.paging.usage.average metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemPagingUsageAverageDataPoint(ts pcommon.Timestamp, val float64, memoryStateAttributeValue AttributeMemoryState) {
	mb.metricMongodbatlasSystemPagingUsageAverage.recordDataPoint(mb.startTime, ts, val, memoryStateAttributeValue.String())
}

// RecordMongodbatlasSystemPagingUsageMaxDataPoint adds a data point to mongodbatlas.system.paging.usage.max metric.
func (mb *MetricsBuilder) RecordMongodbatlasSystemPagingUsageMaxDataPoint(ts pcommon.Timestamp, val float64, memoryStateAttributeValue AttributeMemoryState) {
	mb.metricMongodbatlasSystemPagingUsageMax.recordDataPoint(mb.startTime, ts, val, memoryStateAttributeValue.String())
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...metricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(mb)
	}
}
