# Datadog Connector

<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Distributions | [contrib] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aopen%20label%3Aconnector%2Fdatadog%20&label=open&color=orange&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aopen+is%3Aissue+label%3Aconnector%2Fdatadog) [![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aclosed%20label%3Aconnector%2Fdatadog%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aclosed+is%3Aissue+label%3Aconnector%2Fdatadog) |
| Code coverage | [![codecov](https://codecov.io/github/open-telemetry/opentelemetry-collector-contrib/graph/main/badge.svg?component=connector_datadog)](https://app.codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/tree/main/?components%5B0%5D=connector_datadog&displayType=list) |
| [Code Owners](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/CONTRIBUTING.md#becoming-a-code-owner)    | [@mx-psi](https://www.github.com/mx-psi), [@dineshg13](https://www.github.com/dineshg13), [@ankitpatel96](https://www.github.com/ankitpatel96), [@jade-guiton-dd](https://www.github.com/jade-guiton-dd), [@IbraheemA](https://www.github.com/IbraheemA) |
| Emeritus      | [@gbbr](https://www.github.com/gbbr) |

[beta]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/component-stability.md#beta
[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib

## Supported Pipeline Types

| [Exporter Pipeline Type] | [Receiver Pipeline Type] | [Stability Level] |
| ------------------------ | ------------------------ | ----------------- |
| traces | metrics | [beta] |
| traces | traces | [beta] |

[Exporter Pipeline Type]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/connector/README.md#exporter-pipeline-type
[Receiver Pipeline Type]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/connector/README.md#receiver-pipeline-type
[Stability Level]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/component-stability.md#stability-levels
<!-- end autogenerated section -->

## Description

The Datadog Connector is a connector component that derives APM statistics, in the form of metrics, from service traces, for display in the Datadog APMâ€¯product. This component is *required* for trace-emitting services and their statistics to appear in Datadog APM.

The Datadog connector can also forward the traces passed into it into another trace pipeline. Notably, if you plan to sample your traces with the [tailsamplingprocessor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/tailsamplingprocessor#tail-sampling-processor) or the [probabilisticsamplerprocessor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/probabilisticsamplerprocessor), you should place the Datadog connector upstream to ensure that the metrics are computed before sampling, ensuring their accuracy. An example is given below.

## Usage

```yaml
# ...
processors:
  # ...
  probabilistic_sampler:
    sampling_percentage: 20

connectors:
  # add the "datadog" connector definition and further configurations
  datadog/connector:

exporters:
  datadog:
    api:
      key: ${env:DD_API_KEY}

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [datadog/connector]

    traces/2: # this pipeline uses sampling
      receivers: [datadog/connector]
      processors: [batch, probabilistic_sampler]
      exporters: [datadog]

    metrics:
      receivers: [datadog/connector]
      processors: [batch]
      exporters: [datadog]
```

In this example configuration, incoming traces are received through OTLP, and processed by the Datadog connector in the `traces` pipeline. The traces are then forwarded to the `traces/2` pipeline, where a sample of them is exported to Datadog. In parallel, the APM stats computed from the full stream of traces are sent to the `metrics` pipeline, where they are exported to Datadog as well.

## Configurations

```yaml
connectors:
    datadog/connector:
      traces:
        ## @param ignore_resources - list of strings - optional
        ## A blacklist of regular expressions can be provided to disable certain traces based on their resource name
        ## all entries must be surrounded by double quotes and separated by commas.
        #
        # ignore_resources: ["(GET|POST) /healthcheck"]

        ## @param span_name_remappings - map of key/value pairs - optional
        ## A map of Datadog span operation name keys and preferred name valuues to update those names to. This can be used to
        ## automatically map Datadog Span Operation Names to an updated value, and is useful when a user wants to
        ## shorten or modify span names to something more user friendly in the case of instrumentation libraries with
        ## particularly verbose names.
        #
        # span_name_remappings:
        #   io.opentelemetry.javaagent.spring.client: spring.client
        #   instrumentation:express.server: express
        #   go.opentelemetry.io_contrib_instrumentation_net_http_otelhttp.client: http.client

        ## @param span_name_as_resource_name - use OpenTelemetry semantic convention for span naming - optional
        ## Option created to maintain similarity with the OpenTelemetry semantic conventions as discussed in the issue below.
        ## https://github.com/open-telemetry/opentelemetry-specification/tree/main/specification/trace/semantic_conventions
        ## https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/1909
        #
        # span_name_as_resource_name: true

        ## @param compute_stats_by_span_kind - enables APM stats computation based on `span.kind` - optional
        ## If set to true, enables an additional stats computation check on spans to see they have an eligible `span.kind` (server, consumer, client, producer).
        ## If enabled, a span with an eligible `span.kind` will have stats computed. If disabled, only top-level and measured spans will have stats computed.
        ## NOTE: For stats computed from OTel traces, only top-level spans are considered when this option is off.
        #
        # compute_stats_by_span_kind: true

        ## @param peer_tags_aggregation - enables aggregation of peer related tags in Datadog exporter - optional
        ## If set to true, enables aggregation of peer related tags (e.g., `peer.service`, `db.instance`, etc.) in Datadog exporter.
        ## If disabled, aggregated trace stats will not include these tags as dimensions on trace metrics.
        ## For the best experience with peer tags, Datadog also recommends enabling `compute_stats_by_span_kind`.
        ## If you are using an OTel tracer, it's best to have both enabled because client/producer spans with relevant peer tags
        ## may not be marked by Datadog exporter as top-level spans.
        ## If enabling both causes Datadog exporter to consume too many resources, try disabling `compute_stats_by_span_kind` first.
        ## A high cardinality of peer tags or APM resources can also contribute to higher CPU and memory consumption.
        ## You can check for the cardinality of these fields by making trace search queries in the Datadog UI.
        ## The default list of peer tags can be found in https://github.com/DataDog/datadog-agent/blob/main/pkg/trace/stats/concentrator.go.
        #
        # peer_tags_aggregation: false

        ## @param trace_buffer - specifies the number of outgoing trace payloads to buffer before dropping - optional
        ## If unset, the default value is 1000.
        ## If you start seeing log messages like `Payload in channel full. Dropped 1 payload.` in the datadog exporter, consider
        ## setting a higher `trace_buffer` to avoid traces being dropped.
        #
        # trace_buffer: 1000

        ## @param peer_tags - [BETA] Optional list of supplementary peer tags that go beyond the defaults. The Datadog backend validates all tags
        ## and will drop ones that are unapproved. The default set of peer tags can be found at
        ## https://github.com/DataDog/datadog-agent/blob/505170c4ac8c3cbff1a61cf5f84b28d835c91058/pkg/trace/stats/concentrator.go#L55.
        #
        # peer_tags: ["tag"]

        ## @param resource_attributes_as_container_tags - enables the use of resource attributes as container tags - Optional
        ## A list of resource attributes that should be used as container tags.
        #
        # resource_attributes_as_container_tags: ["cloud.availability_zone", "cloud.region"]

        ## @param bucket_interval specifies the time interval size of aggregation buckets that aggregate the Datadog trace metrics.
        ## It is also the time interval that Datadog trace metrics payloads are flushed to the pipeline.
        ## If you are concerned about the metric volume generated by the Datadog connector and the resulting networking egress, try increasing bucket_interval.
        ## Default is 10s if unset.
        #
        # bucket_interval: 30s
```
