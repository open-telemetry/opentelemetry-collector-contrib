<!-- status autogenerated section -->
# Azure Logs/Traces/Metrics Encoding Extension

This extension is designed for unmarshaling logs/traces/metrics encoded in specific format produced by [Azure Diagnostic Settings Export](https://learn.microsoft.com/en-us/azure/azure-monitor/essentials/diagnostic-settings) or [Azure Data Collection Rules (DCRs)](https://learn.microsoft.com/en-us/azure/azure-monitor/data-collection/data-collection-rule-overview)


| Status        |           |
| ------------- |-----------|
| Stability     | [development]  |
| Distributions | [] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aopen%20label%3Aextension%2Fazureencoding%20&label=open&color=orange&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aopen+is%3Aissue+label%3Aextension%2Fazureencoding) [![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aclosed%20label%3Aextension%2Fazureencoding%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aclosed+is%3Aissue+label%3Aextension%2Fazureencoding) |
| [Code Owners](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/CONTRIBUTING.md#becoming-a-code-owner)    | [@axw](https://www.github.com/axw), [@constanca-m](https://www.github.com/constanca-m) |

[development]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/component-stability.md#development
<!-- end autogenerated section -->

### Configuration

This Encoding extension has set of configuration options for each type of telemetry signals,
for list of specific configuration options and example - see below.

### Supported formats

Azure can expose log records in multiple different wrapper formats, depending on export destination and log Category.

This extension supports auto-detection and parsing of the following formats:

* `{ "records": [ {... record ...}, {... record ...} ] }` - mostly used in Azure EventHub export, but sometimes could be used for Azure BlobStorage export
* `[ {... record ...}, {... record ...} ]` - detected for some cases in Azure BlobStorage export
* `{... record ...}\n{... record ...}` (Newline-delimited JSON) - detected for some cases in Azure BlobStorage export

### Metrics

Currently supported following Azure Metrics export formats:

* export via Diagnostic Settings ([multi-dimensional metrics are not supported](https://learn.microsoft.com/en-us/azure/azure-monitor/platform/diagnostic-settings?tabs=portal#metrics-limitations))
* export via Data Collection Rules (DCRs) ([dimensions and metric filtering are supported](https://learn.microsoft.com/en-us/azure/azure-monitor/data-collection/data-collection-rule-overview))

***time_formats (Optional)***

List of time formats that should be applied during Timestamp parsing of incoming metrics records.

Time formats are based on standard [Go time parsing layouts](https://pkg.go.dev/time#Layout).

Formats are applied in order specified in configuration, ISO8601 parser will be checked first no matter of provided list of formats.

Default: (unset), parse provided timestamp using default ISO8601

***aggregations (Optional)***

List of Azure Metrics aggregations that should be exposed as a metrics.

Supported list of aggregations:

* total
* count
* minimum
* maximum
* average

Default: (unset), expose all supported metric aggregations as a separate metrics

#### Example configuration for Metrics encoding

```yaml
extensions:
  azure_encoding:
    metrics:
      time_formats: ["01/02/2006 15:04:05", "2006-01-02T15:04:05Z"]
      aggregations: ["total", "count", "average"]
...
receivers:
  kafka:
    metrics:
      encoding: azure_encoding
```

### Traces

Currently supported following Azure Traces export formats:

* export via Diagnostic Settings
* export via Data Collection Rules (DCRs)

Please take a note that as a source for Diagnostic Settings or DCRs you should use Application Insights in Azure Monitor, not a specific Azure Resource

Following list of Azure Logs Categories are supported as a Trace source:

* [Availability results](https://learn.microsoft.com/en-us/azure/azure-monitor/reference/tables/appavailabilityresults)
* [Dependencies](https://learn.microsoft.com/en-us/azure/azure-monitor/reference/tables/appdependencies)
* [Requests](https://learn.microsoft.com/en-us/azure/azure-monitor/reference/tables/apprequests)

***time_formats (Optional)***

List of time formats that should be applied during Timestamp parsing of incoming traces records.

Time formats are based on standard [Go time parsing layouts](https://pkg.go.dev/time#Layout).

Formats are applied in order specified in configuration, ISO8601 parser will be checked first no matter of provided list of formats.

Default: (unset), parse provided timestamp using default ISO8601

#### Example configuration for Traces encoding

```yaml
extensions:
  azure_encoding:
    traces:
      time_formats: ["01/02/2006 15:04:05", "2006-01-02T15:04:05Z"]
...
receivers:
  kafka:
    traces:
      encoding: azure_encoding
```

### Logs

Currently supported following Azure Resource Logs export formats:

* export via Diagnostic Settings
* export via Data Collection Rules (DCRs)

Currently only subset of available Azure Resource Logs Categories properly translated using OpenTelemetry SemConv.

[Transformation rules from Azure Resource Logs fields to OpenTelemetry](./internal/unmarshaler/logs/README.md).

Unsupported Categories simply copies attributes from "properties" field of incoming Azure Log Record to OpenTelemetry Log Attributes as a strings.

***time_formats (Optional)***

This option will override the list of time formats that should be applied during Timestamp parsing of incoming logs records.

If not set - following list of time formats will be used:

* `01/02/2006 15:04:05`
* `1/2/2006 3:04:05.000 PM -07:00`
* `1/2/2006 3:04:05 PM -07:00`

Time formats are based on standard [Go time parsing layouts](https://pkg.go.dev/time#Layout).

Formats are applied in order specified in configuration, ISO8601 parser will be checked first no matter of provided list of formats.

Default: (unset), parse provided timestamp using default formats set

***include_categories (Optional)***

List of Azure Resource Logs Categories to process. Other Azure Resource Logs Categories that are not in the provided list - will be silently ignored

Default: (unset), process all incoming categories

***exclude_categories (Optional)***

List of Azure Resource Logs Categories to ignore during processing. All Azure Resource Logs Categories will be processed, excluding Categories in provided list

Default: (unset), process all incoming categories

**Note**: If both `include_categories` and `exclude_categories` are specified,
the `exclude_categories` takes precedences and Categories will be ignored even in case of presence in both lists.

#### Example configuration for Logs encoding

```yaml
extensions:
  azure_encoding:
    logs:
      time_formats: ["01/02/2006 15:04:05", "1/2/2006 3:04:05.000 PM -07:00"]
      exclude_categories: ["AzureCdnAccessLog"]
      include_categories: ["AzureCdnAccessLog", "FrontDoorAccessLog"] # only FrontDoorAccessLog will be processed
...
receivers:
  kafka:
    logs:
      encoding: azure_encoding
```
