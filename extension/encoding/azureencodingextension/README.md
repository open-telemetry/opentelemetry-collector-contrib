# Azure Logs/Traces/Metrics encoding extension
<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [development]  |
| Distributions | [] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aopen%20label%3Aextension%2Fazureencoding%20&label=open&color=orange&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aopen+is%3Aissue+label%3Aextension%2Fazureencoding) [![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aclosed%20label%3Aextension%2Fazureencoding%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aclosed+is%3Aissue+label%3Aextension%2Fazureencoding) |
| [Code Owners](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/CONTRIBUTING.md#becoming-a-code-owner)    | [@axw](https://www.github.com/axw), [@constanca-m](https://www.github.com/constanca-m) |

[development]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/component-stability.md#development
<!-- end autogenerated section -->

## Overview

This extension is designed for unmarshaling logs/traces/metrics encoded in specific format
produced by [Azure Diagnostic Settings Export](https://learn.microsoft.com/en-us/azure/azure-monitor/essentials/diagnostic-settings) or
[Azure Data Collection Rules (DCRs)](https://learn.microsoft.com/en-us/azure/azure-monitor/data-collection/data-collection-rule-overview)

## Configuration

Encoding extension has both top-level configuration, that applied to all telemetry signals
and own set of configuration options for each type of telemetry signals

### General configuration options

***format (Optional)***

Identifies format of incoming JSON records for all supported telemetry signals:

* `eventhub` (default) - extension will be expecting JSON records as they are exposed to Azure EventHub,
i.e. `{ "records": [ {... record ...}, {... record ...} ] }`
* `blobstorage` - extension will be expecting JSON records as they are exposed to Azure Blob Storage,
i.e. `[ {... record ...}, {... record ...} ]`

#### Example configuration for incoming format

```yaml
extensions:
  azure_encoding:
    format: eventhub
    metrics:
      time_formats: ["01/02/2006 15:04:05", "2006-01-02T15:04:05Z"]
      aggregations: ["total", "count", "average"]
...
receivers:
  kafka:
    metrics:
      encoding: azure_encoding
```

### Metrics

Currently supported following Azure Metrics export formats:

* export via Diagnostic Settings ([multi-dimensional metrics are not supported](https://learn.microsoft.com/en-us/azure/azure-monitor/platform/diagnostic-settings?tabs=portal#metrics-limitations))
* export via Data Collection Rules (DCRs) ([dimensions and metric filtering are supported](https://learn.microsoft.com/en-us/azure/azure-monitor/data-collection/data-collection-metrics))

***time_formats (Optional)***

List of time formats that should be applied during Timestamp parsing of incoming metrics records.

Time formats are based on standard [Go time parsing layouts](https://pkg.go.dev/time#Layout).

Formats are applied in order specified in configuration, if all failed - will be used ISO8601 parser.

Default: (unset), parse provided timestamp using default ISO8601

***aggregations (Optional)***

List of Azure Metrics aggregations that should be exposed as a metrics.

Supported list of aggregations:

* total
* count
* minimum
* maximum
* average

Default: (unset), expose all supported metric aggregations as a separate metrics

#### Example configuration for Metrics encoding

```yaml
extensions:
  azure_encoding:
    metrics:
      time_formats: ["01/02/2006 15:04:05", "2006-01-02T15:04:05Z"]
      aggregations: ["total", "count", "average"]
...
receivers:
  kafka:
    metrics:
      encoding: azure_encoding
```

### Traces

Currently supported following Azure Traces export formats:

* export via Diagnostic Settings
* export via Data Collection Rules (DCRs)

Please take a note that as a source for Diagnostic Settings or DCRs you should use Application Insights in Azure Monitor, not a specific Azure Resource

Following list of Azure Logs Categories are supported as a Trace source:

* [Availability results](https://learn.microsoft.com/en-us/azure/azure-monitor/reference/tables/appavailabilityresults)
* [Dependencies](https://learn.microsoft.com/en-us/azure/azure-monitor/reference/tables/appdependencies)
* [Requests](https://learn.microsoft.com/en-us/azure/azure-monitor/reference/tables/apprequests)

***time_formats (Optional)***

List of time formats that should be applied during Timestamp parsing of incoming traces records.

Time formats are based on standard [Go time parsing layouts](https://pkg.go.dev/time#Layout).

Formats are applied in order specified in configuration, if all failed - will be used ISO8601 parser.

Default: (unset), parse provided timestamp using default ISO8601

#### Example configuration for Traces encoding

```yaml
extensions:
  azure_encoding:
    traces:
      time_formats: ["01/02/2006 15:04:05", "2006-01-02T15:04:05Z"]
...
receivers:
  kafka:
    traces:
      encoding: azure_encoding
```

### Logs

Currently supported following Azure Resource Logs export formats:

* export via Diagnostic Settings
* export via Data Collection Rules (DCRs)

Currently only subset of available Azure Resource Logs Categories properly translated using OpenTelemetry SemConv.

Unsupported Categories simply copies attributes from "properties" field of incoming Azure Log Record to OpenTelemetry Log Attributes as a strings.

***time_formats (Optional)***

List of time formats that should be applied during Timestamp parsing of incoming logs records.

Time formats are based on standard [Go time parsing layouts](https://pkg.go.dev/time#Layout).

Formats are applied in order specified in configuration, if all failed - will be used ISO8601 parser.

Default: (unset), parse provided timestamp using default ISO8601

***include_categories (Optional)***

List of Azure Resource Logs Categories to process. Other Azure Resource Logs Categories that are not in the provided list - will be silently ignored

Default: (unset), process all incoming categories

***exclude_categories (Optional)***

List of Azure Resource Logs Categories to ignore during processing. All Azure Resource Logs Categories will be processed, excluding Categories in provided list

Default: (unset), process all incoming categories

**Note**: If both `include_categories` and `exclude_categories` are specified,
the `exclude_categories` takes precedences and Categories will be ignored even in case of presence in both lists.

#### Example configuration for Logs encoding

```yaml
extensions:
  azure_encoding:
    logs:
      time_formats: ["01/02/2006 15:04:05", "2006-01-02T15:04:05Z"]
      exclude_categories: ["AzureCdnAccessLog"]
      include_categories: ["AzureCdnAccessLog", "FrontDoorAccessLog"] # only FrontDoorAccessLog will be processed
...
receivers:
  kafka:
    logs:
      encoding: azure_encoding
```
