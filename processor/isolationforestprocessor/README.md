# IsolationÂ Forest Processor for OpenTelemetry CollectorÂ Contrib

> **Status:**Â Alpha â€“ interfaces and behaviour may still evolve.

The **IsolationÂ Forest processor** adds inline, unsupervised anomaly detection to any OpenTelemetry Collector pipeline (traces, metrics, or logs). It embeds a lightweight implementation of the IsolationÂ Forest algorithm that automatically learns normal behaviour from recent telemetry and tags, scores, or optionally drops anomalies *inâ€‘flight* â€“ no external ML service required.

---

## âœ¨Â Key Features

| Capability                    | Description                                                                                                                                         |
| ----------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Realtime IsolationÂ Forest** | Builds an ensemble of random trees over a sliding window of recent data and assigns a 0â€“1 anomaly score on ingestion (â‰ˆÂ *O(logÂ n)* per point).      |
| **Multiâ€‘signal support**      | Can be inserted into **traces**, **metrics**, **logs** pipelines â€“ one config powers all three.                                                     |
| **Perâ€‘entity modelling**      | `features` config lets you maintain a separate model per unique combination of resource / attribute keys (e.g. perâ€‘pod, perâ€‘service).               |
| **Flexible output**           | â€¢ Add an attribute `iforest.is_anomaly=true`Â <br>â€¢ Emit a gauge metric `iforest.anomaly_score`Â <br>â€¢ Drop anomalous telemetry entirely.             |
| **Configâ€‘driven**             | Tune tree count, subsample size, contamination rate, slidingâ€‘window length, retraining interval, target metrics, and more â€“ all in `collector.yml`. |
| **Zero external deps**        | PureÂ Go implementation; runs wherever the Collector does (edge, gateway, or backend).                                                               |

---

## âš™ï¸Â How it Works

1. **Training window** â€“ The processor keeps up to `window_size` of the most recent data points for every featureâ€‘group.
2. **Periodic (reâ€‘)training** â€“ Every `training_interval`, it draws `subsample_size` points from that window and grows `forest_size` random isolation trees.
3. **Scoring** â€“ Each new point is pushed through the forest. Shorter average path length â‡’ higher anomaly score.
4. **Postâ€‘processing** â€“

   * If `add_anomaly_score: true`, a gauge metric `iforest.anomaly_score` is emitted with identical attributes/timestamp.
   * If the score â‰¥ `anomaly_threshold`, the original span/metric/log is flagged with `iforest.is_anomaly=true`.
   * If `drop_anomalous_data: true`, flagged items are removed from the batch instead of being forwarded.

> **ContaminationÂ rate** â€“ instead of hardâ€‘coding `anomaly_threshold`, you can supply `contamination_rate` (expected % of outliers). The processor then autoâ€‘derives a dynamic threshold equal to the `(1Â â€“Â contamination_rate)` quantile of recent scores.

Performance is linear in `forest_size` and logarithmic in `window_size`; a default of 100 trees and a 1Â kâ€‘point window easily sustains 10â€“50Â k points/s on a vCPU.

---

## ğŸ”§ Configuration

| Field                 | Type        | Default   | Notes                                                                          |
| --------------------- | ----------- | --------- | ------------------------------------------------------------------------------ |
| `forest_size`         | int         | `100`     | Number of trees in the ensemble. HigherÂ â†’ smoother scores, more CPU.           |
| `subsample_size`      | int         | `256`     | Rows sampled to build **each** tree. Must be â‰¤Â `window_size`.                  |
| `window_size`         | int         | `1000`    | Sliding window of recent data maintained per featureâ€‘group.                    |
| `contamination_rate`  | float (0â€“1) | `0.10`    | Fraction of points expected to be outliers; used to autoâ€‘tune threshold.       |
| `anomaly_threshold`   | float (0â€“1) | *derived* | Manual override â€“ score â‰¥Â this â‡’ anomaly. Ignored if `contamination_rate` set. |
| `training_interval`   | duration    | `5m`      | Model is retrained no sooner than this interval.                               |
| `features`            | \[]string   | `[]`      | Resource/attribute keys that define **grouping**. BlankÂ â‡’ single global model. |
| `metrics_to_analyze`  | \[]string   | `[]`      | Only these metric names are scored (metrics pipeline only). BlankÂ â‡’ all.       |
| `add_anomaly_score`   | bool        | `false`   | Emit `iforest.anomaly_score` metric.                                           |
| `drop_anomalous_data` | bool        | `false`   | Remove anomalous items from the batch instead of forwarding.                   |

See the sample below for context.

---

## ğŸ“„Â Sample `config.yml`

```yaml
receivers:
  otlp:
    protocols:
      grpc:            # â†’ listen on 0.0.0.0:4317

processors:
  isolationforest:
    # â”€â”€â”€ core algorithm parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    forest_size:        150          # trees per forest
    subsample_size:     512          # rows per tree
    contamination_rate: 0.05         # 5 % expected outliers
    threshold:          0.0          # 0 â‡’ let contamination_rate drive the cut-off
    mode:               both         # enrich + filter (see docstring)
    training_window:    24h          # window of data kept for training
    update_frequency:   5m           # retrain every 5 minutes
    min_samples:        1000         # wait until this many points seen

    # â”€â”€â”€ where to write results on each data point â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    score_attribute:          anomaly.isolation_score   # float 0â€“1
    classification_attribute: anomaly.is_anomaly        # bool

    # â”€â”€â”€ which numeric features the model should look at â”€â”€â”€â”€â”€â”€â”€â”€â”€
    features:
      traces:  [duration]           # span duration (Âµs / ns)
      metrics: [value]              # the sampleâ€™s numeric value
      logs:    [severity_number]    # log severity enum

    # â”€â”€â”€ performance guard-rails (optional) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    performance:
      max_memory_mb:     512
      batch_size:        1000
      parallel_workers:  4

exporters:
  prometheus:
    endpoint: "0.0.0.0:9464"   # Prom-server will scrape /metrics here
    send_timestamps: true      # (field is valid in the standard exporter)

service:
  pipelines:
    metrics:
      receivers:  [otlp]
      processors: [isolationforest]
      exporters:  [prometheus]

```

### What the example does

| Signal      | Whatâ€™s scored                                              | Feature grouping               | Output                                    | Notes                                                                                            |
| ----------- | ---------------------------------------------------------- | ------------------------------ | ----------------------------------------- | ------------------------------------------------------------------------------------------------ |
| **Traces**  | Span **duration** (ns)                                     | `service.name`, `k8s.pod.name` | `iforest.is_anomaly` attr + optional drop | Use a span/trace exporter to route anomalies.                                                    |
| **Metrics** | Only `system.cpu.utilization`, `system.memory.utilization` | Same                           | Attribute + score metric                  | The score appears as `iforest.anomaly_score` gauge.                                              |
| **Logs**    | Size of the log payload (bytes) by default                 | Same                           | Attribute flag                            | You can expose a numeric logÂ attribute and configure the processor to use that via code changes. |

---

## ğŸš€Â Best Practices

* **Tune `forest_size` vs. latency** â€“ start with 100 trees; raise to 200â€“300 if scores look noisy.
* **Use perâ€‘entity models** â€“ add `features` (service, pod, host) to avoid global comparisons across very different series.
* **Let contamination drive threshold** â€“ set `contamination_rate` to the % of traffic youâ€™re comfortable labelling outlier; avoid handâ€‘tuning `anomaly_threshold`.
* **Route anomalies** â€“ keep `drop_anomalous_data=false` and add a simple \[routingâ€‘processor] downstream to ship anomalies to a dedicated exporter or topic.
* **Monitor model health** â€“ the emitted `iforest.anomaly_score` metric is perfect for a Grafana panel; watch its distribution and adapt window / contamination accordingly.

---

## ğŸ—ï¸Â Internals (Highâ€‘Level)

```text
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ IsolationForestProcessor (per Collector instance)â”‚
               â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
               â”‚  â€¢ Sliding window (per featureâ€‘group)           â”‚
               â”‚  â€¢ Forest of N trees (per featureâ€‘group)        â”‚
Telemetry â”€â”€â”€â–¶  â”‚  â€¢ Score calculator & anomaly decision         â”‚ â”€â”€â”€â–¶  Next processor/exporter
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

*TrainingÂ cost*: **O(window\_sizeÂ Ã—Â forest\_sizeÂ Ã—Â logâ€¯subsample\_size)** every `training_interval`
*ScoringÂ cost*: **O(forest\_sizeÂ Ã—Â logâ€¯subsample\_size)** per item

---

## ğŸ“¦Â Building & Enabling

1. Add `isolationforestprocessor` to your Collectorâ€™s goâ€‘builder manifest or vendor the contrib repo at the `feature/isolation-forest-processor` branch.
2. Rebuild the Collector (`make otelcontribcol`).
3. Enable the processor in your YAML as shown above and restart the service.

> **Note** â€“ until merged upstream, you need a custom build of `otelcontribcol` that includes this processor.

---

## ğŸ¤Â Contributing

* **Bugs / Questions** â€“ please open an issue in the fork first.
* **Planned enhancements**

  * Multivariate scoring (multiple numeric attributes per point).
  * Adaptive window size.
  * Expose Prometheus counters for training time / CPU cost.

PRs welcome â€“ please include unit tests and doc updates.

---

## ğŸ“œÂ License

This processor is released under the [ApacheÂ 2.0 License](../../LICENSE).
