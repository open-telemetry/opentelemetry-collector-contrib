# Isolation Forest Processor

> **Status:** In Development ‚Äì interfaces and behaviour may still evolve.

The **Isolation Forest processor** adds inline, unsupervised anomaly detection to any OpenTelemetry Collector pipeline (traces, metrics, or logs). It embeds a lightweight implementation of the Isolation Forest algorithm that automatically learns normal behaviour from recent telemetry and tags, scores, or optionally drops anomalies *in‚Äëflight* ‚Äì no external ML service required.

---

## ‚ú® Key Features

| Capability                    | Description                                                                                                                                         |
| ----------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Realtime Isolation Forest** | Builds an ensemble of random trees over a sliding window of recent data and assigns a 0‚Äì1 anomaly score on ingestion (‚âà *O(log n)* per point).      |
| **Multi‚Äësignal support**      | Can be inserted into **traces**, **metrics**, **logs** pipelines ‚Äì one config powers all three.                                                     |
| **Per‚Äëentity modelling**      | `features` config lets you maintain a separate model per unique combination of resource / attribute keys (e.g. per‚Äëpod, per‚Äëservice).               |
| **Flexible output**           | ‚Ä¢ Add an attribute `iforest.is_anomaly=true` <br>‚Ä¢ Emit a gauge metric `iforest.anomaly_score` <br>‚Ä¢ Drop anomalous telemetry entirely.             |
| **Config‚Äëdriven**             | Tune tree count, subsample size, contamination rate, sliding‚Äëwindow length, retraining interval, target metrics, and more ‚Äì all in `collector.yml`. |
| **Zero external deps**        | Pure Go implementation; runs wherever the Collector does (edge, gateway, or backend).                                                               |

---

## ‚öôÔ∏è How it Works

1. **Training window** ‚Äì The processor keeps up to `window_size` of the most recent data points for every feature‚Äëgroup.
2. **Periodic (re‚Äë)training** ‚Äì Every `training_interval`, it draws `subsample_size` points from that window and grows `forest_size` random isolation trees.
3. **Scoring** ‚Äì Each new point is pushed through the forest. Shorter average path length ‚áí higher anomaly score.
4. **Post‚Äëprocessing** ‚Äì

   * If `add_anomaly_score: true`, a gauge metric `iforest.anomaly_score` is emitted with identical attributes/timestamp.
   * If the score ‚â• `anomaly_threshold`, the original span/metric/log is flagged with `iforest.is_anomaly=true`.
   * If `drop_anomalous_data: true`, flagged items are removed from the batch instead of being forwarded.

> **Contamination rate** ‚Äì instead of hard‚Äëcoding `anomaly_threshold`, you can supply `contamination_rate` (expected % of outliers). The processor then auto‚Äëderives a dynamic threshold equal to the `(1 ‚Äì contamination_rate)` quantile of recent scores.

Performance is linear in `forest_size` and logarithmic in `window_size`; a default of 100 trees and a 1 k‚Äëpoint window easily sustains 10‚Äì50 k points/s on a vCPU.

---

## üîß Configuration

| Field                 | Type        | Default   | Notes                                                                          |
| --------------------- | ----------- | --------- | ------------------------------------------------------------------------------ |
| `forest_size`         | int         | `100`     | Number of trees in the ensemble. Higher ‚Üí smoother scores, more CPU.           |
| `subsample_size`      | int         | `256`     | Rows sampled to build **each** tree. Must be ‚â§ `window_size`.                  |
| `window_size`         | int         | `1000`    | Sliding window of recent data maintained per feature‚Äëgroup.                    |
| `contamination_rate`  | float (0‚Äì1) | `0.10`    | Fraction of points expected to be outliers; used to auto‚Äëtune threshold.       |
| `anomaly_threshold`   | float (0‚Äì1) | *derived* | Manual override ‚Äì score ‚â• this ‚áí anomaly. Ignored if `contamination_rate` set. |
| `training_interval`   | duration    | `5m`      | Model is retrained no sooner than this interval.                               |
| `features`            | \[]string   | `[]`      | Resource/attribute keys that define **grouping**. Blank ‚áí single global model. |
| `metrics_to_analyze`  | \[]string   | `[]`      | Only these metric names are scored (metrics pipeline only). Blank ‚áí all.       |
| `add_anomaly_score`   | bool        | `false`   | Emit `iforest.anomaly_score` metric.                                           |
| `drop_anomalous_data` | bool        | `false`   | Remove anomalous items from the batch instead of forwarding.                   |

See the sample below for context.

---

## üìÑ Sample `config.yml`

```yaml
receivers:
  otlp:
    protocols:
      grpc:            # ‚Üí listen on 0.0.0.0:4317

processors:
  isolationforest:
    # ‚îÄ‚îÄ‚îÄ core algorithm parameters ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    forest_size:        150          # trees per forest
    subsample_size:     512          # rows per tree
    contamination_rate: 0.05         # 5 % expected outliers
    threshold:          0.0          # 0 ‚áí let contamination_rate drive the cut-off
    mode:               both         # enrich + filter (see docstring)
    training_window:    24h          # window of data kept for training
    update_frequency:   5m           # retrain every 5 minutes
    min_samples:        1000         # wait until this many points seen

    # ‚îÄ‚îÄ‚îÄ where to write results on each data point ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    score_attribute:          anomaly.isolation_score   # float 0‚Äì1
    classification_attribute: anomaly.is_anomaly        # bool

    # ‚îÄ‚îÄ‚îÄ which numeric features the model should look at ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    features:
      traces:  [duration]           # span duration (¬µs / ns)
      metrics: [value]              # the sample‚Äôs numeric value
      logs:    [severity_number]    # log severity enum

    # ‚îÄ‚îÄ‚îÄ performance guard-rails (optional) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    performance:
      max_memory_mb:     512
      batch_size:        1000
      parallel_workers:  4

exporters:
  prometheus:
    endpoint: "0.0.0.0:9464"   # Prom-server will scrape /metrics here
    send_timestamps: true      # (field is valid in the standard exporter)

service:
  pipelines:
    metrics:
      receivers:  [otlp]
      processors: [isolationforest]
      exporters:  [prometheus]

```

### What the example does

| Signal      | What‚Äôs scored                                              | Feature grouping               | Output                                    | Notes                                                                                            |
| ----------- | ---------------------------------------------------------- | ------------------------------ | ----------------------------------------- | ------------------------------------------------------------------------------------------------ |
| **Traces**  | Span **duration** (ns)                                     | `service.name`, `k8s.pod.name` | `iforest.is_anomaly` attr + optional drop | Use a span/trace exporter to route anomalies.                                                    |
| **Metrics** | Only `system.cpu.utilization`, `system.memory.utilization` | Same                           | Attribute + score metric                  | The score appears as `iforest.anomaly_score` gauge.                                              |
| **Logs**    | Size of the log payload (bytes) by default                 | Same                           | Attribute flag                            | You can expose a numeric log attribute and configure the processor to use that via code changes. |

---

## üöÄ Best Practices

* **Tune `forest_size` vs. latency** ‚Äì start with 100 trees; raise to 200‚Äì300 if scores look noisy.
* **Use per‚Äëentity models** ‚Äì add `features` (service, pod, host) to avoid global comparisons across very different series.
* **Let contamination drive threshold** ‚Äì set `contamination_rate` to the % of traffic you‚Äôre comfortable labelling outlier; avoid hand‚Äëtuning `anomaly_threshold`.
* **Route anomalies** ‚Äì keep `drop_anomalous_data=false` and add a simple \[routing‚Äëprocessor] downstream to ship anomalies to a dedicated exporter or topic.
* **Monitor model health** ‚Äì the emitted `iforest.anomaly_score` metric is perfect for a Grafana panel; watch its distribution and adapt window / contamination accordingly.

---

## üèóÔ∏è Internals (High‚ÄëLevel)

```text
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ IsolationForestProcessor (per Collector instance)‚îÇ
               ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ
               ‚îÇ  ‚Ä¢ Sliding window (per feature‚Äëgroup)           ‚îÇ
               ‚îÇ  ‚Ä¢ Forest of N trees (per feature‚Äëgroup)        ‚îÇ
Telemetry ‚îÄ‚îÄ‚îÄ‚ñ∂  ‚îÇ  ‚Ä¢ Score calculator & anomaly decision         ‚îÇ ‚îÄ‚îÄ‚îÄ‚ñ∂  Next processor/exporter
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

*Training cost*: **O(window\_size √ó forest\_size √ó log‚ÄØsubsample\_size)** every `training_interval`
*Scoring cost*: **O(forest\_size √ó log‚ÄØsubsample\_size)** per item

---

## üì¶ Building & Enabling

1. Add `isolationforestprocessor` to your Collector‚Äôs go‚Äëbuilder manifest or vendor the contrib repo at the `feature/isolation-forest-processor` branch.
2. Rebuild the Collector (`make otelcontribcol`).
3. Enable the processor in your YAML as shown above and restart the service.

> **Note** ‚Äì until merged upstream, you need a custom build of `otelcontribcol` that includes this processor.

---

## ü§ù Contributing

* **Bugs / Questions** ‚Äì please open an issue in the fork first.
* **Planned enhancements**

  * Multivariate scoring (multiple numeric attributes per point).
  * Adaptive window size.
  * Expose Prometheus counters for training time / CPU cost.

PRs welcome ‚Äì please include unit tests and doc updates.

---

