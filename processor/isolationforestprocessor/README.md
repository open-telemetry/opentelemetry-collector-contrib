# Isolation Forest Processor

<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [alpha]: traces, metrics, logs   |
| Distributions | [contrib] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aopen%20label%3Aprocessor%2Fisolationforest%20&label=open&color=orange&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aopen+is%3Aissue+label%3Aprocessor%2Fisolationforest) [![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aclosed%20label%3Aprocessor%2Fisolationforest%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aclosed+is%3Aissue+label%3Aprocessor%2Fisolationforest) |
| Code coverage | [![codecov](https://codecov.io/github/open-telemetry/opentelemetry-collector-contrib/graph/main/badge.svg?component=processor_isolationforest)](https://app.codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/tree/main/?components%5B0%5D=processor_isolationforest&displayType=list) |
| [Code Owners](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/CONTRIBUTING.md#becoming-a-code-owner)    | [@atoulme](https://www.github.com/atoulme) |

[alpha]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/component-stability.md#alpha
[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib
<!-- end autogenerated section -->

The **Isolation Forest processor** adds inline, unsupervised anomaly detection to any OpenTelemetry Collector pipeline (traces, metrics, or logs). It embeds a lightweight implementation of the Isolation Forest algorithm that automatically learns normal behaviour from recent telemetry and tags, scores, or optionally drops anomalies *inâ€‘flight* â€“ no external ML service required.

---

## âœ¨ Key Features

| Capability                    | Description                                                                                                                                         |
| ----------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Realtime Isolation Forest** | Builds an ensemble of random trees over a sliding window of recent data and assigns a 0â€“1 anomaly score on ingestion (â‰ˆ *O(log n)* per point).      |
| **Multiâ€‘signal support**      | Can be inserted into **traces**, **metrics**, **logs** pipelines â€“ one config powers all three.                                                     |
| **Perâ€‘entity modelling**      | `features` config lets you maintain a separate model per unique combination of resource / attribute keys (e.g. perâ€‘pod, perâ€‘service).               |
| **Adaptive Window Sizing**    | Automatically adjusts window size based on traffic patterns, memory usage, and model stability for optimal performance and resource utilization.    |
| **Flexible output**           | â€¢ Add an attribute `iforest.is_anomaly=true` <br>â€¢ Emit a gauge metric `iforest.anomaly_score` <br>â€¢ Drop anomalous telemetry entirely.             |
| **Configâ€‘driven**             | Tune tree count, subsample size, contamination rate, slidingâ€‘window length, retraining interval, target metrics, and more â€“ all in `collector.yml`. |
| **Zero external deps**        | Pure Go implementation; runs wherever the Collector does (edge, gateway, or backend).                                                               |

---

## âš™ï¸ How it Works

1. **Training window** â€“ The processor keeps up to `window_size` of the most recent data points for every featureâ€‘group.
2. **Periodic (reâ€‘)training** â€“ Every `training_interval`, it draws `subsample_size` points from that window and grows `forest_size` random isolation trees.
3. **Scoring** â€“ Each new point is pushed through the forest. Shorter average path length â‡’ higher anomaly score.
4. **Adaptive sizing** â€“ When enabled, window size automatically adjusts based on traffic velocity, memory usage, and model stability.
5. **Postâ€‘processing** â€“

   * If `add_anomaly_score: true`, a gauge metric `iforest.anomaly_score` is emitted with identical attributes/timestamp.
   * If the score â‰¥ `anomaly_threshold`, the original span/metric/log is flagged with `iforest.is_anomaly=true`.
   * If `drop_anomalous_data: true`, flagged items are removed from the batch instead of being forwarded.

> **Contamination rate** â€“ instead of hardâ€‘coding `anomaly_threshold`, you can supply `contamination_rate` (expected % of outliers). The processor then autoâ€‘derives a dynamic threshold equal to the `(1 â€“ contamination_rate)` quantile of recent scores.

Performance is linear in `forest_size` and logarithmic in `window_size`; a default of 100 trees and a 1 kâ€‘point window easily sustains 10â€“50 k points/s on a vCPU.

---

## ğŸ”§ Configuration

| Field                 | Type        | Default   | Notes                                                                          |
| --------------------- | ----------- | --------- | ------------------------------------------------------------------------------ |
| `forest_size`         | int         | `100`     | Number of trees in the ensemble. Higher â†’ smoother scores, more CPU.           |
| `subsample_size`      | int         | `256`     | Rows sampled to build **each** tree. Must be â‰¤ `window_size`.                  |
| `window_size`         | int         | `1000`    | Sliding window of recent data maintained per featureâ€‘group.                    |
| `contamination_rate`  | float (0â€“1) | `0.10`    | Fraction of points expected to be outliers; used to autoâ€‘tune threshold.       |
| `anomaly_threshold`   | float (0â€“1) | *derived* | Manual override â€“ score â‰¥ this â‡’ anomaly. Ignored if `contamination_rate` set. |
| `training_interval`   | duration    | `5m`      | Model is retrained no sooner than this interval.                               |
| `features`            | \[]string   | `[]`      | Resource/attribute keys that define **grouping**. Blank â‡’ single global model. |
| `metrics_to_analyze`  | \[]string   | `[]`      | Only these metric names are scored (metrics pipeline only). Blank â‡’ all.       |
| `add_anomaly_score`   | bool        | `false`   | Emit `iforest.anomaly_score` metric.                                           |
| `drop_anomalous_data` | bool        | `false`   | Remove anomalous items from the batch instead of forwarding.                   |
| `adaptive_window`     | object      | `null`    | Enables adaptive window sizing (see Adaptive Window section below).            |

### ğŸ”„ Adaptive Window Configuration

When enabled, the processor automatically adjusts window size based on traffic patterns and resource constraints:

| Field                      | Type     | Default | Notes                                                    |
| -------------------------- | -------- | ------- | -------------------------------------------------------- |
| `enabled`                  | bool     | `false` | Enable adaptive window sizing.                          |
| `min_window_size`          | int      | `1000`  | Minimum window size (safety bound).                     |
| `max_window_size`          | int      | `100000`| Maximum window size (memory protection).                |
| `memory_limit_mb`          | int      | `256`   | Shrink window when memory usage exceeds this limit.     |
| `adaptation_rate`          | float    | `0.1`   | Rate of window size changes (0.0-1.0).                  |
| `velocity_threshold`       | float    | `50.0`  | Samples/sec threshold for triggering window growth.     |
| `stability_check_interval` | duration | `5m`    | How often to evaluate model stability for expansion.    |

See the sample below for context.

---

## ğŸ“„ Sample `config.yml`

```yaml
receivers:
  otlp:
    protocols:
      grpc:            # â†’ listen on 0.0.0.0:4317

processors:
  isolationforest:
    # â”€â”€â”€ core algorithm parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    forest_size:        150          # trees per forest
    subsample_size:     512          # rows per tree
    contamination_rate: 0.05         # 5 % expected outliers
    threshold:          0.0          # 0 â‡’ let contamination_rate drive the cut-off
    mode:               both         # enrich + filter (see docstring)
    training_window:    24h          # window of data kept for training
    update_frequency:   5m           # retrain every 5 minutes
    min_samples:        1000         # wait until this many points seen

    # â”€â”€â”€ where to write results on each data point â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    score_attribute:          anomaly.isolation_score   # float 0â€“1
    classification_attribute: anomaly.is_anomaly        # bool

    # â”€â”€â”€ which numeric features the model should look at â”€â”€â”€â”€â”€â”€â”€â”€â”€
    features:
      traces:  [duration]           # span duration (Âµs / ns)
      metrics: [value]              # the sampleâ€™s numeric value
      logs:    [severity_number]    # log severity enum

    # â”€â”€â”€ performance guard-rails (optional) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    performance:
      max_memory_mb:     512
      batch_size:        1000
      parallel_workers:  4

exporters:
  prometheus:
    endpoint: "0.0.0.0:9464"   # Prom-server will scrape /metrics here
    send_timestamps: true      # (field is valid in the standard exporter)

service:
  pipelines:
    metrics:
      receivers:  [otlp]
      processors: [isolationforest]
      exporters:  [prometheus]

```

> Note: Use `routingconnector` to seggregate the different kind of spans(db, messaging etc.) and send them to separate `isolationforestprocessor` deployments so the anomaly detection is pertianing to the respective category of signals.
 
### What the example does

| Signal      | Whatâ€™s scored                                              | Feature grouping               | Output                                    | Notes                                                                                          |
| ----------- | ---------------------------------------------------------- | ------------------------------ | ----------------------------------------- | ------------------------------------------------------------------------------------------------ |
| **Traces**  | Span **duration** (ns)                                     | `service.name`, `k8s.pod.name` | `iforest.is_anomaly` attr + optional drop | Use a span/trace exporter to route anomalies.                                                    |
| **Metrics** | Only `system.cpu.utilization`, `system.memory.utilization` | Same                           | Attribute + score metric                  | The score appears as `iforest.anomaly_score` gauge.                                              |
| **Logs**    | Size of the log payload (bytes) by default                 | Same                           | Attribute flag                            | You can expose a numeric log attribute and configure the processor to use that via code changes. |

---

## ğŸš€ Best Practices

* **Tune `forest_size` vs. latency** â€“ start with 100 trees; raise to 200â€“300 if scores look noisy.
* **Use perâ€‘entity models** â€“ add `features` (service, pod, host) to avoid global comparisons across very different series.
* **Let contamination drive threshold** â€“ set `contamination_rate` to the % of traffic youâ€™re comfortable labelling outlier; avoid handâ€‘tuning `anomaly_threshold`.
* **Use adaptive window sizing** â€“ enable for dynamic workloads; the processor will automatically grow windows during high traffic and shrink under memory pressure.
* **Route anomalies** â€“ keep `drop_anomalous_data=false` and add a simple \[routingâ€‘processor] downstream to ship anomalies to a dedicated exporter or topic.
* **Monitor model health** â€“ the emitted `iforest.anomaly_score` metric is perfect for a Grafana panel; watch its distribution and adapt window / contamination accordingly.

---

## ğŸ—ï¸ Internals (Highâ€‘Level)

```text
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ IsolationForestProcessor (per Collector instance) â”‚
               â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
               â”‚  â€¢ Sliding window (per featureâ€‘group)             â”‚
               â”‚  â€¢ Forest of N trees (per featureâ€‘group)          â”‚
Telemetry â”€â”€â”€â–¶ â”‚  â€¢ Score calculator & anomaly decision            â”‚ â”€â”€â”€â–¶  Next processor/exporter
               â”‚  â€¢ Adaptive window sizing (optional)              â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


*Training cost*: **O(current_window_size Ã— forest_size Ã— log subsample_size)** every `training_interval`
*Scoring cost*: **O(forest_size Ã— log subsample_size)** per item

**Note:** With adaptive window sizing enabled, `current_window_size` dynamically adjusts between `min_window_size` and `max_window_size` based on traffic patterns and memory constraints, making training costs adaptive to workload conditions.


---

## ğŸ¤ Contributing

* **Bugs / Questions** â€“ please open an issue in the fork first.
* **Recently added**: Adaptive window sizing for dynamic traffic patterns.
* **Planned enhancements**

  * Multivariate scoring (multiple numeric attributes per point).
  * Expose Prometheus counters for training time / CPU cost.

PRs welcome â€“ please include unit tests and doc updates.

---

