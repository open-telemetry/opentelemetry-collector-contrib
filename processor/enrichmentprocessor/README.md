# Enrichment Processor

<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [alpha]: traces, metrics, logs   |
| Distributions | [contrib] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aopen%20label%3Aprocessor%2Fenrichment%20&label=open&color=orange&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aopen+is%3Aissue+label%3Aprocessor%2Fenrichment) [![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aclosed%20label%3Aprocessor%2Fenrichment%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aclosed+is%3Aissue+label%3Aprocessor%2Fenrichment) |
| Code coverage | [![codecov](https://codecov.io/github/open-telemetry/opentelemetry-collector-contrib/graph/main/badge.svg?component=processor_enrichment)](https://app.codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/tree/main/?components%5B0%5D=processor_enrichment&displayType=list) |
| [Code Owners](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/CONTRIBUTING.md#becoming-a-code-owner)    | [@sokoide](https://www.github.com/sokoide) |

[alpha]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/component-stability.md#alpha
[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib
<!-- end autogenerated section -->

The enrichment processor adds attributes to telemetry by looking up external metadata. It supports enriching:
- Resource attributes (context: "resource")
- Individual span/log/metric data point attributes (context: "individual")

Metadata can be provided via:
- File
- HTTP

Both HTTP and file sources are periodically refreshed.

Accepted data format for metadata is CSV/JSON.

CSV requires a header row and each row should contain same number of values.
JSON should be simple list of key value pairs like below:

**Service inventory data (JSON format):**
```json
[
	{
	  "service_name": "user-service",
	  "owner_team": "platform-team",
	  "environment": "production",
	  "region": "us-east-1"
	},
	{
	  "service_name": "payment-service",
	  "owner_team": "payments-team",
	  "environment": "production",
	  "region": "us-west-2"
	}
]
```

**Host metadata (CSV format):**
```csv
hostname,datacenter
web-01,dc1
web-02,dc2
db-01,dc1
```

## Configuration

```yaml
processors:
  enrichment:
    data_sources:
      - name: service_inventory
        type: http
        http:
          url: https://example.com/api/services
          headers: { }
          timeout: 30s
          refresh_interval: 5m
          format: json  # json|csv
      - name: host_metadata
        type: file
        file:
          path: /etc/collector/hosts.csv
          format: csv
          refresh_interval: 1m
    enrichment_rules:
      - name: enrich_individual_from_service
        context: individual
        data_source: service_inventory
        lookup_attributekey: service.name.      # attribute in telemetry
        lookup_field: service_name.             # field in data source
        mappings:
          - source_field: owner_team
            target_attribute: team.name
          - source_field: environment
            target_attribute: deployment.environment
          - source_field: region
            target_attribute: cloud.region
      - name: enrich_resource_from_host
        context: individual
        data_source: host_metadata
        lookup_attributekey: host.name
        lookup_field: hostname
        mappings:
          - source_field: datacenter
            target_attribute: host.datacenter
```

## Configuration options

- processors.enrichment
  - data_sources: List of external sources to read enrichment data from.
    - name: Unique identifier for this source. Required.
    - type: "http" or "file". Required.
    - http: Required when type=http.
      - url: Endpoint returning an array of JSON or csv objects. Required.
      - headers: Optional map of request headers.
      - timeout: Request timeout (e.g., 30s, 1m). Optional.
      - refresh_interval: How often to refetch data (e.g., 5m). Required for periodic refresh.
      - format: csv or json
    - file: Required when type=file.
      - path: Path to the file. Required.
      - format: "json" or "csv". Required.
      - refresh_interval: How often to reload the file (e.g., 1m). Required for periodic refresh.
  - enrichment_rules: List of rules describing how to map source fields to attributes.
    - name: Unique rule name. Required.
    - context: Where to apply the rule. One of "resource" or "individual". Required.
    - data_source: Name of a configured data source to query. Required.
    - lookup_attributekey: Attribute in telemetry used as the lookup key (e.g., service.name). Required.
    - lookup_field: Field name in the data source to match against (e.g., service_name). Required.
    - mappings: List of field mappings to apply. At least one required.
      - source_field: Field name in the data source row. Required.
      - target_attribute: Attribute to set on the telemetry. Required.

Behavior:
- If multiple rows share the same lookup_field value, the last one loaded wins.
- Empty values in the source row are skipped (no attribute is set).
- Each source is refreshed on its refresh_interval.
- Rule errors are logged; processing continues with other rules.

## Using in a pipeline

```yaml
service:
  pipelines:
    traces:
      processors: [enrichment]
    metrics:
      processors: [enrichment]
    logs:
      processors: [enrichment]
```

## Example: How metrics are enriched

Consider a metric with the following attributes before enrichment:
```yaml
# Input metric data point
attributes:
  service.name: "payment-service"
  http.method: "POST"
  host.name: web-01
value: 42
```

After applying the enrichment rules with the service inventory data, the metric becomes:
```yaml
# Enriched metric data point  
attributes:
  service.name: "payment-service"      # original
  http.method: "POST"                  # original
  team.name: "payments-team"           # enriched from service inventory
  deployment.environment: "production" # enriched from service inventory
  cloud.region: "us-west-2"           # enriched from service inventory
  host.name: web-01
  host.datacenter: dc1

value: 42
```

The processor looks up `service.name: "payment-service"` in the service inventory data source, finds the matching row, and adds the mapped attributes to the metric data point.

## Notes

- **Context types:**
  - `resource`: Enriches resource attributes that apply to all telemetry from that resource
  - `individual`: Enriches individual span, log record, or metric data point attributes
- **Data format requirements:**
  - JSON files/endpoints must return an array of objects
  - CSV files require a header row with consistent column counts per row
- **Refresh behavior:**
  - HTTP and file sources are periodically refreshed using `refresh_interval`
  - Data is cached in memory between refreshes for performance
- **Lookup behavior:**
  - When multiple rows share the same `lookup_field` value, the last one read wins
  - Empty values in source data are skipped (no attribute is set)
  - Failed lookups are logged but don't stop processing other rules
- **Error handling:**
  - Rule errors are logged and processing continues with remaining rules
  - Data source connection failures will retry on next refresh interval
