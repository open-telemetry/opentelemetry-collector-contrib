# Interval Processor

<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [alpha]: metrics   |
| Distributions | [contrib], [k8s] |
| Warnings      | [Statefulness](#warnings) |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aopen%20label%3Aprocessor%2Finterval%20&label=open&color=orange&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aopen+is%3Aissue+label%3Aprocessor%2Finterval) [![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aclosed%20label%3Aprocessor%2Finterval%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aclosed+is%3Aissue+label%3Aprocessor%2Finterval) |
| Code coverage | [![codecov](https://codecov.io/github/open-telemetry/opentelemetry-collector-contrib/graph/main/badge.svg?component=processor_interval)](https://app.codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/tree/main/?components%5B0%5D=processor_interval&displayType=list) |
| [Code Owners](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/CONTRIBUTING.md#becoming-a-code-owner)    | [@RichieSams](https://www.github.com/RichieSams) |
| Emeritus      | [@tombrk](https://www.github.com/tombrk) |

[alpha]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/component-stability.md#alpha
[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib
[k8s]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-k8s
<!-- end autogenerated section -->

## Description

The interval processor (`intervalprocessor`) aggregates metrics and periodically forwards the latest values to the next component in the pipeline. The processor supports aggregating the following metric types:

* Monotonically increasing, cumulative sums
* Monotonically increasing, cumulative histograms
* Monotonically increasing, cumulative exponential histograms
* Gauges 
* Summaries

The following metric types will *not* be aggregated, and will instead be passed, unchanged, to the next component in the pipeline:

* All delta metrics
* Non-monotonically increasing sums

> NOTE: Aggregating data over an interval is an inherently "lossy" process. For monotonically increasing, cumulative sums, histograms, and exponential histograms, you "lose" precision, but you don't lose overall data. But for non-monotonically increasing sums, gauges, and summaries, aggregation represents actual data loss. IE you could "lose" that a value increased and then decreased back to the original value. In most cases, this data "loss" is ok. However, if you would rather these values be passed through, and *not* aggregated, you can set that in the configuration

## Configuration

The following settings can be optionally configured:

```yaml
interval:
  # The interval in which the processor should export the aggregated metrics. 
  [ interval: <duration> | default = 60s ]
  
  pass_through:
    # Whether gauges should be aggregated or passed through to the next component as they are
    [ gauge: <bool> | default = false ]
    # Whether summaries should be aggregated or passed through to the next component as they are
    [ summary: <bool> | default = false ]

  # Aggregate gauge or counter (Sum) metrics into histograms over the interval
  aggregate_to_histogram:
    # The name of the source metric to aggregate (exact match)
    - metric_name: <string>
      # The name of the resulting histogram metric. Defaults to "<metric_name>_histogram" if not specified
      [ output_name: <string> ]
      # Type of histogram to produce: "explicit" or "exponential". Defaults to "explicit"
      [ histogram_type: <string> | default = "explicit" ]
      # For explicit histograms: bucket boundaries (must be sorted in ascending order)
      # Required when histogram_type is "explicit", ignored for "exponential"
      [ buckets: [<float>, ...] ]
      # For exponential histograms: maximum number of buckets. Defaults to 160
      # Only used when histogram_type is "exponential"
      [ max_size: <int32> | default = 160 ]
```

## Example of metric flows

The following sum metrics come into the processor to be handled

| Timestamp | Metric Name  | Aggregation Temporality | Attributes        | Value |
| --------- | ------------ | ----------------------- | ----------------- | ----: |
| 0         | test_metric  | Cumulative              | labelA: foo       |   4.0 |
| 2         | test_metric  | Cumulative              | labelA: bar       |   3.1 |
| 4         | other_metric | Delta                   | fruitType: orange |  77.4 |
| 6         | test_metric  | Cumulative              | labelA: foo       |   8.2 |
| 8         | test_metric  | Cumulative              | labelA: foo       |  12.8 |
| 10        | test_metric  | Cumulative              | labelA: bar       |   6.4 |

The processor would immediately pass the following metrics to the next processor in the chain

| Timestamp | Metric Name  | Aggregation Temporality | Attributes        | Value |
| --------- | ------------ | ----------------------- | ----------------- | ----: |
| 4         | other_metric | Delta                   | fruitType: orange |  77.4 |

Because it's a Delta metric.

At the next `interval` (15s by default), the processor would pass the following metrics to the next processor in the chain

| Timestamp | Metric Name | Aggregation Temporality | Attributes  | Value |
| --------- | ----------- | ----------------------- | ----------- | ----: |
| 8         | test_metric | Cumulative              | labelA: foo |  12.8 |
| 10        | test_metric | Cumulative              | labelA: bar |   6.4 |

> [!IMPORTANT]
> After exporting, any internal state is cleared. So if no new metrics come in, the next interval will export nothing.

## Aggregating Gauges or Counters to Histograms

The processor can aggregate gauge or counter (Sum) metrics into histograms over the configured interval. This is useful when you have a stream of individual measurements and want to compute histogram distributions.

Two histogram types are supported:
- **Explicit bucket histograms**: You define the bucket boundaries
- **Exponential histograms**: Bucket boundaries are automatically determined using a logarithmic scale

### Example Configuration

```yaml
processors:
  interval:
    interval: 60s
    aggregate_to_histogram:
      # Explicit bucket histogram
      - metric_name: response.latency
        output_name: response.latency.distribution
        histogram_type: explicit
        buckets: [10, 25, 50, 100, 250, 500, 1000]
      # Exponential histogram (automatic bucket boundaries)
      - metric_name: request.duration
        histogram_type: exponential
        max_size: 160
      # Default is explicit histogram
      - metric_name: request.size
        buckets: [100, 500, 1000, 5000, 10000]
```

### How it Works

1. When a gauge or counter metric matches a configured `metric_name`, all data points are collected during the interval
2. At each interval, the collected values are aggregated into a histogram
3. The resulting histogram has:
   - Delta aggregation temporality
   - Count, sum, min, and max statistics
   - Bucket structure based on the configured type
   - All original attributes preserved

### Explicit Bucket Histogram Example

Given the following gauge metrics arriving during an interval:

| Timestamp | Metric Name      | Value  | Attributes      |
| --------- | ---------------- | -----: | --------------- |
| 10        | response.latency |    5.5 | endpoint: /api  |
| 20        | response.latency |   15.2 | endpoint: /api  |
| 30        | response.latency |   25.8 | endpoint: /api  |
| 40        | response.latency |  150.0 | endpoint: /api  |
| 50        | response.latency |    8.3 | endpoint: /api  |

With buckets configured as `[10, 25, 50, 100]`, the processor outputs a histogram:

| Metric Name                      | Bucket Bounds    | Bucket Counts   | Sum   | Count | Min | Max |
| -------------------------------- | ---------------- | --------------- | ----: | ----: | --: | --: |
| response.latency_histogram       | [10, 25, 50, 100]| [2, 1, 1, 0, 1] | 204.8 |     5 | 5.5 | 150 |

Where bucket counts represent: `[≤10, ≤25, ≤50, ≤100, >100]`

### Exponential Histogram

Exponential histograms use a logarithmic scale where bucket boundaries are automatically determined based on the data. This provides:
- Better resolution for values close to zero
- Automatic adaptation to the data range
- More efficient storage for high-cardinality data

```yaml
aggregate_to_histogram:
  - metric_name: request.duration
    histogram_type: exponential
    max_size: 160  # Maximum number of buckets (default: 160)
```

The exponential histogram will automatically:
- Handle both positive and negative values
- Track zero-count separately
- Adjust the scale based on the data range
